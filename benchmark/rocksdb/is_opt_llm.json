[
    {
        "hash": "e48ccc28f4eebcc05b6333b129ee5908214d3259",
        "author": "Peter Dillinger",
        "date": "2025-01-02T10:48:46-08:00",
        "message": "Reduce unnecessary manifest data when no file checksum (#13250)\n\nSummary:\nDon't write file checksum manifest entries when unused, to avoid using extra manifest file space.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/13250\n\nTest Plan: very minor performance improvement, existing tests\n\nReviewed By: cbi42\n\nDifferential Revision: D67653954\n\nPulled By: pdillinger\n\nfbshipit-source-id: 9156e093ed5e4a5152cc55354a4beea9a841b89f",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_edit.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e48ccc28f4eebcc05b6333b129ee5908214d3259",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionEdit::EncodeTo"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "d386385e0bb7a17564493b3a2f5eed0f2356e05e",
        "author": "Andrew Chang",
        "date": "2024-12-09T13:24:16-08:00",
        "message": "Temporarily disable file system buffer reuse optimization for compaction prefetches (#13177)\n\nSummary:\nhttps://github.com/facebook/rocksdb/issues/13182 successfully fixed the heap `use-after-free` issue.\n\nHowever, there was one additional error I found while looking through the warm storage crash test logs. There are repeated (though infrequent) unsigned pointer arithmetic overflow errors that look like this:\n```cpp\nfile_prefetch_buffer.cc:860:46: runtime error: addition of unsigned offset to 0x7f282001880f overflowed to 0x7f2820017667\n```\n\nIt took me a while to figure it out, but I was finally able to reproduce the issue locally. It turns out the issue is when we call `TryReadFromCache` with `for_compaction` set to `true`. The default value for `for_compaction` is `false`, and this was not covered in the unit tests written for https://github.com/facebook/rocksdb/issues/13118.\n\nWhen I run the same unit tests with `for_compaction` set to `true`, I am able to break this assertion that I added at the end of `TryReadFromCacheUntracked`:\n```cpp\nassert(buf->offset_ <= offset);\n```\n\nIf `buf->offset_` is greater than `offset`, then that explains the overflow we get in the following lines:\n```cpp\nuint64_t offset_in_buffer = offset - buf->offset_;\n*result = Slice(buf->buffer_.BufferStart() + offset_in_buffer, n);\n```\n\nI will have another PR out that fixes the issue and enables the optimization when `for_compaction` is set to `true`. I will need to add some overlap buffer logic, similar to what I have inside `PrefetchInternal`. For now, since I have confirmed that there is indeed a bug, we should disable the optimization where needed. It will take me some time to implement the fix and write new test cases.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/13177\n\nTest Plan: I kept the existing unit tests which test the file system buffer reuse code when `for_compaction` is `false`. I expect that the warm storage crash test logs will no longer show the integer overflow issue once we merge this PR.\n\nReviewed By: anand1976\n\nDifferential Revision: D66721857\n\nPulled By: archang19\n\nfbshipit-source-id: 22d523646f969a7a0ccbbea73f63c32601f1179a",
        "modified_files_count": 1,
        "modified_files": [
            "file/file_prefetch_buffer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d386385e0bb7a17564493b3a2f5eed0f2356e05e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FilePrefetchBuffer::Prefetch"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "632746bb5b8d9d817b0075b295e1a085e1e543a4",
        "author": "Hui Xiao",
        "date": "2024-10-09T12:51:19-07:00",
        "message": "Improve DBTest.DynamicLevelCompressionPerLevel (#13044)\n\nSummary:\n**Context/Summary:**\n\nA part of this test is to verify compression conditionally happens depending on the shape of the LSM when `options.level_compaction_dynamic_level_bytes = true;`. It uses the total file size to determine whether compression has happened or not. This involves some hard-coded math hard to understand. This PR replaces those with statistics that directly shows whether compression has happened or not.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/13044\n\nTest Plan: Existing test\n\nReviewed By: jaykorean\n\nDifferential Revision: D63666361\n\nPulled By: hx235\n\nfbshipit-source-id: 8c9b1bea9b06ff1e3ed95c576aec6705159af137",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/632746bb5b8d9d817b0075b295e1a085e1e543a4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "92ad4a88f3199b013532b37d6598c442319355a5",
        "author": "Changyu Bi",
        "date": "2024-08-27T13:57:40-07:00",
        "message": "Small CPU optimization in InlineSkipList::Insert() (#12975)\n\nSummary:\nreuse decode key in more places to avoid decoding length prefixed key x->Key().\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12975\n\nTest Plan:\nran benchmarks simultaneously for \"before\" and \"after\"\n* fillseq:\n```\n(for I in $(seq 1 50); do ./db_bench --benchmarks=fillseq --disable_auto_compactions=1 --min_write_buffer_number_to_merge=100 --max_write_buffer_number=1000  --write_buffer_size=268435456 --num=5000000 --seed=1723056275 --disable_wal=1 2>&1 | grep \"fillseq\"\ndone;) | awk '{ t += $5; c++; print } END { printf (\"%9.3f\\n\", 1.0 * t / c) }';\n\nbefore: 1483191\nafter: 1490555 (+0.5%)\n```\n\n* fillrandom:\n```\n(for I in $(seq 1 2); do ./db_bench_imain --benchmarks=fillrandom --disable_auto_compactions=1 --min_write_buffer_number_to_merge=100 --max_write_buffer_number=1000  --write_buffer_size=268435456 --num=2500000 --seed=1723056275 --disable_wal=1 2>&1 | grep \"fillrandom\"\n\nbefore: 255463\nafter: 256128 (+0.26%)\n```\n\nReviewed By: anand1976\n\nDifferential Revision: D61835340\n\nPulled By: cbi42\n\nfbshipit-source-id: 70345510720e348bacd51269acb5d2dd5a62bf0a",
        "modified_files_count": 1,
        "modified_files": [
            "memtable/inlineskiplist.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/92ad4a88f3199b013532b37d6598c442319355a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "compare_"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "5c456c4c08ac046429c38792d242dd095c50b049",
        "author": "SGZW",
        "date": "2024-08-09T15:05:02-07:00",
        "message": "fix compaction speedup for marked files ut (#12912)\n\nSummary: Pull Request resolved: https://github.com/facebook/rocksdb/pull/12912\n\nReviewed By: hx235\n\nDifferential Revision: D60973460\n\nPulled By: cbi42\n\nfbshipit-source-id: ebaa343757f09f7281884a512ebe3a7d6845c8b3",
        "modified_files_count": 1,
        "modified_files": [
            "db/column_family_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/5c456c4c08ac046429c38792d242dd095c50b049",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_P"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "16c21afc061bffba8ec1a518273080e1d59e3d96",
        "author": "Hui Xiao",
        "date": "2024-08-08T15:37:19-07:00",
        "message": "Fix failure to clean the temporary directory due to NotFound in crash test checkpoint creation (#12919)\n\nSummary:\n**Context/Summary:**\nhttps://github.com/facebook/rocksdb/commit/b26b395e0a15255d322be08110db551976188745 propagates `CleanStagingDirectory()` status to `CreateCheckpoint()`.  However, we didn't return early when `Status s = db_->GetEnv()->FileExists(full_private_path);` return non-NotFound non-ok stratus in `CleanStagingDirectory()`. Therefore we can proceed to the next step when `full_private_path` doesn't exist.\n```\nVerification failed: Checkpoint failed: Operation aborted: Failed to clean the temporary directory /dev/shm/rocksdb.J4Su/rocksdb_crashtest_blackbox/.checkpoint28.tmp needed before checkpoint creation : NotFound:\n\ndb_stress: db_stress_tool/db_stress_test_base.cc:549: void rocksdb::StressTest::ProcessStatus(rocksdb::SharedState*, std::string, const rocksdb::Status&, bool) const: Assertion `false' failed.\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12919\n\nTest Plan:\nBelow failed before the fix and passes after\n\n```\n./db_stress --WAL_size_limit_MB=1 --WAL_ttl_seconds=0 --acquire_snapshot_one_in=100 --adaptive_readahead=1 --adm_policy=1 --advise_random_on_open=0 --allow_data_in_errors=True --allow_fallocate=1 --async_io=1 --auto_readahead_size=0 --avoid_flush_during_recovery=1 --avoid_flush_during_shutdown=0 --avoid_unnecessary_blocking_io=1 --backup_max_size=104857600 --backup_one_in=100000 --batch_protection_bytes_per_key=8 --bgerror_resume_retry_interval=1000000 --block_align=0 --block_protection_bytes_per_key=4 --block_size=16384 --bloom_before_level=2 --bloom_bits=4 --bottommost_compression_type=snappy --bottommost_file_compaction_delay=0 --bytes_per_sync=0 --cache_index_and_filter_blocks=1 --cache_index_and_filter_blocks_with_high_priority=0 --cache_size=8388608 --cache_type=auto_hyper_clock_cache --charge_compression_dictionary_building_buffer=0 --charge_file_metadata=1 --charge_filter_construction=1 --charge_table_reader=1 --check_multiget_consistency=0 --check_multiget_entity_consistency=0 --checkpoint_one_in=10000 --checksum_type=kxxHash64 --clear_column_family_one_in=0 --compact_files_one_in=1000 --compact_range_one_in=1000000 --compaction_pri=3 --compaction_readahead_size=1048576 --compaction_ttl=0 --compress_format_version=2 --compressed_secondary_cache_ratio=0.0 --compressed_secondary_cache_size=0 --compression_checksum=0 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=1 --compression_type=none --compression_use_zstd_dict_trainer=0 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --daily_offpeak_time_utc= --data_block_index_type=0 --db=/dev/shm/rocksdb.J4Su/rocksdb_crashtest_blackbox --db_write_buffer_size=134217728 --default_temperature=kUnknown --default_write_temperature=kHot --delete_obsolete_files_period_micros=21600000000 --delpercent=4 --delrangepercent=1 --destroy_db_initially=0 --detect_filter_construct_corruption=0 --disable_file_deletions_one_in=1000000 --disable_manual_compaction_one_in=10000 --disable_wal=0 --dump_malloc_stats=0 --enable_checksum_handoff=0 --enable_compaction_filter=0 --enable_custom_split_merge=0 --enable_do_not_compress_roles=1 --enable_index_compression=1 --enable_memtable_insert_with_hint_prefix_extractor=0 --enable_pipelined_write=0 --enable_sst_partitioner_factory=0 --enable_thread_tracking=0 --enable_write_thread_adaptive_yield=1 --error_recovery_with_no_fault_injection=1 --exclude_wal_from_write_fault_injection=0 --expected_values_dir=/dev/shm/rocksdb.J4Su/rocksdb_crashtest_expected --fail_if_options_file_error=1 --fifo_allow_compaction=1 --file_checksum_impl=xxh64 --fill_cache=1 --flush_one_in=1000000 --format_version=6 --get_all_column_family_metadata_one_in=1000000 --get_current_wal_file_one_in=0 --get_live_files_apis_one_in=1000000 --get_properties_of_all_tables_one_in=1000000 --get_property_one_in=1000000 --get_sorted_wal_files_one_in=0 --hard_pending_compaction_bytes_limit=274877906944 --high_pri_pool_ratio=0.5 --index_block_restart_interval=13 --index_shortening=0 --index_type=3 --ingest_external_file_one_in=0 --initial_auto_readahead_size=16384 --inplace_update_support=0 --iterpercent=10 --key_len_percent_dist=1,30,69 --key_may_exist_one_in=100000 --last_level_temperature=kWarm --level_compaction_dynamic_level_bytes=1 --lock_wal_one_in=1000000 --log_file_time_to_roll=0 --log_readahead_size=0 --long_running_snapshots=0 --low_pri_pool_ratio=0 --lowest_used_cache_tier=0 --manifest_preallocation_size=5120 --manual_wal_flush_one_in=1000 --mark_for_compaction_one_file_in=10 --max_auto_readahead_size=16384 --max_background_compactions=20 --max_bytes_for_level_base=10485760 --max_key=2500000 --max_key_len=3 --max_log_file_size=0 --max_manifest_file_size=1073741824 --max_sequential_skip_in_iterations=8 --max_total_wal_size=0 --max_write_batch_group_size_bytes=16 --max_write_buffer_number=10 --max_write_buffer_size_to_maintain=0 --memtable_insert_hint_per_batch=0 --memtable_max_range_deletions=100 --memtable_prefix_bloom_size_ratio=0.1 --memtable_protection_bytes_per_key=4 --memtable_whole_key_filtering=0 --memtablerep=skip_list --metadata_charge_policy=1 --metadata_read_fault_one_in=32 --metadata_write_fault_one_in=128 --min_write_buffer_number_to_merge=2 --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --num_file_reads_for_auto_readahead=2 --open_files=500000 --open_metadata_read_fault_one_in=8 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=0 --open_write_fault_one_in=16 --ops_per_thread=100000000 --optimize_filters_for_hits=0 --optimize_filters_for_memory=1 --optimize_multiget_for_io=0 --paranoid_file_checks=1 --partition_filters=0 --partition_pinning=0 --pause_background_one_in=10000 --periodic_compaction_seconds=0 --prefix_size=7 --prefixpercent=5 --prepopulate_block_cache=1 --preserve_internal_time_seconds=36000 --progress_reports=0 --promote_l0_one_in=0 --read_amp_bytes_per_bit=0 --read_fault_one_in=0 --readahead_size=0 --readpercent=45 --recycle_log_file_num=1 --reopen=0 --report_bg_io_stats=0 --reset_stats_one_in=10000 --sample_for_compression=5 --secondary_cache_fault_one_in=32 --set_options_one_in=10000 --skip_stats_update_on_db_open=1 --snapshot_hold_ops=100000 --soft_pending_compaction_bytes_limit=68719476736 --sqfc_name=foo --sqfc_version=0 --sst_file_manager_bytes_per_sec=104857600 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=600 --stats_history_buffer_size=1048576 --strict_bytes_per_sync=1 --subcompactions=3 --sync=0 --sync_fault_injection=0 --table_cache_numshardbits=6 --target_file_size_base=524288 --target_file_size_multiplier=2 --test_batches_snapshots=0 --test_cf_consistency=1 --top_level_index_pinning=1 --uncache_aggressiveness=0 --universal_max_read_amp=0 --unpartitioned_pinning=0 --use_adaptive_mutex=0 --use_adaptive_mutex_lru=1 --use_attribute_group=0 --use_delta_encoding=1 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=0 --use_get_entity=1 --use_merge=0 --use_multi_cf_iterator=0 --use_multi_get_entity=0 --use_multiget=0 --use_put_entity_one_in=0 --use_sqfc_for_range_queries=1 --use_timed_put_one_in=1 --use_write_buffer_manager=1 --user_timestamp_size=0 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000 --verify_compression=1 --verify_db_one_in=100000 --verify_file_checksums_one_in=1000 --verify_iterator_with_expected_state_one_in=0 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=0 --wal_compression=none --write_buffer_size=1048576 --write_dbid_to_manifest=0 --write_fault_one_in=128 --writepercent=35\n```\n\nReviewed By: cbi42\n\nDifferential Revision: D60938952\n\nPulled By: hx235\n\nfbshipit-source-id: 5696cd6b00f33c9f9a256944fecb4e2f4d52a2e6",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/checkpoint/checkpoint_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/16c21afc061bffba8ec1a518273080e1d59e3d96",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CheckpointImpl::CleanStagingDirectory"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "5e203c76a2b3be439705770e5ebbc8415b1dadf6",
        "author": "Hui Xiao",
        "date": "2024-08-02T10:45:34-07:00",
        "message": "SyncWAL() before Close() when FLAGS_avoid_flush_during_shutdown=true in crash test (#12900)\n\nSummary:\n**Context/Summary:**\nWhen we use WAL and don't flush data during shutdown `FLAGS_avoid_flush_during_shutdown=true`, then we rely on WAL to recover data in next Open() so will need to sync WAL in crash test. Currently the condition is flipped.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12900\n\nTest Plan:\nBelow fails with data loss `Verification failed. Expected state has key 000000000000015D000000000000012B0000000000000147, iterator is at key 000000000000015D000000000000012B0000000000000152` before the fix but not after the fix\n```\n./db_stress --WAL_size_limit_MB=0 --WAL_ttl_seconds=0 --acquire_snapshot_one_in=10000 --adaptive_readahead=1 --adm_policy=3 --advise_random_on_open=1 --allow_concurrent_memtable_write=0 --allow_data_in_errors=True --allow_fallocate=1 --async_io=1 --auto_readahead_size=1 --avoid_flush_during_recovery=0 --avoid_flush_during_shutdown=1 --avoid_unnecessary_blocking_io=0 --backup_max_size=104857600 --backup_one_in=1000 --batch_protection_bytes_per_key=8 --bgerror_resume_retry_interval=100 --block_align=0 --block_protection_bytes_per_key=4 --block_size=16384 --bloom_before_level=0 --bloom_bits=10 --bottommost_compression_type=disable --bottommost_file_compaction_delay=3600 --bytes_per_sync=262144 --cache_index_and_filter_blocks=1 --cache_index_and_filter_blocks_with_high_priority=0 --cache_size=33554432 --cache_type=tiered_auto_hyper_clock_cache --charge_compression_dictionary_building_buffer=1 --charge_file_metadata=0 --charge_filter_construction=0 --charge_table_reader=0 --check_multiget_consistency=0 --check_multiget_entity_consistency=0 --checkpoint_one_in=1000000 --checksum_type=kxxHash64 --clear_column_family_one_in=0 --column_families=1 --compact_files_one_in=1000000 --compact_range_one_in=1000000 --compaction_pri=3 --compaction_readahead_size=0 --compaction_style=1 --compaction_ttl=0 --compress_format_version=1 --compressed_secondary_cache_ratio=0.3333333333333333 --compressed_secondary_cache_size=0 --compression_checksum=1 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=8 --compression_type=zlib --compression_use_zstd_dict_trainer=0 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --daily_offpeak_time_utc= --data_block_index_type=1 --db=/dev/shm/rocksdb_test/rocksdb_crashtest_whitebox_2 --db_write_buffer_size=0 --default_temperature=kUnknown --default_write_temperature=kWarm --delete_obsolete_files_period_micros=30000000 --delpercent=4 --delrangepercent=1 --destroy_db_initially=1 --detect_filter_construct_corruption=0 --disable_file_deletions_one_in=1000000 --disable_manual_compaction_one_in=10000 --disable_wal=0 --dump_malloc_stats=0 --enable_checksum_handoff=0 --enable_compaction_filter=0 --enable_custom_split_merge=0 --enable_do_not_compress_roles=0 --enable_index_compression=1 --enable_memtable_insert_with_hint_prefix_extractor=0 --enable_pipelined_write=0 --enable_sst_partitioner_factory=0 --enable_thread_tracking=1 --enable_write_thread_adaptive_yield=1 --error_recovery_with_no_fault_injection=0 --exclude_wal_from_write_fault_injection=1 --expected_values_dir=/dev/shm/rocksdb_test/rocksdb_crashtest_expected_2 --fail_if_options_file_error=1 --fifo_allow_compaction=1 --file_checksum_impl=none --fill_cache=0 --flush_one_in=1000000 --format_version=5 --get_all_column_family_metadata_one_in=1000000 --get_current_wal_file_one_in=0 --get_live_files_apis_one_in=10000 --get_properties_of_all_tables_one_in=100000 --get_property_one_in=1000000 --get_sorted_wal_files_one_in=0 --hard_pending_compaction_bytes_limit=274877906944 --high_pri_pool_ratio=0.5 --index_block_restart_interval=13 --index_shortening=1 --index_type=2 --ingest_external_file_one_in=0 --initial_auto_readahead_size=524288 --inplace_update_support=0 --iterpercent=10 --key_len_percent_dist=1,30,69 --key_may_exist_one_in=100000 --last_level_temperature=kHot --level_compaction_dynamic_level_bytes=0 --lock_wal_one_in=10000 --log2_keys_per_lock=10 --log_file_time_to_roll=60 --log_readahead_size=16777216 --long_running_snapshots=0 --low_pri_pool_ratio=0.5 --lowest_used_cache_tier=0 --manifest_preallocation_size=0 --manual_wal_flush_one_in=0 --mark_for_compaction_one_file_in=0 --max_auto_readahead_size=0 --max_background_compactions=1 --max_bytes_for_level_base=67108864 --max_key=100000 --max_key_len=3 --max_log_file_size=1048576 --max_manifest_file_size=1073741824 --max_sequential_skip_in_iterations=16 --max_total_wal_size=0 --max_write_batch_group_size_bytes=16 --max_write_buffer_number=3 --max_write_buffer_size_to_maintain=8388608 --memtable_insert_hint_per_batch=0 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0.01 --memtable_protection_bytes_per_key=4 --memtable_whole_key_filtering=1 --memtablerep=skip_list --metadata_charge_policy=1 --metadata_read_fault_one_in=0 --metadata_write_fault_one_in=0 --min_write_buffer_number_to_merge=1 --mmap_read=0 --mock_direct_io=True --nooverwritepercent=1 --num_file_reads_for_auto_readahead=2 --open_files=100 --open_metadata_read_fault_one_in=0 --open_metadata_write_fault_one_in=8 --open_read_fault_one_in=0 --open_write_fault_one_in=0 --ops_per_thread=200000 --optimize_filters_for_hits=1 --optimize_filters_for_memory=1 --optimize_multiget_for_io=0 --paranoid_file_checks=0 --partition_filters=0 --partition_pinning=1 --pause_background_one_in=1000000 --periodic_compaction_seconds=0 --prefix_size=1 --prefixpercent=5 --prepopulate_block_cache=0 --preserve_internal_time_seconds=0 --progress_reports=0 --promote_l0_one_in=0 --read_amp_bytes_per_bit=0 --read_fault_one_in=0 --readahead_size=16384 --readpercent=45 --recycle_log_file_num=1 --reopen=20 --report_bg_io_stats=1 --reset_stats_one_in=1000000 --sample_for_compression=0 --secondary_cache_fault_one_in=32 --secondary_cache_uri= --skip_stats_update_on_db_open=1 --snapshot_hold_ops=100000 --soft_pending_compaction_bytes_limit=68719476736 --sqfc_name=foo --sqfc_version=2 --sst_file_manager_bytes_per_sec=104857600 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=0 --stats_history_buffer_size=0 --strict_bytes_per_sync=1 --subcompactions=3 --sync=0 --sync_fault_injection=1 --table_cache_numshardbits=6 --target_file_size_base=16777216 --target_file_size_multiplier=1 --test_batches_snapshots=0 --top_level_index_pinning=0 --uncache_aggressiveness=4404 --universal_max_read_amp=-1 --unpartitioned_pinning=2 --use_adaptive_mutex=0 --use_adaptive_mutex_lru=1 --use_attribute_group=0 --use_delta_encoding=1 --use_direct_io_for_flush_and_compaction=1 --use_direct_reads=1 --use_full_merge_v1=1 --use_get_entity=0 --use_merge=0 --use_multi_cf_iterator=1 --use_multi_get_entity=0 --use_multiget=1 --use_put_entity_one_in=0 --use_sqfc_for_range_queries=1 --use_timed_put_one_in=0 --use_write_buffer_manager=0 --user_timestamp_size=0 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000 --verify_compression=1 --verify_db_one_in=10000 --verify_file_checksums_one_in=0 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=0 --wal_compression=none --write_buffer_size=33554432 --write_dbid_to_manifest=1 --write_fault_one_in=0 --writepercent=35\n\n```\n\nReviewed By: anand1976, ltamasi\n\nDifferential Revision: D60489038\n\nPulled By: hx235\n\nfbshipit-source-id: fb35889ae1509eb1bac27b015bb24a07d3b95268",
        "modified_files_count": 1,
        "modified_files": [
            "db_stress_tool/db_stress_test_base.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/5e203c76a2b3be439705770e5ebbc8415b1dadf6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "StressTest::Reopen"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "9883b5f497a6c451065595c8c668728cfa5b8f59",
        "author": "Yu Zhang",
        "date": "2024-07-24T17:50:08-07:00",
        "message": "Fix manifest_number_ point to invalid file (#12882)\n\nSummary:\nThis PR fix `VersionSet`'s `manifest_number_` could be pointing to an invalid number intermediately. This happens when a new manifest roll is attempted but fast failed after loading table handlers and before the new manifest file creation/writing is actually attempted.\n\nIn theory, a later manifest roll effort will overthrow this intermediate invalid in memory state. There is on harm when the DB crashes in this invalid state either. But efforts that takes a file snapshot of the DB like backup will incorrectly try to copy a non existing manifest file.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12882\n\nReviewed By: cbi42\n\nDifferential Revision: D60204956\n\nPulled By: jowlyzhang\n\nfbshipit-source-id: effbdb124b582f879d114988af06ac63867fc549",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_set.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/9883b5f497a6c451065595c8c668728cfa5b8f59",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionSet::ProcessManifestWrites"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "21db55f8164d2a6519dcc993f74bf7f49c700854",
        "author": "Hui Xiao",
        "date": "2024-07-17T13:39:14-07:00",
        "message": "Move WAL sync before memtable insertion (#12869)\n\nSummary:\n**Context/Summary:**\nWAL sync currently happens after memtable write. This causes inconvenience in stress test as we can't simply rollback the ExpectedState when write fails due to injected WAL sync error so something complicated like https://github.com/facebook/rocksdb/pull/12838 might be needed. After moving WAL sync before memtable insertion, there should not be injected IO error after memtable insertion so we can keep the current simple way of handling failed write in stress test with ExpectedState rollback.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12869\n\nTest Plan:\n1. Below command failed with `iterator has key 0000000000000207000000000000012B0000000000000013, but expected state does not.` before this PR and passes after\n```\n./db_stress  --WAL_size_limit_MB=0 --WAL_ttl_seconds=0 --acquire_snapshot_one_in=10000 --adaptive_readahead=1 --adm_policy=1 --advise_random_on_open=0 --allow_concurrent_memtable_write=0 --allow_data_in_errors=True --allow_fallocate=0 --async_io=0 --auto_readahead_size=0 --avoid_flush_during_recovery=0 --avoid_flush_during_shutdown=0 --avoid_unnecessary_blocking_io=0 --backup_max_size=104857600 --backup_one_in=0 --batch_protection_bytes_per_key=0 --bgerror_resume_retry_interval=1000000 --block_align=1 --block_protection_bytes_per_key=4 --block_size=16384 --bloom_before_level=4 --bloom_bits=56.810257702625165 --bottommost_compression_type=none --bottommost_file_compaction_delay=0 --bytes_per_sync=262144 --cache_index_and_filter_blocks=1 --cache_index_and_filter_blocks_with_high_priority=1 --cache_size=8388608 --cache_type=auto_hyper_clock_cache --charge_compression_dictionary_building_buffer=1 --charge_file_metadata=1 --charge_filter_construction=1 --charge_table_reader=0 --check_multiget_consistency=0 --check_multiget_entity_consistency=1 --checkpoint_one_in=10000 --checksum_type=kxxHash --clear_column_family_one_in=0 --column_families=1 --compact_files_one_in=1000 --compact_range_one_in=1000 --compaction_pri=4 --compaction_readahead_size=1048576 --compaction_ttl=10 --compress_format_version=1 --compressed_secondary_cache_ratio=0.0 --compressed_secondary_cache_size=0 --compression_checksum=0 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=1 --compression_type=none --compression_use_zstd_dict_trainer=0 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --daily_offpeak_time_utc=04:00-08:00 --data_block_index_type=1 --db=/dev/shm/rocksdb_test/rocksdb_crashtest_blackbox --db_write_buffer_size=0 --default_temperature=kWarm --default_write_temperature=kCold --delete_obsolete_files_period_micros=30000000 --delpercent=0 --delrangepercent=0 --destroy_db_initially=0 --detect_filter_construct_corruption=0 --disable_file_deletions_one_in=10000 --disable_manual_compaction_one_in=1000000 --disable_wal=0 --dump_malloc_stats=0 --enable_checksum_handoff=1 --enable_compaction_filter=0 --enable_custom_split_merge=0 --enable_do_not_compress_roles=0 --enable_index_compression=1 --enable_memtable_insert_with_hint_prefix_extractor=0 --enable_pipelined_write=0 --enable_sst_partitioner_factory=0 --enable_thread_tracking=0 --enable_write_thread_adaptive_yield=0 --error_recovery_with_no_fault_injection=1 --exclude_wal_from_write_fault_injection=1 --expected_values_dir=/dev/shm/rocksdb_test/rocksdb_crashtest_expected --fail_if_options_file_error=1 --fifo_allow_compaction=0 --file_checksum_impl=crc32c --fill_cache=1 --flush_one_in=1000000 --format_version=3 --get_all_column_family_metadata_one_in=1000000 --get_current_wal_file_one_in=0 --get_live_files_apis_one_in=1000000 --get_properties_of_all_tables_one_in=1000000 --get_property_one_in=100000 --get_sorted_wal_files_one_in=0 --hard_pending_compaction_bytes_limit=274877906944 --high_pri_pool_ratio=0.5 --index_block_restart_interval=4 --index_shortening=2 --index_type=0 --ingest_external_file_one_in=0 --initial_auto_readahead_size=16384 --inplace_update_support=0 --iterpercent=50 --key_len_percent_dist=1,30,69 --key_may_exist_one_in=100 --last_level_temperature=kWarm --level_compaction_dynamic_level_bytes=1 --lock_wal_one_in=10000 --log_file_time_to_roll=60 --log_readahead_size=16777216 --long_running_snapshots=1 --low_pri_pool_ratio=0 --lowest_used_cache_tier=0 --manifest_preallocation_size=0 --manual_wal_flush_one_in=0 --mark_for_compaction_one_file_in=10 --max_auto_readahead_size=16384 --max_background_compactions=1 --max_bytes_for_level_base=67108864 --max_key=100000 --max_key_len=3 --max_log_file_size=1048576 --max_manifest_file_size=32768 --max_sequential_skip_in_iterations=1 --max_total_wal_size=0 --max_write_batch_group_size_bytes=16 --max_write_buffer_number=10 --max_write_buffer_size_to_maintain=8388608 --memtable_insert_hint_per_batch=1 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0.01 --memtable_protection_bytes_per_key=1 --memtable_whole_key_filtering=1 --memtablerep=skip_list --metadata_charge_policy=1 --metadata_read_fault_one_in=32 --metadata_write_fault_one_in=0 --min_write_buffer_number_to_merge=1 --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --num_file_reads_for_auto_readahead=1 --open_files=-1 --open_metadata_read_fault_one_in=0 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=0 --open_write_fault_one_in=0 --ops_per_thread=100000000 --optimize_filters_for_hits=1 --optimize_filters_for_memory=1 --optimize_multiget_for_io=1 --paranoid_file_checks=0 --partition_filters=0 --partition_pinning=3 --pause_background_one_in=1000000 --periodic_compaction_seconds=2 --prefix_size=7 --prefixpercent=0 --prepopulate_block_cache=0 --preserve_internal_time_seconds=0 --progress_reports=0 --promote_l0_one_in=0 --read_amp_bytes_per_bit=0 --read_fault_one_in=1000 --readahead_size=524288 --readpercent=0 --recycle_log_file_num=1 --reopen=0 --report_bg_io_stats=0 --reset_stats_one_in=1000000 --sample_for_compression=0 --secondary_cache_fault_one_in=0 --set_options_one_in=0 --skip_stats_update_on_db_open=1 --snapshot_hold_ops=100000 --soft_pending_compaction_bytes_limit=68719476736 --sqfc_name=foo --sqfc_version=0 --sst_file_manager_bytes_per_sec=104857600 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=10 --stats_history_buffer_size=0 --strict_bytes_per_sync=1 --subcompactions=4 --sync=1 --sync_fault_injection=0 --table_cache_numshardbits=6 --target_file_size_base=16777216 --target_file_size_multiplier=1 --test_batches_snapshots=0 --top_level_index_pinning=2 --uncache_aggressiveness=239 --universal_max_read_amp=-1 --unpartitioned_pinning=1 --use_adaptive_mutex=1 --use_adaptive_mutex_lru=1 --use_attribute_group=0 --use_delta_encoding=0 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=0 --use_get_entity=0 --use_merge=0 --use_multi_cf_iterator=0 --use_multi_get_entity=0 --use_multiget=0 --use_put_entity_one_in=0 --use_sqfc_for_range_queries=1 --use_timed_put_one_in=0 --use_write_buffer_manager=0 --user_timestamp_size=0 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000000 --verify_compression=0 --verify_db_one_in=100000 --verify_file_checksums_one_in=1000000 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=0 --wal_compression=none --write_buffer_size=33554432 --write_dbid_to_manifest=0 --write_fault_one_in=128 --writepercent=50\n\nReviewed By: jowlyzhang\n\nDifferential Revision: D59825730\n\nPulled By: hx235\n\nfbshipit-source-id: 7d77aaf177ded2f99bf1ce19f5a4bd0783b9ca92",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl/db_impl_write.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/21db55f8164d2a6519dcc993f74bf7f49c700854",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::WriteImpl"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "ebe2116240a4efac4226975b975917f889010aa2",
        "author": "Hui Xiao",
        "date": "2024-07-09T15:35:54-07:00",
        "message": "Remove false-postive assertion in `FaultInjectionTestFS::RenameFile` (#12828)\n\nSummary:\n**Context/Summary:**\nThe assertion `tlist.find(tdn.second) == tlist.end()` https://github.com/facebook/rocksdb/blame/9eebaf11cbd875435b572f05f0378ecdb761cc74/utilities/fault_injection_fs.cc#L1003 can catch us false positive.\n\nSome context\n(1) When fault injection is enabled and db open fails because of that, crash test will retry open without injected error in order to proceed with a clean open:\nhttps://github.com/facebook/rocksdb/blob/9eebaf11cbd875435b572f05f0378ecdb761cc74/db_stress_tool/db_stress_test_base.cc#L3559\nhttps://github.com/facebook/rocksdb/blob/9eebaf11cbd875435b572f05f0378ecdb761cc74/db_stress_tool/db_stress_test_base.cc#L3586-L3639\n(2)\na. `FaultInjectionTestFS::dir_to_new_files_since_last_sync` records files that are created but not yet synced.\nb. When we create CURRENT, we will first create a temp file and rename it as \"CURRENT\". As part of the renaming, we will [assert](https://github.com/facebook/rocksdb/blame/9eebaf11cbd875435b572f05f0378ecdb761cc74/utilities/fault_injection_fs.cc#L1003) `FaultInjectionTestFS::dir_to_new_files_since_last_sync ` doesn't already have a file named `CURRENT`.\n\nSuppose the following sequence of events happened:\n\n(1) 1st open, with metadata write error\n1. As part of creating CURRENT file, added \"CURRENT\" to `FaultInjectionTestFS::dir_to_new_files_since_last_sync_`\nhttps://github.com/facebook/rocksdb/blob/9eebaf11cbd875435b572f05f0378ecdb761cc74/utilities/fault_injection_fs.cc#L735\n2.  `SyncDir()` here https://github.com/facebook/rocksdb/blob/9eebaf11cbd875435b572f05f0378ecdb761cc74/file/filename.cc#L412 failed with injected metadata write error. Therefore, \"CURRENT\" file didn't get removed from `FaultInjectionTestFS::dir_to_new_files_since_last_sync_` as it would if `SyncDir()` succeeded https://github.com/facebook/rocksdb/blob/9eebaf11cbd875435b572f05f0378ecdb761cc74/utilities/fault_injection_fs.h#L344\n\n(2) 2st open\n1. Attempted to create a CURRENT file and failed during renaming since `FaultInjectionTestFS::dir_to_new_files_since_last_sync_` already had a file called CURRENT. So  will fail\n```\nassertion failed - tlist.find(tdn.second) == tlist.end()\n```\n\nThis PR fixed this by removing the assertion. It used to catch us some missing sync of some directory (e.,g https://github.com/facebook/rocksdb/pull/10573) so we will keep thinking about a better way to catch that.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12828\n\nTest Plan:\nCommand constantly failed before the fix but passed after the PR running for 10 minutes\n```\npython3 tools/db_crashtest.py --simple blackbox --interval=10 --WAL_size_limit_MB=1 --WAL_ttl_seconds=60 --acquire_snapshot_one_in=100 --adaptive_readahead=1 --adm_policy=2 --advise_random_on_open=1 --allow_concurrent_memtable_write=1 --allow_data_in_errors=True --allow_fallocate=1 --async_io=0 --auto_readahead_size=1 --avoid_flush_during_recovery=0 --avoid_flush_during_shutdown=0 --avoid_unnecessary_blocking_io=0 --backup_max_size=104857600 --backup_one_in=100000 --batch_protection_bytes_per_key=0 --bgerror_resume_retry_interval=100 --block_align=0 --block_protection_bytes_per_key=8 --block_size=16384 --bloom_before_level=1 --bloom_bits=10 --bottommost_compression_type=lz4hc --bottommost_file_compaction_delay=86400 --bytes_per_sync=0 --cache_index_and_filter_blocks=1 --cache_index_and_filter_blocks_with_high_priority=0 --cache_size=8388608 --cache_type=tiered_auto_hyper_clock_cache --charge_compression_dictionary_building_buffer=1 --charge_file_metadata=0 --charge_filter_construction=0 --charge_table_reader=0 --check_multiget_consistency=0 --check_multiget_entity_consistency=0 --checkpoint_one_in=10000 --checksum_type=kCRC32c --clear_column_family_one_in=0 --column_families=1 --compact_files_one_in=1000 --compact_range_one_in=1000000 --compaction_pri=3 --compaction_readahead_size=0 --compaction_ttl=1 --compress_format_version=1 --compressed_secondary_cache_ratio=0.5 --compressed_secondary_cache_size=0 --compression_checksum=0 --compression_max_dict_buffer_bytes=15 --compression_max_dict_bytes=16384 --compression_parallel_threads=1 --compression_type=zstd --compression_use_zstd_dict_trainer=1 --compression_zstd_max_train_bytes=65536 --continuous_verification_interval=0 --daily_offpeak_time_utc= --data_block_index_type=1 --db_write_buffer_size=0 --default_temperature=kHot --default_write_temperature=kUnknown --delete_obsolete_files_period_micros=30000000 --delpercent=4 --delrangepercent=1 --destroy_db_initially=0 --detect_filter_construct_corruption=1 --disable_file_deletions_one_in=10000 --disable_manual_compaction_one_in=10000 --disable_wal=0 --dump_malloc_stats=0 --enable_checksum_handoff=1 --enable_compaction_filter=0 --enable_custom_split_merge=0 --enable_do_not_compress_roles=0 --enable_index_compression=1 --enable_memtable_insert_with_hint_prefix_extractor=0 --enable_pipelined_write=0 --enable_sst_partitioner_factory=1 --enable_thread_tracking=1 --enable_write_thread_adaptive_yield=0 --error_recovery_with_no_fault_injection=1 --exclude_wal_from_write_fault_injection=1 --fail_if_options_file_error=1 --fifo_allow_compaction=0 --file_checksum_impl=crc32c --fill_cache=1 --flush_one_in=1000000 --format_version=3 --get_all_column_family_metadata_one_in=1000000 --get_current_wal_file_one_in=0 --get_live_files_apis_one_in=1000000 --get_properties_of_all_tables_one_in=100000 --get_property_one_in=100000 --get_sorted_wal_files_one_in=0 --hard_pending_compaction_bytes_limit=2097152 --high_pri_pool_ratio=0 --index_block_restart_interval=2 --index_shortening=0 --index_type=2 --ingest_external_file_one_in=0 --initial_auto_readahead_size=16384 --inplace_update_support=0 --iterpercent=10 --key_len_percent_dist=1,30,69 --key_may_exist_one_in=100000 --last_level_temperature=kWarm --level_compaction_dynamic_level_bytes=0 --lock_wal_one_in=10000 --log_file_time_to_roll=60 --log_readahead_size=16777216 --long_running_snapshots=1 --low_pri_pool_ratio=0.5 --lowest_used_cache_tier=1 --manifest_preallocation_size=0 --manual_wal_flush_one_in=0 --mark_for_compaction_one_file_in=10 --max_auto_readahead_size=16384 --max_background_compactions=1 --max_bytes_for_level_base=67108864 --max_key=1000000 --max_key_len=3 --max_log_file_size=0 --max_manifest_file_size=1073741824 --max_sequential_skip_in_iterations=1 --max_total_wal_size=0 --max_write_batch_group_size_bytes=16 --max_write_buffer_number=3 --max_write_buffer_size_to_maintain=2097152 --memtable_insert_hint_per_batch=0 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0.1 --memtable_protection_bytes_per_key=8 --memtable_whole_key_filtering=0 --memtablerep=skip_list --metadata_charge_policy=1 --metadata_read_fault_one_in=32 --metadata_write_fault_one_in=0 --min_write_buffer_number_to_merge=2 --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --num_file_reads_for_auto_readahead=1 --open_files=-1 --open_metadata_read_fault_one_in=0 --open_metadata_write_fault_one_in=8 --open_read_fault_one_in=0 --open_write_fault_one_in=0 --ops_per_thread=100000000 --optimize_filters_for_hits=0 --optimize_filters_for_memory=0 --optimize_multiget_for_io=1 --paranoid_file_checks=1 --partition_filters=1 --partition_pinning=3 --pause_background_one_in=1000000 --periodic_compaction_seconds=1000 --prefix_size=5 --prefixpercent=5 --prepopulate_block_cache=1 --preserve_internal_time_seconds=0 --progress_reports=0 --promote_l0_one_in=0 --read_amp_bytes_per_bit=32 --read_fault_one_in=0 --readahead_size=524288 --readpercent=45 --recycle_log_file_num=0 --reopen=0 --report_bg_io_stats=0 --reset_stats_one_in=1000000 --sample_for_compression=0 --secondary_cache_fault_one_in=32 --secondary_cache_uri= --set_options_one_in=0 --skip_stats_update_on_db_open=0 --snapshot_hold_ops=100000 --soft_pending_compaction_bytes_limit=68719476736 --sqfc_name=foo --sqfc_version=1 --sst_file_manager_bytes_per_sec=0 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=10 --stats_history_buffer_size=1048576 --strict_bytes_per_sync=1 --subcompactions=2 --sync=0 --sync_fault_injection=1 --table_cache_numshardbits=6 --target_file_size_base=16777216 --target_file_size_multiplier=1 --test_batches_snapshots=0 --top_level_index_pinning=2 --uncache_aggressiveness=1582 --universal_max_read_amp=4 --unpartitioned_pinning=0 --use_adaptive_mutex=0 --use_adaptive_mutex_lru=1 --use_attribute_group=1 --use_delta_encoding=0 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=0 --use_get_entity=0 --use_merge=0 --use_multi_cf_iterator=1 --use_multi_get_entity=1 --use_multiget=0 --use_put_entity_one_in=1 --use_sqfc_for_range_queries=1 --use_timed_put_one_in=0 --use_write_buffer_manager=0 --user_timestamp_size=0 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000 --verify_compression=1 --verify_db_one_in=10000 --verify_file_checksums_one_in=1000 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=0 --wal_compression=none --write_buffer_size=33554432 --write_dbid_to_manifest=1 --write_fault_one_in=8 --writepercent=35\n```\n\nReviewed By: cbi42\n\nDifferential Revision: D59241548\n\nPulled By: hx235\n\nfbshipit-source-id: 5bb49e6a94943273f47578a2caf3d08ca5b67e5f",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/fault_injection_fs.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/ebe2116240a4efac4226975b975917f889010aa2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FaultInjectionTestFS::RenameFile"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "093f4ef82cdd599896517f5414ee9ae7f6af3b35",
        "author": "Jeffery",
        "date": "2024-07-01T16:14:19-07:00",
        "message": "Fix db_rate_limiter_test for win (#12816)\n\nSummary:\nWe didn't implement file system prefetch for OS Win. During table open, it uses `FilePrefetchBuffer` instead and only do 1 read instead of 4 in BufferedIO.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12816\n\nReviewed By: jaykorean\n\nDifferential Revision: D59181835\n\nPulled By: ajkr\n\nfbshipit-source-id: 18b8f0247408cd1a80f289357ede5232ae5a3c66",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_rate_limiter_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/093f4ef82cdd599896517f5414ee9ae7f6af3b35",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_P"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "aec15eebec08429142fde04a4006303412def90c",
        "author": "Hui Xiao",
        "date": "2024-06-26T23:02:28-07:00",
        "message": "Ignore non-critical IO error in `BlockCacheLookupForReadAheadSize()` in crash test (#12814)\n\nSummary:\n**Context/Summary:**\n\nError in `BlockCacheLookupForReadAheadSize()` is not critical enough to return such error in read path. That's because the worst case is to not have any read ahead. See below comment. https://github.com/facebook/rocksdb/blob/a31fe521732c6150003ea43f1e30f27f13be597c/table/block_based/block_based_table_iterator.cc#L867-L871\n\nTherefore we should allow the read to return ok() even when we inject read error there.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12814\n\nTest Plan:\nBelow command failed with ` Didn't get expected error from PrefixScan` before the fix but passes after\n\n```\n./db_stress --WAL_size_limit_MB=0 --WAL_ttl_seconds=60 --acquire_snapshot_one_in=100 --adaptive_readahead=0 --adm_policy=3 --advise_random_on_open=0 --allow_concurrent_memtable_write=0 --allow_data_in_errors=True --allow_fallocate=1 --async_io=0 --auto_readahead_size=1 --avoid_flush_during_recovery=0 --avoid_flush_during_shutdown=1 --avoid_unnecessary_blocking_io=1 --backup_max_size=104857600 --backup_one_in=1000 --batch_protection_bytes_per_key=8 --bgerror_resume_retry_interval=1000000 --block_align=0 --block_protection_bytes_per_key=1 --block_size=16384 --bloom_before_level=5 --bloom_bits=29.31310447925055 --bottommost_compression_type=lz4hc --bottommost_file_compaction_delay=0 --bytes_per_sync=262144 --cache_index_and_filter_blocks=1 --cache_index_and_filter_blocks_with_high_priority=0 --cache_size=8388608 --cache_type=tiered_auto_hyper_clock_cache --charge_compression_dictionary_building_buffer=0 --charge_file_metadata=1 --charge_filter_construction=0 --charge_table_reader=1 --check_multiget_consistency=0 --check_multiget_entity_consistency=0 --checkpoint_one_in=1000000 --checksum_type=kxxHash64 --clear_column_family_one_in=0 --column_families=1 --compact_files_one_in=1000000 --compact_range_one_in=1000000 --compaction_pri=0 --compaction_readahead_size=0 --compaction_ttl=0 --compress_format_version=2 --compressed_secondary_cache_ratio=0.6666666666666666 --compressed_secondary_cache_size=0 --compression_checksum=1 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=1 --compression_type=lz4 --compression_use_zstd_dict_trainer=0 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --daily_offpeak_time_utc= --data_block_index_type=0 --db=/dev/shm/rocksdb_test/rocksdb_crashtest_whitebox --db_write_buffer_size=8388608 --default_temperature=kHot --default_write_temperature=kHot --delete_obsolete_files_period_micros=30000000 --delpercent=4 --delrangepercent=1 --destroy_db_initially=0 --detect_filter_construct_corruption=1 --disable_file_deletions_one_in=10000 --disable_manual_compaction_one_in=10000 --disable_wal=0 --dump_malloc_stats=0 --enable_checksum_handoff=1 --enable_compaction_filter=0 --enable_custom_split_merge=0 --enable_do_not_compress_roles=1 --enable_index_compression=0 --enable_memtable_insert_with_hint_prefix_extractor=0 --enable_pipelined_write=1 --enable_sst_partitioner_factory=0 --enable_thread_tracking=1 --enable_write_thread_adaptive_yield=1 --error_recovery_with_no_fault_injection=0 --exclude_wal_from_write_fault_injection=0 --expected_values_dir=/dev/shm/rocksdb_test/rocksdb_crashtest_expected --fail_if_options_file_error=0 --fifo_allow_compaction=0 --file_checksum_impl=big --fill_cache=1 --flush_one_in=1000 --format_version=3 --get_all_column_family_metadata_one_in=1000000 --get_current_wal_file_one_in=0 --get_live_files_apis_one_in=10000 --get_properties_of_all_tables_one_in=100000 --get_property_one_in=1000000 --get_sorted_wal_files_one_in=0 --hard_pending_compaction_bytes_limit=274877906944 --high_pri_pool_ratio=0 --index_block_restart_interval=2 --index_shortening=0 --index_type=2 --ingest_external_file_one_in=1000 --initial_auto_readahead_size=0 --inplace_update_support=0 --iterpercent=10 --key_len_percent_dist=1,30,69 --key_may_exist_one_in=100 --last_level_temperature=kHot --level_compaction_dynamic_level_bytes=0 --lock_wal_one_in=1000000 --log2_keys_per_lock=10 --log_file_time_to_roll=60 --log_readahead_size=0 --long_running_snapshots=0 --low_pri_pool_ratio=0 --lowest_used_cache_tier=2 --manifest_preallocation_size=0 --manual_wal_flush_one_in=0 --mark_for_compaction_one_file_in=0 --max_auto_readahead_size=16384 --max_background_compactions=1 --max_bytes_for_level_base=67108864 --max_key=100000 --max_key_len=3 --max_log_file_size=0 --max_manifest_file_size=1073741824 --max_sequential_skip_in_iterations=1 --max_total_wal_size=0 --max_write_batch_group_size_bytes=16 --max_write_buffer_number=10 --max_write_buffer_size_to_maintain=2097152 --memtable_insert_hint_per_batch=0 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0.1 --memtable_protection_bytes_per_key=8 --memtable_whole_key_filtering=1 --memtablerep=skip_list --metadata_charge_policy=0 --metadata_read_fault_one_in=32 --metadata_write_fault_one_in=128 --min_write_buffer_number_to_merge=2 --mmap_read=0 --mock_direct_io=True --nooverwritepercent=1 --num_file_reads_for_auto_readahead=1 --open_files=100 --open_metadata_read_fault_one_in=0 --open_metadata_write_fault_one_in=8 --open_read_fault_one_in=0 --open_write_fault_one_in=0 --ops_per_thread=20000000 --optimize_filters_for_hits=0 --optimize_filters_for_memory=1 --optimize_multiget_for_io=0 --paranoid_file_checks=1 --partition_filters=1 --partition_pinning=2 --pause_background_one_in=10000 --periodic_compaction_seconds=0 --prefix_size=5 --prefixpercent=5 --prepopulate_block_cache=1 --preserve_internal_time_seconds=0 --progress_reports=0 --promote_l0_one_in=0 --read_amp_bytes_per_bit=32 --read_fault_one_in=1000 --readahead_size=524288 --readpercent=45 --recycle_log_file_num=0 --reopen=20 --report_bg_io_stats=1 --reset_stats_one_in=1000000 --sample_for_compression=5 --secondary_cache_fault_one_in=32 --secondary_cache_uri= --skip_stats_update_on_db_open=1 --snapshot_hold_ops=100000 --soft_pending_compaction_bytes_limit=1048576 --sqfc_name=foo --sqfc_version=1 --sst_file_manager_bytes_per_sec=0 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=600 --stats_history_buffer_size=0 --strict_bytes_per_sync=1 --subcompactions=2 --sync=0 --sync_fault_injection=0 --table_cache_numshardbits=6 --target_file_size_base=16777216 --target_file_size_multiplier=1 --test_batches_snapshots=0 --top_level_index_pinning=1 --uncache_aggressiveness=203 --universal_max_read_amp=10 --unpartitioned_pinning=0 --use_adaptive_mutex=1 --use_adaptive_mutex_lru=1 --use_attribute_group=0 --use_delta_encoding=0 --use_direct_io_for_flush_and_compaction=1 --use_direct_reads=0 --use_full_merge_v1=1 --use_get_entity=0 --use_merge=0 --use_multi_cf_iterator=0 --use_multi_get_entity=0 --use_multiget=1 --use_put_entity_one_in=0 --use_sqfc_for_range_queries=1 --use_timed_put_one_in=0 --use_write_buffer_manager=0 --user_timestamp_size=0 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000000 --verify_compression=1 --verify_db_one_in=10000 --verify_file_checksums_one_in=1000 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=0 --wal_compression=none --write_buffer_size=33554432 --write_dbid_to_manifest=0 --write_fault_one_in=1000 --writepercent=35\n```\n\nReviewed By: jaykorean\n\nDifferential Revision: D59092430\n\nPulled By: hx235\n\nfbshipit-source-id: 39558c34461ce92275cae706c33dfd00e6f0ecce",
        "modified_files_count": 1,
        "modified_files": [
            "table/block_based/block_based_table_iterator.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/aec15eebec08429142fde04a4006303412def90c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlockBasedTableIterator::BlockCacheLookupForReadAheadSize"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "a2f772910ed80a3ba357351bf5e835bb73f4fd6d",
        "author": "Hui Xiao",
        "date": "2024-06-12T12:17:45-07:00",
        "message": "Fix manual WAL flush causing false-positive inconsistent values in TestBackupRestore() (#12758)\n\nSummary:\n**Context/Summary:**\nWhen manual WAL flush is used, the following can happen:\n\nt1: Issued Put(k1) to original DB. It entered WAL buffer since manual_wal_flush_one_in > 0. It never made it to WAL file without FlushWAL()\nt2: The same WAL got back-up and restored to restore DB. So the restore DB's WAL does not contain this Put()\nt3: The same WAL in the original DB got FlushWAL() so it got the Put() entry\n\nQuerying k1 in original and restored DB will give different result and fail our consistency check in stress test.\n\n```\nFailure in a backup/restore operation with: Corruption: 0x000000000000000178 exists in original db but not in restore\n```\n\nThis PR fixed it.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12758\n\nTest Plan:\n```\n\n./db_stress --WAL_size_limit_MB=0 --WAL_ttl_seconds=0 --acquire_snapshot_one_in=10000 --adaptive_readahead=1 --adm_policy=1 --advise_random_on_open=1 --allow_concurrent_memtable_write=0 --allow_data_in_errors=True --allow_fallocate=1 --async_io=1 --auto_readahead_size=0 --avoid_flush_during_recovery=1 --avoid_flush_during_shutdown=1 --avoid_unnecessary_blocking_io=0 --backup_max_size=104857600 --backup_one_in=100 --batch_protection_bytes_per_key=8 --bgerror_resume_retry_interval=1000000 --block_align=1 --block_protection_bytes_per_key=0 --block_size=16384 --bloom_before_level=2147483646 --bloom_bits=13 --bottommost_compression_type=none --bottommost_file_compaction_delay=600 --bytes_per_sync=262144 --cache_index_and_filter_blocks=0 --cache_index_and_filter_blocks_with_high_priority=0 --cache_size=33554432 --cache_type=auto_hyper_clock_cache --charge_compression_dictionary_building_buffer=0 --charge_file_metadata=0 --charge_filter_construction=1 --charge_table_reader=0 --check_multiget_consistency=0 --check_multiget_entity_consistency=1 --checkpoint_one_in=1000000 --checksum_type=kxxHash --clear_column_family_one_in=0 --column_families=1 --compact_files_one_in=1000 --compact_range_one_in=1000000 --compaction_pri=3 --compaction_readahead_size=0 --compaction_ttl=0 --compress_format_version=1 --compressed_secondary_cache_size=8388608 --compression_checksum=0 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=4 --compression_type=none --compression_use_zstd_dict_trainer=0 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --daily_offpeak_time_utc= --data_block_index_type=0 --db=/dev/shm/rocksdb_test/rocksdb_crashtest_blackbox_1 --db_write_buffer_size=0 --default_temperature=kCold --default_write_temperature=kHot --delete_obsolete_files_period_micros=21600000000 --delpercent=40 --delrangepercent=0 --destroy_db_initially=0 --detect_filter_construct_corruption=1 --disable_file_deletions_one_in=1000000 --disable_manual_compaction_one_in=10000 --disable_wal=0 --dump_malloc_stats=0 --enable_checksum_handoff=0 --enable_compaction_filter=0 --enable_custom_split_merge=1 --enable_do_not_compress_roles=1 --enable_index_compression=0 --enable_memtable_insert_with_hint_prefix_extractor=0 --enable_pipelined_write=0 --enable_sst_partitioner_factory=1 --enable_thread_tracking=0 --enable_write_thread_adaptive_yield=1 --expected_values_dir=/dev/shm/rocksdb_test/rocksdb_crashtest_expected_1 --fail_if_options_file_error=1 --fifo_allow_compaction=1 --file_checksum_impl=none --fill_cache=0 --flush_one_in=1000000 --format_version=2 --get_all_column_family_metadata_one_in=1000000 --get_current_wal_file_one_in=0 --get_live_files_apis_one_in=1000000 --get_properties_of_all_tables_one_in=1000000 --get_property_one_in=100000 --get_sorted_wal_files_one_in=0 --hard_pending_compaction_bytes_limit=274877906944 --high_pri_pool_ratio=0.5 --index_block_restart_interval=5 --index_shortening=2 --index_type=0 --ingest_external_file_one_in=0 --initial_auto_readahead_size=16384 --inplace_update_support=0 --iterpercent=10 --key_len_percent_dist=1,30,69 --key_may_exist_one_in=100 --last_level_temperature=kUnknown --level_compaction_dynamic_level_bytes=1 --lock_wal_one_in=0 --log_file_time_to_roll=60 --log_readahead_size=16777216 --long_running_snapshots=0 --low_pri_pool_ratio=0.5 --lowest_used_cache_tier=1 --manifest_preallocation_size=5120 --manual_wal_flush_one_in=100 --mark_for_compaction_one_file_in=10 --max_auto_readahead_size=524288 --max_background_compactions=1 --max_bytes_for_level_base=67108864 --max_key=10 --max_key_len=3 --max_log_file_size=0 --max_manifest_file_size=1073741824 --max_sequential_skip_in_iterations=16 --max_total_wal_size=0 --max_write_batch_group_size_bytes=64 --max_write_buffer_number=10 --max_write_buffer_size_to_maintain=2097152 --memtable_insert_hint_per_batch=1 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0.1 --memtable_protection_bytes_per_key=1 --memtable_whole_key_filtering=0 --memtablerep=skip_list --metadata_charge_policy=1 --min_write_buffer_number_to_merge=1 --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --num_file_reads_for_auto_readahead=0 --open_files=-1 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=0 --open_write_fault_one_in=16 --ops_per_thread=100000000 --optimize_filters_for_hits=0 --optimize_filters_for_memory=0 --optimize_multiget_for_io=1 --paranoid_file_checks=1 --partition_filters=0 --partition_pinning=0 --pause_background_one_in=1000000 --periodic_compaction_seconds=2 --prefix_size=7 --prefixpercent=5 --prepopulate_block_cache=0 --preserve_internal_time_seconds=0 --progress_reports=0 --promote_l0_one_in=0 --read_amp_bytes_per_bit=0 --read_fault_one_in=1000 --readahead_size=16384 --readpercent=0 --recycle_log_file_num=0 --reopen=0 --report_bg_io_stats=0 --reset_stats_one_in=10000 --sample_for_compression=0 --secondary_cache_fault_one_in=0 --secondary_cache_uri= --set_options_one_in=0 --skip_stats_update_on_db_open=1 --snapshot_hold_ops=100000 --soft_pending_compaction_bytes_limit=68719476736 --sst_file_manager_bytes_per_sec=0 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=600 --stats_history_buffer_size=0 --strict_bytes_per_sync=1 --subcompactions=2 --sync=0 --sync_fault_injection=1 --table_cache_numshardbits=-1 --target_file_size_base=16777216 --target_file_size_multiplier=1 --test_batches_snapshots=0 --top_level_index_pinning=2 --uncache_aggressiveness=709 --universal_max_read_amp=0 --unpartitioned_pinning=0 --use_adaptive_mutex=0 --use_adaptive_mutex_lru=1 --use_attribute_group=1 --use_delta_encoding=1 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=0 --use_get_entity=0 --use_merge=1 --use_multi_cf_iterator=0 --use_multi_get_entity=0 --use_multiget=0 --use_put_entity_one_in=0 --use_timed_put_one_in=0 --use_write_buffer_manager=0 --user_timestamp_size=0 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000 --verify_compression=0 --verify_db_one_in=100000 --verify_file_checksums_one_in=0 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=0 --wal_compression=none --write_buffer_size=335544 --write_dbid_to_manifest=1 --write_fault_one_in=128 --writepercent=45\n```\nRepro-ed quickly before the fix and stably run after the fix.\n\nReviewed By: jowlyzhang\n\nDifferential Revision: D58426535\n\nPulled By: hx235\n\nfbshipit-source-id: 611e56086e76f8c06d292624e60fd96e511ce723",
        "modified_files_count": 1,
        "modified_files": [
            "db_stress_tool/db_stress_test_base.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a2f772910ed80a3ba357351bf5e835bb73f4fd6d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "StressTest::TestBackupRestore"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "d64eac28d32a025770cba641ea04e697f475cdd6",
        "author": "Peter Dillinger",
        "date": "2024-06-11T21:41:21-07:00",
        "message": "Fix a failure to propagate ReadOptions (#12757)\n\nSummary:\nThe crash test revealed a case in which the uncache functionality in ~BlockBasedTableReader could initiate an block read (IO), despite setting ReadOptions::read_tier = kBlockCacheTier.\n\nThe root cause is a place in the code where many people have over time decided to opt-in propagating ReadOptions and no one took the initiative to propagate ReadOptions by default (opt out / override only as needed). The fix is in partitioned_index_reader.cc. Here,\nReadOptions::readahead_size is opted-out to avoid churn in prefetch_test that is not clearly an improvement or regression. It's hard to tell given the poor state of relevant documentation https://github.com/facebook/rocksdb/issues/12756. The affected unit test was added in https://github.com/facebook/rocksdb/issues/10602.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12757\n\nTest Plan: (Now postponed to a follow-up diff) I have added some new infrastructure to DEBUG builds to catch this specific kind of violation in unit tests and in the stress/crash test. `EnforceReadOpts` establishes a thread-local context under which we assert no IOs are performed if ReadOptions said it should be forbidden. With this new checking, the Uncache unit test would catch the critical step toward a violation (inner ReadOptions allowing IO, even if no IO is actually performed), which is fixed with the production code change.\n\nReviewed By: hx235\n\nDifferential Revision: D58421526\n\nPulled By: pdillinger\n\nfbshipit-source-id: 9e9917a0e320c78967e751bd887926a2ed231d37",
        "modified_files_count": 1,
        "modified_files": [
            "table/block_based/partitioned_index_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d64eac28d32a025770cba641ea04e697f475cdd6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PartitionIndexReader::NewIterator"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "a8a52e5b4d938c1aea28d7a96ec70a459ffaa1a4",
        "author": "Valery Mironov",
        "date": "2024-06-04T09:41:53-07:00",
        "message": "Fix AddressSanitizer container-overflow (#12722)\n\nSummary:\n```\nERROR: AddressSanitizer: container-overflow on address 0x506000682221 at pc 0x5583da569f76 bp 0x7f0ec8a9ffb0 sp 0x7f0ec8a9f780\nWRITE of size 53 at 0x506000682221 thread T29\n    #0 0x5583da569f75 in pread\n    https://github.com/facebook/rocksdb/issues/1 0x5583e334fde4 in rocksdb::PosixRandomAccessFile::Read(unsigned long, unsigned long, rocksdb::IOOptions const&, rocksdb::Slice*, char*, rocksdb::IODebugContext*) const /rocksdb/env/io_posix.cc:580:9\n    https://github.com/facebook/rocksdb/issues/2 0x5583e2cac42b in rocksdb::(anonymous namespace)::CompositeRandomAccessFileWrapper::Read(unsigned long, unsigned long, rocksdb::Slice*, char*) const /rocksdb/env/composite_env.cc:61:21\n    https://github.com/facebook/rocksdb/issues/3 0x5583e2c8a8e4 in rocksdb::(anonymous namespace)::LegacyRandomAccessFileWrapper::Read(unsigned long, unsigned long, rocksdb::IOOptions const&, rocksdb::Slice*, char*, rocksdb::IODebugContext*) const /rocksdb/env/env.cc:152:41\n    https://github.com/facebook/rocksdb/issues/4 0x5583e2d6cbfb in rocksdb::RandomAccessFileReader::Read(rocksdb::IOOptions const&, unsigned long, unsigned long, rocksdb::Slice*, char*, std::__2::unique_ptr<char [], std::__2::default_delete<char []>>*, rocksdb::Env::IOPriority) const /rocksdb/file/random_access_file_reader.cc:204:25\n    https://github.com/facebook/rocksdb/issues/5 0x5583e307c614 in rocksdb::ReadFooterFromFile(rocksdb::IOOptions const&, rocksdb::RandomAccessFileReader*, rocksdb::FilePrefetchBuffer*, unsigned long, rocksdb::Footer*, unsigned long) /rocksdb/table/format.cc:383:17\n    https://github.com/facebook/rocksdb/issues/6 0x5583e2f88456 in rocksdb::BlockBasedTable::Open(rocksdb::ReadOptions const&, rocksdb::ImmutableOptions const&, rocksdb::EnvOptions const&, rocksdb::BlockBasedTableOptions const&, rocksdb::InternalKeyComparator const&, std::__2::unique_ptr<rocksdb::RandomAccessFileReader, std::__2::default_delete<rocksdb::RandomAccessFileReader>>&&, unsigned long, std::__2::unique_ptr<rocksdb::TableReader, std::__2::default_delete<rocksdb::TableReader>>*, std::__2::shared_ptr<rocksdb::CacheReservationManager>, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, bool, bool, int, bool, unsigned long, bool, rocksdb::TailPrefetchStats*, rocksdb::BlockCacheTracer*, unsigned long, std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>> const&, unsigned long) /rocksdb/table/block_based/block_based_table_reader.cc:610:9\n    https://github.com/facebook/rocksdb/issues/7 0x5583e2ef7837 in rocksdb::BlockBasedTableFactory::NewTableReader(rocksdb::ReadOptions const&, rocksdb::TableReaderOptions const&, std::__2::unique_ptr<rocksdb::RandomAccessFileReader, std::__2::default_delete<rocksdb::RandomAccessFileReader>>&&, unsigned long, std::__2::unique_ptr<rocksdb::TableReader, std::__2::default_delete<rocksdb::TableReader>>*, bool) const /rocksdb/table/block_based/block_based_table_factory.cc:599:10\n    https://github.com/facebook/rocksdb/issues/8 0x5583e2ab873c in rocksdb::TableCache::GetTableReader(rocksdb::ReadOptions const&, rocksdb::FileOptions const&, rocksdb::InternalKeyComparator const&, rocksdb::FileDescriptor const&, bool, bool, rocksdb::HistogramImpl*, std::__2::unique_ptr<rocksdb::TableReader, std::__2::default_delete<rocksdb::TableReader>>*, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, bool, int, bool, unsigned long, rocksdb::Temperature) /rocksdb/db/table_cache.cc:142:34\n    https://github.com/facebook/rocksdb/issues/9 0x5583e2aba5f6 in rocksdb::TableCache::FindTable(rocksdb::ReadOptions const&, rocksdb::FileOptions const&, rocksdb::InternalKeyComparator const&, rocksdb::FileDescriptor const&, rocksdb::Cache::Handle**, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, bool, bool, rocksdb::HistogramImpl*, bool, int, bool, unsigned long, rocksdb::Temperature) /rocksdb/db/table_cache.cc:190:16\n    https://github.com/facebook/rocksdb/issues/10 0x5583e2abb7e1 in rocksdb::TableCache::NewIterator(rocksdb::ReadOptions const&, rocksdb::FileOptions const&, rocksdb::InternalKeyComparator const&, rocksdb::FileMetaData const&, rocksdb::RangeDelAggregator*, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, rocksdb::TableReader**, rocksdb::HistogramImpl*, rocksdb::TableReaderCaller, rocksdb::Arena*, bool, int, unsigned long, rocksdb::InternalKey const*, rocksdb::InternalKey const*, bool) /rocksdb/db/table_cache.cc:235:9\n    https://github.com/facebook/rocksdb/issues/11 0x5583e28d14cf in rocksdb::BuildTable(std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>> const&, rocksdb::VersionSet*, rocksdb::ImmutableDBOptions const&, rocksdb::TableBuilderOptions const&, rocksdb::FileOptions const&, rocksdb::TableCache*, rocksdb::InternalIteratorBase<rocksdb::Slice>*, std::__2::vector<std::__2::unique_ptr<rocksdb::FragmentedRangeTombstoneIterator, std::__2::default_delete<rocksdb::FragmentedRangeTombstoneIterator>>, std::__2::allocator<std::__2::unique_ptr<rocksdb::FragmentedRangeTombstoneIterator, std::__2::default_delete<rocksdb::FragmentedRangeTombstoneIterator>>>>, rocksdb::FileMetaData*, std::__2::vector<rocksdb::BlobFileAddition, std::__2::allocator<rocksdb::BlobFileAddition>>*, std::__2::vector<unsigned long, std::__2::allocator<unsigned long>>, unsigned long, unsigned long, rocksdb::SnapshotChecker*, bool, rocksdb::InternalStats*, rocksdb::IOStatus*, std::__2::shared_ptr<rocksdb::IOTracer> const&, rocksdb::BlobFileCreationReason, rocksdb::EventLogger*, int, rocksdb::Env::IOPriority, rocksdb::TableProperties*, rocksdb::Env::WriteLifeTimeHint, std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>> const*, rocksdb::BlobFileCompletionCallback*, unsigned long*, unsigned long*, unsigned long*) /rocksdb/db/builder.cc:335:57\n    https://github.com/facebook/rocksdb/issues/12 0x5583e29bf29d in rocksdb::FlushJob::WriteLevel0Table() /rocksdb/db/flush_job.cc:919:11\n    https://github.com/facebook/rocksdb/issues/13 0x5583e29b33ac in rocksdb::FlushJob::Run(rocksdb::LogsWithPrepTracker*, rocksdb::FileMetaData*, bool*) /rocksdb/db/flush_job.cc:276:9\n    https://github.com/facebook/rocksdb/issues/14 0x5583e27a4781 in rocksdb::DBImpl::FlushMemTableToOutputFile(rocksdb::ColumnFamilyData*, rocksdb::MutableCFOptions const&, bool*, rocksdb::JobContext*, rocksdb::SuperVersionContext*, std::__2::vector<unsigned long, std::__2::allocator<unsigned long>>&, unsigned long, rocksdb::SnapshotChecker*, rocksdb::LogBuffer*, rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:258:19\n    https://github.com/facebook/rocksdb/issues/15 0x5583e27a7a96 in rocksdb::DBImpl::FlushMemTablesToOutputFiles(rocksdb::autovector<rocksdb::DBImpl::BGFlushArg, 8ul> const&, bool*, rocksdb::JobContext*, rocksdb::LogBuffer*, rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:377:14\n    https://github.com/facebook/rocksdb/issues/16 0x5583e27d6777 in rocksdb::DBImpl::BackgroundFlush(bool*, rocksdb::JobContext*, rocksdb::LogBuffer*, rocksdb::FlushReason*, rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:2778:14\n    https://github.com/facebook/rocksdb/issues/17 0x5583e27d14e2 in rocksdb::DBImpl::BackgroundCallFlush(rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:2817:16\n    https://github.com/facebook/rocksdb/issues/18 0x5583e323d353 in std::__2::__function::__policy_func<void ()>::operator()[abi:ne180100]() const /root/build/3rdParty/llvm/runtimes/include/c++/v1/__functional/function.h:714:12\n    https://github.com/facebook/rocksdb/issues/19 0x5583e323d353 in std::__2::function<void ()>::operator()() const /root/build/3rdParty/llvm/runtimes/include/c++/v1/__functional/function.h:981:10\n    https://github.com/facebook/rocksdb/issues/20 0x5583e323d353 in rocksdb::ThreadPoolImpl::Impl::BGThread(unsigned long) /rocksdb/util/threadpool_imp.cc:266:5\n    https://github.com/facebook/rocksdb/issues/21 0x5583e3243d18 in decltype(std::declval<void (*)(void*)>()(std::declval<rocksdb::BGThreadMetadata*>())) std::__2::__invoke[abi:ne180100]<void (*)(void*), rocksdb::BGThreadMetadata*>(void (*&&)(void*), rocksdb::BGThreadMetadata*&&) /root/build/3rdParty/llvm/runtimes/include/c++/v1/__type_traits/invoke.h:344:25\n    https://github.com/facebook/rocksdb/issues/22 0x5583e3243d18 in void std::__2::__thread_execute[abi:ne180100]<std::__2::unique_ptr<std::__2::__thread_struct, std::__2::default_delete<std::__2::__thread_struct>>, void (*)(void*), rocksdb::BGThreadMetadata*, 2ul>(std::__2::tuple<std::__2::unique_ptr<std::__2::__thread_struct, std::__2::default_delete<std::__2::__thread_struct>>, void (*)(void*), rocksdb::BGThreadMetadata*>&, std::__2::__tuple_indices<2ul>) /root/build/3rdParty/llvm/runtimes/include/c++/v1/__thread/thread.h:193:3\n    https://github.com/facebook/rocksdb/issues/23 0x5583e3243d18 in void* std::__2::__thread_proxy[abi:ne180100]<std::__2::tuple<std::__2::unique_ptr<std::__2::__thread_struct, std::__2::default_delete<std::__2::__thread_struct>>, void (*)(void*), rocksdb::BGThreadMetadata*>>(void*) /root/build/3rdParty/llvm/runtimes/include/c++/v1/__thread/thread.h:202:3\n    https://github.com/facebook/rocksdb/issues/24 0x5583da5e819e in asan_thread_start(void*) crtstuff.c\n    https://github.com/facebook/rocksdb/issues/25 0x7f0eda362a93 in start_thread nptl/pthread_create.c:447:8\n    https://github.com/facebook/rocksdb/issues/26 0x7f0eda3efc3b in clone3 misc/../sysdeps/unix/sysv/linux/x86_64/clone3.S:78\n\n0x506000682221 is located 1 bytes inside of 56-byte region [0x506000682220,0x506000682258)\nallocated by thread T29 here:\n    #0 0x5583da6281d1 in operator new(unsigned long)\n    https://github.com/facebook/rocksdb/issues/1 0x5583da6c987d in __libcpp_operator_new<unsigned long> /root/build/3rdParty/llvm/runtimes/include/c++/v1/new:271:10\n    https://github.com/facebook/rocksdb/issues/2 0x5583da6c987d in __libcpp_allocate /root/build/3rdParty/llvm/runtimes/include/c++/v1/new:295:10\n    https://github.com/facebook/rocksdb/issues/3 0x5583da6c987d in allocate /root/build/3rdParty/llvm/runtimes/include/c++/v1/__memory/allocator.h:125:32\n    https://github.com/facebook/rocksdb/issues/4 0x5583da6c987d in allocate_at_least /root/build/3rdParty/llvm/runtimes/include/c++/v1/__memory/allocator.h:131:13\n    https://github.com/facebook/rocksdb/issues/5 0x5583da6c987d in allocate_at_least<std::__2::allocator<char> > /root/build/3rdParty/llvm/runtimes/include/c++/v1/__memory/allocate_at_least.h:34:20\n    https://github.com/facebook/rocksdb/issues/6 0x5583da6c987d in __allocate_at_least<std::__2::allocator<char> > /root/build/3rdParty/llvm/runtimes/include/c++/v1/__memory/allocate_at_least.h:42:10\n    https://github.com/facebook/rocksdb/issues/7 0x5583da6c987d in std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>>::__shrink_or_extend[abi:ne180100](unsigned long) /root/build/3rdParty/llvm/runtimes/include/c++/v1/string:3236:27\n    https://github.com/facebook/rocksdb/issues/8 0x5583e307c5aa in std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>>::reserve(unsigned long) /root/build/3rdParty/llvm/runtimes/include/c++/v1/string:3207:3\n    https://github.com/facebook/rocksdb/issues/9 0x5583e307c5aa in rocksdb::ReadFooterFromFile(rocksdb::IOOptions const&, rocksdb::RandomAccessFileReader*, rocksdb::FilePrefetchBuffer*, unsigned long, rocksdb::Footer*, unsigned long) /rocksdb/table/format.cc:382:18\n    https://github.com/facebook/rocksdb/issues/10 0x5583e2f88456 in rocksdb::BlockBasedTable::Open(rocksdb::ReadOptions const&, rocksdb::ImmutableOptions const&, rocksdb::EnvOptions const&, rocksdb::BlockBasedTableOptions const&, rocksdb::InternalKeyComparator const&, std::__2::unique_ptr<rocksdb::RandomAccessFileReader, std::__2::default_delete<rocksdb::RandomAccessFileReader>>&&, unsigned long, std::__2::unique_ptr<rocksdb::TableReader, std::__2::default_delete<rocksdb::TableReader>>*, std::__2::shared_ptr<rocksdb::CacheReservationManager>, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, bool, bool, int, bool, unsigned long, bool, rocksdb::TailPrefetchStats*, rocksdb::BlockCacheTracer*, unsigned long, std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>> const&, unsigned long) /rocksdb/table/block_based/block_based_table_reader.cc:610:9\n    https://github.com/facebook/rocksdb/issues/11 0x5583e2ef7837 in rocksdb::BlockBasedTableFactory::NewTableReader(rocksdb::ReadOptions const&, rocksdb::TableReaderOptions const&, std::__2::unique_ptr<rocksdb::RandomAccessFileReader, std::__2::default_delete<rocksdb::RandomAccessFileReader>>&&, unsigned long, std::__2::unique_ptr<rocksdb::TableReader, std::__2::default_delete<rocksdb::TableReader>>*, bool) const /rocksdb/table/block_based/block_based_table_factory.cc:599:10\n    https://github.com/facebook/rocksdb/issues/12 0x5583e2ab873c in rocksdb::TableCache::GetTableReader(rocksdb::ReadOptions const&, rocksdb::FileOptions const&, rocksdb::InternalKeyComparator const&, rocksdb::FileDescriptor const&, bool, bool, rocksdb::HistogramImpl*, std::__2::unique_ptr<rocksdb::TableReader, std::__2::default_delete<rocksdb::TableReader>>*, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, bool, int, bool, unsigned long, rocksdb::Temperature) /rocksdb/db/table_cache.cc:142:34\n    https://github.com/facebook/rocksdb/issues/13 0x5583e2aba5f6 in rocksdb::TableCache::FindTable(rocksdb::ReadOptions const&, rocksdb::FileOptions const&, rocksdb::InternalKeyComparator const&, rocksdb::FileDescriptor const&, rocksdb::Cache::Handle**, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, bool, bool, rocksdb::HistogramImpl*, bool, int, bool, unsigned long, rocksdb::Temperature) /rocksdb/db/table_cache.cc:190:16\n    https://github.com/facebook/rocksdb/issues/14 0x5583e2abb7e1 in rocksdb::TableCache::NewIterator(rocksdb::ReadOptions const&, rocksdb::FileOptions const&, rocksdb::InternalKeyComparator const&, rocksdb::FileMetaData const&, rocksdb::RangeDelAggregator*, std::__2::shared_ptr<rocksdb::SliceTransform const> const&, rocksdb::TableReader**, rocksdb::HistogramImpl*, rocksdb::TableReaderCaller, rocksdb::Arena*, bool, int, unsigned long, rocksdb::InternalKey const*, rocksdb::InternalKey const*, bool) /rocksdb/db/table_cache.cc:235:9\n    https://github.com/facebook/rocksdb/issues/15 0x5583e28d14cf in rocksdb::BuildTable(std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>> const&, rocksdb::VersionSet*, rocksdb::ImmutableDBOptions const&, rocksdb::TableBuilderOptions const&, rocksdb::FileOptions const&, rocksdb::TableCache*, rocksdb::InternalIteratorBase<rocksdb::Slice>*, std::__2::vector<std::__2::unique_ptr<rocksdb::FragmentedRangeTombstoneIterator, std::__2::default_delete<rocksdb::FragmentedRangeTombstoneIterator>>, std::__2::allocator<std::__2::unique_ptr<rocksdb::FragmentedRangeTombstoneIterator, std::__2::default_delete<rocksdb::FragmentedRangeTombstoneIterator>>>>, rocksdb::FileMetaData*, std::__2::vector<rocksdb::BlobFileAddition, std::__2::allocator<rocksdb::BlobFileAddition>>*, std::__2::vector<unsigned long, std::__2::allocator<unsigned long>>, unsigned long, unsigned long, rocksdb::SnapshotChecker*, bool, rocksdb::InternalStats*, rocksdb::IOStatus*, std::__2::shared_ptr<rocksdb::IOTracer> const&, rocksdb::BlobFileCreationReason, rocksdb::EventLogger*, int, rocksdb::Env::IOPriority, rocksdb::TableProperties*, rocksdb::Env::WriteLifeTimeHint, std::__2::basic_string<char, std::__2::char_traits<char>, std::__2::allocator<char>> const*, rocksdb::BlobFileCompletionCallback*, unsigned long*, unsigned long*, unsigned long*) /rocksdb/db/builder.cc:335:57\n    https://github.com/facebook/rocksdb/issues/16 0x5583e29bf29d in rocksdb::FlushJob::WriteLevel0Table() /rocksdb/db/flush_job.cc:919:11\n    https://github.com/facebook/rocksdb/issues/17 0x5583e29b33ac in rocksdb::FlushJob::Run(rocksdb::LogsWithPrepTracker*, rocksdb::FileMetaData*, bool*) /rocksdb/db/flush_job.cc:276:9\n    https://github.com/facebook/rocksdb/issues/18 0x5583e27a4781 in rocksdb::DBImpl::FlushMemTableToOutputFile(rocksdb::ColumnFamilyData*, rocksdb::MutableCFOptions const&, bool*, rocksdb::JobContext*, rocksdb::SuperVersionContext*, std::__2::vector<unsigned long, std::__2::allocator<unsigned long>>&, unsigned long, rocksdb::SnapshotChecker*, rocksdb::LogBuffer*, rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:258:19\n    https://github.com/facebook/rocksdb/issues/19 0x5583e27a7a96 in rocksdb::DBImpl::FlushMemTablesToOutputFiles(rocksdb::autovector<rocksdb::DBImpl::BGFlushArg, 8ul> const&, bool*, rocksdb::JobContext*, rocksdb::LogBuffer*, rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:377:14\n    https://github.com/facebook/rocksdb/issues/20 0x5583e27d6777 in rocksdb::DBImpl::BackgroundFlush(bool*, rocksdb::JobContext*, rocksdb::LogBuffer*, rocksdb::FlushReason*, rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:2778:14\n    https://github.com/facebook/rocksdb/issues/21 0x5583e27d14e2 in rocksdb::DBImpl::BackgroundCallFlush(rocksdb::Env::Priority) /rocksdb/db/db_impl/db_impl_compaction_flush.cc:2817:16\n    https://github.com/facebook/rocksdb/issues/22 0x5583e323d353 in std::__2::__function::__policy_func<void ()>::operator()[abi:ne180100]() const /root/build/3rdParty/llvm/runtimes/include/c++/v1/__functional/function.h:714:12\n    https://github.com/facebook/rocksdb/issues/23 0x5583e323d353 in std::__2::function<void ()>::operator()() const /root/build/3rdParty/llvm/runtimes/include/c++/v1/__functional/function.h:981:10\n    https://github.com/facebook/rocksdb/issues/24 0x5583e323d353 in rocksdb::ThreadPoolImpl::Impl::BGThread(unsigned long) /rocksdb/util/threadpool_imp.cc:266:5\n    https://github.com/facebook/rocksdb/issues/25 0x5583e3243d18 in decltype(std::declval<void (*)(void*)>()(std::declval<rocksdb::BGThreadMetadata*>())) std::__2::__invoke[abi:ne180100]<void (*)(void*), rocksdb::BGThreadMetadata*>(void (*&&)(void*), rocksdb::BGThreadMetadata*&&) /root/build/3rdParty/llvm/runtimes/include/c++/v1/__type_traits/invoke.h:344:25\n    https://github.com/facebook/rocksdb/issues/26 0x5583e3243d18 in void std::__2::__thread_execute[abi:ne180100]<std::__2::unique_ptr<std::__2::__thread_struct, std::__2::default_delete<std::__2::__thread_struct>>, void (*)(void*), rocksdb::BGThreadMetadata*, 2ul>(std::__2::tuple<std::__2::unique_ptr<std::__2::__thread_struct, std::__2::default_delete<std::__2::__thread_struct>>, void (*)(void*), rocksdb::BGThreadMetadata*>&, std::__2::__tuple_indices<2ul>) /root/build/3rdParty/llvm/runtimes/include/c++/v1/__thread/thread.h:193:3\n    https://github.com/facebook/rocksdb/issues/27 0x5583e3243d18 in void* std::__2::__thread_proxy[abi:ne180100]<std::__2::tuple<std::__2::unique_ptr<std::__2::__thread_struct, std::__2::default_delete<std::__2::__thread_struct>>, void (*)(void*), rocksdb::BGThreadMetadata*>>(void*) /root/build/3rdParty/llvm/runtimes/include/c++/v1/__thread/thread.h:202:3\n    https://github.com/facebook/rocksdb/issues/28 0x5583da5e819e in asan_thread_start(void*) crtstuff.c\n\nHINT: if you don't care about these errors you may set ASAN_OPTIONS=detect_container_overflow=0.\nIf you suspect a false positive see also: https://github.com/google/sanitizers/wiki/AddressSanitizerContainerOverflow.\n AddressSanitizer:container-overflow in pread\nShadow bytes around the buggy address:\n  0x506000681f80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x506000682000: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x506000682080: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x506000682100: fa fa fa fa fa fa fa fa fa fa fa fa 00 00 00 00\n  0x506000682180: 00 00 00 fa fa fa fa fa fa fa fa fa fa fa fa fa\n=>0x506000682200: fa fa fa fa[01]fc fc fc fc fc fc fa fa fa fa fa\n  0x506000682280: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x506000682300: fa fa fa fa fa fa fa fa 00 00 00 00 00 00 00 01\n  0x506000682380: fa fa fa fa fd fd fd fd fd fd fd fd fa fa fa fa\n  0x506000682400: fd fd fd fd fd fd fd fa fa fa fa fa fd fd fd fd\n  0x506000682480: fd fd fd fd fa fa fa fa fd fd fd fd fd fd fd fd\nShadow byte legend (one shadow byte represents 8 application bytes):\n  Addressable:           00\n  Partially addressable: 01 02 03 04 05 06 07\n  Heap left redzone:       fa\n  Freed heap region:       fd\n  Stack left redzone:      f1\n  Stack mid redzone:       f2\n  Stack right redzone:     f3\n  Stack after return:      f5\n  Stack use after scope:   f8\n  Global redzone:          f9\n  Global init order:       f6\n  Poisoned by user:        f7\n  Container overflow:      fc\n  Array cookie:            ac\n  Intra object redzone:    bb\n  ASan internal:           fe\n  Left alloca redzone:     ca\n  Right alloca redzone:    cb\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12722\n\nReviewed By: hx235\n\nDifferential Revision: D58118264\n\nPulled By: ajkr\n\nfbshipit-source-id: 0dd914c886c022d82697b769d664ba52de0770de",
        "modified_files_count": 1,
        "modified_files": [
            "table/format.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a8a52e5b4d938c1aea28d7a96ec70a459ffaa1a4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ReadFooterFromFile"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "e4428b7eb9b32d85495186757a13cc782f505535",
        "author": "Andrii Lysenko",
        "date": "2024-06-03T11:37:35-07:00",
        "message": "More details for 'tail prefetch size is calculated based on' (#12667)\n\nSummary:\nThese messages indicate that SST file was created by a pre-9.0.0 RocksDB. Eventually, `TailPrefetchStats` might be removed, so it would be more informative if log message also included name of the affected SST file.\n\nIssue: https://github.com/facebook/rocksdb/issues/12664\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12667\n\nReviewed By: ajkr\n\nDifferential Revision: D57464025\n\nPulled By: hx235\n\nfbshipit-source-id: 12f2f2635e3092f8c29362aa132462492b5c1417",
        "modified_files_count": 1,
        "modified_files": [
            "table/block_based/block_based_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e4428b7eb9b32d85495186757a13cc782f505535",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlockBasedTable::PrefetchTail"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "3fdc7243f3c72ac191a56cfc16b4262b86c3fcb7",
        "author": "Patrik Valo",
        "date": "2024-05-06T08:53:06-07:00",
        "message": "Fix truncating last character in the StderrLogger (#12620)\n\nSummary:\nThis PR fixes a bug in the StderrLogger that truncated the last character in the logline. The problem was that we provided an incorrect max size parameter into the vsnprintf function. The size didn't take into account the null byte that the function automatically adds.\n\nBefore fix\n```\n** File Read Latency Histogram By Level [default] **\n2024/05/04-18:50:24.209304 4788 [/db_impl/db_impl.cc:498] Shutdown: canceling all background wor\n2024/05/04-18:50:24.209598 4788 [/db_impl/db_impl.cc:692] Shutdown complet\n```\n\nAfter fix\n```\n** File Read Latency Histogram By Level [default] **\n\n2024/05/04-18:51:19.814584 4d4d [/db_impl/db_impl.cc:498] Shutdown: canceling all background work\n2024/05/04-18:51:19.815528 4d4d [/db_impl/db_impl.cc:692] Shutdown complete\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12620\n\nTest Plan:\ntested on examples/simple_example.cc with StderrLogger\nFixes: https://github.com/facebook/rocksdb/issues/12576\n\nReviewed By: jaykorean\n\nDifferential Revision: D56972332\n\nPulled By: ajkr\n\nfbshipit-source-id: 70405e8231ae6e90d24fe0b351bc8e749176bd15",
        "modified_files_count": 1,
        "modified_files": [
            "util/stderr_logger.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/3fdc7243f3c72ac191a56cfc16b4262b86c3fcb7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "StderrLogger::Logv"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "ef38d99edcf6cbcdb05cc265ee5bc58404986ba5",
        "author": "Levi Tamasi",
        "date": "2024-04-18T14:26:58-07:00",
        "message": "Sanity check the keys parameter in MultiGetEntityFromBatchAndDB (#12564)\n\nSummary:\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12564\n\nSimilarly to how `db`, `column_family`, and `results` are handled, bail out early from `WriteBatchWithIndex::MultiGetEntityFromBatchAndDB` if `keys` is `nullptr`. Note that these checks are best effort in the sense that with the current method signature, the callee has no way of reporting an error if `statuses` is `nullptr` or catching other types of invalid pointers (e.g. when `keys` and/or `results` is non-`nullptr` but do not point to a contiguous range of `num_keys` objects). We can improve this (and many similar RocksDB APIs) using `std::span` in a major release once we move to C++20.\n\nReviewed By: jaykorean\n\nDifferential Revision: D56318179\n\nfbshipit-source-id: bc7a258eda82b5f6c839f212ab824130e773a4f0",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/write_batch_with_index/write_batch_with_index.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/ef38d99edcf6cbcdb05cc265ee5bc58404986ba5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatchWithIndex::MultiGetEntityFromBatchAndDB"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "1fa5dff7d1ce7be64555e7bdc8371be562b3eac6",
        "author": "\u594f\u4e4b\u7ae0",
        "date": "2024-02-27T15:23:54-08:00",
        "message": "WriteThread::EnterAsBatchGroupLeader reorder writers (#12138)\n\nSummary:\nReorder writers list to allow a leader can take as more commits as possible to maximize the throughput of the system and reduce IOPS.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12138\n\nReviewed By: hx235\n\nDifferential Revision: D53955592\n\nPulled By: ajkr\n\nfbshipit-source-id: 4d899d038faef691b63801d9d85f5cc079b7bbb5",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_thread.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1fa5dff7d1ce7be64555e7bdc8371be562b3eac6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteThread::EnterAsBatchGroupLeader"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "2233a2f4c0161d13ed4831a7a0a45e3a0fd0f740",
        "author": "Changyu Bi",
        "date": "2024-01-26T09:12:07-08:00",
        "message": "Enhance corruption status message for record mismatch in compaction (#12297)\n\nSummary:\n... to include the actual numbers of processed and expected records, and the file number for input files. The purpose is to be able to find the offending files even when the relevant LOG file is gone.\n\nAnother change is to check the record count even when `compaction_verify_record_count` is false, and log a warning message without setting corruption status if there is a mismatch. This is consistent with how we check the record count for flush.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12297\n\nTest Plan:\nprint the status message in `DBCompactionTest.VerifyRecordCount`\n```\nbefore\nCorruption: Compaction number of input keys does not match number of keys processed.\nafter\nCompaction number of input keys does not match number of keys processed. Expected 20 but processed 10. Compaction summary: Base version 4 Base level 0, inputs: [11(2156B) 9(2156B)]\n```\n\nReviewed By: ajkr\n\nDifferential Revision: D53110130\n\nPulled By: cbi42\n\nfbshipit-source-id: 6325cbfb8f71f25ce37f23f8277ebe9264863c3b",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction/compaction_job.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/2233a2f4c0161d13ed4831a7a0a45e3a0fd0f740",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionJob::Run"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "a29db3048fbc020f16700681d9d4742ba5540d79",
        "author": "Changyu Bi",
        "date": "2024-01-22T12:15:17-08:00",
        "message": "Fix TestGetEntity failure with UDT (#12264)\n\nSummary:\nUse the read option with right timestamp and skip verification when using old timestamps.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12264\n\nTest Plan:\nI can repro with small keyspace:\n```\n./db_stress --acquire_snapshot_one_in=10000 --adaptive_readahead=0 --allow_data_in_errors=True --async_io=0 --auto_readahead_size=1 --avoid_flush_during_recovery=0 --avoid_unnecessary_blocking_io=0 --backup_max_size=104857600 --backup_one_in=1000 --batch_protection_bytes_per_key=0 --block_protection_bytes_per_key=4 --block_size=16384 --bloom_before_level=7 --bloom_bits=15 --bottommost_compression_type=xpress --bottommost_file_compaction_delay=0 --bytes_per_sync=262144 --cache_index_and_filter_blocks=1 --cache_size=33554432 --cache_type=fixed_hyper_clock_cache --charge_compression_dictionary_building_buffer=1 --charge_file_metadata=0 --charge_filter_construction=1 --charge_table_reader=1 --checkpoint_one_in=10000 --checksum_type=kXXH3 --clear_column_family_one_in=0 --compact_files_one_in=1000000 --compact_range_one_in=1000000 --compaction_pri=4 --compaction_readahead_size=0 --compaction_style=1 --compaction_ttl=0 --compressed_secondary_cache_size=16777216 --compression_checksum=1 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=1 --compression_type=snappy --compression_use_zstd_dict_trainer=0 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --data_block_index_type=1 --db_write_buffer_size=0 --delpercent=4 --delrangepercent=1 --destroy_db_initially=1 --detect_filter_construct_corruption=1 --disable_wal=0 --enable_compaction_filter=0 --enable_pipelined_write=1 --enable_thread_tracking=0 --fail_if_options_file_error=1 --fifo_allow_compaction=1 --file_checksum_impl=big --flush_one_in=1000 --format_version=2 --get_current_wal_file_one_in=0 --get_live_files_one_in=10000 --get_property_one_in=100000 --get_sorted_wal_files_one_in=0 --index_block_restart_interval=13 --index_type=0 --ingest_external_file_one_in=0 --initial_auto_readahead_size=16384 --iterpercent=10 --key_len_percent_dist=1,30,69 --level_compaction_dynamic_level_bytes=0 --lock_wal_one_in=10000 --log2_keys_per_lock=10 --long_running_snapshots=0 --manual_wal_flush_one_in=1000 --mark_for_compaction_one_file_in=0 --max_auto_readahead_size=0 --max_background_compactions=20 --max_bytes_for_level_base=10485760 --max_key=1000 --max_key_len=3 --max_manifest_file_size=16384 --max_write_batch_group_size_bytes=1048576 --max_write_buffer_number=3 --max_write_buffer_size_to_maintain=2097152 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0.01 --memtable_protection_bytes_per_key=0 --memtable_whole_key_filtering=0 --memtablerep=skip_list --min_write_buffer_number_to_merge=2 --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --num_file_reads_for_auto_readahead=1 --open_files=100 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=32 --open_write_fault_one_in=16 --ops_per_thread=200000 --optimize_filters_for_memory=0 --paranoid_file_checks=0 --partition_filters=0 --partition_pinning=2 --pause_background_one_in=1000000 --periodic_compaction_seconds=0 --persist_user_defined_timestamps=1 --prefix_size=8 --prefixpercent=5 --prepopulate_block_cache=1 --preserve_internal_time_seconds=3600 --progress_reports=0 --read_fault_one_in=0 --readahead_size=16384 --readpercent=45 --recycle_log_file_num=1 --reopen=20 --secondary_cache_fault_one_in=32 --secondary_cache_uri= --snapshot_hold_ops=100000 --sst_file_manager_bytes_per_sec=0 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=0 --subcompactions=3 --sync=0 --sync_fault_injection=0 --target_file_size_base=524288 --target_file_size_multiplier=2 --test_batches_snapshots=0 --test_cf_consistency=0 --top_level_index_pinning=1 --unpartitioned_pinning=1 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=0 --use_get_entity=1 --use_merge=0 --use_multi_get_entity=0 --use_multiget=1 --use_put_entity_one_in=0 --use_txn=0 --use_write_buffer_manager=0 --user_timestamp_size=8 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000000 --verify_db_one_in=100000 --verify_file_checksums_one_in=100000 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=524288 --wal_compression=zstd --write_buffer_size=4194304 --write_dbid_to_manifest=0 --write_fault_one_in=0 --writepercent=35 --db=/dev/shm/rocksdb_test/rocksdb_crashtest_whitebox --expected_values_dir=/dev/shm/rocksdb_test/rocksdb_crashtest_expected\n\nErrors when run with main:\nerror : inconsistent values for key 0x00000000000000E5000000000000012B000000000000014D: expected state has the key, GetEntity returns NotFound.\n\nerror : inconsistent values for key 0x0000000000000009000000000000012B0000000000000254: GetEntity returns :0x010000000504070609080B0A0D0C0F0E111013121514171619181B1A1D1C1F1E212023222524272629282B2A2D2C2F2E313033323534373639383B3A3D3C3F3E, expected state does not have the key.\n```\n\nReviewed By: jaykorean\n\nDifferential Revision: D52966251\n\nPulled By: cbi42\n\nfbshipit-source-id: 09436a1b747f1ac545140fc83a2fa4555fef51c1",
        "modified_files_count": 1,
        "modified_files": [
            "db_stress_tool/no_batched_ops_stress.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a29db3048fbc020f16700681d9d4742ba5540d79",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TestGetEntity"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "ec5b1be18dabb99acfc52872db36d9d163baea84",
        "author": "Changyu Bi",
        "date": "2024-01-19T10:13:52-08:00",
        "message": "Deflake `PerfContextTest.CPUTimer` (#12252)\n\nSummary:\nWe saw failures like\n```\ndb/perf_context_test.cc:952: Failure\nExpected: (next_count) > (count), actual: 26699 vs 26699\n```\nI can repro by running the test repeatedly and the test fails with different seek keys. So\nthe cause is likely not with Seek() implementation. I found that\n`clock_gettime(CLOCK_THREAD_CPUTIME_ID, &ts);` can return the same time when\ncalled repeatedly. However, I don't know if Seek() is fast enough that this happened during\ncontinuous test.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12252\n\nTest Plan: `gtest_parallel.py --repeat=10000 --workers=1 ./perf_context_test --gtest_filter=\"PerfContextTest.CPUTimer\"`\n\nReviewed By: ajkr\n\nDifferential Revision: D52912751\n\nPulled By: cbi42\n\nfbshipit-source-id: 8985ae93baa99cdf4b9136ea38addd2e41f4b202",
        "modified_files_count": 1,
        "modified_files": [
            "db/perf_context_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/ec5b1be18dabb99acfc52872db36d9d163baea84",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "1de69409805e196dae4daad4975f6f83080f8a7c",
        "author": "akankshamahajan",
        "date": "2024-01-05T18:10:58-08:00",
        "message": "Fix heap use after free error in FilePrefetchBuffer (#12211)\n\nSummary:\nFix heap use after free error in FilePrefetchBuffer\nFix heap use after free error in FilePrefetchBuffer\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12211\n\nTest Plan:\nRan db_stress in ASAN mode\n```\n==652957==ERROR: AddressSanitizer: heap-use-after-free on address 0x6150006d8578 at pc 0x7f91f74ae85b bp 0x7f91c25f90c0 sp 0x7f91c25f90b8\nREAD of size 8 at 0x6150006d8578 thread T48\n    #0 0x7f91f74ae85a in void __gnu_cxx::new_allocator<rocksdb::BufferInfo*>::construct<rocksdb::BufferInfo*, rocksdb::BufferInfo*&>(rocksdb::BufferInfo**, rocksdb::BufferInfo*&) /mnt/gvfs/third-party2/libgcc/c00dcc6a3e4125c7e8b248e9a79c14b78ac9e0ca/11.x/platform010/5684a5a/include/c++/trunk/ext/new_allocator.h:163\n    https://github.com/facebook/rocksdb/issues/1 0x7f91f74ae85a in void std::allocator_traits<std::allocator<rocksdb::BufferInfo*> >::construct<rocksdb::BufferInfo*, rocksdb::BufferInfo*&>(std::allocator<rocksdb::BufferInfo*>&, rocksdb::BufferInfo**, rocksdb::BufferInfo*&) /mnt/gvfs/third-party2/libgcc/c00dcc6a3e4125c7e8b248e9a79c14b78ac9e0ca/11.x/platform010/5684a5a/include/c++/trunk/bits/alloc_traits.h:512\n    https://github.com/facebook/rocksdb/issues/2 0x7f91f74ae85a in rocksdb::BufferInfo*& std::deque<rocksdb::BufferInfo*, std::allocator<rocksdb::BufferInfo*> >::emplace_back<rocksdb::BufferInfo*&>(rocksdb::BufferInfo*&) /mnt/gvfs/third-party2/libgcc/c00dcc6a3e4125c7e8b248e9a79c14b78ac9e0ca/11.x/platform010/5684a5a/include/c++/trunk/bits/deque.tcc:170\n    https://github.com/facebook/rocksdb/issues/3 0x7f91f74b93d8 in rocksdb::FilePrefetchBuffer::FreeAllBuffers() file/file_prefetch_buffer.h:557\n```\n\nReviewed By: ajkr\n\nDifferential Revision: D52575217\n\nPulled By: akankshamahajan15\n\nfbshipit-source-id: 6811ec10a393f5a62fedaff0fab5fd6e823c2687",
        "modified_files_count": 1,
        "modified_files": [
            "file/file_prefetch_buffer.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1de69409805e196dae4daad4975f6f83080f8a7c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FreeAllBuffers"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "81b6296c7e5a6a4a0241559d2de878677f160b38",
        "author": "Hui Xiao",
        "date": "2024-01-02T17:33:00-08:00",
        "message": "Pass flush IO activity enum in FlushJob::MaybeIncreaseFullHistoryTsLowToAboveCutoffUDT...() (#12197)\n\nSummary:\n**Context/Summary:** as titled\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12197\n\nTest Plan:\n```\n./db_stress --acquire_snapshot_one_in=100 --adaptive_readahead=0 --allow_concurrent_memtable_write=0 --allow_data_in_errors=True --async_io=1 --atomic_flush=0 --auto_readahead_size=1 --avoid_flush_during_recovery=0 --avoid_unnecessary_blocking_io=0 --backup_max_size=104857600 --backup_one_in=100000 --batch_protection_bytes_per_key=0 --block_protection_bytes_per_key=0 --block_size=16384 --bloom_before_level=2147483647 --bloom_bits=4.393039399748979 --bottommost_compression_type=disable --bottommost_file_compaction_delay=86400 --bytes_per_sync=262144 --cache_index_and_filter_blocks=0 --cache_size=33554432 --cache_type=fixed_hyper_clock_cache --charge_compression_dictionary_building_buffer=1 --charge_file_metadata=0 --charge_filter_construction=0 --charge_table_reader=1 --checkpoint_one_in=1000000 --checksum_type=kxxHash64 --clear_column_family_one_in=0 --compact_files_one_in=1000 --compact_range_one_in=1000 --compaction_pri=3 --compaction_readahead_size=1048576 --compaction_ttl=0 --compressed_secondary_cache_ratio=0.0 --compressed_secondary_cache_size=0 --compression_checksum=0 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=1 --compression_type=lz4hc --compression_use_zstd_dict_trainer=1 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --data_block_index_type=1 --db=/dev/shm/rocksdb_test/rocksdb_crashtest_blackbox --db_write_buffer_size=0 --delpercent=5 --delrangepercent=0 --destroy_db_initially=0 --detect_filter_construct_corruption=0 --disable_wal=0 --enable_blob_files=0 --enable_compaction_filter=0 --enable_pipelined_write=0 --enable_thread_tracking=1 --expected_values_dir=/dev/shm/rocksdb_test/rocksdb_crashtest_expected --fail_if_options_file_error=1 --fifo_allow_compaction=0 --file_checksum_impl=none --flush_one_in=1000 --format_version=6 --get_current_wal_file_one_in=0 --get_live_files_one_in=1000000 --get_property_one_in=100000 --get_sorted_wal_files_one_in=0 --index_block_restart_interval=13 --index_type=0 --ingest_external_file_one_in=0 --initial_auto_readahead_size=16384 --iterpercent=0 --key_len_percent_dist=1,30,69 --level_compaction_dynamic_level_bytes=1 --lock_wal_one_in=10000 --long_running_snapshots=0 --manual_wal_flush_one_in=0 --mark_for_compaction_one_file_in=10 --max_auto_readahead_size=524288 --max_background_compactions=20 --max_bytes_for_level_base=10485760 --max_key=100000 --max_key_len=3 --max_manifest_file_size=1073741824 --max_write_batch_group_size_bytes=64 --max_write_buffer_number=10 --max_write_buffer_size_to_maintain=8388608 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0.1 --memtable_protection_bytes_per_key=2 --memtable_whole_key_filtering=1 --memtablerep=skip_list --min_write_buffer_number_to_merge=2 --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --num_file_reads_for_auto_readahead=2 --open_files=100 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=0 --open_write_fault_one_in=16 --ops_per_thread=100000000 --optimize_filters_for_memory=0 --paranoid_file_checks=0 --partition_filters=0 --partition_pinning=2 --pause_background_one_in=10000 --periodic_compaction_seconds=0 --persist_user_defined_timestamps=0 --prefix_size=5 --prefixpercent=5 --prepopulate_block_cache=0 --preserve_internal_time_seconds=0 --progress_reports=0 --read_fault_one_in=0 --readahead_size=16384 --readpercent=55 --recycle_log_file_num=0 --reopen=0 --secondary_cache_fault_one_in=0 --set_options_one_in=10000 --snapshot_hold_ops=100000 --sst_file_manager_bytes_per_sec=0 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=10 --subcompactions=1 --sync=0 --sync_fault_injection=0 --target_file_size_base=2097152 --target_file_size_multiplier=2 --test_batches_snapshots=0 --test_cf_consistency=0 --top_level_index_pinning=3 --unpartitioned_pinning=1 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=0 --use_get_entity=0 --use_merge=0 --use_multi_get_entity=0 --use_multiget=0 --use_put_entity_one_in=0 --use_txn=0 --use_write_buffer_manager=0 --user_timestamp_size=8 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000000 --verify_db_one_in=10000 --verify_file_checksums_one_in=0 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=524288 --wal_compression=zstd --write_buffer_size=1048576 --write_dbid_to_manifest=1 --write_fault_one_in=128 --writepercent=35\n```\n\nBefore fix:\n```\ndb_stress_tool/db_stress_env_wrapper.h:92: virtual rocksdb::IOStatus rocksdb::DbStressWritableFileWrapper::Append(const rocksdb::Slice &, const rocksdb::IOOptions &, rocksdb::IODebugContext *): Assertion `io_activity == Env::IOActivity::kUnknown || io_activity == options.io_activity' failed.\n```\n\nAfter fix:\nSucceed\n\nReviewed By: ajkr\n\nDifferential Revision: D52492030\n\nPulled By: hx235\n\nfbshipit-source-id: 842a0dcbdf135838b57ddb4a3a6f1effc8dd3e82",
        "modified_files_count": 1,
        "modified_files": [
            "db/flush_job.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/81b6296c7e5a6a4a0241559d2de878677f160b38",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FlushJob::MaybeIncreaseFullHistoryTsLowToAboveCutoffUDT"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "cd21e4e69d76ec4ec3b080c8cdae016ac2309cc5",
        "author": "Levi Tamasi",
        "date": "2023-12-13T17:34:18-08:00",
        "message": "Some further cleanup in WriteBatchWithIndex::MultiGetFromBatchAndDB (#12143)\n\nSummary:\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12143\n\nhttps://github.com/facebook/rocksdb/pull/11982 changed `WriteBatchWithIndex::MultiGetFromBatchDB` to preallocate space in the `autovector`s `key_contexts` and `merges` in order to prevent any reallocations, both as an optimization and in order to prevent pointers into the container from being invalidated during subsequent insertions. On second thought, this preallocation can actually be a pessimization in cases when only a small subset of keys require querying the underlying database. To prevent any memory regressions, the PR reverts this preallocation. In addition, it makes some small code hygiene improvements like incorporating the `PinnableWideColumns` object into `MergeTuple`.\n\nReviewed By: jaykorean\n\nDifferential Revision: D52136513\n\nfbshipit-source-id: 21aa835084433feab27b501d9d1fc5434acea609",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/write_batch_with_index/write_batch_with_index.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/cd21e4e69d76ec4ec3b080c8cdae016ac2309cc5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatchWithIndex::MultiGetFromBatchAndDB"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "d68f45e777563018453c1506a94dc3a4f2cc7b82",
        "author": "Yu Zhang",
        "date": "2023-11-29T11:35:59-08:00",
        "message": "Flush buffered logs when FlushRequest is rescheduled (#12105)\n\nSummary:\nThe optimization to not find and delete obsolete files when FlushRequest is re-scheduled also inadvertently skipped flushing the `LogBuffer`, resulting in missed logs. This PR fixes the issue.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12105\n\nTest Plan:\nmanually check this test has the correct info log after the fix\n`./column_family_test --gtest_filter=ColumnFamilyRetainUDTTest.NotAllKeysExpiredFlushRescheduled`\n\nReviewed By: ajkr\n\nDifferential Revision: D51671079\n\nPulled By: jowlyzhang\n\nfbshipit-source-id: da0640e07e35c69c08988772ed611ec9e67f2e92",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl/db_impl_compaction_flush.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d68f45e777563018453c1506a94dc3a4f2cc7b82",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::BackgroundCallFlush"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "018eede679f6df74f78b158caf21f76c00c1bad7",
        "author": "Akanksha Mahajan",
        "date": "2023-10-16T15:14:58-07:00",
        "message": "Remove assertion from PrefetchAsync (#11965)\n\nSummary:\nRemove assertion from PrefetchAsync (roundup_len2 >= alignment) as for non direct_io, buffer size can be less than alignment resulting in assertion.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/11965\n\nTest Plan: Ran the issue causing db_stress without this assertion and the verification completes successfully.\n\nReviewed By: anand1976\n\nDifferential Revision: D50328955\n\nPulled By: akankshamahajan15\n\nfbshipit-source-id: 65f55ca230d2bbc63f4e2cc34c7273b22b515879",
        "modified_files_count": 1,
        "modified_files": [
            "file/file_prefetch_buffer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/018eede679f6df74f78b158caf21f76c00c1bad7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FilePrefetchBuffer::PrefetchAsync"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "99f8820054898d44e5cd5f67edd8c940ce1633bb",
        "author": "Jay Huh",
        "date": "2023-09-15T22:50:49-07:00",
        "message": "Fix test on IOActivity check for MultiGetEntity (#11850)\n\nSummary:\nAfter https://github.com/facebook/rocksdb/issues/11842  merged, we started to see some crash_test failures.\n\nThere is a flow inside `TestMultiGetEntity()` that it calls `GetEntity()` to compare the result between `MultiGetEntity()` and `GetEntity()` https://github.com/facebook/rocksdb/blob/1c6faf35871a236222bcbf0b69718ee43376a951/db_stress_tool/no_batched_ops_stress.cc#L1068-L1072\n\nHowever, IOActivity check inside DbStressRandomAccessFileWrapper was expecting IOActivity::MultiGet when GetEntity() was called. We are fixing the test by setting expected operation to be GetEntity before calling GetEntity()\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/11850\n\nTest Plan:\nError repro'ed by the following run before fix and no more error after the fix.\n\n```\n./db_stress --acquire_snapshot_one_in=10000 --adaptive_readahead=0 --allow_concurrent_memtable_write=0 --allow_data_in_errors=True --async_io=1 --auto_readahead_size=1 --avoid_flush_during_recovery=0 --avoid_unnecessary_blocking_io=1 --backup_max_size=104857600 --backup_one_in=100000 --batch_protection_bytes_per_key=8 --block_protection_bytes_per_key=0 --block_size=16384 --bloom_before_level=1 --bloom_bits=9.880688060667444 --bottommost_compression_type=zstd --bottommost_file_compaction_delay=86400 --bytes_per_sync=262144 --cache_index_and_filter_blocks=0 --cache_size=8388608 --cache_type=auto_hyper_clock_cache --charge_compression_dictionary_building_buffer=1 --charge_file_metadata=0 --charge_filter_construction=0 --charge_table_reader=1 --checkpoint_one_in=1000000 --checksum_type=kxxHash64 --clear_column_family_one_in=0 --column_families=1 --compact_files_one_in=1000000 --compact_range_one_in=1000000 --compaction_pri=3 --compaction_readahead_size=1048576 --compaction_ttl=0 --compression_checksum=0 --compression_max_dict_buffer_bytes=0 --compression_max_dict_bytes=0 --compression_parallel_threads=1 --compression_type=none --compression_use_zstd_dict_trainer=1 --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --data_block_index_type=1 --db=/dev/shm/rocksdb_test/rocksdb_crashtest_blackbox --db_write_buffer_size=0 --delpercent=4 --delrangepercent=1 --destroy_db_initially=0 --detect_filter_construct_corruption=1 --disable_wal=0 --enable_compaction_filter=0 --enable_pipelined_write=0 --enable_thread_tracking=1 --expected_values_dir=/dev/shm/rocksdb_test/rocksdb_crashtest_expected --fail_if_options_file_error=0 --fifo_allow_compaction=1 --file_checksum_impl=big --flush_one_in=1000000 --format_version=6 --get_current_wal_file_one_in=0 --get_live_files_one_in=1000000 --get_property_one_in=1000000 --get_sorted_wal_files_one_in=0 --index_block_restart_interval=4 --index_type=0 --ingest_external_file_one_in=0 --initial_auto_readahead_size=0 --iterpercent=10 --key_len_percent_dist=1,30,69 --level_compaction_dynamic_level_bytes=0 --lock_wal_one_in=1000000 --long_running_snapshots=0 --manual_wal_flush_one_in=0 --mark_for_compaction_one_file_in=0 --max_auto_readahead_size=524288 --max_background_compactions=1 --max_bytes_for_level_base=67108864 --max_key=25000000 --max_key_len=3 --max_manifest_file_size=1073741824 --max_write_batch_group_size_bytes=16777216 --max_write_buffer_number=3 --max_write_buffer_size_to_maintain=2097152 --memtable_max_range_deletions=0 --memtable_prefix_bloom_size_ratio=0 --memtable_protection_bytes_per_key=2 --memtable_whole_key_filtering=0 --memtablerep=skip_list --min_write_buffer_number_to_merge=2 --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --num_file_reads_for_auto_readahead=0 --open_files=-1 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=0 --open_write_fault_one_in=0 --ops_per_thread=100000000 --optimize_filters_for_memory=0 --paranoid_file_checks=1 --partition_filters=0 --partition_pinning=3 --pause_background_one_in=1000000 --periodic_compaction_seconds=1 --prefix_size=-1 --prefixpercent=0 --prepopulate_block_cache=0 --preserve_internal_time_seconds=0 --progress_reports=0 --read_fault_one_in=32 --readahead_size=16384 --readpercent=50 --recycle_log_file_num=1 --reopen=0 --secondary_cache_fault_one_in=0 --secondary_cache_uri=compressed_secondary_cache://capacity=8388608;enable_custom_split_merge=true --set_options_one_in=0 --snapshot_hold_ops=100000 --sst_file_manager_bytes_per_sec=104857600 --sst_file_manager_bytes_per_truncate=0 --stats_dump_period_sec=0 --subcompactions=2 --sync=0 --sync_fault_injection=1 --target_file_size_base=16777216 --target_file_size_multiplier=1 --test_batches_snapshots=0 --top_level_index_pinning=3 --unpartitioned_pinning=0 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=0 --use_get_entity=0 --use_merge=1 --use_multi_get_entity=1 --use_multiget=1 --use_put_entity_one_in=0 --user_timestamp_size=0 --value_size_mult=32 --verification_only=0 --verify_checksum=1 --verify_checksum_one_in=1000000 --verify_db_one_in=100000 --verify_file_checksums_one_in=1000000 --verify_iterator_with_expected_state_one_in=5 --verify_sst_unique_id_in_manifest=1 --wal_bytes_per_sync=524288 --wal_compression=none --write_buffer_size=33554432 --write_dbid_to_manifest=0 --writepercent=35\n```\n\nReviewed By: cbi42\n\nDifferential Revision: D49344996\n\nPulled By: jaykorean\n\nfbshipit-source-id: 8059b8127c0e3cb8af96cf222f47398413c92c50",
        "modified_files_count": 1,
        "modified_files": [
            "db_stress_tool/no_batched_ops_stress.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/99f8820054898d44e5cd5f67edd8c940ce1633bb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TestMultiGetEntity"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "f53018c0c8a312be86eb0df956e03d4c81706030",
        "author": "Hui Xiao",
        "date": "2023-08-18T17:47:22-07:00",
        "message": "Improve PrefetchTest.Basic with explicit flush and file num variable (#11720)\n\nSummary:\n**Context/Summary:** as title, should be harmless. And it's a guessed fix to https://github.com/facebook/rocksdb/issues/11717 while no repro has obtained on my end yet.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/11720\n\nTest Plan: existing tests\n\nReviewed By: cbi42\n\nDifferential Revision: D48475661\n\nPulled By: hx235\n\nfbshipit-source-id: 7c7390319f094c540e703fe2e78a8d601b7a894b",
        "modified_files_count": 1,
        "modified_files": [
            "file/prefetch_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f53018c0c8a312be86eb0df956e03d4c81706030",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_P"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "a85eccc6d6837f5ffb69427eb4074e13fa0dde10",
        "author": "Peter Dillinger",
        "date": "2023-08-10T13:05:45-07:00",
        "message": "Adjust db_stress handling of TryAgain from optimistic txn (#11691)\n\nSummary:\nWe're still getting some rare cases of 5x TryAgains in a row. Here I'm boosting the failure threshold to 10 in a row and adding more info in the output, to help us manually verify whether there's anything suspicous about the sequence of TryAgains, such as if Rollback failed to reset to new sequence numbers.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/11691\n\nTest Plan: By lowering the threshold to 2 and adjusting some other db_crashtest parameters, I was able to hit my new code and saw fresh sequence number on the subsequent TryAgain.\n\nReviewed By: cbi42\n\nDifferential Revision: D48236153\n\nPulled By: pdillinger\n\nfbshipit-source-id: c0530e969ddcf8de7348e5cf7daf5d6d5dec24f4",
        "modified_files_count": 1,
        "modified_files": [
            "db_stress_tool/db_stress_test_base.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a85eccc6d6837f5ffb69427eb4074e13fa0dde10",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "StressTest::ExecuteTransaction"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "d2b0652b32b8671c9ec4057e6da2fa564d1cc610",
        "author": "Xinye Tao",
        "date": "2023-08-07T12:29:31-07:00",
        "message": "compute compaction score once for a batch of range file deletes (#10744)\n\nSummary:\nOnly re-calculate compaction score once for a batch of deletions. Fix performance regression brought by https://github.com/facebook/rocksdb/pull/8434.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10744\n\nTest Plan:\nIn one of our production cluster that recently upgraded to RocksDB 6.29, it takes more than 10 minutes to delete files in 30,000 ranges. The RocksDB instance contains approximately 80,000 files. After this patch, the duration reduces to 100+ ms, which is on par with RocksDB 6.4.\n\nCherry-picking downstream PR: https://github.com/tikv/rocksdb/pull/316\n\nSigned-off-by: tabokie <xy.tao@outlook.com>\n\nReviewed By: cbi42\n\nDifferential Revision: D48002581\n\nPulled By: ajkr\n\nfbshipit-source-id: 7245607ee3ad79c53b648a6396c9159f166b9437",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d2b0652b32b8671c9ec4057e6da2fa564d1cc610",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::DeleteFilesInRanges"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "b8555ba470ba0592c66a3caafd4d8ea74387d565",
        "author": "Andrew Kryczka",
        "date": "2023-04-17T10:36:22-07:00",
        "message": "Deflake DBBloomFilterTest.OptimizeFiltersForHits (#11383)\n\nSummary:\nIn CircleCI build-linux-arm-test-full job (https://app.circleci.com/pipelines/github/facebook/rocksdb/26462/workflows/a9d39d2c-c970-4b0f-9c10-7743beb9771b/jobs/591722), this test exhibited the following flaky failure:\n\n```\ndb/db_bloom_filter_test.cc:2506: Failure\nExpected: (TestGetTickerCount(options, BLOOM_FILTER_USEFUL)) > (65000 * 2), actual: 120558 vs 130000\n```\n\nI ssh'd to an instance and observed it cuts memtables at slightly different points across runs. Logging in `ConcurrentArena` pointed to `try_lock()` returning false at different points across runs.\n\nThis PR changes the approach to allow a fixed number of keys per memtable flush. I verified the bloom filter useful count is deterministic now even on the CircleCI ARM instance.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/11383\n\nReviewed By: cbi42\n\nDifferential Revision: D45036829\n\nPulled By: ajkr\n\nfbshipit-source-id: b602dacb63955f1af09bf0ed409cde0552805a08",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_bloom_filter_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b8555ba470ba0592c66a3caafd4d8ea74387d565",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "760b773f58277f9ce449389c0773a1eee2d14363",
        "author": "Andrew Kryczka",
        "date": "2023-04-10T13:59:44-07:00",
        "message": "fix optimization-disabled test builds with platform010 (#11361)\n\nSummary:\nFixed the following failure:\n\n```\nthird-party/gtest-1.8.1/fused-src/gtest/gtest-all.cc: In function \u2018bool testing::internal::StackGrowsDown()\u2019:\nthird-party/gtest-1.8.1/fused-src/gtest/gtest-all.cc:8681:24: error: \u2018dummy\u2019 may be used uninitialized [-Werror=maybe-uninitialized]\n 8681 |   StackLowerThanAddress(&dummy, &result);\n      |   ~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\nthird-party/gtest-1.8.1/fused-src/gtest/gtest-all.cc:8671:13: note: by argument 1 of type \u2018const void*\u2019 to \u2018void testing::internal::StackLowerThanAddress(const void*, bool*)\u2019 declared here\n 8671 | static void StackLowerThanAddress(const void* ptr, bool* result) {\n      |             ^~~~~~~~~~~~~~~~~~~~~\nthird-party/gtest-1.8.1/fused-src/gtest/gtest-all.cc:8679:7: note: \u2018dummy\u2019 declared here\n 8679 |   int dummy;\n      |       ^~~~~\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/11361\n\nReviewed By: cbi42\n\nDifferential Revision: D44838033\n\nPulled By: ajkr\n\nfbshipit-source-id: 27d68b5a24a15723bbaaa7de45ccd70a60fe259e",
        "modified_files_count": 1,
        "modified_files": [
            "third-party/gtest-1.8.1/fused-src/gtest/gtest-all.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/760b773f58277f9ce449389c0773a1eee2d14363",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "StackGrowsDown"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "df680b24ef2bbd8c9ee8cf882baa7636bcc21be4",
        "author": "Levi Tamasi",
        "date": "2023-02-01T10:03:07-08:00",
        "message": "Clean up InvokeFilterIfNeeded a bit (#11174)\n\nSummary:\nThe patch makes some code quality enhancements in `CompactionIterator::InvokeFilterIfNeeded`\nincluding the renaming of `filter` (which is most likely a remnant of the days before the `FilterV2`\nAPI when the compaction filter used to return a boolean) to `decision`, the removal of some\noutdated comments, the elimination of an `error` flag which was only used in one failure case\nout of many, as well as some small stylistic improvements. (Some the above will also come in\nhandy when adding compaction filter support for wide-column entities.)\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/11174\n\nTest Plan: `make check`\n\nReviewed By: akankshamahajan15\n\nDifferential Revision: D42901408\n\nPulled By: ltamasi\n\nfbshipit-source-id: ab382d59a4990c5dfe1cee219d49e1d80902b666",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction/compaction_iterator.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/df680b24ef2bbd8c9ee8cf882baa7636bcc21be4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionIterator::InvokeFilterIfNeeded"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "db9cbddc6fbf95d9baee7c51ff0bda3e9d36982d",
        "author": "Andrew Kryczka",
        "date": "2022-11-22T13:07:17-08:00",
        "message": "Deflake DBTest2.TraceAndReplay by relaxing latency checks (#10979)\n\nSummary:\nSince the latency measurement uses real time it is possible for the operation to complete in zero microseconds and then fail these checks. We saw this with the operation that invokes Get() on an invalid CF. This PR relaxes the assertions to allow for operations completing in zero microseconds.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10979\n\nReviewed By: riversand963\n\nDifferential Revision: D41478300\n\nPulled By: ajkr\n\nfbshipit-source-id: 50ef096bd8f0162b31adb46f54ae6ddc337d0a5e",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test2.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/db9cbddc6fbf95d9baee7c51ff0bda3e9d36982d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "1562524e63229f41547f8d72c88001a4e259a4c3",
        "author": "Akanksha Mahajan",
        "date": "2022-11-14T16:14:41-08:00",
        "message": "Fix db_stress failure in async_io in FilePrefetchBuffer (#10949)\n\nSummary:\nFix db_stress failure in async_io in FilePrefetchBuffer.\n\nFrom the logs, assertion was caused when\n- prev_offset_ = offset but somehow prev_len != 0 and explicit_prefetch_submitted_ = true. That scenario is when we send async request to prefetch buffer during seek but in second seek that data is found in cache. prev_offset_ and prev_len_ get updated but we were not setting explicit_prefetch_submitted_ = false because of which buffers were getting out of sync.\nIt's possible a read by another thread might have loaded the block into the cache in the meantime.\n\nParticular assertion example:\n```\nprev_offset: 0, prev_len_: 8097 , offset: 0, length: 8097, actual_length: 8097 , actual_offset: 0 ,\ncurr_: 0, bufs_[curr_].offset_: 4096 ,bufs_[curr_].CurrentSize(): 48541 , async_len_to_read: 278528, bufs_[curr_].async_in_progress_: false\nsecond: 1, bufs_[second].offset_: 282624 ,bufs_[second].CurrentSize(): 0, async_len_to_read: 262144 ,bufs_[second].async_in_progress_: true ,\nexplicit_prefetch_submitted_: true , copy_to_third_buffer: false\n```\nAs we can see curr_ was expected to read 278528 but it read 48541. Also buffers are out of sync.\nAlso `explicit_prefetch_submitted_` is set true but prev_len not 0.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10949\n\nTest Plan:\n- Ran db_bench for regression to make sure there is no regression;\n- Ran db_stress failing without this fix,\n- Ran build-linux-mini-crashtest 7- 8 times locally + CircleCI\n\nReviewed By: anand1976\n\nDifferential Revision: D41257786\n\nPulled By: akankshamahajan15\n\nfbshipit-source-id: 1d100f94f8c06bbbe4cc76ca27f1bbc820c2494f",
        "modified_files_count": 1,
        "modified_files": [
            "file/file_prefetch_buffer.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1562524e63229f41547f8d72c88001a4e259a4c3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "UpdateReadPattern"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "1ee747d7950d04d324437e86448d98763b3147a9",
        "author": "Peter Dillinger",
        "date": "2022-10-13T09:08:09-07:00",
        "message": "Deflake^2 DBBloomFilterTest.OptimizeFiltersForHits (#10816)\n\nSummary:\nThis reverts https://github.com/facebook/rocksdb/issues/10792 and uses a different strategy to stabilize the test: remove the unnecessary randomness by providing a constant seed for shuffling keys.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10816\n\nTest Plan: `gtest-parallel ./db_bloom_filter_test -r1000 --gtest_filter=*ForHits*`\n\nReviewed By: jay-zhuang\n\nDifferential Revision: D40347957\n\nPulled By: pdillinger\n\nfbshipit-source-id: a270e157485cbd94ed03b80cdd21b954ebd57d57",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_bloom_filter_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1ee747d7950d04d324437e86448d98763b3147a9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "62ba5c80343e5ab097415f709f92043309c86d6e",
        "author": "Jay Zhuang",
        "date": "2022-10-10T12:34:25-07:00",
        "message": "Deflake DBBloomFilterTest.OptimizeFiltersForHits (#10792)\n\nSummary:\nThe test may fail because the L5 files may only cover small portion of the whole key range.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10792\n\nTest Plan:\n```\ngtest-parallel ./db_bloom_filter_test --gtest_filter=DBBloomFilterTest.OptimizeFiltersForHits -r 1000 -w 100\n```\n\nReviewed By: siying\n\nDifferential Revision: D40217600\n\nPulled By: siying\n\nfbshipit-source-id: 18db549184bccf5e513eaa7e31ab17385b71ef71",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_bloom_filter_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/62ba5c80343e5ab097415f709f92043309c86d6e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "f9cfc6a808c9dc3ab7366edb10368559155d5172",
        "author": "Changyu Bi",
        "date": "2022-07-06T09:30:25-07:00",
        "message": "Updated NewDataBlockIterator to not fetch compression dict for non-da\u2026 (#10310)\n\nSummary:\n\u2026ta blocks\n\nDuring MyShadow testing, ajkr helped me find out that with partitioned index and dictionary compression enabled, `PartitionedIndexIterator::InitPartitionedIndexBlock()` spent considerable amount of time (1-2% CPU) on fetching uncompression dictionary. Fetching uncompression dict was not needed since the index blocks were not compressed (and even if they were, they use empty dictionary). This should only affect use cases with partitioned index, dictionary compression and without uncompression dictionary pinned. This PR updates NewDataBlockIterator to not fetch uncompression dictionary when it is not for data blocks.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10310\n\nTest Plan:\n1. `make check`\n2. Perf benchmark: 1.5% (143950 -> 146176) improvement in op/sec for partitioned index + dict compression benchmark.\nFor default config without partitioned index and without dict compression, there is no regression in readrandom perf from multiple runs of db_bench.\n\n```\n# Set up for partitioned index with dictionary compression\nTEST_TMPDIR=/dev/shm ./db_bench_main -benchmarks=filluniquerandom,compact -max_background_jobs=24 -memtablerep=vector -allow_concurrent_memtable_write=false -partition_index=true  -compression_max_dict_bytes=16384 -compression_zstd_max_train_bytes=1638400\n\n# Pre PR\nTEST_TMPDIR=/dev/shm ./db_bench_main -use_existing_db=true -benchmarks=readrandom[-X50] -partition_index=true\nreadrandom [AVG    50 runs] : 143950 (\u00b1 1108) ops/sec;   15.9 (\u00b1 0.1) MB/sec\nreadrandom [MEDIAN 50 runs] : 144406 ops/sec;   16.0 MB/sec\n\n# Post PR\nTEST_TMPDIR=/dev/shm ./db_bench_opt -use_existing_db=true -benchmarks=readrandom[-X50] -partition_index=true\nreadrandom [AVG    50 runs] : 146176 (\u00b1 1121) ops/sec;   16.2 (\u00b1 0.1) MB/sec\nreadrandom [MEDIAN 50 runs] : 146014 ops/sec;   16.2 MB/sec\n\n# Set up for no partitioned index and no dictionary compression\nTEST_TMPDIR=/dev/shm/baseline ./db_bench_main -benchmarks=filluniquerandom,compact -max_background_jobs=24 -memtablerep=vector -allow_concurrent_memtable_write=false\n# Pre PR\nTEST_TMPDIR=/dev/shm/baseline/ ./db_bench_main --use_existing_db=true \"--benchmarks=readrandom[-X50]\"\nreadrandom [AVG    50 runs] : 158546 (\u00b1 1000) ops/sec;   17.5 (\u00b1 0.1) MB/sec\nreadrandom [MEDIAN 50 runs] : 158280 ops/sec;   17.5 MB/sec\n\n# Post PR\nTEST_TMPDIR=/dev/shm/baseline/ ./db_bench_opt --use_existing_db=true \"--benchmarks=readrandom[-X50]\"\nreadrandom [AVG    50 runs] : 161061 (\u00b1 1520) ops/sec;   17.8 (\u00b1 0.2) MB/sec\nreadrandom [MEDIAN 50 runs] : 161596 ops/sec;   17.9 MB/sec\n```\n\nReviewed By: ajkr\n\nDifferential Revision: D37631358\n\nPulled By: cbi42\n\nfbshipit-source-id: 6ca2665e270e63871968e061ba4a99d3136785d9",
        "modified_files_count": 1,
        "modified_files": [
            "table/block_based/block_based_table_reader_impl.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f9cfc6a808c9dc3ab7366edb10368559155d5172",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlockBasedTable::NewDataBlockIterator"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "2e5a323dbd4dbfad5b1e3d45d489e6dca37f4257",
        "author": "Ali Saidi",
        "date": "2022-06-15T13:08:11-07:00",
        "message": "Change the instruction used for a pause on arm64 (#10118)\n\nSummary:\nWhile the yield instruction conseptually sounds correct on most platforms it is\na simple nop that doesn't delay the execution anywhere close to what an x86\npause instruction does. In other projects with spin-wait loops an isb has been\nobserved to be much closer to the x86 behavior.\n\nOn a Graviton3 system the following test improves on average by 2x with this\nchange averaged over 20 runs:\n\n```\n./db_bench  -benchmarks=fillrandom -threads=64 -batch_size=1\n-memtablerep=skip_list -value_size=100 --num=100000\nlevel0_slowdown_writes_trigger=9999 -level0_stop_writes_trigger=9999\n-disable_auto_compactions --max_write_buffer_number=8 -max_background_flushes=8\n--disable_wal --write_buffer_size=160000000 --block_size=16384\n--allow_concurrent_memtable_write -compression_type none\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10118\n\nReviewed By: jay-zhuang\n\nDifferential Revision: D37120578\n\nfbshipit-source-id: c20bde4298222edfab7ff7cb6d42497e7012400d",
        "modified_files_count": 1,
        "modified_files": [
            "port/port_posix.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/2e5a323dbd4dbfad5b1e3d45d489e6dca37f4257",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AsmVolatilePause"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "f3bcac39a601585dadbf27f632522bb48d622d13",
        "author": "Akanksha Mahajan",
        "date": "2022-04-11T10:56:11-07:00",
        "message": "Fix stress test failure in ReadAsync. (#9824)\n\nSummary:\nFix stress test failure in ReadAsync by ignoring errors\ninjected during async read by FaultInjectionFS.\nFailure:\n```\n WARNING: prefix_size is non-zero but memtablerep != prefix_hash\nDidn't get expected error from MultiGet.\nnum_keys 14 Expected 1 errors, seen 0\nCallstack that injected the fault\nInjected error type = 32538\nMessage: error;\n#0   ./db_stress() [0x6f7dd4] rocksdb::port::SaveStack(int*, int)\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/port/stack_trace.cc:152\nhttps://github.com/facebook/rocksdb/issues/1   ./db_stress() [0x7f2bda] rocksdb::FaultInjectionTestFS::InjectThreadSpecificReadError(rocksdb::FaultInjectionTestFS::ErrorOperation, rocksdb::Slice*, bool, char*, bool, bool*)\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/utilities/fault_injection_fs.cc:891\nhttps://github.com/facebook/rocksdb/issues/2   ./db_stress() [0x7f2e78] rocksdb::TestFSRandomAccessFile::Read(unsigned long, unsigned long, rocksdb::IOOptions const&, rocksdb::Slice*, char*, rocksdb::IODebugContext*) const\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/utilities/fault_injection_fs.cc:367\nhttps://github.com/facebook/rocksdb/issues/3   ./db_stress() [0x6483d7] rocksdb::(anonymous namespace)::CompositeRandomAccessFileWrapper::Read(unsigned long, unsigned long, rocksdb::Slice*, char*) const\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/env/composite_env.cc:61\nhttps://github.com/facebook/rocksdb/issues/4   ./db_stress() [0x654564] rocksdb::(anonymous namespace)::LegacyRandomAccessFileWrapper::Read(unsigned long, unsigned long, rocksdb::IOOptions const&, rocksdb::Slice*, char*, rocksdb::IODebugContext*) const\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/env/env.cc:152\nhttps://github.com/facebook/rocksdb/issues/5   ./db_stress() [0x659b3b] rocksdb::FSRandomAccessFile::ReadAsync(rocksdb::FSReadRequest&, rocksdb::IOOptions const&, std::function<void (rocksdb::FSReadRequest const&, void*)>, void*, void**, std::function<void (void*)>*, rocksdb::IODebugContext*)\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/./include/rocksdb/file_system.h:896\nhttps://github.com/facebook/rocksdb/issues/6   ./db_stress() [0x8b8bab] rocksdb::RandomAccessFileReader::ReadAsync(rocksdb::FSReadRequest&, rocksdb::IOOptions const&, std::function<void (rocksdb::FSReadRequest const&, void*)>, void*, void**, std::function<void (void*)>*, rocksdb::Env::IOPriority)\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/file/random_access_file_reader.cc:459\nhttps://github.com/facebook/rocksdb/issues/7   ./db_stress() [0x8b501f] rocksdb::FilePrefetchBuffer::ReadAsync(rocksdb::IOOptions const&, rocksdb::RandomAccessFileReader*, rocksdb::Env::IOPriority, unsigned long, unsigned long, unsigned long, unsigned int)\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/file/file_prefetch_buffer.cc:124\nhttps://github.com/facebook/rocksdb/issues/8   ./db_stress() [0x8b55fc] rocksdb::FilePrefetchBuffer::PrefetchAsync(rocksdb::IOOptions const&, rocksdb::RandomAccessFileReader*, unsigned long, unsigned long, unsigned long, rocksdb::Env::IOPriority, bool&)\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/file/file_prefetch_buffer.cc:363\nhttps://github.com/facebook/rocksdb/issues/9   ./db_stress() [0x8b61f8] rocksdb::FilePrefetchBuffer::TryReadFromCacheAsync(rocksdb::IOOptions const&, rocksdb::RandomAccessFileReader*, unsigned long, unsigned long, rocksdb::Slice*, rocksdb::Status*, rocksdb::Env::IOPriority, bool)\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/file/file_prefetch_buffer.cc:482\nhttps://github.com/facebook/rocksdb/issues/10  ./db_stress() [0x745e04] rocksdb::BlockFetcher::TryGetFromPrefetchBuffer()\t/data/sandcastle/boxes/trunk-hg-fbcode-fbsource/fbcode/internal_repo_rocksdb/repo/table/block_fetcher.cc:76\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/9824\n\nTest Plan:\n```\n./db_stress --acquire_snapshot_one_in=10000 --adaptive_readahead=1 --allow_concurrent_memtable_write=0 --async_io=1 --atomic_flush=1 --avoid_flush_during_recovery=0 --avoid_unnecessary_blocking_io=0 -- backup_max_size=104857600 --backup_one_in=100000 --batch_protection_bytes_per_key=0 --block_size=16384 --bloom_bits=5.037629726741734 --bottommost_compression_type=lz4hc --cache_index_and_filter_blocks=0 --cache_size=8388608 --checkpoint_one_in=1000000 --checksum_type=kxxHash --clear_column_family_one_in=0 --column_families=1 --compact_files_one_in=1000000 --compact_range_one_in=1000000 --compaction_ttl=100 --compression_max_dict_buffer_bytes=1073741823 --compression_max_dict_bytes=16384 --compression_parallel_threads=1 --compression_type=zstd --compression_zstd_max_train_bytes=0 --continuous_verification_interval=0 --db=/home/akankshamahajan/dev/shm/rocksdb/rocksdb_crashtest_blackbox --db_write_buffer_size=8388608 --delpercent=0 --delrangepercent=0 --destroy_db_initially=0 - detect_filter_construct_corruption=1 --disable_wal=1 --enable_compaction_filter=0 --enable_pipelined_write=0 --expected_values_dir=/home/akankshamahajan/dev/shm/rocksdb/rocksdb_crashtest_expected --experimental_mempurge_threshold=8.772789063014715 --fail_if_options_file_error=0 --file_checksum_impl=crc32c --flush_one_in=1000000 --format_version=3 --get_current_wal_file_one_in=0 --get_live_files_one_in=1000000 --get_property_one_in=1000000 --get_sorted_wal_files_one_in=0 --index_block_restart_interval=15 --index_type=3 --iterpercent=0 --key_len_percent_dist=1,30,69 --level_compaction_dynamic_level_bytes=False --long_running_snapshots=0 --mark_for_compaction_one_file_in=0 --max_background_compactions=1 --max_bytes_for_level_base=67108864 --max_key=25000000 --max_key_len=3 --max_manifest_file_size=1073741824 --max_write_batch_group_size_bytes=16777216 --max_write_buffer_number=3 --max_write_buffer_size_to_maintain=2097152 --memtable_prefix_bloom_size_ratio=0.001 --memtable_whole_key_filtering=1 --memtablerep=skip_list --mmap_read=0 --mock_direct_io=True --nooverwritepercent=1 --open_files=-1 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=0 --open_write_fault_one_in=0 --ops_per_thread=100000000 --optimize_filters_for_memory=0 --paranoid_file_checks=1 --partition_filters=0 --partition_pinning=2 --pause_background_one_in=1000000 --periodic_compaction_seconds=1000 --prefix_size=-1 --prefixpercent=0 --prepopulate_block_cache=0 --progress_reports=0 --read_fault_one_in=32 --readpercent=100 --recycle_log_file_num=1 --reopen=0 --reserve_table_reader_memory=1 --ribbon_starting_level=999 --secondary_cache_fault_one_in=0 --set_options_one_in=0 --snapshot_hold_ops=100000 --sst_file_manager_bytes_per_sec=0 --sst_file_manager_bytes_per_truncate=0 --subcompactions=2 --sync=0 --sync_fault_injection=False --target_file_size_base=16777216 --target_file_size_multiplier=1 --test_batches_snapshots=0 --top_level_index_pinning=3 --unpartitioned_pinning=2 --use_block_based_filter=0 --use_clock_cache=0 --use_direct_io_for_flush_and_compaction=1 --use_direct_reads=0 --use_full_merge_v1=0 --use_merge=1 --use_multiget=1 --user_timestamp_size=0 --value_size_mult=32 --verify_checksum=1 --verify_checksum_one_in=1000000 --verify_db_one_in=100000 --wal_compression=none --write_buffer_size=33554432 --write_dbid_to_manifest=1 --write_fault_one_in=0 --writepercent=0\n```\n\nReviewed By: anand1976\n\nDifferential Revision: D35514566\n\nPulled By: akankshamahajan15\n\nfbshipit-source-id: e2a868fdd7422604774c1419738f9926a21e92a4",
        "modified_files_count": 1,
        "modified_files": [
            "file/file_prefetch_buffer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f3bcac39a601585dadbf27f632522bb48d622d13",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FilePrefetchBuffer::PrefetchAsyncCallback"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "3fc2eaf5612de7077446a55a00ba80744ccd0ce6",
        "author": "Akanksha Mahajan",
        "date": "2022-04-07T10:31:50-07:00",
        "message": "Fix valgrind test failure for async read (#9819)\n\nSummary:\nSince all plaftorms don't support io_uring. So updated the unit\ntest to take that into consideration when testing async reads in unit tests.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/9819\n\nTest Plan:\nvalgrind --error-exitcode=2 --leak-check=full ./prefetch_test\n--gtest_filter=PrefetchTest2.ReadAsyncWithPosixFS\nCircleCI jobs\n\nReviewed By: pdillinger\n\nDifferential Revision: D35469959\n\nPulled By: akankshamahajan15\n\nfbshipit-source-id: b170459ec816487fc0a13b1d55dbbe4f754b2eba",
        "modified_files_count": 1,
        "modified_files": [
            "file/prefetch_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/3fc2eaf5612de7077446a55a00ba80744ccd0ce6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "791723c1ec828baba4d2be825f6eb10541c834d8",
        "author": "Andrew Kryczka",
        "date": "2021-12-20T13:05:23-08:00",
        "message": "Fix race condition in db_stress thread setup (#9314)\n\nSummary:\nWe need to grab `SharedState`'s mutex while calling `IncThreads()` or `IncBgThreads()`. Otherwise the newly launched threads can simultaneously access the thread counters to check if every thread has finished initializing.\n\nRepro command:\n\n```\n$ rm -rf /dev/shm/rocksdb/rocksdb_crashtest_{whitebox,expected}/ && mkdir -p /dev/shm/rocksdb/rocksdb_crashtest_{whitebox,expected}/ && ./db_stress --acquire_snapshot_one_in=10000 --atomic_flush=1 --avoid_flush_during_recovery=0 --avoid_unnecessary_blocking_io=1 --backup_max_size=104857600 --backup_one_in=100000 --batch_protection_bytes_per_key=0 --block_size=16384 --bloom_bits=131.8094496796033 --bottommost_compression_type=zlib --cache_index_and_filter_blocks=1 --cache_size=1048576 --checkpoint_one_in=1000000 --checksum_type=kCRC32c --clear_column_family_one_in=0 --compact_files_one_in=1000000 --compact_range_one_in=1000000 --compaction_style=1 --compaction_ttl=0 --compression_max_dict_buffer_bytes=134217727 --compression_max_dict_bytes=16384 --compression_parallel_threads=1 --compression_type=zstd --compression_zstd_max_train_bytes=65536 --continuous_verification_interval=0 --db=/dev/shm/rocksdb/rocksdb_crashtest_whitebox --db_write_buffer_size=8388608 --delpercent=5 --delrangepercent=0 --destroy_db_initially=0 --disable_wal=1 --enable_compaction_filter=0 --enable_pipelined_write=0 --fail_if_options_file_error=1 --file_checksum_impl=crc32c --flush_one_in=1000000 --format_version=5 --get_current_wal_file_one_in=0 --get_live_files_one_in=1000000 --get_property_one_in=1000000 --get_sorted_wal_files_one_in=0 --index_block_restart_interval=15 --index_type=3 --iterpercent=10 --key_len_percent_dist=1,30,69 --level_compaction_dynamic_level_bytes=True --log2_keys_per_lock=22 --long_running_snapshots=0 --mark_for_compaction_one_file_in=10 --max_background_compactions=20 --max_bytes_for_level_base=10485760 --max_key=1000000 --max_key_len=3 --max_manifest_file_size=1073741824 --max_write_batch_group_size_bytes=1048576 --max_write_buffer_number=3 --max_write_buffer_size_to_maintain=4194304 --memtablerep=skip_list --mmap_read=1 --mock_direct_io=False --nooverwritepercent=1 --open_files=500000 --open_metadata_write_fault_one_in=0 --open_read_fault_one_in=32 --open_write_fault_one_in=0 --ops_per_thread=20000 --optimize_filters_for_memory=1 --paranoid_file_checks=0 --partition_filters=0 --partition_pinning=0 --pause_background_one_in=1000000 --periodic_compaction_seconds=0 --prefixpercent=5 --prepopulate_block_cache=1 --progress_reports=0 --read_fault_one_in=1000 --readpercent=45 --recycle_log_file_num=1 --reopen=0 --ribbon_starting_level=999 --secondary_cache_fault_one_in=32 --snapshot_hold_ops=100000 --sst_file_manager_bytes_per_sec=104857600 --sst_file_manager_bytes_per_truncate=1048576 --subcompactions=2 --sync=0 --sync_fault_injection=False --target_file_size_base=2097152 --target_file_size_multiplier=2 --test_batches_snapshots=1 --test_cf_consistency=1 --top_level_index_pinning=0 --unpartitioned_pinning=0 --use_block_based_filter=1 --use_clock_cache=0 --use_direct_io_for_flush_and_compaction=0 --use_direct_reads=0 --use_full_merge_v1=1 --use_merge=0 --use_multiget=1 --user_timestamp_size=0 --verify_checksum=1 --verify_checksum_one_in=1000000 --verify_db_one_in=100000 --write_buffer_size=1048576 --write_dbid_to_manifest=1 --write_fault_one_in=0 --writepercent=35\n```\n\nTSAN error:\n\n```\nWARNING: ThreadSanitizer: data race (pid=2750142)\n  Read of size 4 at 0x7ffc21d7f58c by thread T39 (mutexes: write M670895590377780496):\n    #0 rocksdb::SharedState::AllInitialized() const db_stress_tool/db_stress_shared_state.h:204 (db_stress+0x4fd307)\n    https://github.com/facebook/rocksdb/issues/1 rocksdb::ThreadBody(void*) db_stress_tool/db_stress_driver.cc:26 (db_stress+0x4fd307)\n    https://github.com/facebook/rocksdb/issues/2 StartThreadWrapper env/env_posix.cc:454 (db_stress+0x84472f)\n\n  Previous write of size 4 at 0x7ffc21d7f58c by main thread:\n    #0 rocksdb::SharedState::IncThreads() db_stress_tool/db_stress_shared_state.h:194 (db_stress+0x4fd779)\n    https://github.com/facebook/rocksdb/issues/1 rocksdb::RunStressTest(rocksdb::StressTest*) db_stress_tool/db_stress_driver.cc:78 (db_stress+0x4fd779)\n    https://github.com/facebook/rocksdb/issues/2 rocksdb::db_stress_tool(int, char**) db_stress_tool/db_stress_tool.cc:348 (db_stress+0x4b97dc)\n    https://github.com/facebook/rocksdb/issues/3 main db_stress_tool/db_stress.cc:21 (db_stress+0x47a351)\n\n  Location is stack of main thread.\n\n  Location is global '<null>' at 0x000000000000 ([stack]+0x00000001d58c)\n\n  Mutex M670895590377780496 is already destroyed.\n\n  Thread T39 (tid=2750211, running) created by main thread at:\n    #0 pthread_create /home/engshare/third-party2/gcc/9.x/src/gcc-10.x/libsanitizer/tsan/tsan_interceptors.cc:964 (libtsan.so.0+0x613c3)\n    https://github.com/facebook/rocksdb/issues/1 StartThread env/env_posix.cc:464 (db_stress+0x8463c2)\n    https://github.com/facebook/rocksdb/issues/2 rocksdb::CompositeEnvWrapper::StartThread(void (*)(void*), void*) env/composite_env_wrapper.h:288 (db_stress+0x4bcd20)\n    https://github.com/facebook/rocksdb/issues/3 rocksdb::EnvWrapper::StartThread(void (*)(void*), void*) include/rocksdb/env.h:1475 (db_stress+0x4bb950)\n    https://github.com/facebook/rocksdb/issues/4 rocksdb::RunStressTest(rocksdb::StressTest*) db_stress_tool/db_stress_driver.cc:80 (db_stress+0x4fd9d2)\n    https://github.com/facebook/rocksdb/issues/5 rocksdb::db_stress_tool(int, char**) db_stress_tool/db_stress_tool.cc:348 (db_stress+0x4b97dc)\n    https://github.com/facebook/rocksdb/issues/6 main db_stress_tool/db_stress.cc:21 (db_stress+0x47a351)\n\n ThreadSanitizer: data race db_stress_tool/db_stress_shared_state.h:204 in rocksdb::SharedState::AllInitialized() const\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/9314\n\nTest Plan: verified repro command works after this PR.\n\nReviewed By: jay-zhuang\n\nDifferential Revision: D33217698\n\nPulled By: ajkr\n\nfbshipit-source-id: 79358fe5adb779fc9dcf80643cc102d4b467fc38",
        "modified_files_count": 1,
        "modified_files": [
            "db_stress_tool/db_stress_driver.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/791723c1ec828baba4d2be825f6eb10541c834d8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RunStressTest"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "8f4f302316017fd89a2dbf4f965b797b8a85210e",
        "author": "Yanqin Jin",
        "date": "2021-10-31T22:08:48-07:00",
        "message": "Attempt to deflake DBFlushTest.FireOnFlushCompletedAfterCommittedResult (#9083)\n\nSummary:\nDBFlushTest.FireOnFlushCompletedAfterCommittedResult uses test sync\npoints to coordinate interleaving of different threads. Before this PR,\nthe test writes some data to memtable, triggers a manual flush, and\ntriggers a second manual flush after a first bg flush thread starts\nexecuting. Though unlikely, it is possible for the second bg flush\nthread to run faster than the first bg flush thread and deques flush\nqueue first. In this case, the original test will fail.\nThe fix is to wait until the first bg flush thread deques the flush\nqueue before triggering second manual flush.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/9083\n\nTest Plan: ./db_flush_test --gtest_filter=DBFlushTest.FireOnFlushCompletedAfterCommittedResult\n\nReviewed By: jay-zhuang\n\nDifferential Revision: D31951239\n\nPulled By: riversand963\n\nfbshipit-source-id: f32d7cdabe6ad6808fd18e54e663936dc0a9edb4",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_flush_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/8f4f302316017fd89a2dbf4f965b797b8a85210e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "f053851af643755dc2ee252f92e3853b30a12be3",
        "author": "sdong",
        "date": "2021-10-19T12:48:18-07:00",
        "message": "Ignore non-overlapping levels when determinig grandparent files (#9051)\n\nSummary:\nRight now, when picking a compaction, grand parent files are from output_level + 1. This usually works, but if the level doesn't have any overlapping file, it will be more efficient to go further down. This is because the files are likely to be trivial moved further and might create a violation of max_compaction_bytes. This situation can naturally happen and might happen even more with TTL compactions. There is no harm to fix it.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/9051\n\nTest Plan: Run existing tests and see it passes. Also briefly run crash test.\n\nReviewed By: ajkr\n\nDifferential Revision: D31748829\n\nfbshipit-source-id: 52b99ab4284dc816d22f34406d528a3c98ff6719",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction/compaction_picker.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f053851af643755dc2ee252f92e3853b30a12be3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionPicker::GetGrandparents"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "c268859aaac3bf9d7ee854d9888ae36e89ccab20",
        "author": "anand76",
        "date": "2021-08-04T15:48:54-07:00",
        "message": "Remove corruption error injection in FaultInjectionTestFS (#8616)\n\nSummary:\n```FaultInjectionTestFS``` injects various types of read errors in ```FileSystem``` APIs. One type of error is corruption errors, where data is intentionally corrupted or truncated. There is corresponding validation in db_stress to verify that an injected error results in a user visible Get/MultiGet error. However, for corruption errors, its hard to know when a corruption is supposed to be detected by the user request, due to prefetching and, in case of direct IO, padding. This results in false positives. So remove that functionality.\n\nBlock checksum validation for Get/MultiGet is confined to ```BlockFetcher```, so we don't lose a lot by disabling this since its a small surface area to test.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/8616\n\nReviewed By: zhichao-cao\n\nDifferential Revision: D30074422\n\nPulled By: anand1976\n\nfbshipit-source-id: 6a61fac18f95514c15364b75013799ddf83294df",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/fault_injection_fs.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/c268859aaac3bf9d7ee854d9888ae36e89ccab20",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FaultInjectionTestFS::InjectThreadSpecificReadError"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "d5f3b77f23b2fbd887f6af045d5f8785ba4caa9c",
        "author": "Peter Dillinger",
        "date": "2021-07-19T08:10:29-07:00",
        "message": "Add GetMapProperty to db_stress (#8551)\n\nSummary:\nAlready has good coverage for GetProperty and GetIntProperty\nbut this one was missing.\n\nThis should add more confidence to https://github.com/facebook/rocksdb/issues/8538\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/8551\n\nTest Plan:\nbrief local run with boosted probability showed no immediate\nissues\n\nReviewed By: siying\n\nDifferential Revision: D29746383\n\nPulled By: pdillinger\n\nfbshipit-source-id: 9f9f525bc1a7607f85e563e33bda1979ef197127",
        "modified_files_count": 1,
        "modified_files": [
            "db_stress_tool/db_stress_test_base.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d5f3b77f23b2fbd887f6af045d5f8785ba4caa9c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "StressTest::TestGetProperty"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "ce0fc71adf5b767694d3c2d7f3125792110f75bf",
        "author": "sdong",
        "date": "2021-05-19T10:28:08-07:00",
        "message": "Minor improvements in env_test (#8317)\n\nSummary:\nFix typo in comments in env_test and add PermitUncheckedError() to two statuses.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/8317\n\nReviewed By: jay-zhuang\n\nDifferential Revision: D28525093\n\nfbshipit-source-id: 7a1ed3e45b6f500b8d2ae19fa339c9368111e922",
        "modified_files_count": 1,
        "modified_files": [
            "env/env_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/ce0fc71adf5b767694d3c2d7f3125792110f75bf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "11c4be2222e9a26c43a965b907b30d4c8e269a67",
        "author": "Yanqin Jin",
        "date": "2020-12-08T02:37:38-08:00",
        "message": "Refactor ProcessManifestWrites a little bit (#7751)\n\nSummary:\nThis PR removes a nested loop inside ProcessManifestWrites. The new\nimplementation has the same behavior as the old code with simpler logic\nand lower complexity.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/7751\n\nTest Plan:\nmake check\nRun make crash_test on devserver and succeeds 3 times.\n\nReviewed By: ltamasi\n\nDifferential Revision: D25363526\n\nPulled By: riversand963\n\nfbshipit-source-id: 27e681949dacd7501a752e5e517b9e85b54ccb2e",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_set.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/11c4be2222e9a26c43a965b907b30d4c8e269a67",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionSet::ProcessManifestWrites"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "b005f9693768a4a33eb5e108f43242cba1e4ecb5",
        "author": "rockeet",
        "date": "2020-09-23T09:53:24-07:00",
        "message": "db_iter.cc: DBIter::Next(): minor improve (#7407)\n\nSummary: Pull Request resolved: https://github.com/facebook/rocksdb/pull/7407\n\nReviewed By: ajkr\n\nDifferential Revision: D23817122\n\nPulled By: jay-zhuang\n\nfbshipit-source-id: 62bf43e4d780fad8c682edd750b4800b5b8f4a77",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_iter.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b005f9693768a4a33eb5e108f43242cba1e4ecb5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBIter::Next"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "4a60cb20ad384e9a847e945f46493a47691019ae",
        "author": "Jason Volk",
        "date": "2020-07-22T15:03:22-07:00",
        "message": "Fix bug in MultiRead() coalescing introduced in 4fc216649d (#6446). (#6979)\n\nSummary:\nTryMerge() overzealously creates one huge file read request in an attempt to merge smaller disjoint requests. For example, ~30 input requests of ~100 bytes output as 1 request of 100 MiB causing alarmingly large read throughputs to be repeatedly observed by the environment.\n\nSigned-off-by: Jason Volk <jason@zemos.net>\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/6979\n\nReviewed By: siying\n\nDifferential Revision: D22668892\n\nPulled By: cheng-chang\n\nfbshipit-source-id: 7506fe9621b7f1a747dadf6b8ddb1b1a141c1937",
        "modified_files_count": 1,
        "modified_files": [
            "file/random_access_file_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4a60cb20ad384e9a847e945f46493a47691019ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TryMerge"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "4b107ceb7ebdf0d2b04443f7ced89587adc291d8",
        "author": "Peter Dillinger",
        "date": "2020-07-06T16:17:02-07:00",
        "message": "Improve code comments in EstimateLiveDataSize (#7072)\n\nSummary: Pull Request resolved: https://github.com/facebook/rocksdb/pull/7072\n\nReviewed By: ajkr\n\nDifferential Revision: D22391641\n\nPulled By: pdillinger\n\nfbshipit-source-id: 0ef355576454514263ab684eb1a5c06787f3242a",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_set.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4b107ceb7ebdf0d2b04443f7ced89587adc291d8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionStorageInfo::EstimateLiveDataSize"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "946c43a026bc8855e200bcce888b8aeb6a6b0390",
        "author": "Yanqin Jin",
        "date": "2020-01-06T10:57:22-08:00",
        "message": "Improve error msg for SstFileWriter Merge (#6261)\n\nSummary:\nReword the error message when keys are not added in strict ascending order.\nSpecifically, original error message is not clear when application tries to\ncall SstFileWriter::Merge() with duplicate keys.\n\nTest plan (dev server)\n```\nmake check\n```\nPull Request resolved: https://github.com/facebook/rocksdb/pull/6261\n\nDifferential Revision: D19290398\n\nPulled By: riversand963\n\nfbshipit-source-id: 4dc30a701414e6894db2eb024e3734470c22b371",
        "modified_files_count": 1,
        "modified_files": [
            "table/sst_file_writer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/946c43a026bc8855e200bcce888b8aeb6a6b0390",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Add"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "111ebf3161e3ef03986f02a16f1b2207be2567fe",
        "author": "sdong",
        "date": "2019-11-06T17:38:25-08:00",
        "message": "db_stress: improve TestGet() failure printing (#5989)\n\nSummary:\nRight now, in db_stress's CF consistency test's TestGet case, if failure happens, we do normal string printing, rather than hex printing, so that some text is not printed out, which makes debugging harder. Fix it by printing hex instead.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5989\n\nTest Plan: Build db_stress and see t passes.\n\nDifferential Revision: D18363552\n\nfbshipit-source-id: 09d1b8f6fbff37441cbe7e63a1aef27551226cec",
        "modified_files_count": 1,
        "modified_files": [
            "tools/db_stress_tool.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/111ebf3161e3ef03986f02a16f1b2207be2567fe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TestGet"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "672befea2a514e32c8506389883f552129d2d5eb",
        "author": "Yanqin Jin",
        "date": "2019-08-30T12:42:01-07:00",
        "message": "Fix assertion failure in FIFO compaction with TTL (#5754)\n\nSummary:\nBefore this PR, the following sequence of events can cause assertion failure as shown below.\nStack trace (partial):\n```\n(gdb) bt\n2  0x00007f59b350ad15 in __assert_fail_base (fmt=<optimized out>, assertion=assertion@entry=0x9f8390 \"mark_as_compacted ? !inputs_[i][j]->being_compacted : inputs_[i][j]->being_compacted\", file=file@entry=0x9e347c \"db/compaction/compaction.cc\", line=line@entry=395, function=function@entry=0xa21ec0 <rocksdb::Compaction::MarkFilesBeingCompacted(bool)::__PRETTY_FUNCTION__> \"void rocksdb::Compaction::MarkFilesBeingCompacted(bool)\") at assert.c:92\n3  0x00007f59b350adc3 in __GI___assert_fail (assertion=assertion@entry=0x9f8390 \"mark_as_compacted ? !inputs_[i][j]->being_compacted : inputs_[i][j]->being_compacted\", file=file@entry=0x9e347c \"db/compaction/compaction.cc\", line=line@entry=395, function=function@entry=0xa21ec0 <rocksdb::Compaction::MarkFilesBeingCompacted(bool)::__PRETTY_FUNCTION__> \"void rocksdb::Compaction::MarkFilesBeingCompacted(bool)\") at assert.c:101\n4  0x0000000000492ccd in rocksdb::Compaction::MarkFilesBeingCompacted (this=<optimized out>, mark_as_compacted=<optimized out>) at db/compaction/compaction.cc:394\n5  0x000000000049467a in rocksdb::Compaction::Compaction (this=0x7f59af013000, vstorage=0x7f581af53030, _immutable_cf_options=..., _mutable_cf_options=..., _inputs=..., _output_level=<optimized out>, _target_file_size=0, _max_compaction_bytes=0, _output_path_id=0, _compression=<incomplete type>, _compression_opts=..., _max_subcompactions=0, _grandparents=..., _manual_compaction=false, _score=4, _deletion_compaction=true, _compaction_reason=rocksdb::CompactionReason::kFIFOTtl) at db/compaction/compaction.cc:241\n6  0x00000000004af9bc in rocksdb::FIFOCompactionPicker::PickTTLCompaction (this=0x7f59b31a6900, cf_name=..., mutable_cf_options=..., vstorage=0x7f581af53030, log_buffer=log_buffer@entry=0x7f59b1bfa930) at db/compaction/compaction_picker_fifo.cc:101\n7  0x00000000004b0771 in rocksdb::FIFOCompactionPicker::PickCompaction (this=0x7f59b31a6900, cf_name=..., mutable_cf_options=..., vstorage=0x7f581af53030, log_buffer=0x7f59b1bfa930) at db/compaction/compaction_picker_fifo.cc:201\n8  0x00000000004838cc in rocksdb::ColumnFamilyData::PickCompaction (this=this@entry=0x7f59b31b3700, mutable_options=..., log_buffer=log_buffer@entry=0x7f59b1bfa930) at db/column_family.cc:933\n9  0x00000000004f3645 in rocksdb::DBImpl::BackgroundCompaction (this=this@entry=0x7f59b3176000, made_progress=made_progress@entry=0x7f59b1bfa6bf, job_context=job_context@entry=0x7f59b1bfa760, log_buffer=log_buffer@entry=0x7f59b1bfa930, prepicked_compaction=prepicked_compaction@entry=0x0, thread_pri=rocksdb::Env::LOW) at db/db_impl/db_impl_compaction_flush.cc:2541\n10 0x00000000004f5e2a in rocksdb::DBImpl::BackgroundCallCompaction (this=this@entry=0x7f59b3176000, prepicked_compaction=prepicked_compaction@entry=0x0, bg_thread_pri=bg_thread_pri@entry=rocksdb::Env::LOW) at db/db_impl/db_impl_compaction_flush.cc:2312\n11 0x00000000004f648e in rocksdb::DBImpl::BGWorkCompaction (arg=<optimized out>) at db/db_impl/db_impl_compaction_flush.cc:2087\n```\nThis can be caused by the following sequence of events.\n```\nTime\n|      thr          bg_compact_thr1                     bg_compact_thr2\n|      write\n|      flush\n|                   mark all l0 as being compacted\n|      write\n|      flush\n|                   add cf to queue again\n|                                                       mark all l0 as being\n|                                                       compacted, fail the\n|                                                       assertion\nV\n```\nTest plan (on devserver)\nSince bg_compact_thr1 and bg_compact_thr2 are two threads executing the same\ncode, it is difficult to use sync point dependency to\ncoordinate their execution. Therefore, I choose to use db_stress.\n```\n$TEST_TMPDIR=/dev/shm/rocksdb ./db_stress --periodic_compaction_seconds=1 --max_background_compactions=20 --format_version=2 --memtablerep=skip_list --max_write_buffer_number=3 --cache_index_and_filter_blocks=1 --reopen=20 --recycle_log_file_num=0 --acquire_snapshot_one_in=10000 --delpercent=4 --log2_keys_per_lock=22 --compaction_ttl=1 --block_size=16384 --use_multiget=1 --compact_files_one_in=1000000 --target_file_size_multiplier=2 --clear_column_family_one_in=0 --max_bytes_for_level_base=10485760 --use_full_merge_v1=1 --target_file_size_base=2097152 --checkpoint_one_in=1000000 --mmap_read=0 --compression_type=zstd --writepercent=35 --readpercent=45 --subcompactions=4 --use_merge=0 --write_buffer_size=4194304 --test_batches_snapshots=0 --db=/dev/shm/rocksdb/rocksdb_crashtest_whitebox --use_direct_reads=0 --compact_range_one_in=1000000 --open_files=-1 --destroy_db_initially=0 --progress_reports=0 --compression_zstd_max_train_bytes=0 --snapshot_hold_ops=100000 --enable_pipelined_write=0 --nooverwritepercent=1 --compression_max_dict_bytes=0 --max_key=1000000 --prefixpercent=5 --flush_one_in=1000000 --ops_per_thread=40000 --index_block_restart_interval=7 --cache_size=1048576 --compaction_style=2 --verify_checksum=1 --delrangepercent=1 --use_direct_io_for_flush_and_compaction=0\n```\nThis should see no assertion failure.\nLast but not least,\n```\n$COMPILE_WITH_ASAN=1 make -j32 all\n$make check\n```\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5754\n\nDifferential Revision: D17109791\n\nPulled By: riversand963\n\nfbshipit-source-id: 25fc46101235add158554e096540b72c324be078",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction/compaction_picker_fifo.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/672befea2a514e32c8506389883f552129d2d5eb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FIFOCompactionPicker::PickTTLCompaction"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "3f89af1c39da4991ef6c544fc5e3f164a688b375",
        "author": "Levi Tamasi",
        "date": "2019-07-26T15:53:34-07:00",
        "message": "Reduce the number of random iterations in compact_on_deletion_collector_test (#5635)\n\nSummary:\nThis test frequently times out under TSAN; reducing the number of random\niterations to make it complete faster.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5635\n\nTest Plan: buck test mode/dev-tsan internal_repo_rocksdb/repo:compact_on_deletion_collector_test\n\nDifferential Revision: D16523505\n\nPulled By: ltamasi\n\nfbshipit-source-id: 6a69909bce9d204c891150fcb3d536547b3253d0",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/table_properties_collectors/compact_on_deletion_collector_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/3f89af1c39da4991ef6c544fc5e3f164a688b375",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "84c5c9aab15896e1c55c3febfa1fac5ed2009069",
        "author": "Sagar Vemuri",
        "date": "2019-07-03T19:06:46-07:00",
        "message": "Fix a bug in compaction reads causing checksum mismatches and asan errors (#5531)\n\nSummary:\nFixed a bug in compaction reads due to which incorrect number of bytes were being read/utilized. The bug was introduced in https://github.com/facebook/rocksdb/issues/5498 , resulting in \"Corruption: block checksum mismatch\" and \"heap-buffer-overflow\" asan errors in our tests.\n\nhttps://github.com/facebook/rocksdb/issues/5498 was introduced recently and is not in any released versions.\n\nASAN:\n```\n> ==2280939==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x6250005e83da at pc 0x000000d57f62 bp 0x7f954f483770 sp 0x7f954f482f20\n> === How to use this, how to get the raw stack trace, and more: fburl.com/ASAN ===\n> READ of size 4 at 0x6250005e83da thread T4\n> SCARINESS: 27 (4-byte-read-heap-buffer-overflow-far-from-bounds)\n\n>      #0 tests+0xd57f61                           __asan_memcpy\n>      https://github.com/facebook/rocksdb/issues/1 rocksdb/src/util/coding.h:124            rocksdb::DecodeFixed32(char const*)\n>      https://github.com/facebook/rocksdb/issues/2 rocksdb/src/table/block_fetcher.cc:39    rocksdb::BlockFetcher::CheckBlockChecksum()\n>      https://github.com/facebook/rocksdb/issues/3 rocksdb/src/table/block_fetcher.cc:99    rocksdb::BlockFetcher::TryGetFromPrefetchBuffer()\n>      https://github.com/facebook/rocksdb/issues/4 rocksdb/src/table/block_fetcher.cc:209   rocksdb::BlockFetcher::ReadBlockContents()\n>      https://github.com/facebook/rocksdb/issues/5 rocksdb/src/table/block_based/block_based_table_reader.cc:93 rocksdb::(anonymous namespace)::ReadBlockFromFile(rocksdb::RandomAccessFileReader*, rocksdb::FilePrefetchBuffer*, rocksdb::Footer const&, rocksdb::ReadOptions const&, rocksdb::BlockHandle const&, std::unique_ptr<...>*, rocksdb::ImmutableCFOptions const&, bool, bool, rocksdb::UncompressionDict\n const&, rocksdb::PersistentCacheOptions const&, unsigned long, unsigned long, rocksdb::MemoryAllocator*, bool)\n>      https://github.com/facebook/rocksdb/issues/6 rocksdb/src/table/block_based/block_based_table_reader.cc:2331 rocksdb::BlockBasedTable::RetrieveBlock(rocksdb::FilePrefetchBuffer*, rocksdb::ReadOptions const&, rocksdb::BlockHandle const&, rocksdb::UncompressionDict const&, rocksdb::CachableEntry<...>*, rocksdb::BlockType, rocksdb::GetContext*, rocksdb::BlockCacheLookupContext*, bool) const\n>      https://github.com/facebook/rocksdb/issues/7 rocksdb/src/table/block_based/block_based_table_reader.cc:2090 rocksdb::DataBlockIter* rocksdb::BlockBasedTable::NewDataBlockIterator<...>(rocksdb::ReadOptions const&, rocksdb::BlockHandle const&, rocksdb::DataBlockIter*, rocksdb::BlockType, bool, bool, rocksdb::GetContext*, rocksdb::BlockCacheLookupContext*, rocksdb::Status, rocksdb::FilePrefetchBuffe\nr*, bool) const\n>      https://github.com/facebook/rocksdb/issues/8 rocksdb/src/table/block_based/block_based_table_reader.cc:2720 rocksdb::BlockBasedTableIterator<...>::InitDataBlock()\n>      https://github.com/facebook/rocksdb/issues/9 rocksdb/src/table/block_based/block_based_table_reader.cc:2607 rocksdb::BlockBasedTableIterator<...>::SeekToFirst()\n>     https://github.com/facebook/rocksdb/issues/10 rocksdb/src/table/iterator_wrapper.h:83  rocksdb::IteratorWrapperBase<...>::SeekToFirst()\n>     https://github.com/facebook/rocksdb/issues/11 rocksdb/src/table/merging_iterator.cc:100 rocksdb::MergingIterator::SeekToFirst()\n>     https://github.com/facebook/rocksdb/issues/12 rocksdb/compaction/compaction_job.cc:877 rocksdb::CompactionJob::ProcessKeyValueCompaction(rocksdb::CompactionJob::SubcompactionState*)\n>     https://github.com/facebook/rocksdb/issues/13 rocksdb/compaction/compaction_job.cc:590 rocksdb::CompactionJob::Run()\n>     https://github.com/facebook/rocksdb/issues/14 rocksdb/db_impl/db_impl_compaction_flush.cc:2689 rocksdb::DBImpl::BackgroundCompaction(bool*, rocksdb::JobContext*, rocksdb::LogBuffer*, rocksdb::DBImpl::PrepickedCompaction*, rocksdb::Env::Priority)\n>     https://github.com/facebook/rocksdb/issues/15 rocksdb/db_impl/db_impl_compaction_flush.cc:2248 rocksdb::DBImpl::BackgroundCallCompaction(rocksdb::DBImpl::PrepickedCompaction*, rocksdb::Env::Priority)\n>     https://github.com/facebook/rocksdb/issues/16 rocksdb/db_impl/db_impl_compaction_flush.cc:2024 rocksdb::DBImpl::BGWorkCompaction(void*)\n>     https://github.com/facebook/rocksdb/issues/23 rocksdb/src/util/threadpool_imp.cc:266   rocksdb::ThreadPoolImpl::Impl::BGThread(unsigned long)\n>     https://github.com/facebook/rocksdb/issues/24 rocksdb/src/util/threadpool_imp.cc:307   rocksdb::ThreadPoolImpl::Impl::BGThreadWrapper(void*)\n```\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5531\n\nTest Plan: Verified that this fixes the fb-internal Logdevice test which caught the issue.\n\nDifferential Revision: D16109702\n\nPulled By: sagar0\n\nfbshipit-source-id: 1fc08549cf7b553e338a133ae11eb9f4d5011914",
        "modified_files_count": 1,
        "modified_files": [
            "util/file_reader_writer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/84c5c9aab15896e1c55c3febfa1fac5ed2009069",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FilePrefetchBuffer::TryReadFromCache"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "22028aa9ab27cf860b74d12e006f82ff551caee0",
        "author": "Vijay Nadimpalli",
        "date": "2019-06-21T21:31:49-07:00",
        "message": "Compaction Reads should read no more than compaction_readahead_size bytes, when set! (#5498)\n\nSummary:\nAs a result of https://github.com/facebook/rocksdb/issues/5431 the compaction_readahead_size given by a user was not used exactly, the reason being the code behind readahead for user-read and compaction-read was unified in the above PR and the behavior for user-read is to read readahead_size+n bytes (see FilePrefetchBuffer::TryReadFromCache method). Before the unification the ReadaheadRandomAccessFileReader used compaction_readahead_size as it is.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5498\n\nTest Plan:\nRan strace command : strace -e pread64 -f -T -t ./db_compaction_test --gtest_filter=DBCompactionTest.PartialManualCompaction\n\nIn the test the compaction_readahead_size was configured to 2MB and verified the pread syscall did indeed request 2MB. Before the change it was requesting more than 2MB.\n\nStrace Output:\nstrace: Process 3798982 attached\nNote: Google Test filter = DBCompactionTest.PartialManualCompaction\n[==========] Running 1 test from 1 test case.\n[----------] Global test environment set-up.\n[----------] 1 test from DBCompactionTest\n[ RUN      ] DBCompactionTest.PartialManualCompaction\nstrace: Process 3798983 attached\nstrace: Process 3798984 attached\nstrace: Process 3798985 attached\nstrace: Process 3798986 attached\nstrace: Process 3798987 attached\nstrace: Process 3798992 attached\n[pid 3798987] 12:07:05 +++ exited with 0 +++\nstrace: Process 3798993 attached\n[pid 3798993] 12:07:05 +++ exited with 0 +++\nstrace: Process 3798994 attached\nstrace: Process 3799008 attached\nstrace: Process 3799009 attached\n[pid 3799008] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799010 attached\n[pid 3799009] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799011 attached\n[pid 3799010] 12:07:05 +++ exited with 0 +++\n[pid 3799011] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799012 attached\n[pid 3799012] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799013 attached\nstrace: Process 3799014 attached\n[pid 3799013] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799015 attached\n[pid 3799014] 12:07:05 +++ exited with 0 +++\n[pid 3799015] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799016 attached\n[pid 3799016] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799017 attached\n[pid 3799017] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799019 attached\n[pid 3799019] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799020 attached\nstrace: Process 3799021 attached\n[pid 3799020] 12:07:05 +++ exited with 0 +++\n[pid 3799021] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799022 attached\n[pid 3799022] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799023 attached\n[pid 3799023] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799047 attached\nstrace: Process 3799048 attached\n[pid 3799047] 12:07:06 +++ exited with 0 +++\n[pid 3799048] 12:07:06 +++ exited with 0 +++\n[pid 3798994] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799052 attached\n[pid 3799052] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799054 attached\nstrace: Process 3799069 attached\nstrace: Process 3799070 attached\n[pid 3799069] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799071 attached\n[pid 3799070] 12:07:06 +++ exited with 0 +++\n[pid 3799071] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799072 attached\nstrace: Process 3799073 attached\n[pid 3799072] 12:07:06 +++ exited with 0 +++\n[pid 3799073] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799074 attached\n[pid 3799074] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799075 attached\n[pid 3799075] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799076 attached\n[pid 3799076] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799077 attached\n[pid 3799077] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799078 attached\n[pid 3799078] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799079 attached\n[pid 3799079] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799080 attached\n[pid 3799080] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799081 attached\n[pid 3799081] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799082 attached\n[pid 3799082] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799083 attached\n[pid 3799083] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799086 attached\nstrace: Process 3799087 attached\n[pid 3798984] 12:07:06 pread64(9, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000121>\n[pid 3798984] 12:07:06 pread64(9, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000106>\n[pid 3798984] 12:07:06 pread64(9, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000081>\n[pid 3798984] 12:07:06 pread64(9, \"\\0\\v\\3foo\\2\\7\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2\\3\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000138>\n[pid 3798984] 12:07:06 pread64(11, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000097>\n[pid 3798984] 12:07:06 pread64(11, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000086>\n[pid 3798984] 12:07:06 pread64(11, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000064>\n[pid 3798984] 12:07:06 pread64(11, \"\\0\\v\\3foo\\2\\21\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2\\r\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000064>\n[pid 3798984] 12:07:06 pread64(12, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000080>\n[pid 3798984] 12:07:06 pread64(12, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000090>\n[pid 3798984] 12:07:06 pread64(12, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000059>\n[pid 3798984] 12:07:06 pread64(12, \"\\0\\v\\3foo\\2\\33\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2\\27\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000065>\n[pid 3798984] 12:07:06 pread64(13, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000070>\n[pid 3798984] 12:07:06 pread64(13, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000059>\n[pid 3798984] 12:07:06 pread64(13, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000061>\n[pid 3798984] 12:07:06 pread64(13, \"\\0\\v\\3foo\\2%\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2!\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000065>\n[pid 3798984] 12:07:06 pread64(14, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000118>\n[pid 3798984] 12:07:06 pread64(14, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000093>\n[pid 3798984] 12:07:06 pread64(14, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000050>\n[pid 3798984] 12:07:06 pread64(14, \"\\0\\v\\3foo\\2/\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2+\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000082>\n[pid 3798984] 12:07:06 pread64(15, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000080>\n[pid 3798984] 12:07:06 pread64(15, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000086>\n[pid 3798984] 12:07:06 pread64(15, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000091>\n[pid 3798984] 12:07:06 pread64(15, \"\\0\\v\\3foo\\0029\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\0025\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000174>\n[pid 3798984] 12:07:06 pread64(16, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000080>\n[pid 3798984] 12:07:06 pread64(16, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000093>\n[pid 3798984] 12:07:06 pread64(16, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000194>\n[pid 3798984] 12:07:06 pread64(16, \"\\0\\v\\3foo\\2C\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2?\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000086>\n[pid 3798984] 12:07:06 pread64(17, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000079>\n[pid 3798984] 12:07:06 pread64(17, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000047>\n[pid 3798984] 12:07:06 pread64(17, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000045>\n[pid 3798984] 12:07:06 pread64(17, \"\\0\\v\\3foo\\2M\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2I\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000107>\n[pid 3798983] 12:07:06 pread64(17, \"\\0\\v\\200\\10foo\\2P\\0\\0\\0\\0\\0\\0)U?MSg_)j(roFn($e\"..., 2097152, 0) = 11230 <0.000091>\n[pid 3798983] 12:07:06 pread64(17, \"\", 2085922, 11230) = 0 <0.000073>\n[pid 3798983] 12:07:06 pread64(16, \"\\0\\v\\200\\10foo\\2F\\0\\0\\0\\0\\0\\0k[h3%.OPH_^:\\\\S7T&\"..., 2097152, 0) = 11230 <0.000083>\n[pid 3798983] 12:07:06 pread64(16, \"\", 2085922, 11230) = 0 <0.000078>\n[pid 3798983] 12:07:06 pread64(15, \"\\0\\v\\200\\10foo\\2<\\0\\0\\0\\0\\0\\0+qToi_c{*S+4:N(:\"..., 2097152, 0) = 11230 <0.000095>\n[pid 3798983] 12:07:06 pread64(15, \"\", 2085922, 11230) = 0 <0.000067>\n[pid 3798983] 12:07:06 pread64(14, \"\\0\\v\\200\\10foo\\0022\\0\\0\\0\\0\\0\\0%hw%OMa\\\"}9I609Q!B\"..., 2097152, 0) = 11230 <0.000111>\n[pid 3798983] 12:07:06 pread64(14, \"\", 2085922, 11230) = 0 <0.000093>\n[pid 3798983] 12:07:06 pread64(13, \"\\0\\v\\200\\10foo\\2(\\0\\0\\0\\0\\0\\0p}Y&mu^DcaSGb2&nP\"..., 2097152, 0) = 11230 <0.000128>\n[pid 3798983] 12:07:06 pread64(13, \"\", 2085922, 11230) = 0 <0.000076>\n[pid 3798983] 12:07:06 pread64(12, \"\\0\\v\\200\\10foo\\2\\36\\0\\0\\0\\0\\0\\0YIyW#]oSs^6VHfB<`\"..., 2097152, 0) = 11230 <0.000092>\n[pid 3798983] 12:07:06 pread64(12, \"\", 2085922, 11230) = 0 <0.000073>\n[pid 3798983] 12:07:06 pread64(11, \"\\0\\v\\200\\10foo\\2\\24\\0\\0\\0\\0\\0\\0mfF8Jel/*Zf :-#s(\"..., 2097152, 0) = 11230 <0.000088>\n[pid 3798983] 12:07:06 pread64(11, \"\", 2085922, 11230) = 0 <0.000067>\n[pid 3798983] 12:07:06 pread64(9, \"\\0\\v\\200\\10foo\\2\\n\\0\\0\\0\\0\\0\\0\\\\X'cjiHX)D,RSj1X!\"..., 2097152, 0) = 11230 <0.000115>\n[pid 3798983] 12:07:06 pread64(9, \"\", 2085922, 11230) = 0 <0.000073>\n[pid 3798983] 12:07:06 pread64(8, \"\\1\\315\\5 \\36\\30\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 754) = 53 <0.000098>\n[pid 3798983] 12:07:06 pread64(8, \"\\0\\22\\3rocksdb.properties;\\215\\5\\0\\0\\0\\0\\1\\0\\0\\0\"..., 37, 717) = 37 <0.000064>\n[pid 3798983] 12:07:06 pread64(8, \"\\0$\\4rocksdb.block.based.table.ind\"..., 658, 59) = 658 <0.000074>\n[pid 3798983] 12:07:06 pread64(8, \"\\0\\v\\2foo\\1\\0\\0\\0\\0\\0\\0\\0\\0\\31\\0\\0\\0\\0\\1\\0\\0\\0\\0\\212\\216\\222P\", 29, 30) = 29 <0.000064>\n[pid 3799086] 12:07:06 +++ exited with 0 +++\n[pid 3799087] 12:07:06 +++ exited with 0 +++\n[pid 3799054] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799104 attached\n[pid 3799104] 12:07:06 +++ exited with 0 +++\n[       OK ] DBCompactionTest.PartialManualCompaction (757 ms)\n[----------] 1 test from DBCompactionTest (758 ms total)\n\n[----------] Global test environment tear-down\n[==========] 1 test from 1 test case ran. (759 ms total)\n[  PASSED  ] 1 test.\n[pid 3798983] 12:07:06 +++ exited with 0 +++\n[pid 3798984] 12:07:06 +++ exited with 0 +++\n[pid 3798992] 12:07:06 +++ exited with 0 +++\n[pid 3798986] 12:07:06 +++ exited with 0 +++\n[pid 3798982] 12:07:06 +++ exited with 0 +++\n[pid 3798985] 12:07:06 +++ exited with 0 +++\n12:07:06 +++ exited with 0 +++\n\nDifferential Revision: D15948422\n\nPulled By: vjnadimpalli\n\nfbshipit-source-id: 9b189d1e8675d290c7784e4b33e5d3b5761d2ac8",
        "modified_files_count": 1,
        "modified_files": [
            "util/file_reader_writer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/22028aa9ab27cf860b74d12e006f82ff551caee0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FilePrefetchBuffer::TryReadFromCache"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "79edf0a7a8ab75f60692efd54b1e0ed7da7aafca",
        "author": "Yuan Zhou",
        "date": "2019-05-31T17:17:57-07:00",
        "message": "util: fix log_write_bench (#5335)\n\nSummary:\nlog_write_bench doesn't compile due to some recent API changes.\nThis patch fixes the compile by adding the missing params for\nOptimizeForLogWrite() and WritableFileWriter().\n\nSigned-off-by: Yuan Zhou <yuan.zhou@intel.com>\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5335\n\nDifferential Revision: D15588875\n\nPulled By: miasantreble\n\nfbshipit-source-id: 726ff4dc227733e915c3b796df25bd3ab0b431ac",
        "modified_files_count": 1,
        "modified_files": [
            "util/log_write_bench.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/79edf0a7a8ab75f60692efd54b1e0ed7da7aafca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RunBenchmark"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "cd43446d017fd3929e5883bccf1206afafd57952",
        "author": "Siying Dong",
        "date": "2019-05-20T13:50:53-07:00",
        "message": "Improve DBTablePropertiesTest.GetPropertiesOfTablesInRange (#5302)\n\nSummary:\nDBTablePropertiesTest.GetPropertiesOfTablesInRange sometimes hits the assert that generated LSM-tree doesn't have L1 file. Tighten the compaction triggering condition even further, hoping it goes away.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5302\n\nDifferential Revision: D15325971\n\nPulled By: siying\n\nfbshipit-source-id: 3e032bdb16fe8d98d5fcfcd65dd8be9781f3d6ae",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_table_properties_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/cd43446d017fd3929e5883bccf1206afafd57952",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "f82e693a31d07ab8b391888ff60eb7ff5b95bd13",
        "author": "Siying Dong",
        "date": "2019-05-16T15:24:28-07:00",
        "message": "RangeDelAggregator::StripeRep::Invalidate() to be skipped if empty (#5312)\n\nSummary:\nRangeDelAggregator::StripeRep::Invalidate() clears up several vectors. If we know there isn't anything to there, we can safe these small CPUs. Profiling shows that it sometimes take non-negligible amount of CPU. Worth a small optimization.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5312\n\nDifferential Revision: D15380511\n\nPulled By: siying\n\nfbshipit-source-id: 53c5f34c33b4cb1e743643c6086ac56d0b84ec2e",
        "modified_files_count": 1,
        "modified_files": [
            "db/range_del_aggregator.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f82e693a31d07ab8b391888ff60eb7ff5b95bd13",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Invalidate"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "eea1cad850c2e268b0bfde208a005e44289dea47",
        "author": "Zhongyi Xie",
        "date": "2019-05-07T20:20:40-07:00",
        "message": "avoid updating index type during iterator creation (#5288)\n\nSummary:\nRight now there is a potential race condition where two threads are created to iterate through the DB (https://gist.github.com/miasantreble/88f5798a397ee7cb8e7baff9db2d9e85).  The problem is that in `BlockBasedTable::NewIndexIterator`, if both threads failed to find index_reader from block cache, they will call `CreateIndexReader->UpdateIndexType()` which creates a race to update `index_type` in the shared rep_ object. By checking the code, we realize the index type is always populated by `PrefetchIndexAndFilterBlocks` during the table `Open` call, so there is no need to update index type every time during iterator creation. This PR attempts to fix the race condition by removing the unnecessary call to `UpdateIndexType`\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5288\n\nDifferential Revision: D15252509\n\nPulled By: miasantreble\n\nfbshipit-source-id: 6e3258652121d5c76d267f7ac457e15c5e84756e",
        "modified_files_count": 1,
        "modified_files": [
            "table/block_based_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/eea1cad850c2e268b0bfde208a005e44289dea47",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlockBasedTable::CreateIndexReader"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "d51eb0b583fe28ede2b4a6d778de4489433f1bbf",
        "author": "Zhongyi Xie",
        "date": "2019-05-01T20:40:00-07:00",
        "message": "set snappy compression only when supported (#4325)\n\nSummary:\nRight now `OptimizeLevelStyleCompaction` may set compression type to Snappy even when Snappy is not supported, this may cause errors like \"no snappy compression support\"\nFixes https://github.com/facebook/rocksdb/issues/4283\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4325\n\nDifferential Revision: D15125542\n\nPulled By: miasantreble\n\nfbshipit-source-id: 70890b73ababe16752721555dbd290633c2aafac",
        "modified_files_count": 1,
        "modified_files": [
            "options/options.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d51eb0b583fe28ede2b4a6d778de4489433f1bbf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ColumnFamilyOptions::OptimizeLevelStyleCompaction"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "106a94af1552ba6eb89cfe08fd4f92c2078af463",
        "author": "Siying Dong",
        "date": "2019-03-28T13:16:02-07:00",
        "message": "Improve obsolete_files_test (#5125)\n\nSummary:\nWe see a failure of obsolete_files_test but aren't able to identify\nthe issue. Improve the test in following way and hope we can debug\nbetter next time:\n1. Place sync point before automatic compaction runs so race condition\n   will always trigger.\n2. Disable sync point before test finishes.\n3. ASSERT_OK() instead of ASSERT_TRUE(status.ok())\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5125\n\nDifferential Revision: D14669456\n\nPulled By: siying\n\nfbshipit-source-id: dccb7648e334501ad651eb212880096eef1f4ab2",
        "modified_files_count": 1,
        "modified_files": [
            "db/obsolete_files_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/106a94af1552ba6eb89cfe08fd4f92c2078af463",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "d9c9f3c8093f703316e7f93931580c297d074457",
        "author": "Siying Dong",
        "date": "2019-02-05T17:20:02-08:00",
        "message": "db_bench: fix \"micros/op\" reporting (#4949)\n\nSummary:\nhttps://github.com/facebook/rocksdb/commit/4985a9f73b9fb8a0323fbbb06222ae1f758a6b1d#diff-e5276985b26a0551957144f4420a594bR511\nchanges the meaning of latency reporting from running time per query, to elapse_time / #ops, without providing a reason why.\nConsidering that this is a counter-intuitive reporting, Reverting the change.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4949\n\nDifferential Revision: D13964684\n\nPulled By: siying\n\nfbshipit-source-id: d6304d3d4b5a802daa292302623c7dbca9a680bc",
        "modified_files_count": 1,
        "modified_files": [
            "tools/db_bench_tool.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d9c9f3c8093f703316e7f93931580c297d074457",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Report"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "7d13f307ff189c25a6e51f1782b3addd83859989",
        "author": "Siying Dong",
        "date": "2019-01-15T16:46:04-08:00",
        "message": "Improve Error Message When wal_dir doesn't exist (#4874)\n\nSummary:\nRight now the error mesage when options.wal_dir doesn't exist is not helpful to users. Be more specific\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4874\n\nDifferential Revision: D13642425\n\nPulled By: siying\n\nfbshipit-source-id: 9a3172ed0f799af233b0f3b2e5e35bc7ce04c7b5",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl_open.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/7d13f307ff189c25a6e51f1782b3addd83859989",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::Recover"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "de651035535b6d66276edc97c121cb507e9138cb",
        "author": "Yanqin Jin",
        "date": "2018-11-13T20:03:59-08:00",
        "message": "Improve result report of scan (#4648)\n\nSummary:\nWhen iterator becomes invalid, there are two possibilities.\nFirst, all data in the column family have been scanned and there is nothing\nmore to scan.\nSecond, an underlying error has occurred, causing `status()` to be !ok.\nTherefore, we need to check for both cases when `!iter->Valid()`.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4648\n\nDifferential Revision: D12959601\n\nPulled By: riversand963\n\nfbshipit-source-id: 49c9382c9ea9e78f2e2b6f3708f0670b822ca8dd",
        "modified_files_count": 1,
        "modified_files": [
            "tools/db_stress.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/de651035535b6d66276edc97c121cb507e9138cb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VerifyDb"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "d8df169b8498609eda28c0d6c2d91588b0aa925b",
        "author": "Zhongyi Xie",
        "date": "2018-11-13T17:08:34-08:00",
        "message": "release db mutex when calling ApproximateSize (#4630)\n\nSummary:\n`GenSubcompactionBoundaries` calls `VersionSet::ApproximateSize` which gets BlockBasedTableReader for every file and seeks in its index block to find `key`'s offset. If the table or index block aren't in memory already, this involves I/O. This can be improved by releasing DB mutex when calling ApproximateSize.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4630\n\nDifferential Revision: D13052653\n\nPulled By: miasantreble\n\nfbshipit-source-id: cae31d46d10d0860fa8a26b8d5154b2d17d1685f",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction_job.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d8df169b8498609eda28c0d6c2d91588b0aa925b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionJob::GenSubcompactionBoundaries"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "a2de8e52bb6c13baf5f2323eba0ca356f1294f88",
        "author": "Simon Liu",
        "date": "2018-11-13T14:39:03-08:00",
        "message": "optimized the performance of autovector::emplace_back. (#4606)\n\nSummary:\nIt called the autovector::push_back simply in autovector::emplace_back.\nThis was not efficient, and then optimazed this function through the\nperfect forwarding.\n\nThis was the src and result of the benchmark(using the google'benchmark library, the type of elem in\nautovector was std::string, and call emplace_back with the \"char *\" type):\n\nhttps://gist.github.com/monadbobo/93448b89a42737b08cbada81de75c5cd\n\nPS: The benchmark's result of  previous PR was not accurate, and so I update the test case and result.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4606\n\nDifferential Revision: D13046813\n\nPulled By: sagar0\n\nfbshipit-source-id: 19cde1bcadafe899aa454b703acb35737a1cc02d",
        "modified_files_count": 1,
        "modified_files": [
            "util/autovector.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a2de8e52bb6c13baf5f2323eba0ca356f1294f88",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "emplace_back"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "b41b2d431e0757b5651c4ce1133de9284d9635de",
        "author": "Yanqin Jin",
        "date": "2018-10-04T14:53:36-07:00",
        "message": "Improve error message when opening file for truncation (#4454)\n\nSummary:\nThe old error message was misleading because it led people to believe the truncation operation failed.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4454\n\nDifferential Revision: D10203575\n\nPulled By: riversand963\n\nfbshipit-source-id: c76482a132566635cb55d4c73d45c461f295ec43",
        "modified_files_count": 1,
        "modified_files": [
            "util/fault_injection_test_env.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b41b2d431e0757b5651c4ce1133de9284d9635de",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Truncate"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "82e8e9e26bb16d1af07a26741bcf63d8342e4336",
        "author": "JiYou",
        "date": "2018-09-14T19:43:04-07:00",
        "message": "VersionBuilder: optmize SaveTo() to linear time. (#4366)\n\nSummary:\nBecause `base_files` and `added_files` both are sorted, using a merge\noperation to these two sorted arrays is more effective. The complexity\nis reduced to linear time.\n\n    - optmize the merge complexity.\n    - move the `NDEBUG` of sorted `added_files` out of merge process.\n\nSigned-off-by: JiYou <jiyou09@gmail.com>\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4366\n\nDifferential Revision: D9833592\n\nPulled By: ajkr\n\nfbshipit-source-id: dd32b67ebdca4c20e5e9546ab8082cecefe99fd0",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_builder.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/82e8e9e26bb16d1af07a26741bcf63d8342e4336",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SaveTo"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "640cfa7c3316741a0d04ef5163810f710dc44df8",
        "author": "Fenggang Wu",
        "date": "2018-08-21T17:12:45-07:00",
        "message": "DataBlockHashIndex: fix comment in NumRestarts() (#4286)\n\nSummary:\nImprove the description of the backward compatibility check in NumRestarts()\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4286\n\nDifferential Revision: D9412490\n\nPulled By: fgwu\n\nfbshipit-source-id: ea7dd5c61d8ff8eacef623b729d4e4fd53cca066",
        "modified_files_count": 1,
        "modified_files": [
            "table/block.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/640cfa7c3316741a0d04ef5163810f710dc44df8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Block::NumRestarts"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "fa4de6e30ffaf9188a48f5e30d2da1ac0e454917",
        "author": "Andrey Zagrebin",
        "date": "2018-08-17T10:57:25-07:00",
        "message": "#3865 followup for fix performance degression introduced by switching order of operands (#4284)\n\nSummary:\nFollowup for #4266. There is one more place in **get_context.cc** where **MergeOperator::ShouldMerge** should be called with reversed list of operands.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4284\n\nDifferential Revision: D9380008\n\nPulled By: sagar0\n\nfbshipit-source-id: 70ec26e607e5b88465e1acbdcd6c6171bd76b9f2",
        "modified_files_count": 1,
        "modified_files": [
            "table/get_context.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/fa4de6e30ffaf9188a48f5e30d2da1ac0e454917",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetContext::SaveValue"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "eb8885a08a688e08131c2a7acb94bca746de6789",
        "author": "Maysam Yabandeh",
        "date": "2018-08-08T17:43:00-07:00",
        "message": "Return correct usable_size for BlockContents (#4246)\n\nSummary:\nIf jemalloc is disabled or the API is incorrectly referenced (jemalloc api on windows have a prefix je_) memory usage is incorrectly reported for all block sizes. This is because sizeof(char) is always 1. sizeof() is calculated at compile time and *(char*) is char. The patch uses the size of the slice to fix that.\nFixes #4245\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4246\n\nDifferential Revision: D9233958\n\nPulled By: maysamyabandeh\n\nfbshipit-source-id: 9646933b24504e2814c7379f06a31148829c6b4e",
        "modified_files_count": 1,
        "modified_files": [
            "table/format.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/eb8885a08a688e08131c2a7acb94bca746de6789",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "usable_size"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "21171615c10ee1a636ea28f2303a93a4bc39dbde",
        "author": "Yanqin Jin",
        "date": "2018-07-13T17:27:39-07:00",
        "message": "Reduce execution time of IngestFileWithGlobalSeqnoRandomized (#4131)\n\nSummary:\nMake `ExternalSSTFileTest.IngestFileWithGlobalSeqnoRandomized` run faster.\n\n`make format`\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4131\n\nDifferential Revision: D8839952\n\nPulled By: riversand963\n\nfbshipit-source-id: 4a7e842fde1cde4dc902e928a1cf511322578521",
        "modified_files_count": 1,
        "modified_files": [
            "db/external_sst_file_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/21171615c10ee1a636ea28f2303a93a4bc39dbde",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "dbeaa0d397fd2d26e105817242782024d1e607b7",
        "author": "Yanqin Jin",
        "date": "2018-07-12T14:42:39-07:00",
        "message": "Reduce #iterations to shorten execution time. (#4123)\n\nSummary:\nReduce #iterations from 5000 to 1000 so that\n`ExternalSSTFileTest.CompactDuringAddFileRandom` can finish faster.\nOn the one hand, 5000 iterations does not seem to improve the quality of unit\ntest in comparison with 1000. On the other hand, long running tests should belong to stress tests.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4123\n\nDifferential Revision: D8822514\n\nPulled By: riversand963\n\nfbshipit-source-id: 0f439b8d5ccd9a4aed84638f8bac16382de17245",
        "modified_files_count": 1,
        "modified_files": [
            "db/external_sst_file_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/dbeaa0d397fd2d26e105817242782024d1e607b7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "39218a72a4fb728bc2892af684b9a9019cb15dd0",
        "author": "Yanqin Jin",
        "date": "2018-07-05T11:45:11-07:00",
        "message": "Increase the size of LRU cache. (#4090)\n\nSummary:\nIncrease the size of each shard so that the number of cache hit/miss match\nexpectation. Otherwise FilterBlockInBlockCache test will fail.\nCloses https://github.com/facebook/rocksdb/pull/4090\n\nDifferential Revision: D8736158\n\nPulled By: riversand963\n\nfbshipit-source-id: 5cdbc06b02390389fd5b72a6d251d88949ad3d91",
        "modified_files_count": 1,
        "modified_files": [
            "table/table_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/39218a72a4fb728bc2892af684b9a9019cb15dd0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_P"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "25403c2265cb700462d59fa3cb9dbec85d25d48f",
        "author": "Andrew Kryczka",
        "date": "2018-06-28T13:20:29-07:00",
        "message": "Prefetch cache lines for filter lookup (#4068)\n\nSummary:\nSince the filter data is unaligned, even though we ensure all probes are within a span of `cache_line_size` bytes, those bytes can span two cache lines. In that case I doubt hardware prefetching does a great job considering we don't necessarily access those two cache lines in order. This guess seems correct since adding explicit prefetch instructions reduced filter lookup overhead by 19.4%.\nCloses https://github.com/facebook/rocksdb/pull/4068\n\nDifferential Revision: D8674189\n\nPulled By: ajkr\n\nfbshipit-source-id: 747427d9a17900151c17820488e3f7efe06b1871",
        "modified_files_count": 1,
        "modified_files": [
            "util/bloom.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/25403c2265cb700462d59fa3cb9dbec85d25d48f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FullFilterBitsReader::HashMayMatch"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "fbe3b9e2b61c952782821d5dd5e898346d5dee53",
        "author": "Fenggang Wu",
        "date": "2018-06-15T10:42:21-07:00",
        "message": "Udpate db_universal_compaction_test according to PR #3970 (#3995)\n\nSummary:\nThe SST file sizes changed slightly after the improvement of PR #3970\nwhich reduces the size of the properties block. Before PR #3970 a size\nratio compaction included all of the first four flushed files but it\nonly includes two files after. We increase the size_ratio universal\ncompaction option to make that compaction include all four files again.\nCloses https://github.com/facebook/rocksdb/pull/3995\n\nDifferential Revision: D8426925\n\nPulled By: fgwu\n\nfbshipit-source-id: 1429c38672e9f4fb4d4881fd4b06db45c4861d62",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_universal_compaction_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/fbe3b9e2b61c952782821d5dd5e898346d5dee53",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_P"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "b78ed0460b7f16013e62f72a0253eb98220a0965",
        "author": "Andrew Kryczka",
        "date": "2018-02-01T09:42:09-08:00",
        "message": "fix ReadaheadRandomAccessFile/iterator prefetch bug\n\nSummary:\n`ReadaheadRandomAccessFile` is used by iterators for file reads in several cases, like in compaction when `compaction_readahead_size > 0` or `use_direct_io_for_flush_and_compaction == true`, or in user iterator when `ReadOptions::readahead_size > 0`. `ReadaheadRandomAccessFile` maintains an internal buffer for readahead data. It assumes that, if the buffer's length is less than `ReadaheadRandomAccessFile::readahead_size_`, which is fixed in the constructor, then EOF has been reached so it doesn't try reading further.\n\nRecently, d938226af405681c592f25310f41c0c933bcdb19 started calling `RandomAccessFile::Prefetch` with various lengths: 8KB, 16KB, etc. When the `RandomAccessFile` is a `ReadaheadRandomAccessFile`, it triggers the above condition and incorrectly determines EOF. If a block is partially in the readahead buffer and EOF is incorrectly decided, the result is a truncated data block.\n\nThe problem is reproducible:\n\n```\nTEST_TMPDIR=/data/compaction_bench ./db_bench -benchmarks=fillrandom -write_buffer_size=1048576 -target_file_size_base=1048576 -block_size=18384 -use_direct_io_for_flush_and_compaction=true\n...\nput error: Corruption: truncated block read from /data/compaction_bench/dbbench/000014.sst offset 20245, expected 10143 bytes, got 8427\n```\nCloses https://github.com/facebook/rocksdb/pull/3454\n\nDifferential Revision: D6869405\n\nPulled By: ajkr\n\nfbshipit-source-id: 87001c299e7600a37c0dcccbd0368e0954c929cf",
        "modified_files_count": 1,
        "modified_files": [
            "util/file_reader_writer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b78ed0460b7f16013e62f72a0253eb98220a0965",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Prefetch"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "30a017fecae60aa7b87c4a1e283b6ac027724a92",
        "author": "Yi Wu",
        "date": "2018-01-05T16:41:58-08:00",
        "message": "Blob DB: avoid having a separate read of checksum\n\nSummary:\nPreviously on a blob db read, we are making a read of the blob value, and then make another read to get CRC checksum. I'm combining the two read into one.\n\nreadrandom db_bench with 1G database with base db size of 13M, value size 1k:\n`./db_bench --db=/home/yiwu/tmp/db_bench --use_blob_db --value_size=1024 --num=1000000 --benchmarks=readrandom --use_existing_db --cache_size=32000000`\nmaster: throughput 234MB/s, get micros p50 5.984 p95 9.998 p99 20.817 p100 787\nthis PR: throughput 261MB/s, get micros p50 5.157 p95 9.928 p99 20.724 p100 190\nCloses https://github.com/facebook/rocksdb/pull/3301\n\nDifferential Revision: D6615950\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: 052410c6d8539ec0cc305d53793bbc8f3616baa3",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/blob_db/blob_db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/30a017fecae60aa7b87c4a1e283b6ac027724a92",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlobDBImpl::GetBlobValue"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "4634c735a8bb4f83b8099928fb12b50ad8df7b88",
        "author": "Alex Robinson",
        "date": "2017-12-04T01:56:15-08:00",
        "message": "Update DBOptions::IncreaseParallelism to use newer background settings\n\nSummary:\nThe Options header file recommends using max_background_jobs rather than\ndirectly setting max_background_compactions or max_background_flushes.\n\nI've personally seen a performance problem where stalls were happening\nbecause the one background flushing thread was blocked that was fixed\nby this change -\nhttps://github.com/cockroachdb/cockroach/issues/19699#issuecomment-347672485\nCloses https://github.com/facebook/rocksdb/pull/3208\n\nDifferential Revision: D6473178\n\nPulled By: ajkr\n\nfbshipit-source-id: 67c892ceb7b1909d251492640cb15a0f2262b7ed",
        "modified_files_count": 1,
        "modified_files": [
            "options/options.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4634c735a8bb4f83b8099928fb12b50ad8df7b88",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBOptions::IncreaseParallelism"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "f8b5bb2fd82a39ab4c0b27d21bd492bc61177742",
        "author": "Andrew Kryczka",
        "date": "2017-10-20T14:11:52-07:00",
        "message": "remove unused code\n\nSummary:\nfixup 6a541afcc4d1e5b6e6d78e288b9bee3bb2a933b5. This code didn't do anything because (1) `bytes_per_sync` is assigned in `EnvOptions`'s constructor; and (2) `OptimizeForCompactionTableWrite`'s return value was ignored, even though its only purpose is to return something.\nCloses https://github.com/facebook/rocksdb/pull/3055\n\nDifferential Revision: D6114132\n\nPulled By: ajkr\n\nfbshipit-source-id: ea4831770930e9cf83518e13eb2e1934d1f5487c",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f8b5bb2fd82a39ab4c0b27d21bd492bc61177742",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::SetDBOptions"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "b8cea7cc279fe609de85b7ce4f50d4ff4f90047f",
        "author": "Changli Gao",
        "date": "2017-10-17T10:12:37-07:00",
        "message": "VersionBuilder: Erase with iterators for better performance\n\nSummary: Closes https://github.com/facebook/rocksdb/pull/3007\n\nDifferential Revision: D6077701\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: a6fd5b8a23f4feb1660b9ce027f651a7e90352b3",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_builder.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b8cea7cc279fe609de85b7ce4f50d4ff4f90047f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Apply"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "1a61ba179e9d8b55cdc27df5b03e184355901864",
        "author": "Jay Patel",
        "date": "2017-10-09T22:59:02-07:00",
        "message": "compaction picker to use max_bytes_for_level_multiplier_additional\n\nSummary:\nHi,\nAs part of some optimization, we're using multiple DB locations (tmpfs and spindle) to store data and configured max_bytes_for_level_multiplier_additional. But, max_bytes_for_level_multiplier_additional is not used to compute the actual size for the level while picking the DB location. So, even if DB location does not have space, RocksDB mistakenly puts the level at that location.\n\nCan someone pls. verify the fix? Let me know any other changes required.\n\nThanks,\nJay\nCloses https://github.com/facebook/rocksdb/pull/2704\n\nDifferential Revision: D5992515\n\nPulled By: ajkr\n\nfbshipit-source-id: cbbc6c0e0a7dbdca91c72e0f37b218c4cec57e28",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction_picker.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1a61ba179e9d8b55cdc27df5b03e184355901864",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LevelCompactionBuilder::GetPathId"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "821887036e5235c827029d14decb185bea01ec4b",
        "author": "Andrew Kryczka",
        "date": "2017-10-03T16:27:28-07:00",
        "message": "pin L0 filters/indexes for compaction outputs\n\nSummary:\nWe need to tell the iterator the compaction output file's level so it can apply proper optimizations, like pinning filter and index blocks when user enables `pin_l0_filter_and_index_blocks_in_cache` and the output file's level is zero.\nCloses https://github.com/facebook/rocksdb/pull/2949\n\nDifferential Revision: D5945597\n\nPulled By: ajkr\n\nfbshipit-source-id: 2389decf9026ffaa32d45801a77d002529f64a62",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction_job.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/821887036e5235c827029d14decb185bea01ec4b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionJob::FinishCompactionOutputFile"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "025b85b4ac078110302c039556e4c12ba8e7a731",
        "author": "Andrew Kryczka",
        "date": "2017-09-12T11:26:47-07:00",
        "message": "speedup DBTest.EncodeDecompressedBlockSizeTest\n\nSummary:\nit sometimes takes more than 10 minutes (i.e., times out) on our internal CI. mainly because bzip is super slow. so I reduced the amount of  work it tries to do.\nCloses https://github.com/facebook/rocksdb/pull/2856\n\nDifferential Revision: D5795883\n\nPulled By: ajkr\n\nfbshipit-source-id: e69f986ae60b44ecc26b6b024abd0f13bdf3a3c5",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/025b85b4ac078110302c039556e4c12ba8e7a731",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "20dc5e74f276bdcb26c44c13bced506a2d920d3f",
        "author": "Sagar Vemuri",
        "date": "2017-08-05T00:15:35-07:00",
        "message": "Optimize range-delete aggregator call in merge helper.\n\nSummary:\nIn the condition:\n```\nif (range_del_agg != nullptr &&\n    range_del_agg->ShouldDelete(\n        iter->key(),\n        RangeDelAggregator::RangePositioningMode::kForwardTraversal) &&\n    filter != CompactionFilter::Decision::kRemoveAndSkipUntil) {\n...\n}\n```\nit could be possible that all the work done in `range_del_agg->ShouldDelete` is wasted due to not having the right `filter` value later on.\nInstead, check `filter` value before even calling `range_del_agg->ShouldDelete`, which is a much more involved function.\nCloses https://github.com/facebook/rocksdb/pull/2690\n\nDifferential Revision: D5568931\n\nPulled By: sagar0\n\nfbshipit-source-id: 17512d52360425c7ae9de7675383f5d7bc3dad58",
        "modified_files_count": 1,
        "modified_files": [
            "db/merge_helper.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/20dc5e74f276bdcb26c44c13bced506a2d920d3f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MergeHelper::MergeUntil"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "58410aee44e902735659b80364eecc0e075676e9",
        "author": "Maysam Yabandeh",
        "date": "2017-08-03T10:43:28-07:00",
        "message": "Fix the overflow bug in AwaitState\n\nSummary:\nhttps://github.com/facebook/rocksdb/issues/2559 reports an overflow in AwaitState. nbronson has debugged the issue and presented the fix, which is applied to this patch. Moreover this patch adds more comments to clarify the logic in AwaitState.\n\nI tried with both 16 and 64 threads on update benchmark. The fix lowers cpu usage by 1.6 but also lowers the throughput by 1.6 and 2% respectively. Apparently the bug had favored using the spinning more often.\n\nBenchmarks:\nTEST_TMPDIR=/dev/shm/tmpdb time ./db_bench --benchmarks=\"fillrandom\" --threads=16 --num=2000000\nTEST_TMPDIR=/dev/shm/tmpdb time ./db_bench --use_existing_db=1 --benchmarks=\"updaterandom[X3]\" --threads=16 --num=2000000\nTEST_TMPDIR=/dev/shm/tmpdb time ./db_bench --use_existing_db=1 --benchmarks=\"updaterandom[X3]\" --threads=64 --num=200000\n\nResults\n$ cat update-16t-bug.txt | tail -4\nupdaterandom [AVG    3 runs] : 234117 ops/sec;   51.8 MB/sec\nupdaterandom [MEDIAN 3 runs] : 233581 ops/sec;   51.7 MB/sec\n3896.42user 1539.12system 6:50.61elapsed 1323%CPU (0avgtext+0avgdata 331308maxresident)k\n0inputs+0outputs (0major+1281001minor)pagefaults 0swaps\n$ cat update-16t-fixed.txt | tail -4\nupdaterandom [AVG    3 runs] : 230364 ops/sec;   51.0 MB/sec\nupdaterandom [MEDIAN 3 runs] : 226169 ops/sec;   50.0 MB/sec\n3865.46user 1568.32system 6:57.63elapsed 1301%CPU (0avgtext+0avgdata 315012maxresident)k\n0inputs+0outputs (0major+1342568minor)pagefaults 0swaps\n\n$ cat update-64t-bug.txt | tail -4\nupdaterandom [AVG    3 runs] : 261878 ops/sec;   57.9 MB/sec\nupdaterandom [MEDIAN 3 runs] : 262859 ops/sec;   58.2 MB/sec\n926.27user 578.06system 2:27.46elapsed 1020%CPU (0avgtext+0avgdata 475480maxresident)k\n0inputs+0outputs (0major+1058728minor)pagefaults 0swaps\n$ cat update-64t-fixed.txt | tail -4\nupdaterandom [AVG    3 runs] : 256699 ops/sec;   56.8 MB/sec\nupdaterandom [MEDIAN 3 runs] : 256380 ops/sec;   56.7 MB/sec\n933.47user 575.37system 2:30.41elapsed 1003%CPU (0avgtext+0avgdata 482340maxresident)k\n0inputs+0outputs (0major+1078557minor)pagefaults 0swaps\nCloses https://github.com/facebook/rocksdb/pull/2679\n\nDifferential Revision: D5553732\n\nPulled By: maysamyabandeh\n\nfbshipit-source-id: 98b72dc3a8e0f22ea29d4f7c7790af10c369c5bb",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_thread.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/58410aee44e902735659b80364eecc0e075676e9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteThread::AwaitState"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "3e5ea29a83270e8a0a93afe471022fc41adc8180",
        "author": "Islam AbdelRahman",
        "date": "2017-07-20T11:29:01-07:00",
        "message": "Fix Flaky DeleteSchedulerTest::ImmediateDeleteOn25PercDBSize\n\nSummary:\nIn this test we are deleting 100 files, and we are expecting DeleteScheduler to delete 26 files in the background and 74 files immediately in the foreground\n\nThe main purpose of the test is to make sure that we delete files in foreground thread, which is verified in line 546\n\nBut sometimes we may end up with 26 files or 25 files in the trash directory because the background thread may be slow and not be able to delete the first file fast enough, so sometimes this test fail.\n\nRemove\n```\nASSERT_EQ(CountFilesInDir(trash_dir_), 25);\n```\nSince it does not have any benefit any way\nCloses https://github.com/facebook/rocksdb/pull/2618\n\nDifferential Revision: D5458674\n\nPulled By: IslamAbdelRahman\n\nfbshipit-source-id: 5556a9edfa049db71dce80b8e6ae0fdd25e1e74e",
        "modified_files_count": 1,
        "modified_files": [
            "util/delete_scheduler_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/3e5ea29a83270e8a0a93afe471022fc41adc8180",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "521724ba8279df153ceb96eeba30a76904687853",
        "author": "jsteemann",
        "date": "2017-06-23T09:41:19-07:00",
        "message": "fixed wrong type for \"allow_compaction\" parameter\n\nSummary:\nshould be boolean, not uint64_t\nMSVC complains about it during compilation with error `include\\rocksdb\\advanced_options.h(77): warning C4800: 'uint64_t': forcing value to bool 'true' or 'false' (performance warning)`\nCloses https://github.com/facebook/rocksdb/pull/2487\n\nDifferential Revision: D5310685\n\nPulled By: siying\n\nfbshipit-source-id: 719a33b3dba4f711aa72e3f229013c188015dc86",
        "modified_files_count": 1,
        "modified_files": [
            "include/rocksdb/advanced_options.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/521724ba8279df153ceb96eeba30a76904687853",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionOptionsFIFO"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "90d835507581324d0449f1ded4f56a8b16f20bf7",
        "author": "xiusir",
        "date": "2017-02-28T10:39:11-08:00",
        "message": "Fix the wrong address for PREFETCH in DynamicBloom::Prefetch\n\nSummary:\n- Change data_[b] to data_[b / 8] in DynamicBloom::Prefetch, as b means the b-th bit in data_ and data_[b / 8] is the proper byte in data_.\nCloses https://github.com/facebook/rocksdb/pull/1935\n\nDifferential Revision: D4628696\n\nPulled By: siying\n\nfbshipit-source-id: bc5a0c6",
        "modified_files_count": 1,
        "modified_files": [
            "util/dynamic_bloom.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/90d835507581324d0449f1ded4f56a8b16f20bf7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DynamicBloom::Prefetch"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "18eeb7b90e45af4bbac0777021711d8547f41eca",
        "author": "Mike Kolupaev",
        "date": "2017-02-21T16:09:10-08:00",
        "message": "Fix interference between max_total_wal_size and db_write_buffer_size checks\n\nSummary:\nThis is a trivial fix for OOMs we've seen a few days ago in logdevice.\n\nRocksDB get into the following state:\n(1) Write throughput is too high for flushes to keep up. Compactions are out of the picture - automatic compactions are disabled, and for manual compactions we don't care that much if they fall behind. We write to many CFs, with only a few L0 sst files in each, so compactions are not needed most of the time.\n(2) total_log_size_ is consistently greater than GetMaxTotalWalSize(). It doesn't get smaller since flushes are falling ever further behind.\n(3) Total size of memtables is way above db_write_buffer_size and keeps growing. But the write_buffer_manager_->ShouldFlush() is not checked because (2) prevents it (for no good reason, afaict; this is what this commit fixes).\n(4) Every call to WriteImpl() hits the MaybeFlushColumnFamilies() path. This keeps flushing the memtables one by one in order of increasing log file number.\n(5) No write stalling trigger is hit. We rely on max_write_buffer_number\nCloses https://github.com/facebook/rocksdb/pull/1893\n\nDifferential Revision: D4593590\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: af79c5f",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/18eeb7b90e45af4bbac0777021711d8547f41eca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::WriteImpl"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "d438e1ec174bdf1474edcdf9902fe3cb14b8a1e2",
        "author": "Andrew Kryczka",
        "date": "2017-01-24T13:24:14-08:00",
        "message": "Test range deletion block outlives table reader\n\nSummary:\nThis test ensures RangeDelAggregator can still access blocks even if it outlives the table readers that created them (detailed description in comments).\n\nI plan to optimize away the extra cache lookup we currently do in BlockBasedTable::NewRangeTombstoneIterator(), as it is ~5% CPU in my random read benchmark in a database with 1k tombstones. This test will help make sure nothing breaks in the process.\nCloses https://github.com/facebook/rocksdb/pull/1739\n\nDifferential Revision: D4375954\n\nPulled By: ajkr\n\nfbshipit-source-id: aef9357",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_range_del_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d438e1ec174bdf1474edcdf9902fe3cb14b8a1e2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "9f246298e2f0af3973918a0dac0c5f46bc0993c0",
        "author": "Changli Gao",
        "date": "2017-01-11T10:54:37-08:00",
        "message": "Performance: Iterate vector by reference\n\nSummary: Closes https://github.com/facebook/rocksdb/pull/1763\n\nDifferential Revision: D4398796\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: b82636d",
        "modified_files_count": 1,
        "modified_files": [
            "db/event_helpers.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/9f246298e2f0af3973918a0dac0c5f46bc0993c0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "EventHelpers::LogAndNotifyTableFileDeletion"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "a2bf265a393721a30ddae9b04fde4aece6515c97",
        "author": "Islam AbdelRahman",
        "date": "2016-11-28T18:39:13-08:00",
        "message": "Avoid intentional overflow in GetL0ThresholdSpeedupCompaction\n\nSummary:\nhttps://github.com/facebook/rocksdb/commit/99c052a34f93d119b75eccdcd489ecd581d48ee9 fixes integer overflow in GetL0ThresholdSpeedupCompaction() by checking if int become -ve.\nUBSAN will complain about that since this is still an overflow, we can fix the issue by simply using int64_t\nCloses https://github.com/facebook/rocksdb/pull/1582\n\nDifferential Revision: D4241525\n\nPulled By: IslamAbdelRahman\n\nfbshipit-source-id: b3ae21f",
        "modified_files_count": 1,
        "modified_files": [
            "db/column_family.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a2bf265a393721a30ddae9b04fde4aece6515c97",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetL0ThresholdSpeedupCompaction"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "4444256ab79876bf33500ad4907c45b7b4d57137",
        "author": "Nick Terrell",
        "date": "2016-11-21T12:24:14-08:00",
        "message": "Remove use of deprecated LZ4 function\n\nSummary:\nLZ4 1.7.3 emits warnings when calling the deprecated function `LZ4_compress_limitedOutput_continue()`.  Starting in r129, LZ4 introduces `LZ4_compress_fast_continue()` as a replacement, and the two functions calls are [exactly equivalent](https://github.com/lz4/lz4/blob/dev/lib/lz4.c#L1408).\nCloses https://github.com/facebook/rocksdb/pull/1532\n\nDifferential Revision: D4199240\n\nPulled By: siying\n\nfbshipit-source-id: 138c2bc",
        "modified_files_count": 1,
        "modified_files": [
            "util/compression.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4444256ab79876bf33500ad4907c45b7b4d57137",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LZ4_Compress"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "da61f348d37e45a0cfd70893499d9f6625111b4e",
        "author": "Siying Dong",
        "date": "2016-10-31T16:09:13-07:00",
        "message": "Print compression and Fast CRC support info as Header level\n\nSummary:\nCurrently the compression suppport and fast CRC support information is printed as info level. They should be in the same level as options, which is header level.\n\nAlso add ZSTD to this printing.\nCloses https://github.com/facebook/rocksdb/pull/1448\n\nDifferential Revision: D4106608\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: cb9a076",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/da61f348d37e45a0cfd70893499d9f6625111b4e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DumpSupportInfo"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "48e4e842b79a0fe26ee9044830110f9a3484c20a",
        "author": "yiwu-arbug",
        "date": "2016-10-19T18:18:42-07:00",
        "message": "Disable auto compactions in memory_test and re-enable the test (#1408)\n\nSummary: Auto-compactions will change memory usage of DB but memory_test\r\ndidn't take it into account. This PR disable auto compactions in the\r\ntest and hopefully it fixes its flakyness.\r\n\r\nTest Plan:\r\nUBSAN build used to catch the flakyness. Run `make ubsan_check` and it\r\npasses.",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/memory/memory_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/48e4e842b79a0fe26ee9044830110f9a3484c20a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "21c55bdb6e97d3d86efab3770264be0d188c0a07",
        "author": "sdong",
        "date": "2016-07-15T16:10:09-07:00",
        "message": "DBTest.DynamicLevelCompressionPerLevel: Tune Threshold\n\nSummary: Each SST's file size increases after we add more table properties. Threshold in DBTest.DynamicLevelCompressionPerLevel need to adjust accordingly to avoid occasional failures.\n\nTest Plan: Run the test\n\nReviewers: andrewkr, yiwu\n\nSubscribers: leveldb, andrewkr, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D60819",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/21c55bdb6e97d3d86efab3770264be0d188c0a07",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "052299035803827efa6f1c2cb28d3dc3c6e8b1f7",
        "author": "Islam AbdelRahman",
        "date": "2016-04-08T12:05:02-07:00",
        "message": "Improve sst_dump help message\n\nSummary:\nCurrent Message\n\n```\nsst_dump [--command=check|scan|none|raw] [--verify_checksum] --file=data_dir_OR_sst_file [--output_hex] [--input_key_hex] [--from=<user_key>] [--to=<user_key>] [--read_num=NUM] [--show_properties] [--show_compression_sizes] [--show_compression_sizes [--set_block_size=<block_size>]]\n```\nNew message\n\n```\nsst_dump --file=<data_dir_OR_sst_file> [--command=check|scan|raw]\n    --file=<data_dir_OR_sst_file>\n      Path to SST file or directory containing SST files\n\n    --command=check|scan|raw\n        check: Iterate over entries in files but dont print anything except if an error is encounterd (default command)\n        scan: Iterate over entries in files and print them to screen\n        raw: Dump all the table contents to <file_name>_dump.txt\n\n    --output_hex\n      Can be combined with scan command to print the keys and values in Hex\n\n    --from=<user_key>\n      Key to start reading from when executing check|scan\n\n    --to=<user_key>\n      Key to stop reading at when executing check|scan\n\n    --read_num=<num>\n      Maximum number of entries to read when executing check|scan\n\n    --verify_checksum\n      Verify file checksum when executing check|scan\n\n    --input_key_hex\n      Can be combined with --from and --to to indicate that these values are encoded in Hex\n\n    --show_properties\n      Print table properties after iterating over the file\n\n    --show_compression_sizes\n      Independent command that will recreate the SST file using 16K block size with different\n      compressions and report the size of the file using such compression\n\n    --set_block_size=<block_size>\n      Can be combined with --show_compression_sizes to set the block size that will be used\n      when trying different compression algorithms\n```\n\nTest Plan: none\n\nReviewers: yhchiang, andrewkr, kradhakrishnan, yiwu, sdong\n\nReviewed By: sdong\n\nSubscribers: andrewkr, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D56325",
        "modified_files_count": 1,
        "modified_files": [
            "tools/sst_dump_tool.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/052299035803827efa6f1c2cb28d3dc3c6e8b1f7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "print_help"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "1a2cc27e013b561c9d3c8b81384d14443822057f",
        "author": "Dhruba Borthakur",
        "date": "2016-03-14T16:21:54-07:00",
        "message": "ColumnFamilyOptions SanitizeOptions is buggy on 32-bit platforms.\n\nSummary:\nThe pre-existing code is trying to clamp between 65,536 and 0,\nresulting in clamping to 65,536, resulting in very small buffers,\nresulting in ShouldFlushNow() being true quite easily,\nresulting in assertion failing and database performance\nbeing \"not what it should be\".\n\nhttps://github.com/facebook/rocksdb/issues/1018\n\nTest Plan: make check\n\nReviewers: sdong, andrewkr, IslamAbdelRahman, yhchiang, igor\n\nReviewed By: igor\n\nSubscribers: leveldb, andrewkr, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D55455",
        "modified_files_count": 1,
        "modified_files": [
            "db/column_family.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1a2cc27e013b561c9d3c8b81384d14443822057f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SanitizeOptions"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "a7b6f0748a1bcdead0168df19901cfc15c9dc881",
        "author": "reid horuff",
        "date": "2016-02-16T14:04:14-08:00",
        "message": "Improve write_with_callback_test to sync WAL\n\nSummary: Currently write_with_callback_test does not test with WAL syncing enabled. This addresses that.\n\nTest Plan: write_with_callback_test\n\nReviewers: anthony\n\nReviewed By: anthony\n\nSubscribers: leveldb, dhruba, hermanlee4\n\nDifferential Revision: https://reviews.facebook.net/D54255",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_callback_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a7b6f0748a1bcdead0168df19901cfc15c9dc881",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "8019aa9b55c90ae2b89889d6260674f4c8fd19ff",
        "author": "agiardullo",
        "date": "2016-01-22T11:47:59-08:00",
        "message": "improve test for manifest write failure\n\nSummary: Improve testing per discussion in D52989\n\nTest Plan: ran test\n\nReviewers: sdong\n\nReviewed By: sdong\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D53211",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/8019aa9b55c90ae2b89889d6260674f4c8fd19ff",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "291088ae4e583ccdf4de0881a8762bb5412f7d27",
        "author": "sdong",
        "date": "2015-12-07T10:53:29-08:00",
        "message": "Fix undeterministic failure of ColumnFamilyTest.DifferentWriteBufferSizes\n\nSummary: After the skip list optimization, ColumnFamilyTest.DifferentWriteBufferSizes can occasionally fail with flush triggering of column family 3. Insert more data to it to make sure flush will trigger.\n\nTest Plan: Run it multiple times with both of jemaloc on and off and see it always passes. (Without thd commit the run with jemalloc fails with chance of about one in two)\n\nReviewers: rven, yhchiang, IslamAbdelRahman, anthony, kradhakrishnan, igor\n\nReviewed By: igor\n\nSubscribers: leveldb, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D51645",
        "modified_files_count": 1,
        "modified_files": [
            "db/column_family_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/291088ae4e583ccdf4de0881a8762bb5412f7d27",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "e61d9c1484c32bd0028604ef65a724f7f55f2447",
        "author": "sdong",
        "date": "2015-10-09T09:47:56-07:00",
        "message": "Make DBTest.AggregatedTableProperties more deterministic\n\nSummary: Now based on environment, DBTest.AggregatedTableProperties has a possibility of issuing a L0->L1 compaction after reopening and the results are not what we expected. We tune the L0 compaction trigger to make it less likely to happen.\n\nTest Plan: I can't repro the failure but I think the change is better. Just run the test and make sure it passes.\n\nReviewers: kradhakrishnan, yhchiang, igor\n\nReviewed By: igor\n\nSubscribers: leveldb, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D48423",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e61d9c1484c32bd0028604ef65a724f7f55f2447",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "4704833357a8609e7c42df4f337f938a8e870c08",
        "author": "jsteemann",
        "date": "2015-09-18T20:20:32+02:00",
        "message": "pass input string to WriteBatch() by const reference\n\nthis may lead to copying less data (in case compilers don't\noptimize away copying the string by themselves)",
        "modified_files_count": 1,
        "modified_files": [
            "include/rocksdb/write_batch.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4704833357a8609e7c42df4f337f938a8e870c08",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatch"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "abc7f5fdb266745493d89b09719d9dd091e2b3b8",
        "author": "sdong",
        "date": "2015-09-10T11:32:19-07:00",
        "message": "Make DBTest.ReadLatencyHistogramByLevel more robust\n\nSummary: DBTest.ReadLatencyHistogramByLevel was not written as expected. After writes, reads aren't guaranteed to hit data written. It was not expected. Fix it.\n\nTest Plan: Run the test multiple times\n\nReviewers: IslamAbdelRahman, rven, anthony, kradhakrishnan, yhchiang, igor\n\nReviewed By: igor\n\nSubscribers: leveldb, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D46587",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/abc7f5fdb266745493d89b09719d9dd091e2b3b8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "342ba8089528ac1ed4636f2c320b4508151b1f0b",
        "author": "sdong",
        "date": "2015-09-08T19:31:34-07:00",
        "message": "Make DBTest.OptimizeFiltersForHits more deterministic\n\nSummary:\nThis commit makes DBTest.OptimizeFiltersForHits more deterministic by:\n(1) make key inserts more random\n(2) make sure L0 has one file\n(3) make file size smaller compared to level target so L1 will cover more range.\n\nTest Plan: Run the test many times.\n\nReviewers: rven, IslamAbdelRahman, kradhakrishnan, igor, anthony\n\nReviewed By: anthony\n\nSubscribers: leveldb, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D46461",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/342ba8089528ac1ed4636f2c320b4508151b1f0b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "e853191c17eb85f527d0e495a612fd0679b241ea",
        "author": "Andres Noetzli",
        "date": "2015-08-27T16:17:08-07:00",
        "message": "Fix DBTest.ApproximateMemoryUsage\n\nSummary:\nThis patch fixes two issues in DBTest.ApproximateMemoryUsage:\n- It was possible that a flush happened between getting the two properties in\n  Phase 1, resulting in different numbers for the properties and failing the\n  assertion. This is fixed by waiting for the flush to finish before getting\n  the properties.\n- There was a similar issue in Phase 2 and additionally there was an issue that\n  rocksdb.size-all-mem-tables was not monotonically increasing because it was\n  possible that a flush happened just after getting the properties and then\n  another flush just before getting the properties in the next round. In this\n  situation, the reported memory usage decreased. This is fixed by forcing a\n  flush before getting the properties.\n\nNote: during testing, I found that kFlushesPerRound does not seem very\naccurate. I added a TODO for this and it would be great to get some input on\nwhat to do there.\n\nTest Plan:\nThe first issue can be made more likely to trigger by inserting a\n`usleep(10000);` between the calls to GetIntProperty() in Phase 1.\nThe second issue can be made more likely to trigger by inserting a\n`if (r != 0) usleep(10000);` before the calls to GetIntProperty() and a\n`usleep(10000);` after the calls.\nThen execute make db_test && ./db_test --gtest_filter=DBTest.ApproximateMemoryUsage\n\nReviewers: rven, yhchiang, igor, sdong, anthony\n\nReviewed By: anthony\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D45675",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e853191c17eb85f527d0e495a612fd0679b241ea",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "3ab8ffd4dd406d25a4164ea0d7e1aa5b30bca5a8",
        "author": "Yueh-Hsuan Chiang",
        "date": "2015-05-26T14:05:38-07:00",
        "message": "Compaction now conditionally boosts the size of deletion entries.\n\nSummary:\nCompaction now boosts the size of deletion entries of a file only when\nthe number of deletion entries is greater than the number of non-deletion\nentries in the file.  The motivation here is that in a stable workload,\nthe number of deletion entries should be roughly equal to the number of\nnon-deletion entries.  If we compensate the size of deletion entries in a\nstable workload, the deletion compensation logic might introduce unwanted\neffet which changes the shape of LSM tree.\n\nTest Plan: db_test --gtest_filter=\"*Deletion*\"\n\nReviewers: sdong, igor\n\nReviewed By: igor\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D38703",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_set.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/3ab8ffd4dd406d25a4164ea0d7e1aa5b30bca5a8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionStorageInfo::ComputeCompensatedSizes"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "fb5bdbf9875bb2c9b583b82eb6d881ac2c39ddc7",
        "author": "sdong",
        "date": "2015-05-18T11:49:45-07:00",
        "message": "DBTest.DynamicLevelMaxBytesCompactRange: make sure L0 is not empty before running compact range\n\nSummary: DBTest.DynamicLevelMaxBytesCompactRange needs to make sure L0 is not empty to properly cover the code paths we want to cover. However, current codes have a bug that might leave the condition not held. Improve the test to ensure it.\n\nTest Plan: Run the test in an environment that is used to fail. Also run it many times.\n\nSubscribers: leveldb, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D38631",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/fb5bdbf9875bb2c9b583b82eb6d881ac2c39ddc7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "48b0a045da0ef7c07b59c529fc9a5c5f682853b6",
        "author": "Igor Canadi",
        "date": "2015-04-16T19:31:34-07:00",
        "message": "Speed up reduce_levels_test\n\nSummary: For some reason reduce_levels is opening the databse with 65.000 levels. This makes ComputeCompactionScore() function terribly slow and the tests is also very slow (20seconds).\n\nTest Plan: mr reduce_levels_test now takes 20ms\n\nReviewers: sdong, rven, kradhakrishnan, yhchiang\n\nReviewed By: yhchiang\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D37059",
        "modified_files_count": 1,
        "modified_files": [
            "util/ldb_cmd.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/48b0a045da0ef7c07b59c529fc9a5c5f682853b6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "old_levels_"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "08be1803eecb5ae464440812ea06e79b21289053",
        "author": "Igor Canadi",
        "date": "2015-04-13T15:58:45-07:00",
        "message": "Fix bad performance in debug mode\n\nSummary:\nSee github issue 574: https://github.com/facebook/rocksdb/issues/574\n\nBasically when we're running in DEBUG mode we're calling `usleep(0)` on\nevery mutex lock. I bisected the issue to\nhttps://reviews.facebook.net/D36963. Instead of calling sleep(0), this\ndiff just avoids calling SleepForMicroseconds() when delay is not set.\n\nTest Plan:\n    bpl=10485760;overlap=10;mcz=2;del=300000000;levels=2;ctrig=10000000; delay=10000000; stop=10000000; wbn=30; mbc=20; mb=1073741824;wbs=268435456; dds=1; sync=0; r=100000; t=1; vs=800; bs=65536; cs=1048576; of=500000; si=1000000; ./db_bench --benchmarks=fillrandom --disable_seek_compaction=1 --mmap_read=0 --statistics=1 --histogram=1 --num=$r --threads=$t --value_size=$vs --block_size=$bs --cache_size=$cs --bloom_bits=10 --cache_numshardbits=4 --open_files=$of --verify_checksum=1 --db=/tmp/rdb10test --sync=$sync --disable_wal=1 --compression_type=snappy --stats_interval=$si --compression_ratio=0.5 --disable_data_sync=$dds --write_buffer_size=$wbs --target_file_size_base=$mb --max_write_buffer_number=$wbn --max_background_compactions=$mbc --level0_file_num_compaction_trigger=$ctrig --level0_slowdown_writes_trigger=$delay --level0_stop_writes_trigger=$stop --num_levels=$levels --delete_obsolete_files_period_micros=$del --min_level_to_compress=$mcz --max_grandparent_overlap_factor=$overlap --stats_per_interval=1 --max_bytes_for_level_base=$bpl --memtablerep=vector --use_existing_db=0 --disable_auto_compactions=1 --source_compaction_factor=10000000 | grep ops\n\nBefore:\nfillrandom   :     117.525 micros/op 8508 ops/sec;    6.6 MB/s\nAfter:\nfillrandom   :       1.283 micros/op 779502 ops/sec;  606.6 MB/s\n\nReviewers: rven, yhchiang, sdong\n\nReviewed By: sdong\n\nSubscribers: meyering, dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D36963",
        "modified_files_count": 1,
        "modified_files": [
            "util/thread_status_util_debug.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/08be1803eecb5ae464440812ea06e79b21289053",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ThreadStatusUtil::TEST_StateDelay"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "b1bbdd79191d8fc605e3fd41e801b23022d59b5b",
        "author": "sdong",
        "date": "2015-04-08T14:40:42-07:00",
        "message": "Create EnvOptions using sanitized DB Options\n\nSummary: Now EnvOptions uses unsanitized DB options. bytes_per_sync is tuned off when rate_limiter is used, but this change doesn't take effort.\n\nTest Plan: See different I/O pattern in db_bench running fillseq.\n\nReviewers: yhchiang, kradhakrishnan, rven, anthony, igor\n\nReviewed By: igor\n\nSubscribers: leveldb, dhruba\n\nDifferential Revision: https://reviews.facebook.net/D36723",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b1bbdd79191d8fc605e3fd41e801b23022d59b5b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "flush_on_destroy_"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "f69071265203edb0084f136b03bd4fcb42f16911",
        "author": "Igor Canadi",
        "date": "2015-03-13T14:45:15-07:00",
        "message": "Speed up db_bench shutdown\n\nSummary: See t6489044\n\nTest Plan: compiles\n\nReviewers: MarkCallaghan\n\nReviewed By: MarkCallaghan\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D34977",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_bench.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f69071265203edb0084f136b03bd4fcb42f16911",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "~Benchmark"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "c1b3cde18abf2749ca6772cb8747510778c410b3",
        "author": "Yueh-Hsuan Chiang",
        "date": "2015-03-13T13:16:53-07:00",
        "message": "Improve the robustness of ThreadStatusSingleCompaction\n\nSummary:\nImprove the robustness of ThreadStatusSingleCompaction\nby ensuring the number of files flushed in the test.\n\nTest Plan:\nexport ROCKSDB_TESTS=ThreadStatus\n./db_test\n\nReviewers: sdong, igor\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D35019",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/c1b3cde18abf2749ca6772cb8747510778c410b3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "2ddf53b2cad65283538e65436580f9589060a221",
        "author": "Igor Canadi",
        "date": "2015-03-10T17:53:22-07:00",
        "message": "Get OptimizeFilterForHits work on Mac\n\nSummary: Got it working by some voodoo programming\n\nTest Plan: works!\n\nReviewers: sdong\n\nReviewed By: sdong\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D34611",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/2ddf53b2cad65283538e65436580f9589060a221",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "bf9aa4dfcd27e7dc4f55d63d0adf5abaf86b06bd",
        "author": "Yueh-Hsuan Chiang",
        "date": "2015-01-13T00:38:09-08:00",
        "message": "Improve GetThreadStatus to avoid false alarm in some case.",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/bf9aa4dfcd27e7dc4f55d63d0adf5abaf86b06bd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "90ee85f8e11d52a04dedc663f20c8128ee0bde8d",
        "author": "Yueh-Hsuan Chiang",
        "date": "2014-11-24T18:28:06-08:00",
        "message": "Improve listener_test to avoid possible false alarm\n\nSummary:\nImprove listener_test to avoid possible false alarm\n\nTest Plan:\n./listener_test",
        "modified_files_count": 1,
        "modified_files": [
            "db/listener_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/90ee85f8e11d52a04dedc663f20c8128ee0bde8d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "aa31fc506827b11b585d150b63b42f103a74f07a",
        "author": "Yueh-Hsuan Chiang",
        "date": "2014-11-21T10:22:05-08:00",
        "message": "Improve listener_test by ensuring flushes are completed before assert.\n\nSummary: Improve listener_test by ensuring flushes are completed before assert.\n\nTest Plan: listener_test\n\nReviewers: ljin, sdong, igor\n\nReviewed By: igor\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D29319",
        "modified_files_count": 1,
        "modified_files": [
            "db/listener_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/aa31fc506827b11b585d150b63b42f103a74f07a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Flush"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "fb3f8ffe5e7c0bdecc40f89cf95cb1b86746b729",
        "author": "Yueh-Hsuan Chiang",
        "date": "2014-10-28T15:35:10-07:00",
        "message": "Improve the robustness of PartialCompactionFailure test again.\n\nSummary:\nImprove the robustness of PartialCompactionFailure test again.\n\nTest Plan:\n./db_test",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/fb3f8ffe5e7c0bdecc40f89cf95cb1b86746b729",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "60fa7d1365323f32b29b3441b3678dd3c319dafc",
        "author": "Yueh-Hsuan Chiang",
        "date": "2014-10-28T15:17:50-07:00",
        "message": "Improve the robustnesss of PartialCompactionFailure test.\n\nSummary:\nImprove the robustness of PartialCompactionFailure test.\n\nTest Plan:\n./db_test",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/60fa7d1365323f32b29b3441b3678dd3c319dafc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "724fba2b397396978bbe9533c5be81564ffe090e",
        "author": "Yueh-Hsuan Chiang",
        "date": "2014-10-23T15:43:51-07:00",
        "message": "Improve the log in Universal Compaction to include more debug information.\n\nSummary:\nPreviously, the log for Universal Compaction does not include the current\nnumber of files in case the compaction is triggered by the number of files.\nThis diff includes the number of files in the log.\n\nTest Plan:\nmake",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction_picker.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/724fba2b397396978bbe9533c5be81564ffe090e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "UniversalCompactionPicker::PickCompaction"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "55652043c83c463ce57b7748e01c6d12bb5bf9fe",
        "author": "Danny Al-Gaaf",
        "date": "2014-10-01T10:49:08+02:00",
        "message": "table/cuckoo_table_reader.cc: pass func parameter by reference\n\nFix for:\n\n[table/cuckoo_table_reader.cc:196]: (performance) Function\n parameter 'target' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/cuckoo_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/55652043c83c463ce57b7748e01c6d12bb5bf9fe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BucketComparator"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "43c789c8f246a2a35864e3fca9585b55c40c2095",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "spatialdb/spatial_db.cc: use !empty() instead of 'size() > 0'\n\nUse empty() since it should be prefered as it has, following\nthe standard, a constant time complexity regardless of the\ncontainter type. The same is not guaranteed for size().\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/spatialdb/spatial_db.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/43c789c8f246a2a35864e3fca9585b55c40c2095",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SpatialIndexCursor"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "873f1356a1781e8d638973ea320b722d3240fc5a",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "db_ttl_impl.h: pass func parameter by reference\n\nFix for:\n\n[utilities/ttl/db_ttl_impl.h:209]: (performance) Function parameter\n 'merge_op' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/ttl/db_ttl_impl.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/873f1356a1781e8d638973ea320b722d3240fc5a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TtlMergeOperator"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "8558457143bfa76d61e0d2f715e40ec2ddb6ffc2",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "ldb_cmd_execute_result.h: perform init in initialization list\n\nFix for:\n\n[util/ldb_cmd_execute_result.h:18]: (performance) Variable 'message_'\n is assigned in constructor body. Consider performing initialization\n in initialization list.\n[util/ldb_cmd_execute_result.h:23]: (performance) Variable 'message_'\n is assigned in constructor body. Consider performing initialization\n in initialization list.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "util/ldb_cmd_execute_result.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/8558457143bfa76d61e0d2f715e40ec2ddb6ffc2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LDBCommandExecuteResult"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "063471bf7613544496a4d4b5a1e1ba4a7aa605cf",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "table/table_test.cc: pass func parameter by reference\n\nFix for:\n\n[table/table_test.cc:1218]: (performance) Function parameter\n 'prefix' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/table_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/063471bf7613544496a4d4b5a1e1ba4a7aa605cf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AddInternalKey"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "93548ce8f451a701ad0967ba705f04fef80aa11a",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "table/cuckoo_table_reader.cc: pass func parameter by ref\n\nFix for:\n\n[table/cuckoo_table_reader.cc:198]: (performance) Function\n parameter 'file_data' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/cuckoo_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/93548ce8f451a701ad0967ba705f04fef80aa11a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BucketComparator"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "b8b7117e97e649fc65d0a4dd397caf9a39fb71b1",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "db/version_set.cc: use !empty() instead of 'size() > 0'\n\nUse empty() since it should be prefered as it has, following\nthe standard, a constant time complexity regardless of the\ncontainter type. The same is not guaranteed for size().\n\nFix for:\n[db/version_set.cc:2250]: (performance) Possible inefficient\n checking for 'column_families_not_found' emptiness.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_set.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b8b7117e97e649fc65d0a4dd397caf9a39fb71b1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionSet::Recover"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "53910ddb152fbcba95a3e04b058a997c40f654ae",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "db_test.cc: pass parameter by reference\n\nFix for:\n\n[db/db_test.cc:6141]: (performance) Function parameter\n 'key' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/53910ddb152fbcba95a3e04b058a997c40f654ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "convertKey"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "68ca534169a4f9e1930f6511109e973b43cf5998",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "corruption_test.cc: pass parameter by reference\n\nFix for:\n\n[db/corruption_test.cc:134]: (performance) Function parameter\n 'fname' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/corruption_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/68ca534169a4f9e1930f6511109e973b43cf5998",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CorruptFile"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "1f963305a8f3384da3215c37ed7a264c5c99417c",
        "author": "Mark Callaghan",
        "date": "2014-09-29T17:51:40-07:00",
        "message": "Print MB per second compaction throughput separately for reads and writes\n\nSummary:\nFrom this line there used to be one column (MB/sec) that includes reads and writes. This change splits it and for real workloads the rd and wr rates might not match when keys are dropped.\n2014/09/29-17:31:01.213162 7f929fbff700 (Original Log Time 2014/09/29-17:31:01.180025) [default] compacted to: files[2 5 0 0 0 0 0], MB/sec: 14.0 rd, 14.0 wr, level 1, files in(4, 0) out(5) MB in(8.5, 0.0) out(8.5), read-write-amplify(2.0) write-amplify(1.0) OK\n\nTest Plan:\nmake check, grepped LOG\n\n- begin *PUBLIC* platform impact section -\nBugzilla: #\n- end platform impact -\n\nReviewers: igor\n\nDifferential Revision: https://reviews.facebook.net/D24237",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1f963305a8f3384da3215c37ed7a264c5c99417c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::DoCompactionWork"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "0c26e76b28323a6ab10b0aae8832e6d76339cf24",
        "author": "Igor Canadi",
        "date": "2014-08-28T20:40:10-04:00",
        "message": "Merge pull request #237 from tdfischer/tdfischer/faster-timeout-test\n\ntest: db: fix test to have a smaller timeout for when it runs on faster ...",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/0c26e76b28323a6ab10b0aae8832e6d76339cf24",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "536e9973e30d70fd510e5ab6e423ef75248ed582",
        "author": "Igor Canadi",
        "date": "2014-08-27T11:05:41-07:00",
        "message": "Remove assert in vector rep\n\nSummary: This assert makes Insert O(n^2) instead of O(n) in debug mode. Memtable insert is in the critical path. No need to assert uniqunnes of the key here, since we're adding a sequence number to it anyway.\n\nTest Plan: none\n\nReviewers: sdong, ljin\n\nReviewed By: ljin\n\nSubscribers: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D22443",
        "modified_files_count": 1,
        "modified_files": [
            "util/vectorrep.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/536e9973e30d70fd510e5ab6e423ef75248ed582",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VectorRep::Insert"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "01cbdd2aae8f998e3e532dec06f0f373a6cff719",
        "author": "Igor Canadi",
        "date": "2014-08-20T11:14:01-07:00",
        "message": "Optimize storage parameters for spatialDB\n\nSummary: We need to start compression at level 1, while OptimizeForLevelComapaction() only sets up rocksdb to start compressing at level 2. I also adjusted some other things.\n\nTest Plan: compiles\n\nReviewers: yinwang\n\nReviewed By: yinwang\n\nDifferential Revision: https://reviews.facebook.net/D22203",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/spatialdb/spatial_db.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/01cbdd2aae8f998e3e532dec06f0f373a6cff719",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetRocksDBOptionsFromOptions"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "7c5173d27f4432fe7799f5fc7a85f857b61a3d6b",
        "author": "Torrie Fischer",
        "date": "2014-08-19T13:45:12-07:00",
        "message": "test: db: fix test to have a smaller timeout for when it runs on faster hardware",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/7c5173d27f4432fe7799f5fc7a85f857b61a3d6b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "b278ae8e50466e8073a1754a506145df5bb27c72",
        "author": "Lei Jin",
        "date": "2014-07-08T11:40:42-07:00",
        "message": "Apply fractional cascading in ForwardIterator::Seek()\n\nSummary:\nUse search hint to reduce FindFile range thus avoid comparison\nFor a small DB with 50M keys, perf_context counter shows it reduces\ncomparison from 2B to 1.3B for a 15-minute run. No perf change was\nobserved for 1 seek thread, but quite good improvement was seen for 32\nseek threads, when CPU was busy.\nwill post detail results when ready\n\nTest Plan: db_bench and db_test\n\nReviewers: haobo, sdong, dhruba, igor\n\nReviewed By: igor\n\nSubscribers: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D18879",
        "modified_files_count": 1,
        "modified_files": [
            "db/forward_iterator.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b278ae8e50466e8073a1754a506145df5bb27c72",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ForwardIterator::SeekInternal"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "7b85c1e900a1e0f47c78ff1ddfa8ddd924715eaf",
        "author": "Yueh-Hsuan Chiang",
        "date": "2014-07-04T00:02:12-07:00",
        "message": "Improve SimpleWriteTimeoutTest to avoid false alarm.\n\nSummary:\nSimpleWriteTimeoutTest has two parts: 1) insert two large key/values\nto make memtable full and expect both of them are successful; 2) insert\nanother key / value and expect it to be timed-out.  Previously we also\nset a timeout in the first step, but this might sometimes cause\nfalse alarm.\n\nThis diff makes the first two writes run without timeout setting.\n\nTest Plan:\nexport ROCKSDB_TESTS=Time\nmake db_test\n\nReviewers: sdong, ljin\n\nReviewed By: ljin\n\nSubscribers: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D19461",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/7b85c1e900a1e0f47c78ff1ddfa8ddd924715eaf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "faa8d21922b09988c86c75887cd7a49895120e25",
        "author": "Yueh-Hsuan Chiang",
        "date": "2014-06-24T15:29:28-06:00",
        "message": "Improve an assertion in RandomGenerator::Generate() in db_bench.\n\nSummary:\nRandomGenerator::Generate() currently has an assertion len < data_.size().\nHowever, it is actually fine to have len == data_.size().\nThis diff change the assertion to len <= data_.size().\n\nTest Plan:\nmake db_bench\n./db_bench\n\nReviewers: haobo, sdong, ljin\n\nReviewed By: ljin\n\nSubscribers: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D19269",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_bench.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/faa8d21922b09988c86c75887cd7a49895120e25",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Generate"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "beeee9dccc338ae7129016f2f2e17d2a40ecc5df",
        "author": "Igor Canadi",
        "date": "2014-04-08T11:06:39-07:00",
        "message": "Small speedup of CompactionFilterV2\n\nSummary: ToString() is expensive. Profiling shows that most compaction threads are stuck in jemalloc, allocating a new string. This will help out a litte.\n\nTest Plan: make check\n\nReviewers: haobo, danguo\n\nReviewed By: danguo\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D17583",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/beeee9dccc338ae7129016f2f2e17d2a40ecc5df",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::DoCompactionWork"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "7dea558e6d202c9dbf34e15077d5c9c8db594bf9",
        "author": "Siying Dong",
        "date": "2014-01-21T12:44:43-08:00",
        "message": "[Performance Branch] Fix a bug when merging from master\n\nSummary: Commit \"1304d8c8cefe66be1a3caa5e93413211ba2486f2\" (Merge branch 'master' into performance) removes a line in performance branch by mistake. This patch fixes it.\n\nTest Plan: make all check\n\nReviewers: haobo, kailiu, igor\n\nReviewed By: haobo\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D15297",
        "modified_files_count": 1,
        "modified_files": [
            "db/memtable.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/7dea558e6d202c9dbf34e15077d5c9c8db594bf9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MemTableIterator"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "4e8321bfeae8541fb5d827dfcb089e39078841bc",
        "author": "Mark Callaghan",
        "date": "2014-01-17T21:32:23-08:00",
        "message": "Boost access before mutex is unlocked\n\nSummary:\nThis moves the use of versions_ to before the mutex is unlocked\nto avoid a possible race.\n\nTask ID: #\n\nBlame Rev:\n\nTest Plan:\nmake check\n\nRevert Plan:\n\nDatabase Impact:\n\nMemcache Impact:\n\nOther Notes:\n\nEImportant:\n\n- begin *PUBLIC* platform impact section -\nBugzilla: #\n- end platform impact -\n\nReviewers: haobo, dhruba\n\nReviewed By: dhruba\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D15279",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4e8321bfeae8541fb5d827dfcb089e39078841bc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::MakeRoomForWrite"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "9b51af5a17f3cfd754575894e090dd867fb47740",
        "author": "Siying Dong",
        "date": "2014-01-14T17:41:44-08:00",
        "message": "[RocksDB Performance Branch] DBImpl.NewInternalIterator() to reduce works inside mutex\n\nSummary: To reduce mutex contention caused by DBImpl.NewInternalIterator(), in this function, move all the iteration creation works out of mutex, only leaving object ref and get.\n\nTest Plan:\nmake all check\nwill run db_stress for a while too to make sure no problem.\n\nReviewers: haobo, dhruba, kailiu\n\nReviewed By: haobo\n\nCC: igor, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14589\n\nConflicts:\n\tdb/db_impl.cc",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/9b51af5a17f3cfd754575894e090dd867fb47740",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::NewInternalIterator"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "bf4a48ccb356cf5ed205a30201e751218da7cfb0",
        "author": "Haobo Xu",
        "date": "2013-12-20T18:20:06-08:00",
        "message": "[RocksDB] [Performance Branch] Revert previous patch.\n\nSummary: The previous patch is wrong. rep_.resize(kHeader) just resets the header portion to zero, and should not cause a re-allocation if g++ does it right. I will go ahead and revert it.\n\nTest Plan: make check\n\nReviewers: dhruba, sdong\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14793",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_batch.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/bf4a48ccb356cf5ed205a30201e751218da7cfb0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatch::Clear"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "e94eea4527f2d7de82a6bf3303177977011e5dd9",
        "author": "Haobo Xu",
        "date": "2013-12-20T16:29:05-08:00",
        "message": "[RocksDB] [Performance Branch] Minor fix, Remove string resize from WriteBatch::Clear\n\nSummary: tmp_batch_ will get re-allocated for every merged write batch because of the existing resize in WriteBatch::Clear. Note that in DBImpl::BuildBatchGroup, we have a hard coded upper limit of batch size 1<<20 = 1MB already.\n\nTest Plan: make check\n\nReviewers: dhruba, sdong\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14787",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_batch.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e94eea4527f2d7de82a6bf3303177977011e5dd9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatch::Clear"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "5090316f0ded4bf9af04d78cbacb031824d31c3f",
        "author": "Haobo Xu",
        "date": "2013-12-13T14:21:59-08:00",
        "message": "[RocksDB] [Performance Branch] Trivia build fix\n\nSummary: make release complains signed unsigned comparison.\n\nTest Plan: make release\n\nReviewers: kailiu\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14661",
        "modified_files_count": 1,
        "modified_files": [
            "util/cache_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/5090316f0ded4bf9af04d78cbacb031824d31c3f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "e8ab1934d9cb3ffebd61097d67bb23439554b265",
        "author": "Siying Dong",
        "date": "2013-12-12T11:30:00-08:00",
        "message": "[RocksDB Performance Branch] DBImpl.NewInternalIterator() to reduce works inside mutex\n\nSummary: To reduce mutex contention caused by DBImpl.NewInternalIterator(), in this function, move all the iteration creation works out of mutex, only leaving object ref and get.\n\nTest Plan:\nmake all check\nwill run db_stress for a while too to make sure no problem.\n\nReviewers: haobo, dhruba, kailiu\n\nReviewed By: haobo\n\nCC: igor, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14589",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e8ab1934d9cb3ffebd61097d67bb23439554b265",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::NewInternalIterator"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "4c81383628db46d35b674000a3668b5a9a2498a6",
        "author": "lovro",
        "date": "2013-11-27T11:28:06-08:00",
        "message": "Set background thread name with pthread_setname_np()\n\nSummary: Makes it easier to monitor performance with top\n\nTest Plan: ./manual_compaction_test with `top -H` running.  Previously was two `manual_compacti`, now one shows `rocksdb:bg0`.\n\nReviewers: igor, dhruba\n\nReviewed By: igor\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14367",
        "modified_files_count": 1,
        "modified_files": [
            "util/env_posix.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4c81383628db46d35b674000a3668b5a9a2498a6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Schedule"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "8aac46d6864d56b1ff2baa4a7b01d2f2e72f28f9",
        "author": "Siying Dong",
        "date": "2013-11-26T14:05:37-08:00",
        "message": "[RocksDB Performance Branch] Fix a regression bug of munmap\n\nSummary:\nFix a stupid bug I just introduced in b59d4d5a5051263b4bfcef00913219ffe4654e42, which I didn't even mean to include.\nGCC might remove the munmap.\n\nTest Plan: Run it and make sure munmap succeeds\n\nReviewers: haobo, kailiu\n\nReviewed By: kailiu\n\nCC: dhruba, reconnect.grayhat, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14361",
        "modified_files_count": 1,
        "modified_files": [
            "util/env_posix.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/8aac46d6864d56b1ff2baa4a7b01d2f2e72f28f9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "~PosixMmapReadableFile"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "1ca86f0391bd4e2d262afef0314a241940d445a8",
        "author": "Kai Liu",
        "date": "2013-10-28T10:51:34-07:00",
        "message": "Fix a bug that index block's restart_block_interval is not 1\n\nSummary:\n\nThis bug may affect the seek performance.\n\nTest Plan:\n\nmake\nmake check\n\nAlso gdb into some index block builder to make sure the restart_block_interval is `1`.",
        "modified_files_count": 1,
        "modified_files": [
            "table/table_builder.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1ca86f0391bd4e2d262afef0314a241940d445a8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Rep"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "821889e20764e88276e83df37e485a64191f1d75",
        "author": "Mayank Agarwal",
        "date": "2013-07-10T18:07:13-07:00",
        "message": "Print complete statistics in db_stress\n\nSummary: db_stress should alos print complete statistics like db_bench. Needed this when I wanted to measure number of delete-IOs dropped due to CheckKeyMayExist to be introduced to rocksdb codebase later- to make deltes in rocksdb faster\n\nTest Plan: make db_stress;./db_stress --max_key=100 --ops_per_thread=1000 --statistics=1\n\nReviewers: sheki, dhruba, vamsi, haobo\n\nReviewed By: dhruba\n\nDifferential Revision: https://reviews.facebook.net/D11655",
        "modified_files_count": 1,
        "modified_files": [
            "tools/db_stress.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/821889e20764e88276e83df37e485a64191f1d75",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PrintStatistics"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "c3c13db346749c3dfe45e167db2129c645377e9e",
        "author": "Haobo Xu",
        "date": "2013-05-21T13:40:38-07:00",
        "message": "[RocksDB] [Performance Bug] MemTable::Get Slow\n\nSummary:\nThe merge operator diff introduced a performance problem in MemTable::Get.\nAn exit condition is missed when the current key does not match the user key.\nThis could lead to full memtable scan if the user key is not found.\n\nTest Plan: make check; db_bench\n\nReviewers: dhruba\n\nReviewed By: dhruba\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D10851",
        "modified_files_count": 1,
        "modified_files": [
            "db/memtable.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/c3c13db346749c3dfe45e167db2129c645377e9e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MemTable::Get"
        ],
        "is_opt_ds_simple": "true"
    },
    {
        "hash": "7c6f5278a27d297cd3b08ad6eb97e11c5af02329",
        "author": "Dhruba Borthakur",
        "date": "2012-11-26T12:01:55-08:00",
        "message": "Merge branch 'performance'",
        "modified_files_count": 1,
        "modified_files": [
            "db/c_test.c"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/7c6f5278a27d297cd3b08ad6eb97e11c5af02329",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "e0cd6bf0e91e9b3892ded3b4e4a10a1e0c47ecf6",
        "author": "Dhruba Borthakur",
        "date": "2012-11-26T11:59:51-08:00",
        "message": "The c_test was sometimes failing with an assertion.\n\nSummary:\nOn fast filesystems (e.g. /dev/shm and ext4), the flushing\nof memstore to disk was fast and quick, and the background compaction\nthread was not getting scheduled fast enough to delete obsolete\nfiles before the db was closed. This caused the repair method\nto pick up those files that were not part of the db and the unit\ntest was failing.\n\nThe fix is to enhance the unti test to run a compaction before\nclosing the database so that all files that are not part of the\ndatabase are truly deleted from the filesystem.\n\nTest Plan: make c_test; ./c_test\n\nReviewers: chip, emayanke, sheki\n\nReviewed By: chip\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D6915",
        "modified_files_count": 1,
        "modified_files": [
            "db/c_test.c"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e0cd6bf0e91e9b3892ded3b4e4a10a1e0c47ecf6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "a4b79b6e28489e1508e9e8ec4d201b6fd1b6a238",
        "author": "Dhruba Borthakur",
        "date": "2012-11-19T13:20:25-08:00",
        "message": "Merge branch 'master' into performance",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a4b79b6e28489e1508e9e8ec4d201b6fd1b6a238",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "delete_filter"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "65855dd8d4d8756eec6c43b6faa3abbfb6ea8a86",
        "author": "Mark Callaghan",
        "date": "2012-10-26T14:19:13-07:00",
        "message": "Normalize compaction stats by time in compaction\n\nSummary:\nI used server uptime to compute per-level IO throughput rates. I\nintended to use time spent doing compaction at that level. This fixes that.\n\nTask ID: #\n\nBlame Rev:\n\nTest Plan:\nrun db_bench, look at results\n\nRevert Plan:\n\nDatabase Impact:\n\nMemcache Impact:\n\nOther Notes:\n\nEImportant:\n\n- begin *PUBLIC* platform impact section -\nBugzilla: #\n- end platform impact -\n\nReviewers: dhruba\n\nReviewed By: dhruba\n\nDifferential Revision: https://reviews.facebook.net/D6237",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/65855dd8d4d8756eec6c43b6faa3abbfb6ea8a86",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::GetProperty"
        ],
        "is_opt_ds_simple": "false"
    },
    {
        "hash": "921a48428ed88d04a263c5269f87222112081523",
        "author": "Arun Sharma",
        "date": "2012-05-14T15:40:11-07:00",
        "message": "Optimize for lp64\n\nSummary:\nSome code reorganization in-preparation for replacing with a hardware\ninstruction.\n\n* Use u64 for some of the key types\n* Use an ALIGN macro so code is easier to read\n\nTest Plan: crc32c_test\n\nReviewers: dhruba\n\nReviewed By: dhruba\n\nDifferential Revision: https://reviews.facebook.net/D3135",
        "modified_files_count": 1,
        "modified_files": [
            "util/crc32c.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/921a48428ed88d04a263c5269f87222112081523",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Extend"
        ],
        "is_opt_ds_simple": "false"
    }
]