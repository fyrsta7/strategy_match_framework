void ByteMixer::ByteUpdate() {
  for (size_t index = 0; index < states_[1].size() - 1; ++index) {
    int input_index = states_[0].size() - states_[1].size() + index;
    states_[0][input_index] = states_[1][index];
  }
  for (size_t layer = 0; layer < weights_.size(); ++layer) {
    int offset = layer + 1; // Precompute offset for the current layer
    size_t layer_size = states_[layer].size(); // Cache size of the current layer
    for (size_t neuron = 0; neuron < weights_[layer].size(); ++neuron) {
      float x1 = 0, x2 = 0, x3 = 0, x4 = 0;
      size_t weight = 0;
      size_t weights_size = weights_[layer][neuron].size(); // Cache size of weights for the neuron
      for (; weight < layer_size - 3; weight += 4) {
        x1 += states_[layer][weight] * weights_[layer][neuron][weight];
        x2 += states_[layer][weight+1] * weights_[layer][neuron][weight+1];
        x3 += states_[layer][weight+2] * weights_[layer][neuron][weight+2];
        x4 += states_[layer][weight+3] * weights_[layer][neuron][weight+3];
      }
      states_[offset][neuron] = x1 + x2 + x3 + x4;
      for (; weight < layer_size; ++weight) {
        states_[offset][neuron] += states_[layer][weight] *
            weights_[layer][neuron][weight];
      }
      states_[offset][neuron] = logistic_.Squash(states_[offset][neuron]);
    }
  }
  probs_ = states_[states_.size() - 1];
  ByteModel::ByteUpdate();
}