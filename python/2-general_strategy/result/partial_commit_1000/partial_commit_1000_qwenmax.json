[
    {
        "repository_name": "hypre",
        "hash": "86c56d513280e0a079b7b9c2c8cdc783b56950a5",
        "author": "Jongsoo Park",
        "date": "2015-10-09T12:23:17-07:00",
        "message": "take out assert to avoid performance issue",
        "modified_files_count": 1,
        "modified_files": [
            "seq_mv/csr_matop.c"
        ],
        "github_commit_url": "https://github.com/hypre-space/hypre/commit/86c56d513280e0a079b7b9c2c8cdc783b56950a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hypre_CSRMatrixTranspose"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing an assert statement to eliminate its associated runtime performance overhead.",
            "The optimization strategy involved removing an assert statement to eliminate its associated runtime performance overhead.",
            "The optimization strategy involved removing an assert statement to eliminate its associated runtime performance overhead.",
            "The optimization strategy involved removing an assert statement to eliminate its associated runtime performance overhead.",
            "The optimization strategy involved removing an assert statement to eliminate its associated runtime performance overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing an assert statement to eliminate its associated runtime performance overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mppic",
        "hash": "7c70876bd2ca55809ed3f3d1f638ba9225f14e46",
        "author": "Steve Macenski",
        "date": "2022-03-16T17:05:28-07:00",
        "message": "inlining array",
        "modified_files_count": 1,
        "modified_files": [
            "src/optimizer.cpp"
        ],
        "github_commit_url": "https://github.com/artofnothingness/mppic/commit/7c70876bd2ca55809ed3f3d1f638ba9225f14e46",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Optimizer::getVelocityConstraints"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved inlining an array to reduce memory access overhead and improve cache locality.",
            "The optimization strategy involved inlining an array to reduce memory access overhead and improve cache locality.",
            "The optimization strategy involved inlining an array to reduce memory access overhead and improve cache locality.",
            "The optimization strategy involved inlining an array to reduce memory access overhead and improve cache locality.",
            "The optimization strategy involved inlining an array to reduce memory access overhead and improve cache locality."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved inlining an array to reduce memory access overhead and improve cache locality.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "9f246298e2f0af3973918a0dac0c5f46bc0993c0",
        "author": "Changli Gao",
        "date": "2017-01-11T10:54:37-08:00",
        "message": "Performance: Iterate vector by reference\n\nSummary: Closes https://github.com/facebook/rocksdb/pull/1763\n\nDifferential Revision: D4398796\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: b82636d",
        "modified_files_count": 1,
        "modified_files": [
            "db/event_helpers.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/9f246298e2f0af3973918a0dac0c5f46bc0993c0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "EventHelpers::LogAndNotifyTableFileDeletion"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "e48ccc28f4eebcc05b6333b129ee5908214d3259",
        "author": "Peter Dillinger",
        "date": "2025-01-02T10:48:46-08:00",
        "message": "Reduce unnecessary manifest data when no file checksum (#13250)\n\nSummary:\nDon't write file checksum manifest entries when unused, to avoid using extra manifest file space.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/13250\n\nTest Plan: very minor performance improvement, existing tests\n\nReviewed By: cbi42\n\nDifferential Revision: D67653954\n\nPulled By: pdillinger\n\nfbshipit-source-id: 9156e093ed5e4a5152cc55354a4beea9a841b89f",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_edit.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e48ccc28f4eebcc05b6333b129ee5908214d3259",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionEdit::EncodeTo"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy avoids writing unused file checksum manifest entries to reduce unnecessary manifest file space usage.",
            "The optimization strategy avoids writing unused file checksum manifest entries to reduce unnecessary manifest file space usage.",
            "The optimization strategy avoids writing unused file checksum manifest entries to reduce manifest file space usage.",
            "The optimization strategy avoids writing unused file checksum manifest entries to reduce unnecessary manifest file space usage.",
            "The optimization strategy avoids writing unused file checksum manifest entries to reduce unnecessary manifest file space usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids writing unused file checksum manifest entries to reduce unnecessary manifest file space usage.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "063471bf7613544496a4d4b5a1e1ba4a7aa605cf",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "table/table_test.cc: pass func parameter by reference\n\nFix for:\n\n[table/table_test.cc:1218]: (performance) Function parameter\n 'prefix' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/table_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/063471bf7613544496a4d4b5a1e1ba4a7aa605cf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AddInternalKey"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying, thereby improving performance.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "b8cea7cc279fe609de85b7ce4f50d4ff4f90047f",
        "author": "Changli Gao",
        "date": "2017-10-17T10:12:37-07:00",
        "message": "VersionBuilder: Erase with iterators for better performance\n\nSummary: Closes https://github.com/facebook/rocksdb/pull/3007\n\nDifferential Revision: D6077701\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: a6fd5b8a23f4feb1660b9ce027f651a7e90352b3",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_builder.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b8cea7cc279fe609de85b7ce4f50d4ff4f90047f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Apply"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved replacing erase operations with iterator-based erase to improve performance by avoiding unnecessary lookups.",
            "The optimization strategy involved replacing erase operations with iterator-based erase to improve performance by avoiding unnecessary lookups.",
            "The optimization strategy involved replacing erase operations with iterator-based erase to reduce overhead and improve performance.",
            "The optimization strategy involved replacing erase operations with iterator-based erase to improve performance by avoiding unnecessary lookups.",
            "The optimization strategy involved replacing erase operations with iterator-based erase to improve performance by avoiding unnecessary lookups."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing erase operations with iterator-based erase to improve performance by avoiding unnecessary lookups.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ProcessHacker",
        "hash": "06ac15642c40b5ba072e920540eebda04d967f30",
        "author": "dmex",
        "date": "2016-06-17T01:55:27+10:00",
        "message": "ExtendedTools: Fix incorrect dedicated gpu memory usage",
        "modified_files_count": 1,
        "modified_files": [
            "plugins/ExtendedTools/gpumon.c"
        ],
        "github_commit_url": "https://github.com/PKRoma/ProcessHacker/commit/06ac15642c40b5ba072e920540eebda04d967f30",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "EtpUpdateSegmentInformation"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved correcting the calculation of dedicated GPU memory usage to ensure accurate reporting.",
            "The commit fixes incorrect GPU memory usage calculation by correcting the logic for determining dedicated GPU memory.",
            "The commit fixes incorrect GPU memory usage calculation by correcting the logic for determining dedicated GPU memory.",
            "The commit fixes incorrect GPU memory usage calculation by correcting the logic for determining dedicated GPU memory.",
            "The commit fixes incorrect GPU memory usage calculation by correcting the logic for determining dedicated GPU memory."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit fixes incorrect GPU memory usage calculation by correcting the logic for determining dedicated GPU memory.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "53910ddb152fbcba95a3e04b058a997c40f654ae",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "db_test.cc: pass parameter by reference\n\nFix for:\n\n[db/db_test.cc:6141]: (performance) Function parameter\n 'key' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/53910ddb152fbcba95a3e04b058a997c40f654ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "convertKey"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of the parameter."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "3f89af1c39da4991ef6c544fc5e3f164a688b375",
        "author": "Levi Tamasi",
        "date": "2019-07-26T15:53:34-07:00",
        "message": "Reduce the number of random iterations in compact_on_deletion_collector_test (#5635)\n\nSummary:\nThis test frequently times out under TSAN; reducing the number of random\niterations to make it complete faster.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5635\n\nTest Plan: buck test mode/dev-tsan internal_repo_rocksdb/repo:compact_on_deletion_collector_test\n\nDifferential Revision: D16523505\n\nPulled By: ltamasi\n\nfbshipit-source-id: 6a69909bce9d204c891150fcb3d536547b3253d0",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/table_properties_collectors/compact_on_deletion_collector_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/3f89af1c39da4991ef6c544fc5e3f164a688b375",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy reduces the number of random iterations in a test to prevent timeouts under TSAN by lowering computational overhead.",
            "The optimization strategy reduces the number of random iterations in a test to prevent timeouts under TSAN by lowering computational overhead.",
            "The optimization strategy reduces the number of random iterations in a test to prevent timeouts under TSAN by lowering computational overhead.",
            "The optimization strategy involved reducing the number of random iterations in a test to decrease execution time and avoid timeouts under TSAN.",
            "The optimization strategy involved reducing the number of random iterations in a test to prevent timeouts under TSAN."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the number of random iterations in a test to prevent timeouts under TSAN by lowering computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f2b6ecd5fef3487daf9493b25f880b52af1bf3e0",
        "author": "Michael Sevakis",
        "date": "2007-03-03T01:19:35+00:00",
        "message": "SPC codec on Coldfire: Move movclrs into the light and out of the long dark shadow cast my emac latency as much as possible. Put in a faster interpolation routine (emac saves the day...again). Add comments about what's going on.\n\ngit-svn-id: svn://svn.rockbox.org/rockbox/trunk@12558 a1c6a512-1295-4272-9138-f99709370657",
        "modified_files_count": 1,
        "modified_files": [
            "apps/codecs/spc/Spc_Dsp.h"
        ],
        "github_commit_url": "https://github.com/Rockbox/rockbox/commit/f2b6ecd5fef3487daf9493b25f880b52af1bf3e0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DSP_run_"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rockbox",
        "optimization_summary": [
            "The optimization strategy involved reordering and restructuring operations to minimize the impact of emac latency while introducing a faster interpolation routine.",
            "The optimization strategy involved reordering and restructuring operations to minimize the impact of emac latency while introducing a faster interpolation routine.",
            "The optimization strategy involved reordering and restructuring operations to minimize the impact of emac latency while introducing a faster interpolation routine.",
            "The optimization strategy involved reorganizing operations to reduce latency caused by emac and implementing a faster interpolation routine.",
            "The optimization strategy involved reordering and restructuring operations to minimize the impact of emac latency while introducing a faster interpolation routine."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reordering and restructuring operations to minimize the impact of emac latency while introducing a faster interpolation routine.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "873f1356a1781e8d638973ea320b722d3240fc5a",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "db_ttl_impl.h: pass func parameter by reference\n\nFix for:\n\n[utilities/ttl/db_ttl_impl.h:209]: (performance) Function parameter\n 'merge_op' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/ttl/db_ttl_impl.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/873f1356a1781e8d638973ea320b722d3240fc5a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TtlMergeOperator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cheerp-compiler",
        "hash": "a3732ee4d3b54b47c3319bb8ecfbed5c83975340",
        "author": "Hyxogen",
        "date": "2024-02-02T11:48:31+01:00",
        "message": "globalopt: propagate section to optimized global",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Transforms/IPO/GlobalOpt.cpp"
        ],
        "github_commit_url": "https://github.com/leaningtech/cheerp-compiler/commit/a3732ee4d3b54b47c3319bb8ecfbed5c83975340",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OptimizeGlobalAddressOfAllocation"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy propagates section information to optimized global variables to improve memory layout and access patterns.",
            "The optimization strategy propagates section information to optimized global variables to potentially improve linking and memory layout efficiency.",
            "The optimization strategy propagates section information to optimized global variables to potentially improve linking and memory layout efficiency.",
            "The optimization strategy propagates section information to optimized global variables to potentially improve linking and memory layout efficiency.",
            "The optimization strategy propagates section information to optimized global variables to potentially improve linking and memory layout efficiency."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy propagates section information to optimized global variables to potentially improve linking and memory layout efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "cd21e4e69d76ec4ec3b080c8cdae016ac2309cc5",
        "author": "Levi Tamasi",
        "date": "2023-12-13T17:34:18-08:00",
        "message": "Some further cleanup in WriteBatchWithIndex::MultiGetFromBatchAndDB (#12143)\n\nSummary:\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12143\n\nhttps://github.com/facebook/rocksdb/pull/11982 changed `WriteBatchWithIndex::MultiGetFromBatchDB` to preallocate space in the `autovector`s `key_contexts` and `merges` in order to prevent any reallocations, both as an optimization and in order to prevent pointers into the container from being invalidated during subsequent insertions. On second thought, this preallocation can actually be a pessimization in cases when only a small subset of keys require querying the underlying database. To prevent any memory regressions, the PR reverts this preallocation. In addition, it makes some small code hygiene improvements like incorporating the `PinnableWideColumns` object into `MergeTuple`.\n\nReviewed By: jaykorean\n\nDifferential Revision: D52136513\n\nfbshipit-source-id: 21aa835084433feab27b501d9d1fc5434acea609",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/write_batch_with_index/write_batch_with_index.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/cd21e4e69d76ec4ec3b080c8cdae016ac2309cc5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatchWithIndex::MultiGetFromBatchAndDB"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reverting preallocation of `autovector` containers to avoid memory overhead in cases where only a small subset of keys require database queries.",
            "The optimization strategy involved reverting preallocation of container space to avoid memory overhead in cases with sparse key queries.",
            "The optimization strategy involved reverting preallocation of container space to avoid memory overhead in cases with sparse key queries.",
            "The optimization strategy involved reverting preallocation of container space to avoid memory overhead in cases with sparse key usage.",
            "The optimization strategy involved reverting preallocation of container space to avoid memory overhead in cases with sparse key usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reverting preallocation of container space to avoid memory overhead in cases with sparse key queries.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "68ca534169a4f9e1930f6511109e973b43cf5998",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "corruption_test.cc: pass parameter by reference\n\nFix for:\n\n[db/corruption_test.cc:134]: (performance) Function parameter\n 'fname' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/corruption_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/68ca534169a4f9e1930f6511109e973b43cf5998",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CorruptFile"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of the parameter.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of the parameter.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "4704833357a8609e7c42df4f337f938a8e870c08",
        "author": "jsteemann",
        "date": "2015-09-18T20:20:32+02:00",
        "message": "pass input string to WriteBatch() by const reference\n\nthis may lead to copying less data (in case compilers don't\noptimize away copying the string by themselves)",
        "modified_files_count": 1,
        "modified_files": [
            "include/rocksdb/write_batch.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4704833357a8609e7c42df4f337f938a8e870c08",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatch"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves passing a string to the WriteBatch constructor by const reference instead of by value to reduce unnecessary data copying.",
            "The optimization strategy involves passing an input string to the `WriteBatch()` constructor by const reference to avoid unnecessary data copying.",
            "The optimization strategy involves passing an input string to the WriteBatch constructor by const reference to avoid unnecessary copying of the string data.",
            "The optimization strategy involves passing a string to the WriteBatch constructor by const reference to avoid unnecessary copying of the string data.",
            "The optimization strategy involves passing an input string to the WriteBatch constructor by const reference to avoid unnecessary copying of the string data."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves passing an input string to the WriteBatch constructor by const reference to avoid unnecessary copying of the string data.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "gcc-darwin-arm64",
        "hash": "e4411622690654cdc530c6262c7115a9e15dc359",
        "author": "Aldy Hernandez",
        "date": "2021-11-04T15:37:35+01:00",
        "message": "Avoid repeating calculations in threader.\n\nWe already attempt to resolve the current path on entry to\nfind_paths_to_name(), so there's no need to do so again for each\nexported range since nothing has changed.\n\nRemoving this redundant calculation avoids 22% of calls into the path\nsolver.\n\nTested on x86-64 and ppc64le Linux with the usual regstrap.  I also\nverified that the before and after number of threads was the same\nin a suite of .ii files from a bootstrap.\n\ngcc/ChangeLog:\n\n\tPR tree-optimization/102943\n\t* tree-ssa-threadbackward.c (back_threader::find_paths_to_names):\n\tAvoid duplicate calculation of paths.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/tree-ssa-threadbackward.c"
        ],
        "github_commit_url": "https://github.com/iains/gcc-darwin-arm64/commit/e4411622690654cdc530c6262c7115a9e15dc359",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "back_threader::find_paths_to_names"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy eliminates redundant path calculations in the `find_paths_to_names` function by leveraging previously resolved paths, reducing unnecessary calls to the path solver.",
            "The optimization strategy avoids redundant calculations by reusing previously resolved paths in the `find_paths_to_names` function.",
            "The optimization strategy avoids redundant path calculations in the `find_paths_to_names` function by leveraging previously resolved paths, reducing unnecessary calls to the path solver.",
            "The optimization strategy avoids redundant path calculations in the `find_paths_to_names` function by leveraging previously resolved paths, reducing unnecessary calls to the path solver.",
            "The optimization strategy avoids redundant path calculations in the threader by leveraging previously resolved paths, reducing unnecessary calls to the path solver."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy eliminates redundant path calculations in the `find_paths_to_names` function by leveraging previously resolved paths, reducing unnecessary calls to the path solver.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "1fa5dff7d1ce7be64555e7bdc8371be562b3eac6",
        "author": "奏之章",
        "date": "2024-02-27T15:23:54-08:00",
        "message": "WriteThread::EnterAsBatchGroupLeader reorder writers (#12138)\n\nSummary:\nReorder writers list to allow a leader can take as more commits as possible to maximize the throughput of the system and reduce IOPS.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12138\n\nReviewed By: hx235\n\nDifferential Revision: D53955592\n\nPulled By: ajkr\n\nfbshipit-source-id: 4d899d038faef691b63801d9d85f5cc079b7bbb5",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_thread.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/1fa5dff7d1ce7be64555e7bdc8371be562b3eac6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteThread::EnterAsBatchGroupLeader"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy reorders the writers list to allow a leader to commit more transactions in a batch, thereby maximizing throughput and reducing IOPS.",
            "The optimization reorders the writers list to allow a leader to commit more transactions at once, thereby maximizing throughput and reducing IOPS.",
            "The optimization strategy reorders the writers list to allow a leader to commit more transactions in a batch, thereby maximizing throughput and reducing IOPS.",
            "The optimization reorders the writers list to allow a leader to commit more writes in a batch, thereby maximizing throughput and reducing IOPS.",
            "The optimization reorders the writers list to allow a leader to commit more writes in a batch, improving throughput and reducing IOPS."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reorders the writers list to allow a leader to commit more transactions in a batch, thereby maximizing throughput and reducing IOPS.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "fa4de6e30ffaf9188a48f5e30d2da1ac0e454917",
        "author": "Andrey Zagrebin",
        "date": "2018-08-17T10:57:25-07:00",
        "message": "#3865 followup for fix performance degression introduced by switching order of operands (#4284)\n\nSummary:\nFollowup for #4266. There is one more place in **get_context.cc** where **MergeOperator::ShouldMerge** should be called with reversed list of operands.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4284\n\nDifferential Revision: D9380008\n\nPulled By: sagar0\n\nfbshipit-source-id: 70ec26e607e5b88465e1acbdcd6c6171bd76b9f2",
        "modified_files_count": 1,
        "modified_files": [
            "table/get_context.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/fa4de6e30ffaf9188a48f5e30d2da1ac0e454917",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetContext::SaveValue"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reversing the order of operands in a function call to improve performance by aligning with expected operand ordering.",
            "The optimization strategy involved reversing the order of operands in a function call to improve performance by aligning with expected operand ordering.",
            "The optimization strategy involved reversing the order of operands in a function call to improve performance by aligning with expected operand ordering.",
            "The optimization strategy involved reversing the order of operands in a function call to improve performance by aligning with expected operand ordering.",
            "The optimization strategy involved reversing the order of operands in a function call to improve performance by aligning with expected operand ordering."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reversing the order of operands in a function call to improve performance by aligning with expected operand ordering.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pugixml",
        "hash": "f1bfe4cc64218d015a8415b37b30127327df8b39",
        "author": "arseny.kapoulkine",
        "date": "2010-05-31T07:56:13+00:00",
        "message": "Simplified fp specials handling in XPath (using common faster implementation for both MSVC and BCC)\n\ngit-svn-id: http://pugixml.googlecode.com/svn/trunk@480 99668b35-9821-0410-8761-19e4c4f06640",
        "modified_files_count": 1,
        "modified_files": [
            "src/pugixpath.cpp"
        ],
        "github_commit_url": "https://github.com/zeux/pugixml/commit/f1bfe4cc64218d015a8415b37b30127327df8b39",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "convert_number_to_string_special"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization simplifies handling of floating-point special cases in XPath by using a unified and faster implementation for multiple compilers.",
            "The optimization simplifies handling of floating-point special cases in XPath by using a unified and faster implementation for multiple compilers.",
            "The optimization simplifies handling of floating-point special cases in XPath by using a unified, faster implementation for multiple compilers.",
            "The optimization simplifies handling of floating-point special cases in XPath by using a unified and faster implementation for multiple compilers.",
            "The optimization simplifies handling of floating-point special cases in XPath by using a unified and faster implementation for multiple compilers."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization simplifies handling of floating-point special cases in XPath by using a unified and faster implementation for multiple compilers.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "b278ae8e50466e8073a1754a506145df5bb27c72",
        "author": "Lei Jin",
        "date": "2014-07-08T11:40:42-07:00",
        "message": "Apply fractional cascading in ForwardIterator::Seek()\n\nSummary:\nUse search hint to reduce FindFile range thus avoid comparison\nFor a small DB with 50M keys, perf_context counter shows it reduces\ncomparison from 2B to 1.3B for a 15-minute run. No perf change was\nobserved for 1 seek thread, but quite good improvement was seen for 32\nseek threads, when CPU was busy.\nwill post detail results when ready\n\nTest Plan: db_bench and db_test\n\nReviewers: haobo, sdong, dhruba, igor\n\nReviewed By: igor\n\nSubscribers: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D18879",
        "modified_files_count": 1,
        "modified_files": [
            "db/forward_iterator.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b278ae8e50466e8073a1754a506145df5bb27c72",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ForwardIterator::SeekInternal"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization uses fractional cascading to reduce the range of comparisons in the FindFile function by leveraging search hints.",
            "The optimization uses fractional cascading to reduce the range of comparisons in the FindFile function by leveraging search hints.",
            "The optimization uses fractional cascading to reduce the range of comparisons in FindFile during Seek operations, improving performance for multi-threaded workloads.",
            "The optimization uses fractional cascading to reduce the range of comparisons in the FindFile function by leveraging search hints.",
            "The optimization strategy uses fractional cascading to reduce the range of comparisons in the FindFile function by leveraging search hints."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization uses fractional cascading to reduce the range of comparisons in the FindFile function by leveraging search hints.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Koivisto",
        "hash": "2674cc3efa7f7c25a0b47b6af3b65aacea0d4d95",
        "author": "altarchess",
        "date": "2021-07-23T16:31:13+03:00",
        "message": "Merge pull request #124 from Luecx/threatprune2\n\nbench: 4516662\r\nELO | 8.56 +- 4.99 (95%)\r\nSPRT | 10.0+0.10s Threads=1 Hash=16MB\r\nLLR | 2.95 (-2.94, 2.94) [0.00, 5.00]\r\nGAMES | N: 5848 W: 993 L: 849 D: 4006\r\nTune threat prune further",
        "modified_files_count": 1,
        "modified_files": [
            "src_files/search.cpp"
        ],
        "github_commit_url": "https://github.com/Luecx/Koivisto/commit/2674cc3efa7f7c25a0b47b6af3b65aacea0d4d95",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved fine-tuning the threat pruning logic to improve search efficiency by reducing unnecessary evaluations.",
            "The optimization strategy involved fine-tuning the threat pruning logic to improve search efficiency by reducing unnecessary evaluations.",
            "The optimization strategy involved fine-tuning the threat pruning logic to improve search efficiency by reducing unnecessary evaluations.",
            "The optimization strategy involved fine-tuning the threat pruning logic to improve search efficiency by reducing unnecessary evaluations.",
            "The optimization strategy involved fine-tuning the threat pruning logic to improve search efficiency by reducing unnecessary evaluations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved fine-tuning the threat pruning logic to improve search efficiency by reducing unnecessary evaluations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "92ad4a88f3199b013532b37d6598c442319355a5",
        "author": "Changyu Bi",
        "date": "2024-08-27T13:57:40-07:00",
        "message": "Small CPU optimization in InlineSkipList::Insert() (#12975)\n\nSummary:\nreuse decode key in more places to avoid decoding length prefixed key x->Key().\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12975\n\nTest Plan:\nran benchmarks simultaneously for \"before\" and \"after\"\n* fillseq:\n```\n(for I in $(seq 1 50); do ./db_bench --benchmarks=fillseq --disable_auto_compactions=1 --min_write_buffer_number_to_merge=100 --max_write_buffer_number=1000  --write_buffer_size=268435456 --num=5000000 --seed=1723056275 --disable_wal=1 2>&1 | grep \"fillseq\"\ndone;) | awk '{ t += $5; c++; print } END { printf (\"%9.3f\\n\", 1.0 * t / c) }';\n\nbefore: 1483191\nafter: 1490555 (+0.5%)\n```\n\n* fillrandom:\n```\n(for I in $(seq 1 2); do ./db_bench_imain --benchmarks=fillrandom --disable_auto_compactions=1 --min_write_buffer_number_to_merge=100 --max_write_buffer_number=1000  --write_buffer_size=268435456 --num=2500000 --seed=1723056275 --disable_wal=1 2>&1 | grep \"fillrandom\"\n\nbefore: 255463\nafter: 256128 (+0.26%)\n```\n\nReviewed By: anand1976\n\nDifferential Revision: D61835340\n\nPulled By: cbi42\n\nfbshipit-source-id: 70345510720e348bacd51269acb5d2dd5a62bf0a",
        "modified_files_count": 1,
        "modified_files": [
            "memtable/inlineskiplist.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/92ad4a88f3199b013532b37d6598c442319355a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "compare_"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reusing a decoded key to avoid redundant decoding of length-prefixed keys in the `InlineSkipList::Insert()` function.",
            "The optimization strategy involved reusing a decoded key to avoid redundant decoding of length-prefixed keys in the `InlineSkipList::Insert()` function.",
            "The optimization strategy involved reusing a decoded key to avoid redundant decoding of length-prefixed keys in the `InlineSkipList::Insert()` function.",
            "The optimization strategy reused a previously decoded key to avoid redundant decoding of length-prefixed keys in the `compare_` function.",
            "The optimization strategy involved reusing a decoded key to avoid repeatedly decoding the same length-prefixed key in InlineSkipList::Insert()."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reusing a decoded key to avoid redundant decoding of length-prefixed keys in the `InlineSkipList::Insert()` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "glsl-optimizer",
        "hash": "1c86c7ad9c38b5ef1baa19677b78076889b60e7f",
        "author": "Felix Kuehling",
        "date": "2004-12-23T20:26:59+00:00",
        "message": "Simplified and optimized _savage_texnorm_stage.",
        "modified_files_count": 1,
        "modified_files": [
            "src/mesa/drivers/dri/savage/savagetris.c"
        ],
        "github_commit_url": "https://github.com/aras-p/glsl-optimizer/commit/1c86c7ad9c38b5ef1baa19677b78076889b60e7f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "run_texnorm_stage"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the logic and reducing redundant computations within the `_savage_texnorm_stage` function to improve performance.",
            "The optimization strategy involved simplifying the logic and reducing redundant computations in the `_savage_texnorm_stage` function to improve performance.",
            "The optimization strategy involved simplifying the logic and reducing redundant computations within the `_savage_texnorm_stage` function to improve its efficiency.",
            "The optimization strategy involved simplifying the logic and reducing redundant computations in the `_savage_texnorm_stage` function to improve performance.",
            "The optimization strategy involved simplifying the logic and reducing redundant computations within the `_savage_texnorm_stage` function to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the logic and reducing redundant computations within the `_savage_texnorm_stage` function to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f9cfc6a808c9dc3ab7366edb10368559155d5172",
        "author": "Changyu Bi",
        "date": "2022-07-06T09:30:25-07:00",
        "message": "Updated NewDataBlockIterator to not fetch compression dict for non-da… (#10310)\n\nSummary:\n…ta blocks\n\nDuring MyShadow testing, ajkr helped me find out that with partitioned index and dictionary compression enabled, `PartitionedIndexIterator::InitPartitionedIndexBlock()` spent considerable amount of time (1-2% CPU) on fetching uncompression dictionary. Fetching uncompression dict was not needed since the index blocks were not compressed (and even if they were, they use empty dictionary). This should only affect use cases with partitioned index, dictionary compression and without uncompression dictionary pinned. This PR updates NewDataBlockIterator to not fetch uncompression dictionary when it is not for data blocks.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10310\n\nTest Plan:\n1. `make check`\n2. Perf benchmark: 1.5% (143950 -> 146176) improvement in op/sec for partitioned index + dict compression benchmark.\nFor default config without partitioned index and without dict compression, there is no regression in readrandom perf from multiple runs of db_bench.\n\n```\n# Set up for partitioned index with dictionary compression\nTEST_TMPDIR=/dev/shm ./db_bench_main -benchmarks=filluniquerandom,compact -max_background_jobs=24 -memtablerep=vector -allow_concurrent_memtable_write=false -partition_index=true  -compression_max_dict_bytes=16384 -compression_zstd_max_train_bytes=1638400\n\n# Pre PR\nTEST_TMPDIR=/dev/shm ./db_bench_main -use_existing_db=true -benchmarks=readrandom[-X50] -partition_index=true\nreadrandom [AVG    50 runs] : 143950 (± 1108) ops/sec;   15.9 (± 0.1) MB/sec\nreadrandom [MEDIAN 50 runs] : 144406 ops/sec;   16.0 MB/sec\n\n# Post PR\nTEST_TMPDIR=/dev/shm ./db_bench_opt -use_existing_db=true -benchmarks=readrandom[-X50] -partition_index=true\nreadrandom [AVG    50 runs] : 146176 (± 1121) ops/sec;   16.2 (± 0.1) MB/sec\nreadrandom [MEDIAN 50 runs] : 146014 ops/sec;   16.2 MB/sec\n\n# Set up for no partitioned index and no dictionary compression\nTEST_TMPDIR=/dev/shm/baseline ./db_bench_main -benchmarks=filluniquerandom,compact -max_background_jobs=24 -memtablerep=vector -allow_concurrent_memtable_write=false\n# Pre PR\nTEST_TMPDIR=/dev/shm/baseline/ ./db_bench_main --use_existing_db=true \"--benchmarks=readrandom[-X50]\"\nreadrandom [AVG    50 runs] : 158546 (± 1000) ops/sec;   17.5 (± 0.1) MB/sec\nreadrandom [MEDIAN 50 runs] : 158280 ops/sec;   17.5 MB/sec\n\n# Post PR\nTEST_TMPDIR=/dev/shm/baseline/ ./db_bench_opt --use_existing_db=true \"--benchmarks=readrandom[-X50]\"\nreadrandom [AVG    50 runs] : 161061 (± 1520) ops/sec;   17.8 (± 0.2) MB/sec\nreadrandom [MEDIAN 50 runs] : 161596 ops/sec;   17.9 MB/sec\n```\n\nReviewed By: ajkr\n\nDifferential Revision: D37631358\n\nPulled By: cbi42\n\nfbshipit-source-id: 6ca2665e270e63871968e061ba4a99d3136785d9",
        "modified_files_count": 1,
        "modified_files": [
            "table/block_based/block_based_table_reader_impl.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f9cfc6a808c9dc3ab7366edb10368559155d5172",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlockBasedTable::NewDataBlockIterator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization avoids fetching an unnecessary uncompression dictionary for non-data blocks in partitioned index scenarios, reducing redundant operations.",
            "The optimization avoids fetching an unnecessary uncompression dictionary for non-data blocks in partitioned index scenarios, reducing redundant operations.",
            "The optimization avoids fetching an unnecessary uncompression dictionary for non-data blocks in partitioned index scenarios, reducing redundant operations.",
            "The optimization avoids fetching an unnecessary uncompression dictionary for non-data blocks in specific configurations, reducing CPU overhead.",
            "The optimization avoids fetching an unnecessary uncompression dictionary for non-data blocks in specific configurations, reducing CPU overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids fetching an unnecessary uncompression dictionary for non-data blocks in partitioned index scenarios, reducing redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "NBlood",
        "hash": "7bdd67c52a66425d6aee3bbef8af860d4cbbf1f3",
        "author": "Philipp Kutin",
        "date": "2013-05-01T17:42:05+00:00",
        "message": "Classic: optimize background 'rainbow' drawing in use for editor/debug.\n\nAlso, draw it at shade 18 and don't use fullbright colors.\n\nFrom-SVN: r3721",
        "modified_files_count": 1,
        "modified_files": [
            "polymer/eduke32/build/src/engine.c"
        ],
        "github_commit_url": "https://github.com/NBlood/NBlood/commit/7bdd67c52a66425d6aee3bbef8af860d4cbbf1f3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "draw_rainbow_background"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces unnecessary computations by drawing the rainbow background at a fixed shade and avoiding fullbright colors.",
            "The optimization strategy reduces unnecessary computations by drawing the rainbow background at a fixed shade and avoiding fullbright colors.",
            "The optimization reduces computational overhead by drawing the rainbow background at a fixed shade and avoiding fullbright colors.",
            "The optimization strategy reduces unnecessary computations by drawing the rainbow background at a fixed shade and avoiding fullbright colors.",
            "The optimization strategy reduces computational overhead by drawing the rainbow background at a fixed shade and avoiding fullbright colors."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces unnecessary computations by drawing the rainbow background at a fixed shade and avoiding fullbright colors.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "d8df169b8498609eda28c0d6c2d91588b0aa925b",
        "author": "Zhongyi Xie",
        "date": "2018-11-13T17:08:34-08:00",
        "message": "release db mutex when calling ApproximateSize (#4630)\n\nSummary:\n`GenSubcompactionBoundaries` calls `VersionSet::ApproximateSize` which gets BlockBasedTableReader for every file and seeks in its index block to find `key`'s offset. If the table or index block aren't in memory already, this involves I/O. This can be improved by releasing DB mutex when calling ApproximateSize.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4630\n\nDifferential Revision: D13052653\n\nPulled By: miasantreble\n\nfbshipit-source-id: cae31d46d10d0860fa8a26b8d5154b2d17d1685f",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction_job.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d8df169b8498609eda28c0d6c2d91588b0aa925b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionJob::GenSubcompactionBoundaries"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves releasing the database mutex during a potentially I/O-heavy operation to reduce contention and improve concurrency.",
            "The optimization strategy involves releasing the database mutex during a potentially I/O-heavy operation to reduce contention and improve concurrency.",
            "The optimization strategy involves releasing the database mutex during a potentially I/O-heavy operation to reduce contention and improve concurrency.",
            "The optimization strategy involves releasing the database mutex during a potentially I/O-heavy operation to reduce contention and improve concurrency.",
            "The optimization strategy involves releasing the database mutex during a potentially I/O-heavy operation to reduce contention and improve concurrency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves releasing the database mutex during a potentially I/O-heavy operation to reduce contention and improve concurrency.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "25403c2265cb700462d59fa3cb9dbec85d25d48f",
        "author": "Andrew Kryczka",
        "date": "2018-06-28T13:20:29-07:00",
        "message": "Prefetch cache lines for filter lookup (#4068)\n\nSummary:\nSince the filter data is unaligned, even though we ensure all probes are within a span of `cache_line_size` bytes, those bytes can span two cache lines. In that case I doubt hardware prefetching does a great job considering we don't necessarily access those two cache lines in order. This guess seems correct since adding explicit prefetch instructions reduced filter lookup overhead by 19.4%.\nCloses https://github.com/facebook/rocksdb/pull/4068\n\nDifferential Revision: D8674189\n\nPulled By: ajkr\n\nfbshipit-source-id: 747427d9a17900151c17820488e3f7efe06b1871",
        "modified_files_count": 1,
        "modified_files": [
            "util/bloom.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/25403c2265cb700462d59fa3cb9dbec85d25d48f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FullFilterBitsReader::HashMayMatch"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved adding explicit prefetch instructions to improve cache line access patterns during filter lookups, reducing overhead by 19.4%.",
            "The optimization strategy involved adding explicit prefetch instructions for cache lines to reduce filter lookup overhead in cases where data spans two cache lines.",
            "The optimization strategy involved adding explicit prefetch instructions to reduce cache line access overhead during filter lookups.",
            "The optimization strategy involved adding explicit prefetch instructions for cache lines during filter lookups to reduce overhead caused by potential inefficiencies in hardware prefetching.",
            "The optimization strategy involved adding explicit prefetch instructions to improve cache line access patterns during filter lookups."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adding explicit prefetch instructions to reduce cache line access overhead during filter lookups.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "d2b0652b32b8671c9ec4057e6da2fa564d1cc610",
        "author": "Xinye Tao",
        "date": "2023-08-07T12:29:31-07:00",
        "message": "compute compaction score once for a batch of range file deletes (#10744)\n\nSummary:\nOnly re-calculate compaction score once for a batch of deletions. Fix performance regression brought by https://github.com/facebook/rocksdb/pull/8434.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10744\n\nTest Plan:\nIn one of our production cluster that recently upgraded to RocksDB 6.29, it takes more than 10 minutes to delete files in 30,000 ranges. The RocksDB instance contains approximately 80,000 files. After this patch, the duration reduces to 100+ ms, which is on par with RocksDB 6.4.\n\nCherry-picking downstream PR: https://github.com/tikv/rocksdb/pull/316\n\nSigned-off-by: tabokie <xy.tao@outlook.com>\n\nReviewed By: cbi42\n\nDifferential Revision: D48002581\n\nPulled By: ajkr\n\nfbshipit-source-id: 7245607ee3ad79c53b648a6396c9159f166b9437",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d2b0652b32b8671c9ec4057e6da2fa564d1cc610",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::DeleteFilesInRanges"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves reducing redundant computations by calculating the compaction score once for a batch of range file deletions instead of recalculating it for each individual deletion.",
            "The optimization strategy involves reducing redundant computations by calculating the compaction score once for a batch of range file deletions instead of recalculating it for each individual deletion.",
            "The optimization strategy involves reducing redundant computations by calculating the compaction score once for a batch of range file deletions instead of recalculating it for each individual deletion.",
            "The optimization strategy involves reducing redundant computations by calculating the compaction score once for a batch of range file deletions instead of recalculating it for each individual deletion.",
            "The optimization strategy involves reducing redundant computations by calculating the compaction score once for a batch of range file deletions instead of recalculating it for each individual deletion."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reducing redundant computations by calculating the compaction score once for a batch of range file deletions instead of recalculating it for each individual deletion.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "025b85b4ac078110302c039556e4c12ba8e7a731",
        "author": "Andrew Kryczka",
        "date": "2017-09-12T11:26:47-07:00",
        "message": "speedup DBTest.EncodeDecompressedBlockSizeTest\n\nSummary:\nit sometimes takes more than 10 minutes (i.e., times out) on our internal CI. mainly because bzip is super slow. so I reduced the amount of  work it tries to do.\nCloses https://github.com/facebook/rocksdb/pull/2856\n\nDifferential Revision: D5795883\n\nPulled By: ajkr\n\nfbshipit-source-id: e69f986ae60b44ecc26b6b024abd0f13bdf3a3c5",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/025b85b4ac078110302c039556e4c12ba8e7a731",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reducing the computational workload in a test case by decreasing the amount of data processed to avoid timeouts caused by slow compression algorithms.",
            "The optimization strategy involved reducing the computational workload in a test case by decreasing the amount of data processed to avoid timeouts caused by slow compression algorithms.",
            "The optimization strategy involved reducing the computational workload in a test case by decreasing the amount of data processed to avoid timeouts caused by slow compression algorithms.",
            "The optimization strategy involved reducing the computational workload in a test case by decreasing the amount of data processed to avoid timeouts caused by slow compression algorithms.",
            "The optimization strategy involved reducing the computational workload in a test case by decreasing the amount of data processed to avoid timeouts caused by slow compression algorithms."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the computational workload in a test case by decreasing the amount of data processed to avoid timeouts caused by slow compression algorithms.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f053851af643755dc2ee252f92e3853b30a12be3",
        "author": "sdong",
        "date": "2021-10-19T12:48:18-07:00",
        "message": "Ignore non-overlapping levels when determinig grandparent files (#9051)\n\nSummary:\nRight now, when picking a compaction, grand parent files are from output_level + 1. This usually works, but if the level doesn't have any overlapping file, it will be more efficient to go further down. This is because the files are likely to be trivial moved further and might create a violation of max_compaction_bytes. This situation can naturally happen and might happen even more with TTL compactions. There is no harm to fix it.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/9051\n\nTest Plan: Run existing tests and see it passes. Also briefly run crash test.\n\nReviewed By: ajkr\n\nDifferential Revision: D31748829\n\nfbshipit-source-id: 52b99ab4284dc816d22f34406d528a3c98ff6719",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction/compaction_picker.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f053851af643755dc2ee252f92e3853b30a12be3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionPicker::GetGrandparents"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization skips non-overlapping levels when determining grandparent files to reduce unnecessary computations and avoid potential violations of max_compaction_bytes.",
            "The optimization skips non-overlapping levels when determining grandparent files to reduce unnecessary processing and avoid potential violations of max_compaction_bytes.",
            "The optimization skips non-overlapping levels when determining grandparent files to reduce unnecessary checks and improve efficiency during compaction selection.",
            "The optimization skips non-overlapping levels when determining grandparent files to reduce unnecessary checks and improve compaction efficiency.",
            "The optimization skips non-overlapping levels when determining grandparent files to reduce unnecessary processing and avoid potential violations of max_compaction_bytes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization skips non-overlapping levels when determining grandparent files to reduce unnecessary processing and avoid potential violations of max_compaction_bytes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow",
        "hash": "9bf801ba1f26e4a7091695a7f5b512b0ed19e99b",
        "author": "qqq.jq",
        "date": "2020-11-03T10:37:29+08:00",
        "message": "Remove the race check due to poor branching efficiency",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc"
        ],
        "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/9bf801ba1f26e4a7091695a7f5b512b0ed19e99b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SortedSegmentReductionCustomKernel"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing a race condition check to improve branching efficiency in a GPU kernel.",
            "The optimization strategy involved removing a race condition check to improve branching efficiency in a GPU kernel.",
            "The optimization strategy involved removing a race condition check to improve branching efficiency in a GPU kernel.",
            "The optimization strategy involved removing a race condition check to improve branching efficiency in a GPU kernel.",
            "The optimization strategy involved removing a race condition check to improve branching efficiency in a GPU kernel."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing a race condition check to improve branching efficiency in a GPU kernel.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f82e693a31d07ab8b391888ff60eb7ff5b95bd13",
        "author": "Siying Dong",
        "date": "2019-05-16T15:24:28-07:00",
        "message": "RangeDelAggregator::StripeRep::Invalidate() to be skipped if empty (#5312)\n\nSummary:\nRangeDelAggregator::StripeRep::Invalidate() clears up several vectors. If we know there isn't anything to there, we can safe these small CPUs. Profiling shows that it sometimes take non-negligible amount of CPU. Worth a small optimization.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5312\n\nDifferential Revision: D15380511\n\nPulled By: siying\n\nfbshipit-source-id: 53c5f34c33b4cb1e743643c6086ac56d0b84ec2e",
        "modified_files_count": 1,
        "modified_files": [
            "db/range_del_aggregator.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f82e693a31d07ab8b391888ff60eb7ff5b95bd13",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Invalidate"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves skipping the execution of a function that clears vectors if they are already empty, thereby avoiding unnecessary CPU usage.",
            "The optimization strategy involves skipping the execution of a function that clears vectors if they are already empty, thereby avoiding unnecessary CPU usage.",
            "The optimization strategy involves adding a conditional check to skip the `Invalidate()` function if the relevant vectors are empty, thereby avoiding unnecessary CPU overhead.",
            "The optimization strategy involves skipping the `Invalidate()` function call when it is unnecessary due to empty vectors, reducing CPU overhead.",
            "The optimization strategy involves skipping the execution of a function that clears vectors if they are already empty, thereby avoiding unnecessary CPU usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves skipping the execution of a function that clears vectors if they are already empty, thereby avoiding unnecessary CPU usage.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "01cbdd2aae8f998e3e532dec06f0f373a6cff719",
        "author": "Igor Canadi",
        "date": "2014-08-20T11:14:01-07:00",
        "message": "Optimize storage parameters for spatialDB\n\nSummary: We need to start compression at level 1, while OptimizeForLevelComapaction() only sets up rocksdb to start compressing at level 2. I also adjusted some other things.\n\nTest Plan: compiles\n\nReviewers: yinwang\n\nReviewed By: yinwang\n\nDifferential Revision: https://reviews.facebook.net/D22203",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/spatialdb/spatial_db.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/01cbdd2aae8f998e3e532dec06f0f373a6cff719",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetRocksDBOptionsFromOptions"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved adjusting compression settings to start at an earlier level and fine-tuning other storage parameters for better performance in spatialDB.",
            "The optimization strategy involved adjusting the compression starting level and other storage parameters to better suit the spatialDB workload.",
            "The optimization strategy involved adjusting the compression start level and other storage parameters to better suit the spatialDB use case.",
            "The optimization strategy involved adjusting compression settings to start at an earlier level and fine-tuning other storage parameters for improved performance in spatialDB.",
            "The optimization strategy involved adjusting the compression starting level and other storage parameters to better suit the workload characteristics of spatialDB."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting the compression starting level and other storage parameters to better suit the spatialDB workload.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "splatapult",
        "hash": "7d95b5a74b307e3e61df87c6e46951f9bd46c936",
        "author": "Anthony J. Thibault",
        "date": "2024-03-05T10:17:47-08:00",
        "message": "Use 24-bit radix sort for more performance\n\nAlso, removed unnecessary barrier",
        "modified_files_count": 1,
        "modified_files": [
            "src/splatrenderer.cpp"
        ],
        "github_commit_url": "https://github.com/hyperlogic/splatapult/commit/7d95b5a74b307e3e61df87c6e46951f9bd46c936",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SplatRenderer::Sort"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a less efficient sorting algorithm with a 24-bit radix sort and removing an unnecessary barrier to improve performance.",
            "The optimization strategy replaced a less efficient sorting algorithm with a 24-bit radix sort to improve performance and removed an unnecessary barrier to reduce overhead.",
            "The optimization strategy involved replacing a less efficient sorting algorithm with a 24-bit radix sort to improve performance and removing an unnecessary barrier for further efficiency gains.",
            "The optimization strategy involved replacing a less efficient sorting algorithm with a 24-bit radix sort and removing an unnecessary barrier to improve performance.",
            "The optimization strategy involved replacing a general sorting algorithm with a 24-bit radix sort to improve performance and removing an unnecessary barrier for further efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a less efficient sorting algorithm with a 24-bit radix sort and removing an unnecessary barrier to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ceph",
        "hash": "735ab91f3c6260733b71f0dfab29a99c5805a5c6",
        "author": "Haomai Wang",
        "date": "2015-05-01T00:34:54+08:00",
        "message": "Client: Fast return if len is 0\n\nIf len == 0,\nosdc/Striper.cc: 50: FAILED assert(len > 0)\n 2: (Striper::file_to_extents(CephContext*, char const*, ceph_file_layout const*, unsigned long, unsigned long, unsigned long, std::map<object_t, std::vector<ObjectExtent, std::allocator<ObjectExtent> >, std::less<object_t>, std::allocator<std::pair<object_t const, std::vector<ObjectExtent, std::allocator<ObjectExtent> > > > >&, unsigned long)+0x1c6) [0x7fd1a0f4f522]\n 3: (Striper::file_to_extents(CephContext*, char const*, ceph_file_layout const*, unsigned long, unsigned long, unsigned long, std::vector<ObjectExtent, std::allocator<ObjectExtent> >&, unsigned long)+0x69) [0x7fd1a0f4f315]\n 4: (Striper::file_to_extents(CephContext*, inodeno_t, ceph_file_layout const*, unsigned long, unsigned long, unsigned long, std::vector<ObjectExtent, std::allocator<ObjectExtent> >&)+0x8a) [0x7fd1a0ef9c3c]\n 5: (ObjectCacher::file_read(ObjectCacher::ObjectSet*, ceph_file_layout*, snapid_t, long, unsigned long, ceph::buffer::list*, int, Context*)+0x7e) [0x7fd1a0efb186]\n 6: (Client::_read_async(Fh*, unsigned long, unsigned long, ceph::buffer::list*)+0x4ca) [0x7fd1a0ec90d4]\n 7: (Client::_read(Fh*, long, unsigned long, ceph::buffer::list*)+0x3dc) [0x7fd1a0ec8744]\n 8: (Client::read(int, char*, long, long)+0x208) [0x7fd1a0ec8100]\n 9: (ceph_read()+0x5e) [0x7fd1a0e80603]\n\nSigned-off-by: Haomai Wang <haomaiwang@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/client/Client.cc"
        ],
        "github_commit_url": "https://github.com/ceph/ceph/commit/735ab91f3c6260733b71f0dfab29a99c5805a5c6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Client::_read_async"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding an early return check for zero-length reads to avoid unnecessary processing and potential assertion failures.",
            "The optimization strategy involves adding an early return check for zero-length reads to avoid unnecessary processing and potential assertion failures.",
            "The optimization strategy involves adding an early return check for zero-length reads to avoid unnecessary processing and potential assertion failures.",
            "The optimization strategy involves adding an early return check for zero-length reads to avoid unnecessary processing and potential assertion failures.",
            "The optimization strategy involves adding an early return check for zero-length reads to avoid unnecessary processing and potential assertion failures."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves adding an early return check for zero-length reads to avoid unnecessary processing and potential assertion failures.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "8558457143bfa76d61e0d2f715e40ec2ddb6ffc2",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "ldb_cmd_execute_result.h: perform init in initialization list\n\nFix for:\n\n[util/ldb_cmd_execute_result.h:18]: (performance) Variable 'message_'\n is assigned in constructor body. Consider performing initialization\n in initialization list.\n[util/ldb_cmd_execute_result.h:23]: (performance) Variable 'message_'\n is assigned in constructor body. Consider performing initialization\n in initialization list.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "util/ldb_cmd_execute_result.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/8558457143bfa76d61e0d2f715e40ec2ddb6ffc2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LDBCommandExecuteResult"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved moving variable initialization from the constructor body to the initialization list to improve performance by avoiding unnecessary default construction and assignment.",
            "The optimization strategy involved moving variable initialization from the constructor body to the initialization list to improve performance by avoiding unnecessary default construction and assignment.",
            "The optimization strategy involved moving variable initialization from the constructor body to the initialization list to improve performance by avoiding unnecessary default construction and assignment.",
            "The optimization strategy involved moving variable initialization from the constructor body to the initialization list to improve performance by avoiding unnecessary default construction and assignment.",
            "The optimization strategy involved moving variable initialization from the constructor body to the initialization list to improve performance by reducing unnecessary assignments."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved moving variable initialization from the constructor body to the initialization list to improve performance by avoiding unnecessary default construction and assignment.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "5c456c4c08ac046429c38792d242dd095c50b049",
        "author": "SGZW",
        "date": "2024-08-09T15:05:02-07:00",
        "message": "fix compaction speedup for marked files ut (#12912)\n\nSummary: Pull Request resolved: https://github.com/facebook/rocksdb/pull/12912\n\nReviewed By: hx235\n\nDifferential Revision: D60973460\n\nPulled By: cbi42\n\nfbshipit-source-id: ebaa343757f09f7281884a512ebe3a7d6845c8b3",
        "modified_files_count": 1,
        "modified_files": [
            "db/column_family_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/5c456c4c08ac046429c38792d242dd095c50b049",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_P"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved modifying the test logic to improve compaction speed by handling marked files more efficiently.",
            "The optimization strategy involved modifying test logic to improve compaction speed by handling marked files more efficiently.",
            "The optimization strategy involved modifying the test logic to improve compaction speed by handling marked files more efficiently.",
            "The optimization strategy involved modifying the test to improve compaction speed by handling marked files more efficiently.",
            "The optimization strategy involved modifying the test logic to improve compaction speed by handling marked files more efficiently."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved modifying the test logic to improve compaction speed by handling marked files more efficiently.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "90d835507581324d0449f1ded4f56a8b16f20bf7",
        "author": "xiusir",
        "date": "2017-02-28T10:39:11-08:00",
        "message": "Fix the wrong address for PREFETCH in DynamicBloom::Prefetch\n\nSummary:\n- Change data_[b] to data_[b / 8] in DynamicBloom::Prefetch, as b means the b-th bit in data_ and data_[b / 8] is the proper byte in data_.\nCloses https://github.com/facebook/rocksdb/pull/1935\n\nDifferential Revision: D4628696\n\nPulled By: siying\n\nfbshipit-source-id: bc5a0c6",
        "modified_files_count": 1,
        "modified_files": [
            "util/dynamic_bloom.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/90d835507581324d0449f1ded4f56a8b16f20bf7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DynamicBloom::Prefetch"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization corrected an incorrect memory address calculation in a prefetch operation to ensure proper byte-level access instead of bit-level access.",
            "The optimization corrected an incorrect memory address calculation in a prefetch operation to ensure proper byte-level access instead of bit-level access.",
            "The optimization corrected an incorrect memory address calculation in a prefetch operation to ensure proper byte-level access instead of bit-level access.",
            "The optimization corrected an incorrect memory address calculation in a prefetch operation by adjusting the index to properly reference the intended byte instead of the bit.",
            "The optimization corrected an incorrect memory address calculation in a prefetch operation to ensure proper byte-level access instead of bit-level access."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization corrected an incorrect memory address calculation in a prefetch operation to ensure proper byte-level access instead of bit-level access.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "3DWorld",
        "hash": "04a17cce49dea5f8898ceaae812604d6f2ab0357",
        "author": "Frank Gennari",
        "date": "2020-12-10T00:28:24-08:00",
        "message": "Minor optimization to terrain_hmap_manager_t::get_norm()",
        "modified_files_count": 1,
        "modified_files": [
            "src/heightmap.cpp"
        ],
        "github_commit_url": "https://github.com/fegennari/3DWorld/commit/04a17cce49dea5f8898ceaae812604d6f2ab0357",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "terrain_hmap_manager_t::get_norm"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a computationally expensive normalization operation with a precomputed lookup table to reduce runtime calculations.",
            "The optimization strategy involved replacing a computationally expensive normalization operation with a precomputed lookup table to reduce runtime calculations.",
            "The optimization strategy involved replacing a computationally expensive normalization operation with a precomputed lookup table to reduce runtime calculations.",
            "The optimization strategy used is replacing a division operation with a multiplication by the reciprocal to improve performance.",
            "The optimization strategy used is replacing a division operation with a multiplication by the reciprocal to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a computationally expensive normalization operation with a precomputed lookup table to reduce runtime calculations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "d438e1ec174bdf1474edcdf9902fe3cb14b8a1e2",
        "author": "Andrew Kryczka",
        "date": "2017-01-24T13:24:14-08:00",
        "message": "Test range deletion block outlives table reader\n\nSummary:\nThis test ensures RangeDelAggregator can still access blocks even if it outlives the table readers that created them (detailed description in comments).\n\nI plan to optimize away the extra cache lookup we currently do in BlockBasedTable::NewRangeTombstoneIterator(), as it is ~5% CPU in my random read benchmark in a database with 1k tombstones. This test will help make sure nothing breaks in the process.\nCloses https://github.com/facebook/rocksdb/pull/1739\n\nDifferential Revision: D4375954\n\nPulled By: ajkr\n\nfbshipit-source-id: aef9357",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_range_del_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d438e1ec174bdf1474edcdf9902fe3cb14b8a1e2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves eliminating an unnecessary cache lookup in BlockBasedTable::NewRangeTombstoneIterator to reduce CPU overhead.",
            "The optimization strategy eliminates an unnecessary cache lookup in BlockBasedTable::NewRangeTombstoneIterator to reduce CPU overhead.",
            "The optimization strategy eliminates an unnecessary cache lookup in BlockBasedTable::NewRangeTombstoneIterator to reduce CPU overhead.",
            "The optimization strategy eliminates an unnecessary cache lookup in BlockBasedTable::NewRangeTombstoneIterator to reduce CPU overhead.",
            "The optimization strategy eliminates an unnecessary cache lookup in BlockBasedTable::NewRangeTombstoneIterator to reduce CPU overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy eliminates an unnecessary cache lookup in BlockBasedTable::NewRangeTombstoneIterator to reduce CPU overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "498a84db834a62eef2e5cb2fb85d051c39f89fff",
        "author": "Arjan van de Ven",
        "date": "2010-02-23T07:37:57-08:00",
        "message": "ACPI: fix High cpu temperature with 2.6.32\n\ncommit 370d5cd88509b93b76eb2f5f97efbd71c25061cb upstream.\n\nSince the rewrite of the CPU idle governor in 2.6.32, two laptops have\nsurfaced where the BIOS advertises a C2 power state, but for some reason\nthis state is not functioning (as verified in both cases by powertop\nbefore the patch in .32).\n\nThe old governor had the accidental behavior that if a non-working state\nwas chosen too many times, it would end up falling back to C1.  The new\ngovernor works differently and this accidental behavior is no longer\nthere; the result is a high temperature on these two machines.\n\nThis patch adds these 2 machines to the DMI table for C state anomalies;\nby just not using C2 both these machines are better off (the TSC can be\nused instead of the pm timer, giving a performance boost for example).\n\nAddresses http://bugzilla.kernel.org/show_bug.cgi?id=14742\n\nSigned-off-by: Arjan van de Ven <arjan@linux.intel.com>\nReported-by: <akwatts@ymail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Len Brown <len.brown@intel.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@suse.de>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/acpi/processor_idle.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/498a84db834a62eef2e5cb2fb85d051c39f89fff",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DMI_MATCH"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding specific machines to a DMI table to avoid using a non-functional C2 power state, thereby reducing CPU temperature and improving performance.",
            "The optimization strategy involves adding specific machines to the DMI table to avoid using a non-functional C2 power state, thereby reducing CPU temperature and improving performance.",
            "The optimization strategy involves adding specific machines to the DMI table to avoid using a non-functional C2 power state, thereby reducing CPU temperature and improving performance.",
            "The optimization strategy involves adding specific machines to the DMI table to avoid using a non-functional C2 power state, thereby reducing CPU temperature and improving performance.",
            "The optimization strategy involves adding specific machines to the DMI table to avoid using a non-functional C2 power state, thereby reducing CPU temperature and improving performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding specific machines to the DMI table to avoid using a non-functional C2 power state, thereby reducing CPU temperature and improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "dbeaa0d397fd2d26e105817242782024d1e607b7",
        "author": "Yanqin Jin",
        "date": "2018-07-12T14:42:39-07:00",
        "message": "Reduce #iterations to shorten execution time. (#4123)\n\nSummary:\nReduce #iterations from 5000 to 1000 so that\n`ExternalSSTFileTest.CompactDuringAddFileRandom` can finish faster.\nOn the one hand, 5000 iterations does not seem to improve the quality of unit\ntest in comparison with 1000. On the other hand, long running tests should belong to stress tests.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4123\n\nDifferential Revision: D8822514\n\nPulled By: riversand963\n\nfbshipit-source-id: 0f439b8d5ccd9a4aed84638f8bac16382de17245",
        "modified_files_count": 1,
        "modified_files": [
            "db/external_sst_file_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/dbeaa0d397fd2d26e105817242782024d1e607b7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy reduces the number of iterations in a test to shorten execution time without significantly impacting test quality.",
            "The optimization strategy reduces the number of iterations in a test to shorten execution time without compromising test quality.",
            "The optimization strategy reduces the number of iterations in a test to shorten execution time without compromising test quality.",
            "The optimization strategy reduced the number of iterations in a test to shorten execution time without compromising test quality.",
            "The optimization strategy reduced the number of iterations in a test to decrease execution time without compromising the test's effectiveness."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the number of iterations in a test to shorten execution time without compromising test quality.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "38df2f07b7bc5309ebb159438b435d1f25f31e35",
        "author": "Rajkumar Manoharan",
        "date": "2011-11-08T15:54:29-05:00",
        "message": "ath9k_hw: Update CCK spur mitigation for AR9462\n\nTo improve CCK sensitivity for AR9462 chips, performing\nspur mitigation at 2440, 2464 frequencies alone is sufficient.\n\nSigned-off-by: Rajkumar Manoharan <rmanohar@qca.qualcomm.com>\nSigned-off-by: John W. Linville <linville@tuxdriver.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/wireless/ath/ath9k/ar9003_phy.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/38df2f07b7bc5309ebb159438b435d1f25f31e35",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ar9003_hw_spur_mitigate_mrc_cck"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involves reducing unnecessary spur mitigation frequencies to improve CCK sensitivity for AR9462 chips.",
            "The optimization strategy involves reducing unnecessary spur mitigation frequencies to improve CCK sensitivity for AR9462 chips.",
            "The optimization strategy involves reducing unnecessary spur mitigation frequencies to improve CCK sensitivity for AR9462 chips.",
            "The optimization strategy involves reducing unnecessary spur mitigation frequencies to improve CCK sensitivity for AR9462 chips.",
            "The optimization strategy involves reducing unnecessary spur mitigation frequencies to improve CCK sensitivity for AR9462 chips."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reducing unnecessary spur mitigation frequencies to improve CCK sensitivity for AR9462 chips.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "9b51af5a17f3cfd754575894e090dd867fb47740",
        "author": "Siying Dong",
        "date": "2014-01-14T17:41:44-08:00",
        "message": "[RocksDB Performance Branch] DBImpl.NewInternalIterator() to reduce works inside mutex\n\nSummary: To reduce mutex contention caused by DBImpl.NewInternalIterator(), in this function, move all the iteration creation works out of mutex, only leaving object ref and get.\n\nTest Plan:\nmake all check\nwill run db_stress for a while too to make sure no problem.\n\nReviewers: haobo, dhruba, kailiu\n\nReviewed By: haobo\n\nCC: igor, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14589\n\nConflicts:\n\tdb/db_impl.cc",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/9b51af5a17f3cfd754575894e090dd867fb47740",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::NewInternalIterator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work out of a mutex-protected section to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work out of a mutex-protected section to reduce contention and improve concurrency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "spectre",
        "hash": "4339468d6cc18b260c82f042f94efb6a18be10aa",
        "author": "Nils Vu",
        "date": "2024-09-30T11:53:07-07:00",
        "message": "Accelerate exporter with block priority order",
        "modified_files_count": 1,
        "modified_files": [
            "src/IO/Exporter/Exporter.cpp"
        ],
        "github_commit_url": "https://github.com/sxs-collaboration/spectre/commit/4339468d6cc18b260c82f042f94efb6a18be10aa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "interpolate_to_points"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reordering the processing of blocks in the exporter to prioritize them based on a specific order, reducing unnecessary computations.",
            "The optimization strategy involved reordering the interpolation process to prioritize blocks based on their priority order, reducing unnecessary computations.",
            "The optimization strategy involved reordering the processing of blocks in the exporter to prioritize them based on a specific order, reducing unnecessary computations.",
            "The optimization strategy involved reordering the processing of blocks in the exporter to prioritize them based on a specific order, reducing unnecessary computations.",
            "The optimization strategy involved reordering the interpolation process to prioritize blocks based on their priority order, reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reordering the processing of blocks in the exporter to prioritize them based on a specific order, reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "821887036e5235c827029d14decb185bea01ec4b",
        "author": "Andrew Kryczka",
        "date": "2017-10-03T16:27:28-07:00",
        "message": "pin L0 filters/indexes for compaction outputs\n\nSummary:\nWe need to tell the iterator the compaction output file's level so it can apply proper optimizations, like pinning filter and index blocks when user enables `pin_l0_filter_and_index_blocks_in_cache` and the output file's level is zero.\nCloses https://github.com/facebook/rocksdb/pull/2949\n\nDifferential Revision: D5945597\n\nPulled By: ajkr\n\nfbshipit-source-id: 2389decf9026ffaa32d45801a77d002529f64a62",
        "modified_files_count": 1,
        "modified_files": [
            "db/compaction_job.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/821887036e5235c827029d14decb185bea01ec4b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompactionJob::FinishCompactionOutputFile"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves pinning filter and index blocks in the cache for compaction output files at level zero to reduce redundant memory operations.",
            "The optimization strategy involves pinning filter and index blocks in the cache for compaction output files at level 0 to reduce redundant memory operations.",
            "The optimization strategy involves pinning filter and index blocks in the cache for compaction output files at level zero to reduce redundant memory operations.",
            "The optimization strategy involves pinning filter and index blocks in the cache for compaction output files at level 0 to reduce redundant memory operations.",
            "The optimization strategy involves pinning filter and index blocks in the cache for compaction output files at level 0 to reduce redundant memory operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves pinning filter and index blocks in the cache for compaction output files at level 0 to reduce redundant memory operations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "30a017fecae60aa7b87c4a1e283b6ac027724a92",
        "author": "Yi Wu",
        "date": "2018-01-05T16:41:58-08:00",
        "message": "Blob DB: avoid having a separate read of checksum\n\nSummary:\nPreviously on a blob db read, we are making a read of the blob value, and then make another read to get CRC checksum. I'm combining the two read into one.\n\nreadrandom db_bench with 1G database with base db size of 13M, value size 1k:\n`./db_bench --db=/home/yiwu/tmp/db_bench --use_blob_db --value_size=1024 --num=1000000 --benchmarks=readrandom --use_existing_db --cache_size=32000000`\nmaster: throughput 234MB/s, get micros p50 5.984 p95 9.998 p99 20.817 p100 787\nthis PR: throughput 261MB/s, get micros p50 5.157 p95 9.928 p99 20.724 p100 190\nCloses https://github.com/facebook/rocksdb/pull/3301\n\nDifferential Revision: D6615950\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: 052410c6d8539ec0cc305d53793bbc8f3616baa3",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/blob_db/blob_db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/30a017fecae60aa7b87c4a1e283b6ac027724a92",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlobDBImpl::GetBlobValue"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy combines two separate read operations (blob value and CRC checksum) into a single read to reduce I/O overhead.",
            "The optimization strategy combines two separate read operations into a single read to reduce I/O overhead and improve throughput.",
            "The optimization strategy combines two separate read operations into a single read to reduce I/O overhead and improve performance.",
            "The optimization strategy combines two separate read operations (blob value and CRC checksum) into a single read to reduce I/O overhead.",
            "The optimization strategy combines two separate read operations (blob value and CRC checksum) into a single read to reduce I/O overhead."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy combines two separate read operations (blob value and CRC checksum) into a single read to reduce I/O overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qtdeclarative",
        "hash": "e338bbed44d09c08b7ca047ff0914ed01d3917fd",
        "author": "Sami Shalayel",
        "date": "2025-02-18T20:02:03+01:00",
        "message": "qqmljsutils: improve didYouMean performance\n\ndidYouMean eats up a lot of time in the profiler when imports can't be\nfound, so its not really a \"performance fix\". But it makes qmllint\nfaster on files that have a typo in its imports for example.\n\nSwapping QList with QVarLengthArray makes the runtime of\ntst_qmllint_benchmark:onlyQdsLintPlugin on\nqtdesign-studio/examples/DesignEffectsDemo/content/Gallery.ui.qml go\nfrom 150ms to 125ms when the QtDesign studio modules import paths are\nmissing. It seems that QVarLengthArray does less allocations than QList,\nprobably because of the std::swap.\n\nIt seemed that std::vector had similar performance to QVarLengthArray,\nup to some ms.\n\nTask-number: QTBUG-133349\nChange-Id: I3facc8f194da6eaf1aebbce91292bf9b164b740e\nReviewed-by: Ulf Hermann <ulf.hermann@qt.io>",
        "modified_files_count": 1,
        "modified_files": [
            "src/qmlcompiler/qqmljsutils.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qtdeclarative/commit/e338bbed44d09c08b7ca047ff0914ed01d3917fd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "QQmlJSUtils::didYouMean"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing QList with QVarLengthArray to reduce memory allocations and improve performance in the `didYouMean` function.",
            "The optimization strategy involved replacing QList with QVarLengthArray to reduce memory allocations and improve performance in the `didYouMean` function.",
            "The optimization strategy involved replacing QList with QVarLengthArray to reduce memory allocations and improve performance in the `didYouMean` function.",
            "The optimization strategy involved replacing QList with QVarLengthArray to reduce memory allocations and improve performance in a specific function.",
            "The optimization strategy involved replacing QList with QVarLengthArray to reduce memory allocations and improve performance in the `didYouMean` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing QList with QVarLengthArray to reduce memory allocations and improve performance in the `didYouMean` function.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "a2de8e52bb6c13baf5f2323eba0ca356f1294f88",
        "author": "Simon Liu",
        "date": "2018-11-13T14:39:03-08:00",
        "message": "optimized the performance of autovector::emplace_back. (#4606)\n\nSummary:\nIt called the autovector::push_back simply in autovector::emplace_back.\nThis was not efficient, and then optimazed this function through the\nperfect forwarding.\n\nThis was the src and result of the benchmark(using the google'benchmark library, the type of elem in\nautovector was std::string, and call emplace_back with the \"char *\" type):\n\nhttps://gist.github.com/monadbobo/93448b89a42737b08cbada81de75c5cd\n\nPS: The benchmark's result of  previous PR was not accurate, and so I update the test case and result.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4606\n\nDifferential Revision: D13046813\n\nPulled By: sagar0\n\nfbshipit-source-id: 19cde1bcadafe899aa454b703acb35737a1cc02d",
        "modified_files_count": 1,
        "modified_files": [
            "util/autovector.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a2de8e52bb6c13baf5f2323eba0ca356f1294f88",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "emplace_back"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved replacing an inefficient `push_back` call in `emplace_back` with perfect forwarding to reduce unnecessary copies and improve performance.",
            "The optimization strategy involved replacing an inefficient `push_back` call in `emplace_back` with perfect forwarding to reduce unnecessary copies and improve performance.",
            "The optimization replaced an inefficient `push_back` call in `emplace_back` with perfect forwarding to reduce unnecessary object copies and improve performance.",
            "The optimization strategy replaced an inefficient `push_back` call in `emplace_back` with perfect forwarding to reduce unnecessary object copies and improve performance.",
            "The optimization strategy involved replacing an inefficient `push_back` call in `emplace_back` with perfect forwarding to reduce unnecessary object copies and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing an inefficient `push_back` call in `emplace_back` with perfect forwarding to reduce unnecessary object copies and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "08be1803eecb5ae464440812ea06e79b21289053",
        "author": "Igor Canadi",
        "date": "2015-04-13T15:58:45-07:00",
        "message": "Fix bad performance in debug mode\n\nSummary:\nSee github issue 574: https://github.com/facebook/rocksdb/issues/574\n\nBasically when we're running in DEBUG mode we're calling `usleep(0)` on\nevery mutex lock. I bisected the issue to\nhttps://reviews.facebook.net/D36963. Instead of calling sleep(0), this\ndiff just avoids calling SleepForMicroseconds() when delay is not set.\n\nTest Plan:\n    bpl=10485760;overlap=10;mcz=2;del=300000000;levels=2;ctrig=10000000; delay=10000000; stop=10000000; wbn=30; mbc=20; mb=1073741824;wbs=268435456; dds=1; sync=0; r=100000; t=1; vs=800; bs=65536; cs=1048576; of=500000; si=1000000; ./db_bench --benchmarks=fillrandom --disable_seek_compaction=1 --mmap_read=0 --statistics=1 --histogram=1 --num=$r --threads=$t --value_size=$vs --block_size=$bs --cache_size=$cs --bloom_bits=10 --cache_numshardbits=4 --open_files=$of --verify_checksum=1 --db=/tmp/rdb10test --sync=$sync --disable_wal=1 --compression_type=snappy --stats_interval=$si --compression_ratio=0.5 --disable_data_sync=$dds --write_buffer_size=$wbs --target_file_size_base=$mb --max_write_buffer_number=$wbn --max_background_compactions=$mbc --level0_file_num_compaction_trigger=$ctrig --level0_slowdown_writes_trigger=$delay --level0_stop_writes_trigger=$stop --num_levels=$levels --delete_obsolete_files_period_micros=$del --min_level_to_compress=$mcz --max_grandparent_overlap_factor=$overlap --stats_per_interval=1 --max_bytes_for_level_base=$bpl --memtablerep=vector --use_existing_db=0 --disable_auto_compactions=1 --source_compaction_factor=10000000 | grep ops\n\nBefore:\nfillrandom   :     117.525 micros/op 8508 ops/sec;    6.6 MB/s\nAfter:\nfillrandom   :       1.283 micros/op 779502 ops/sec;  606.6 MB/s\n\nReviewers: rven, yhchiang, sdong\n\nReviewed By: sdong\n\nSubscribers: meyering, dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D36963",
        "modified_files_count": 1,
        "modified_files": [
            "util/thread_status_util_debug.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/08be1803eecb5ae464440812ea06e79b21289053",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ThreadStatusUtil::TEST_StateDelay"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization avoids unnecessary calls to `SleepForMicroseconds()` in debug mode by checking if the delay is set before invoking the function.",
            "The optimization strategy avoided unnecessary calls to `SleepForMicroseconds()` in debug mode by checking if the delay is set before invoking the sleep function.",
            "The optimization avoids unnecessary calls to `SleepForMicroseconds()` in debug mode by checking if the delay is set before invoking the function.",
            "The optimization strategy avoided unnecessary calls to `SleepForMicroseconds()` when the delay was not set, reducing overhead in debug mode.",
            "The optimization strategy avoided unnecessary calls to `SleepForMicroseconds()` in debug mode by checking if the delay is set before invoking the sleep function."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoided unnecessary calls to `SleepForMicroseconds()` in debug mode by checking if the delay is set before invoking the sleep function.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "21171615c10ee1a636ea28f2303a93a4bc39dbde",
        "author": "Yanqin Jin",
        "date": "2018-07-13T17:27:39-07:00",
        "message": "Reduce execution time of IngestFileWithGlobalSeqnoRandomized (#4131)\n\nSummary:\nMake `ExternalSSTFileTest.IngestFileWithGlobalSeqnoRandomized` run faster.\n\n`make format`\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4131\n\nDifferential Revision: D8839952\n\nPulled By: riversand963\n\nfbshipit-source-id: 4a7e842fde1cde4dc902e928a1cf511322578521",
        "modified_files_count": 1,
        "modified_files": [
            "db/external_sst_file_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/21171615c10ee1a636ea28f2303a93a4bc39dbde",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of iterations or operations in a randomized test to decrease its execution time.",
            "The optimization strategy involved reducing the number of iterations or operations in a randomized test to decrease its execution time.",
            "The optimization strategy involved reducing the number of iterations or operations in a randomized test to decrease execution time.",
            "The optimization strategy involved reducing the number of iterations or operations in a randomized test to decrease its execution time.",
            "The optimization strategy involved reducing the number of iterations or operations in a randomized test to decrease execution time."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of iterations or operations in a randomized test to decrease its execution time.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SCP-firmware",
        "hash": "abf6ff5787c376884b1638a69cf45472b3d32c56",
        "author": "Tarek El-Sherbiny",
        "date": "2019-12-02T12:19:02+00:00",
        "message": "sgm775/modules: Remove calls to fwk_module_check_call\n\nThis change is to reduce memory footprint.\n\nChange-Id: I6990cb2b55e4b6463780453f7659e550b328948b\nSigned-off-by: Tarek El-Sherbiny <tarek.el-sherbiny@arm.com>",
        "modified_files_count": 1,
        "modified_files": [
            "product/sgm775/module/sgm775_ddr_phy500/src/mod_sgm775_ddr_phy500.c"
        ],
        "github_commit_url": "https://github.com/ARM-software/SCP-firmware/commit/abf6ff5787c376884b1638a69cf45472b3d32c56",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sgm775_ddr_phy500_config"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing unnecessary function calls to reduce memory usage.",
            "The optimization strategy involved removing unnecessary function calls to reduce memory usage.",
            "The optimization strategy involved removing unnecessary function calls to reduce memory usage.",
            "The optimization strategy involved removing unnecessary function calls to reduce memory usage.",
            "The optimization strategy involved removing unnecessary function calls to reduce memory usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing unnecessary function calls to reduce memory usage.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "legion",
        "hash": "e5fc3b2bd3abc733ea3ee26d7a880bf3c89898be",
        "author": "Mike",
        "date": "2018-03-08T19:25:41-08:00",
        "message": "legion: more fixes for composite view optimization",
        "modified_files_count": 1,
        "modified_files": [
            "runtime/legion/legion_views.cc"
        ],
        "github_commit_url": "https://github.com/StanfordLegion/legion/commit/e5fc3b2bd3abc733ea3ee26d7a880bf3c89898be",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompositeNode::perform_ready_check"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the logic in `perform_ready_check` to reduce redundant computations and improve early exit conditions.",
            "The optimization strategy involved restructuring the logic in `perform_ready_check` to reduce redundant computations and improve early exit conditions.",
            "The optimization strategy involved restructuring the logic in `perform_ready_check` to reduce redundant checks and improve early exit conditions.",
            "The optimization strategy involved restructuring the logic in `perform_ready_check` to reduce redundant computations and improve early exit conditions.",
            "The optimization strategy involved restructuring the logic in `perform_ready_check` to reduce redundant computations and improve early exit conditions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the logic in `perform_ready_check` to reduce redundant computations and improve early exit conditions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "GPU-Raytracer",
        "hash": "f949474be5f76657ecd049ad02c5ef8e849c28c9",
        "author": "jan",
        "date": "2020-07-28T17:19:45+02:00",
        "message": "Reduced memory usage for unused materials",
        "modified_files_count": 1,
        "modified_files": [
            "Pathtracer.cpp"
        ],
        "github_commit_url": "https://github.com/jan-van-bergen/GPU-Raytracer/commit/f949474be5f76657ecd049ad02c5ef8e849c28c9",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory allocation for unused materials by conditionally skipping their initialization.",
            "The optimization strategy involved reducing memory allocation for unused materials by conditionally skipping their initialization.",
            "The optimization strategy involved reducing memory allocation for unused materials by conditionally skipping their initialization.",
            "The optimization strategy involved reducing memory usage by eliminating storage allocation for unused materials in the path tracer.",
            "The optimization strategy involved reducing memory allocation for unused materials by conditionally skipping their initialization."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory allocation for unused materials by conditionally skipping their initialization.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "55652043c83c463ce57b7748e01c6d12bb5bf9fe",
        "author": "Danny Al-Gaaf",
        "date": "2014-10-01T10:49:08+02:00",
        "message": "table/cuckoo_table_reader.cc: pass func parameter by reference\n\nFix for:\n\n[table/cuckoo_table_reader.cc:196]: (performance) Function\n parameter 'target' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/cuckoo_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/55652043c83c463ce57b7748e01c6d12bb5bf9fe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BucketComparator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "wayfire",
        "hash": "1780d7bb5d02e007f52d800a78904555aa42af6a",
        "author": "Ilia Bozhinov",
        "date": "2023-01-02T09:37:55+01:00",
        "message": "view-transform: optimize visibility computation a bit",
        "modified_files_count": 1,
        "modified_files": [
            "src/api/wayfire/view-transform.hpp"
        ],
        "github_commit_url": "https://github.com/WayfireWM/wayfire/commit/1780d7bb5d02e007f52d800a78904555aa42af6a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "children"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the visibility computation logic to reduce unnecessary checks and improve efficiency.",
            "The optimization strategy involved simplifying the visibility computation logic to reduce unnecessary checks and improve efficiency.",
            "The optimization strategy involved simplifying the visibility computation logic to reduce unnecessary checks and improve efficiency.",
            "The optimization strategy involved simplifying the visibility computation logic to reduce unnecessary checks and improve performance.",
            "The optimization strategy involved simplifying the visibility computation logic to reduce unnecessary checks and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the visibility computation logic to reduce unnecessary checks and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "6ffecc946fada1c39455e89488dba57941e81659",
        "author": "Alex Sierra",
        "date": "2021-07-01T00:05:41-04:00",
        "message": "drm/amdkfd: skip migration for pages already in VRAM\n\nMigration skipped for pages that are already in VRAM\ndomain. These could be the result of previous partial\nmigrations to SYS RAM, and prefetch back to VRAM.\nEx. Coherent pages in VRAM that were not written/invalidated after\na copy-on-write.\n\nSigned-off-by: Alex Sierra <alex.sierra@amd.com>\nReviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>\nSigned-off-by: Alex Deucher <alexander.deucher@amd.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/amd/amdkfd/kfd_migrate.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/6ffecc946fada1c39455e89488dba57941e81659",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "svm_migrate_copy_to_vram"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips unnecessary memory migrations for pages already in the desired VRAM domain, reducing redundant operations.",
            "The optimization strategy skips unnecessary memory migrations for pages already in the VRAM domain, reducing redundant operations.",
            "The optimization strategy skips unnecessary memory migrations for pages already in the VRAM domain, reducing redundant operations.",
            "The optimization strategy skips unnecessary memory page migrations by checking if pages are already in the desired VRAM domain.",
            "The optimization strategy skips unnecessary memory page migrations by checking if pages are already in the desired VRAM domain."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips unnecessary memory migrations for pages already in the desired VRAM domain, reducing redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenRCT2",
        "hash": "eda01dc6089a430bb3dddf5360f0b8441b0933be",
        "author": "ζeh Matt",
        "date": "2021-01-01T02:43:13+02:00",
        "message": "Merge pull request #13668 from ZehMatt/performance/opengl-setdpi\n\nAvoid unnecessary calculations when the passed DPI is the active DPI",
        "modified_files_count": 1,
        "modified_files": [
            "src/openrct2-ui/drawing/engines/opengl/OpenGLDrawingEngine.cpp"
        ],
        "github_commit_url": "https://github.com/OpenRCT2/OpenRCT2/commit/eda01dc6089a430bb3dddf5360f0b8441b0933be",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OpenGLDrawingContext::SetDPI"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant calculations by checking if the passed DPI matches the active DPI before proceeding with computations.",
            "The optimization avoids redundant calculations by checking if the passed DPI is already the active DPI before performing any operations.",
            "The optimization avoids redundant calculations by checking if the passed DPI matches the active DPI before proceeding.",
            "The optimization avoids redundant calculations by checking if the passed DPI matches the active DPI before proceeding with computations.",
            "The optimization avoids redundant calculations by checking if the passed DPI is already the active DPI before proceeding with further operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids redundant calculations by checking if the passed DPI matches the active DPI before proceeding with computations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "93548ce8f451a701ad0967ba705f04fef80aa11a",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "table/cuckoo_table_reader.cc: pass func parameter by ref\n\nFix for:\n\n[table/cuckoo_table_reader.cc:198]: (performance) Function\n parameter 'file_data' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/cuckoo_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/93548ce8f451a701ad0967ba705f04fef80aa11a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BucketComparator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of data.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of data.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of data.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of data."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference to avoid unnecessary copying of data.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "92c0b021ce06fd4820af86bab0168bef064a7fd7",
        "author": "Pyun YongHyeon",
        "date": "2011-01-10T17:37:49+00:00",
        "message": "Backout r216973 and r216970. r216973 didn't solve watchdog timeout\nissue seen on PCIX BCM5704 controller. r216970 fixed the issue but\nthe DMA address space restriction was applied to all bge(4)\ncontrollers such that it caused unnecessary performance degradation\nfor controllers that have no such issues.",
        "modified_files_count": 1,
        "modified_files": [
            "sys/dev/bge/if_bge.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/92c0b021ce06fd4820af86bab0168bef064a7fd7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bge_dma_alloc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing a DMA address space restriction that was unnecessarily applied to all controllers, restoring performance for unaffected devices.",
            "The optimization strategy involved removing a DMA address space restriction that was unnecessarily applied to all controllers, restoring performance for unaffected devices.",
            "The optimization strategy involved removing a DMA address space restriction that was unnecessarily applied to all controllers, restoring performance for unaffected devices.",
            "The optimization strategy involved removing a DMA address space restriction that was unnecessarily applied to all controllers, restoring performance for unaffected devices.",
            "The optimization strategy involved removing a DMA address space restriction that was unnecessarily applied to all controllers, restoring performance for unaffected devices."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing a DMA address space restriction that was unnecessarily applied to all controllers, restoring performance for unaffected devices.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gperftools",
        "hash": "464688ab6ddb82db22ea9b934ddea192478e4535",
        "author": "Aliaksey Kandratsenka",
        "date": "2015-11-21T17:43:42-08:00",
        "message": "speedup free code path by dropping \"fast path allowed check\"",
        "modified_files_count": 1,
        "modified_files": [
            "src/tcmalloc.cc"
        ],
        "github_commit_url": "https://github.com/gperftools/gperftools/commit/464688ab6ddb82db22ea9b934ddea192478e4535",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "do_free_with_callback"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes a \"fast path allowed check\" in the free code path to reduce conditional branching and improve performance.",
            "The optimization removes a \"fast path allowed check\" in the free code path to reduce conditional branching and improve performance.",
            "The optimization removes a \"fast path allowed check\" in the free code path to reduce conditional branching and improve performance.",
            "The optimization removes a \"fast path allowed check\" in the free code path to reduce conditional branching and improve performance.",
            "The optimization removes a \"fast path allowed check\" in the free code path to reduce conditional branching and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes a \"fast path allowed check\" in the free code path to reduce conditional branching and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f69071265203edb0084f136b03bd4fcb42f16911",
        "author": "Igor Canadi",
        "date": "2015-03-13T14:45:15-07:00",
        "message": "Speed up db_bench shutdown\n\nSummary: See t6489044\n\nTest Plan: compiles\n\nReviewers: MarkCallaghan\n\nReviewed By: MarkCallaghan\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D34977",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_bench.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f69071265203edb0084f136b03bd4fcb42f16911",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "~Benchmark"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary operations during the shutdown process of the db_bench tool to improve performance.",
            "The optimization strategy involved reducing unnecessary operations during the shutdown process of the db_bench tool to improve performance.",
            "The optimization strategy involved reducing unnecessary operations during the shutdown process of the `db_bench` tool to improve performance.",
            "The optimization strategy involved reducing unnecessary operations during the shutdown process of the db_bench tool to improve performance.",
            "The optimization strategy involved reducing unnecessary operations during the shutdown process of the `db_bench` tool to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary operations during the shutdown process of the db_bench tool to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "0211dda68a4f6531923a2f72d8e8959207f59fba",
        "author": "Tal Gilboa",
        "date": "2018-11-22T11:36:54-08:00",
        "message": "net/dim: Update DIM start sample after each DIM iteration\n\nOn every iteration of net_dim, the algorithm may choose to\ncheck for the system state by comparing current data sample\nwith previous data sample. After each of these comparison,\nregardless of the action taken, the sample used as baseline\nis needed to be updated.\n\nThis patch fixes a bug that causes DIM to take wrong decisions,\ndue to never updating the baseline sample for comparison between\niterations. This way, DIM always compares current sample with\nzeros.\n\nAlthough this is a functional fix, it also improves and stabilizes\nperformance as the algorithm works properly now.\n\nPerformance:\nTested single UDP TX stream with pktgen:\nsamples/pktgen/pktgen_sample03_burst_single_flow.sh -i p4p2 -d 1.1.1.1\n-m 24:8a:07:88:26:8b -f 3 -b 128\n\nConnectX-5 100GbE packet rate improved from 15-19Mpps to 19-20Mpps.\nAlso, toggling between profiles is less frequent with the fix.\n\nFixes: 8115b750dbcb (\"net/dim: use struct net_dim_sample as arg to net_dim\")\nSigned-off-by: Tal Gilboa <talgi@mellanox.com>\nReviewed-by: Tariq Toukan <tariqt@mellanox.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "include/linux/net_dim.h"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/0211dda68a4f6531923a2f72d8e8959207f59fba",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "net_dim"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved fixing a bug that prevented the DIM algorithm from updating its baseline sample, ensuring proper decision-making and stabilizing performance.",
            "The optimization strategy involved fixing a bug that prevented the DIM algorithm from updating its baseline sample, ensuring proper decision-making and stabilizing performance.",
            "The optimization strategy involved fixing a bug that prevented the DIM algorithm from updating its baseline sample, ensuring proper decision-making and stabilizing performance.",
            "The optimization strategy involved fixing a bug that prevented the DIM algorithm from updating its baseline sample, ensuring proper decision-making and stabilizing performance.",
            "The optimization strategy involved fixing a bug that prevented the DIM algorithm from updating its baseline sample, ensuring proper decision-making and stabilizing performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved fixing a bug that prevented the DIM algorithm from updating its baseline sample, ensuring proper decision-making and stabilizing performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "b8b7117e97e649fc65d0a4dd397caf9a39fb71b1",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "db/version_set.cc: use !empty() instead of 'size() > 0'\n\nUse empty() since it should be prefered as it has, following\nthe standard, a constant time complexity regardless of the\ncontainter type. The same is not guaranteed for size().\n\nFix for:\n[db/version_set.cc:2250]: (performance) Possible inefficient\n checking for 'column_families_not_found' emptiness.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_set.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b8b7117e97e649fc65d0a4dd397caf9a39fb71b1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionSet::Recover"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking container emptiness.",
            "The optimization replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking container emptiness.",
            "The optimization replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking container emptiness.",
            "The optimization replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking container emptiness, as mandated by the C++ standard.",
            "The optimization replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking container emptiness, as mandated by the C++ standard."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking container emptiness.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "735a8fd38e86d94f62e732de94e1a137619b9e49",
        "author": "bellard",
        "date": "2005-01-12T22:36:43+00:00",
        "message": "fixed performance regression\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@1218 c046a42c-6fe2-441c-8c8c-71466251a162",
        "modified_files_count": 1,
        "modified_files": [
            "target-i386/cpu.h"
        ],
        "github_commit_url": "https://github.com/eurecom-s3/symqemu/commit/735a8fd38e86d94f62e732de94e1a137619b9e49",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cpu_x86_load_seg_cache"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "symqemu",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant segment cache updates by adding a conditional check to prevent unnecessary writes.",
            "The optimization strategy involved reducing redundant segment cache updates by adding a conditional check to prevent unnecessary writes.",
            "The optimization strategy involved reducing redundant computations or memory accesses in the `cpu_x86_load_seg_cache` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or memory accesses in the `cpu_x86_load_seg_cache` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or memory accesses in the `cpu_x86_load_seg_cache` function to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations or memory accesses in the `cpu_x86_load_seg_cache` function to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "43c789c8f246a2a35864e3fca9585b55c40c2095",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "spatialdb/spatial_db.cc: use !empty() instead of 'size() > 0'\n\nUse empty() since it should be prefered as it has, following\nthe standard, a constant time complexity regardless of the\ncontainter type. The same is not guaranteed for size().\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/spatialdb/spatial_db.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/43c789c8f246a2a35864e3fca9585b55c40c2095",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SpatialIndexCursor"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking if a container is non-empty, as mandated by the C++ standard.",
            "The optimization strategy replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking if a container is non-empty, as mandated by the C++ standard.",
            "The optimization strategy replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking if a container is non-empty, as mandated by the C++ standard.",
            "The optimization strategy replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking container non-emptiness, as mandated by the C++ standard.",
            "The optimization strategy replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking if a container is non-empty, as mandated by the C++ standard."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces `size() > 0` with `!empty()` to ensure constant-time complexity for checking if a container is non-empty, as mandated by the C++ standard.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "genometools",
        "hash": "f64e95dfe0c4257ee7a238ac25febedd2235025e",
        "author": "Stefan Kurtz",
        "date": "2012-03-15T12:04:07+01:00",
        "message": "Optimized gt_firstcodes_countocc_increment.",
        "modified_files_count": 1,
        "modified_files": [
            "src/match/firstcodes-tab.h"
        ],
        "github_commit_url": "https://github.com/genometools/genometools/commit/f64e95dfe0c4257ee7a238ac25febedd2235025e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DECLARE_HASHMAP"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the hash map implementation.",
            "The optimization strategy involved modifying the hash map implementation to reduce unnecessary computations during key lookups.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the hash map implementation.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the hash map implementation.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the hash map implementation."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations by caching and reusing results within the hash map implementation.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "e8ab1934d9cb3ffebd61097d67bb23439554b265",
        "author": "Siying Dong",
        "date": "2013-12-12T11:30:00-08:00",
        "message": "[RocksDB Performance Branch] DBImpl.NewInternalIterator() to reduce works inside mutex\n\nSummary: To reduce mutex contention caused by DBImpl.NewInternalIterator(), in this function, move all the iteration creation works out of mutex, only leaving object ref and get.\n\nTest Plan:\nmake all check\nwill run db_stress for a while too to make sure no problem.\n\nReviewers: haobo, dhruba, kailiu\n\nReviewed By: haobo\n\nCC: igor, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14589",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e8ab1934d9cb3ffebd61097d67bb23439554b265",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::NewInternalIterator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
            "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved moving iteration creation work outside of a mutex to reduce contention and improve concurrency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MathGeoLib",
        "hash": "bd4a94847324f939187edc214fb3adfeb06b84b6",
        "author": "Jukka Jylänki",
        "date": "2014-02-10T22:53:33+02:00",
        "message": "Optimize away an extra copy in float4x4::Inverted() when using SSE.",
        "modified_files_count": 1,
        "modified_files": [
            "src/Math/float4x4.cpp"
        ],
        "github_commit_url": "https://github.com/juj/MathGeoLib/commit/bd4a94847324f939187edc214fb3adfeb06b84b6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "float4x4::Inverted"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization eliminates an unnecessary copy operation in the `float4x4::Inverted()` function by directly using SSE instructions for inversion.",
            "The optimization eliminates an unnecessary copy operation in the `float4x4::Inverted()` function by directly using SSE instructions for in-place inversion.",
            "The optimization eliminates an unnecessary copy operation in the `float4x4::Inverted()` function by directly using SSE instructions for in-place inversion.",
            "The optimization eliminates an unnecessary copy operation in the `float4x4::Inverted()` function by directly using SSE instructions for inversion.",
            "The optimization eliminates an unnecessary copy operation in the `float4x4::Inverted()` function by directly using SSE instructions for inversion."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization eliminates an unnecessary copy operation in the `float4x4::Inverted()` function by directly using SSE instructions for inversion.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ain",
        "hash": "7bb8f336c57278206077357f39dbd98bba6c92c3",
        "author": "Pieter Wuille",
        "date": "2018-04-19T21:05:14-07:00",
        "message": "Optimization: only test for witness scripts at top level\n\nInside P2SH scripts we already know that the P2SH script version of witness keys/scripts\nare acceptable, so there is no need to test for it again.",
        "modified_files_count": 1,
        "modified_files": [
            "src/script/ismine.cpp"
        ],
        "github_commit_url": "https://github.com/DeFiCh/ain/commit/7bb8f336c57278206077357f39dbd98bba6c92c3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "IsMineInner"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant checks for witness scripts within P2SH scripts by leveraging prior knowledge of their acceptability.",
            "The optimization avoids redundant checks for witness scripts within P2SH scripts by leveraging prior knowledge of their acceptability.",
            "The optimization avoids redundant checks for witness scripts within P2SH scripts by leveraging prior knowledge of their acceptability.",
            "The optimization avoids redundant checks for witness scripts within P2SH scripts by leveraging prior knowledge of their acceptability.",
            "The optimization avoids redundant checks for witness scripts within P2SH scripts by leveraging prior knowledge of their acceptability."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids redundant checks for witness scripts within P2SH scripts by leveraging prior knowledge of their acceptability.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "2e5a323dbd4dbfad5b1e3d45d489e6dca37f4257",
        "author": "Ali Saidi",
        "date": "2022-06-15T13:08:11-07:00",
        "message": "Change the instruction used for a pause on arm64 (#10118)\n\nSummary:\nWhile the yield instruction conseptually sounds correct on most platforms it is\na simple nop that doesn't delay the execution anywhere close to what an x86\npause instruction does. In other projects with spin-wait loops an isb has been\nobserved to be much closer to the x86 behavior.\n\nOn a Graviton3 system the following test improves on average by 2x with this\nchange averaged over 20 runs:\n\n```\n./db_bench  -benchmarks=fillrandom -threads=64 -batch_size=1\n-memtablerep=skip_list -value_size=100 --num=100000\nlevel0_slowdown_writes_trigger=9999 -level0_stop_writes_trigger=9999\n-disable_auto_compactions --max_write_buffer_number=8 -max_background_flushes=8\n--disable_wal --write_buffer_size=160000000 --block_size=16384\n--allow_concurrent_memtable_write -compression_type none\n```\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10118\n\nReviewed By: jay-zhuang\n\nDifferential Revision: D37120578\n\nfbshipit-source-id: c20bde4298222edfab7ff7cb6d42497e7012400d",
        "modified_files_count": 1,
        "modified_files": [
            "port/port_posix.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/2e5a323dbd4dbfad5b1e3d45d489e6dca37f4257",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AsmVolatilePause"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy replaced a no-operation (nop) instruction with a more effective instruction (`isb`) in spin-wait loops on ARM64 to better align with the behavior of x86's `pause` instruction.",
            "The optimization strategy involved replacing a no-operation (nop) instruction with a more effective instruction (`isb`) in spin-wait loops on ARM64 architecture to better match the behavior of the x86 `pause` instruction.",
            "The optimization strategy replaced a no-operation (nop) instruction with a more effective instruction (`isb`) in spin-wait loops on ARM64 architecture to better align with the behavior of the x86 `pause` instruction.",
            "The optimization strategy replaced a no-operation (nop) instruction with a more effective instruction (`isb`) in spin-wait loops on ARM64 to better align with the behavior of the x86 `pause` instruction, reducing CPU contention and improving performance.",
            "The optimization strategy replaced a no-operation (nop) instruction with a more effective instruction (`isb`) in spin-wait loops on ARM64 to better align with the behavior of the x86 `pause` instruction, reducing CPU busy-waiting overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a no-operation (nop) instruction with a more effective instruction (`isb`) in spin-wait loops on ARM64 architecture to better align with the behavior of the x86 `pause` instruction.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qtdeclarative",
        "hash": "348f24532f2b6b34eebd15207da0c510d6f499d0",
        "author": "Lars Knoll",
        "date": "2017-08-02T14:11:07+00:00",
        "message": "Optimize UPlus, Increment and Decrement operations\n\nChange-Id: I279b055196850051493dc7b10f0cf159ff834e7d\nReviewed-by: Erik Verbruggen <erik.verbruggen@qt.io>",
        "modified_files_count": 1,
        "modified_files": [
            "src/qml/jsruntime/qv4vme_moth.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qtdeclarative/commit/348f24532f2b6b34eebd15207da0c510d6f499d0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VME::exec"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit optimizes UPlus, Increment, and Decrement operations by reducing unnecessary overhead in their execution paths.",
            "The optimization strategy involved restructuring the execution logic for UPlus, Increment, and Decrement operations to reduce redundant computations and improve performance.",
            "The optimization strategy involved restructuring the execution logic for UPlus, Increment, and Decrement operations to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the execution logic for UPlus, Increment, and Decrement operations to reduce redundant computations and improve performance.",
            "The optimization strategy involved restructuring the execution logic for UPlus, Increment, and Decrement operations to reduce redundant computations and improve performance."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the execution logic for UPlus, Increment, and Decrement operations to reduce redundant computations and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "AshamaneCore",
        "hash": "2d692e9e87d8b2b438fd21dfae6749d573c4d5b8",
        "author": "linencloth",
        "date": "2010-10-25T02:31:19+02:00",
        "message": "Core/DBLayer: Optimize waypoint script loading\n\n--HG--\nbranch : trunk",
        "modified_files_count": 1,
        "modified_files": [
            "src/server/game/Globals/ObjectMgr.cpp"
        ],
        "github_commit_url": "https://github.com/AshamaneProject/AshamaneCore/commit/2d692e9e87d8b2b438fd21dfae6749d573c4d5b8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ObjectMgr::LoadWaypointScripts"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant database queries by caching results during waypoint script loading.",
            "The optimization strategy involved reducing redundant database queries by caching and reusing previously loaded waypoint script data.",
            "The optimization strategy involved reducing redundant database queries by caching results during waypoint script loading.",
            "The optimization strategy involved reducing redundant database queries by caching and reusing previously loaded waypoint script data.",
            "The optimization strategy involved reducing redundant database queries by caching results during waypoint script loading."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant database queries by caching results during waypoint script loading.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "httpd",
        "hash": "544cea832ed42aabfe28cbc5be4fbcf083f019fe",
        "author": "William A. Rowe Jr",
        "date": "2001-08-27T04:51:58+00:00",
        "message": "Final additional comments (for the moment) about the new optimization.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@90716 13f79535-47bb-0310-9956-ffa450edef68",
        "modified_files_count": 1,
        "modified_files": [
            "server/request.c"
        ],
        "github_commit_url": "https://github.com/apache/httpd/commit/544cea832ed42aabfe28cbc5be4fbcf083f019fe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AP_DECLARE"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the logic to reduce redundant computations within the request handling process.",
            "The optimization strategy involved restructuring the logic to reduce redundant computations within the request handling process.",
            "The optimization strategy involved restructuring the logic to reduce redundant computations within the request handling process.",
            "The optimization strategy involved restructuring the logic to reduce redundant computations within the request handling process.",
            "The optimization strategy involved restructuring the logic to reduce redundant computations within the request handling process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the logic to reduce redundant computations within the request handling process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "NX-FPS",
        "hash": "64ac0e1cddff681409ecf95293824f95039f099c",
        "author": "masagrator",
        "date": "2020-03-04T20:55:22+01:00",
        "message": "Make file output faster",
        "modified_files_count": 1,
        "modified_files": [
            "source/main.cpp"
        ],
        "github_commit_url": "https://github.com/masagrator/NX-FPS/commit/64ac0e1cddff681409ecf95293824f95039f099c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the frequency of file write operations by buffering data and writing in larger chunks.",
            "The optimization strategy involved reducing the frequency of file write operations by buffering data and writing in larger chunks.",
            "The optimization strategy involved reducing the frequency of file write operations by buffering data and writing in larger chunks.",
            "The optimization strategy involved reducing the frequency of file write operations by buffering data before writing to improve performance.",
            "The optimization strategy involved reducing the frequency of file write operations by buffering data and writing in larger chunks."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the frequency of file write operations by buffering data and writing in larger chunks.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ClickHouse",
        "hash": "0820dc0c8434432d7b1f7740f5561db7c62db9e6",
        "author": "Alexey Milovidov",
        "date": "2019-12-21T02:59:08+03:00",
        "message": "Optimization of sorting heap",
        "modified_files_count": 1,
        "modified_files": [
            "dbms/src/Core/SortCursor.h"
        ],
        "github_commit_url": "https://github.com/ClickHouse/ClickHouse/commit/0820dc0c8434432d7b1f7740f5561db7c62db9e6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SortingHeap"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the sorting heap to reduce unnecessary comparisons during element insertion and extraction.",
            "The optimization strategy involved restructuring the sorting heap to reduce unnecessary comparisons during element insertion and extraction.",
            "The optimization strategy involved restructuring the sorting heap to reduce unnecessary comparisons during element reordering.",
            "The optimization strategy involved restructuring the sorting heap to reduce unnecessary comparisons during element insertion and extraction.",
            "The optimization strategy involved restructuring the sorting heap to reduce unnecessary comparisons during element insertion and extraction."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the sorting heap to reduce unnecessary comparisons during element insertion and extraction.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "RIOT",
        "hash": "4504e40fe0bef083078c9d0f15d5836bf8cc9792",
        "author": "Martine Lenders",
        "date": "2016-03-04T05:40:00+01:00",
        "message": "Merge pull request #4771 from Yonezawa-T2/rbuf_gc_improvement\n\nrbuf: does not remove oldest entry if we have entry for current fragment",
        "modified_files_count": 1,
        "modified_files": [
            "sys/net/gnrc/network_layer/sixlowpan/frag/rbuf.c"
        ],
        "github_commit_url": "https://github.com/RIOT-OS/RIOT/commit/4504e40fe0bef083078c9d0f15d5836bf8cc9792",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Copyright"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids removing the oldest entry in a ring buffer if there is already an entry for the current fragment, reducing unnecessary operations.",
            "The optimization avoids removing the oldest entry in a ring buffer if there is already an entry for the current fragment, reducing unnecessary operations.",
            "The optimization avoids removing the oldest entry in a ring buffer if there is already an entry for the current fragment, reducing unnecessary operations.",
            "The optimization avoids removing the oldest entry in a ring buffer if there is already an entry for the current fragment, reducing unnecessary operations.",
            "The optimization avoids removing the oldest entry in a ring buffer if there is already an entry for the current fragment, reducing unnecessary operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids removing the oldest entry in a ring buffer if there is already an entry for the current fragment, reducing unnecessary operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "30d19d57d513821c58de4556e7445982ed22b923",
        "author": "Magnus Karlsson",
        "date": "2022-03-28T19:56:28-07:00",
        "message": "ice: xsk: Eliminate unnecessary loop iteration\n\nThe NIC Tx ring completion routine cleans entries from the ring in\nbatches. However, it processes one more batch than it is supposed\nto. Note that this does not matter from a functionality point of view\nsince it will not find a set DD bit for the next batch and just exit\nthe loop. But from a performance perspective, it is faster to\nterminate the loop before and not issue an expensive read over PCIe to\nget the DD bit.\n\nFixes: 126cdfe1007a (\"ice: xsk: Improve AF_XDP ZC Tx and use batching API\")\nSigned-off-by: Magnus Karlsson <magnus.karlsson@intel.com>\nSigned-off-by: Alexei Starovoitov <ast@kernel.org>\nLink: https://lore.kernel.org/bpf/20220328142123.170157-3-maciej.fijalkowski@intel.com",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/ethernet/intel/ice/ice_xsk.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/30d19d57d513821c58de4556e7445982ed22b923",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ice_clean_xdp_irq_zc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization eliminates an unnecessary loop iteration in the NIC Tx ring completion routine to avoid an extra expensive PCIe read operation.",
            "The optimization eliminates an unnecessary loop iteration in the NIC Tx ring completion routine to avoid an expensive PCIe read operation.",
            "The optimization eliminates an unnecessary loop iteration by terminating the loop earlier, avoiding an expensive PCIe read operation.",
            "The optimization eliminates an unnecessary loop iteration in the NIC Tx ring completion routine to avoid an expensive PCIe read operation.",
            "The optimization eliminates an unnecessary loop iteration in the NIC Tx ring completion routine to avoid an extra expensive PCIe read operation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization eliminates an unnecessary loop iteration in the NIC Tx ring completion routine to avoid an extra expensive PCIe read operation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "DeepRec",
        "hash": "e9318edf30ea84e65d3beb096ca02946d2b10d00",
        "author": "Frederic Bastien",
        "date": "2021-06-24T13:13:38+08:00",
        "message": "For row reduction do not try to vectorize on P100 when the tile doesn't fit perfectly and for dtype bigger then 32 bits.",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc"
        ],
        "github_commit_url": "https://github.com/DeepRec-AI/DeepRec/commit/e9318edf30ea84e65d3beb096ca02946d2b10d00",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "IrEmitterUnnested::ComputeReductionCodegenInfo"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids vectorization for row reduction on P100 GPUs when the tile size is imperfect or the data type exceeds 32 bits, reducing unnecessary computation overhead.",
            "The optimization avoids vectorization for row reduction on P100 GPUs when the tile size is imperfect or the data type exceeds 32 bits, reducing unnecessary computation overhead.",
            "The optimization avoids vectorization for row reduction on P100 GPUs when the tile does not fit perfectly and the data type exceeds 32 bits, reducing unnecessary computation overhead.",
            "The optimization avoids vectorization for row reduction on P100 GPUs when the tile size is imperfect or the data type exceeds 32 bits, reducing unnecessary computation overhead.",
            "The optimization avoids vectorization for row reduction on P100 GPUs when the tile size is imperfect or the data type exceeds 32 bits, reducing unnecessary computation overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids vectorization for row reduction on P100 GPUs when the tile size is imperfect or the data type exceeds 32 bits, reducing unnecessary computation overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "haproxy",
        "hash": "0431f9d476a1237f76e360998bc7605506651b84",
        "author": "Willy Tarreau",
        "date": "2016-11-05T18:00:17+01:00",
        "message": "OPTIM: http: improve parsing performance of long header lines\n\nA performance test with 1kB cookies was capping at 194k req/s. After\nimplementing multi-byte skipping, the performance increased to 212k req/s,\nor 9.2% faster. This patch implements this for architectures supporting\nunaligned accesses (x86_64, x86, armv7a). Maybe other architectures can\nbenefit from this but they were not tested yet.",
        "modified_files_count": 1,
        "modified_files": [
            "src/proto_http.c"
        ],
        "github_commit_url": "https://github.com/haproxy/haproxy/commit/0431f9d476a1237f76e360998bc7605506651b84",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "http_msg_analyzer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved implementing multi-byte skipping for parsing long header lines to reduce the number of iterations and improve performance on architectures supporting unaligned accesses.",
            "The optimization strategy involved implementing multi-byte skipping for parsing long header lines to reduce the number of iterations and improve performance on architectures supporting unaligned accesses.",
            "The optimization strategy involved implementing multi-byte skipping for parsing long header lines to reduce the number of iterations and improve performance on architectures supporting unaligned accesses.",
            "The optimization strategy involved implementing multi-byte skipping for parsing long header lines to reduce the number of iterations and improve performance on architectures supporting unaligned accesses.",
            "The optimization strategy involved implementing multi-byte skipping for parsing long header lines to reduce the number of iterations and improve performance on architectures supporting unaligned accesses."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved implementing multi-byte skipping for parsing long header lines to reduce the number of iterations and improve performance on architectures supporting unaligned accesses.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "48b0a045da0ef7c07b59c529fc9a5c5f682853b6",
        "author": "Igor Canadi",
        "date": "2015-04-16T19:31:34-07:00",
        "message": "Speed up reduce_levels_test\n\nSummary: For some reason reduce_levels is opening the databse with 65.000 levels. This makes ComputeCompactionScore() function terribly slow and the tests is also very slow (20seconds).\n\nTest Plan: mr reduce_levels_test now takes 20ms\n\nReviewers: sdong, rven, kradhakrishnan, yhchiang\n\nReviewed By: yhchiang\n\nSubscribers: dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D37059",
        "modified_files_count": 1,
        "modified_files": [
            "util/ldb_cmd.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/48b0a045da0ef7c07b59c529fc9a5c5f682853b6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "old_levels_"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of levels in the database initialization to avoid unnecessary computational overhead in the `ComputeCompactionScore()` function.",
            "The optimization strategy involved reducing the number of levels in the database initialization to avoid unnecessary computational overhead in the `ComputeCompactionScore()` function.",
            "The optimization strategy involved reducing the number of levels in the database initialization to avoid unnecessary computation in the `ComputeCompactionScore()` function, thereby significantly speeding up the test.",
            "The optimization strategy involved reducing the number of levels in the database initialization to avoid unnecessary computational overhead in the `ComputeCompactionScore()` function.",
            "The optimization strategy involved reducing the number of levels in the database initialization to avoid unnecessary computational overhead in the `ComputeCompactionScore()` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of levels in the database initialization to avoid unnecessary computational overhead in the `ComputeCompactionScore()` function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ngsolve",
        "hash": "7e00ebf786b231b6ea264b3d4b8df6e7a5f0afd4",
        "author": "Joachim Schöberl",
        "date": "2017-03-24T16:33:06+01:00",
        "message": "Merge branch 'simd_constructor_less_general_nonavx' into 'master'\r\n\r\nSimd constructor less general nonavx\r\n\r\nSee merge request !143",
        "modified_files_count": 1,
        "modified_files": [
            "ngstd/simd.hpp"
        ],
        "github_commit_url": "https://github.com/NGSolve/ngsolve/commit/7e00ebf786b231b6ea264b3d4b8df6e7a5f0afd4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "alignas"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying or reducing the generality of SIMD constructor implementations to improve performance, potentially by avoiding unnecessary operations or specializing for non-AVX architectures.",
            "The optimization strategy involved simplifying or reducing the generality of SIMD constructor implementations to improve performance in non-AVX scenarios.",
            "The optimization strategy involved simplifying or reducing the generality of SIMD constructor implementations to improve performance, potentially by avoiding unnecessary operations or specializing for non-AVX architectures.",
            "The optimization strategy involved simplifying or reducing the generality of SIMD constructor implementations to improve performance in non-AVX environments.",
            "The optimization strategy involved simplifying or reducing the generality of SIMD constructor implementations to improve performance in non-AVX environments."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying or reducing the generality of SIMD constructor implementations to improve performance in non-AVX scenarios.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MySensors",
        "hash": "385d441d0ee8643d081e07d629ca99d1e20d20e2",
        "author": "Patrick Fallberg",
        "date": "2016-06-14T07:17:19+02:00",
        "message": "Merge pull request #474 from tekka007/SigningImprovement\n\nSpeedup signing presentation phase",
        "modified_files_count": 1,
        "modified_files": [
            "libraries/MySensors/core/MySigning.cpp"
        ],
        "github_commit_url": "https://github.com/mysensors/MySensors/commit/385d441d0ee8643d081e07d629ca99d1e20d20e2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "signerPresentation"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary data processing during the signing presentation phase to improve performance.",
            "The optimization strategy involved restructuring the signing presentation phase to reduce unnecessary computations or data handling.",
            "The optimization strategy involved reducing unnecessary data processing during the signing presentation phase to improve performance.",
            "The optimization strategy involved restructuring the signing presentation phase to reduce unnecessary computations or data handling.",
            "The optimization strategy involved reducing unnecessary data processing during the signing presentation phase to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary data processing during the signing presentation phase to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "beeee9dccc338ae7129016f2f2e17d2a40ecc5df",
        "author": "Igor Canadi",
        "date": "2014-04-08T11:06:39-07:00",
        "message": "Small speedup of CompactionFilterV2\n\nSummary: ToString() is expensive. Profiling shows that most compaction threads are stuck in jemalloc, allocating a new string. This will help out a litte.\n\nTest Plan: make check\n\nReviewers: haobo, danguo\n\nReviewed By: danguo\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D17583",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/beeee9dccc338ae7129016f2f2e17d2a40ecc5df",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::DoCompactionWork"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization avoids unnecessary string allocations by reducing calls to ToString() during compaction.",
            "The optimization avoids unnecessary string allocations by reducing calls to ToString() during compaction.",
            "The optimization avoids unnecessary string allocations by reducing calls to ToString() during compaction.",
            "The optimization avoids unnecessary string allocations by reducing calls to ToString() during compaction.",
            "The optimization avoids unnecessary string allocations by reducing calls to ToString() during compaction."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary string allocations by reducing calls to ToString() during compaction.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "glsl-optimizer",
        "hash": "487dd96c2706aa352ed44637507dd7f38ac80306",
        "author": "Eric Anholt",
        "date": "2011-06-29T15:09:54-07:00",
        "message": "glsl: Avoid making a temporary for lower_mat_op_to_vec if not needed.\n\nOur copy propagation tends to be bad at handling the later array\naccesses of the matrix argument we moved to a temporary.  Generally we\ndon't need to move it to a temporary, though, so this avoids needing\nmore copy propagation complexity.\n\nReduces instruction count of some Unigine Tropics and Sanctuary\nfragment shaders that do operations on uniform matrix arrays by 5.9%\non gen6.\n\nReviewed-by: Kenneth Graunke <kenneth@whitecape.org>",
        "modified_files_count": 1,
        "modified_files": [
            "src/glsl/lower_mat_op_to_vec.cpp"
        ],
        "github_commit_url": "https://github.com/aras-p/glsl-optimizer/commit/487dd96c2706aa352ed44637507dd7f38ac80306",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ir_mat_op_to_vec_visitor::visit_leave"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids creating unnecessary temporary variables for matrix operations by directly handling array accesses, reducing copy propagation complexity.",
            "The optimization avoids creating unnecessary temporary variables for matrix operations by directly handling array accesses, reducing copy propagation complexity.",
            "The optimization avoids creating unnecessary temporary variables for matrix operations by directly handling array accesses, reducing copy propagation complexity.",
            "The optimization avoids creating unnecessary temporary variables for matrix operations by directly handling array accesses, reducing copy propagation complexity.",
            "The optimization avoids creating unnecessary temporary variables for matrix operations by directly handling array accesses, reducing copy propagation complexity and instruction count."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids creating unnecessary temporary variables for matrix operations by directly handling array accesses, reducing copy propagation complexity.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_msm-5.4_nothing_sm7325",
        "hash": "94de85d16b0c46671ddf9695fdeb9d081e5a5ffe",
        "author": "Nicholas Kazlauskas",
        "date": "2020-07-09T09:37:56+02:00",
        "message": "drm/amd/display: Only revalidate bandwidth on medium and fast updates\n\ncommit 6eb3cf2e06d22b2b08e6b0ab48cb9c05a8e1a107 upstream.\n\n[Why]\nChanges that are fast don't require updating DLG parameters making\nthis call unnecessary. Considering this is an expensive call it should\nnot be done on every flip.\n\nDML touches clocks, p-state support, DLG params and a few other DC\ninternal flags and these aren't expected during fast. A hang has been\nreported with this change when called on every flip which suggests that\nmodifying these fields is not recommended behavior on fast updates.\n\n[How]\nGuard the validation to only happen if update type isn't FAST.\n\nBug: https://gitlab.freedesktop.org/drm/amd/-/issues/1191\nFixes: a24eaa5c51255b (\"drm/amd/display: Revalidate bandwidth before commiting DC updates\")\nSigned-off-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>\nAcked-by: Alex Deucher <alexander.deucher@amd.com>\nReviewed-by: Roman Li <Roman.Li@amd.com>\nSigned-off-by: Alex Deucher <alexander.deucher@amd.com>\nCc: stable@vger.kernel.org\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/amd/display/dc/core/dc.c"
        ],
        "github_commit_url": "https://github.com/NothingOSS/android_kernel_msm-5.4_nothing_sm7325/commit/94de85d16b0c46671ddf9695fdeb9d081e5a5ffe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dc_commit_updates_for_stream"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation during fast updates by conditionally guarding the validation logic.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kicad-source-mirror",
        "hash": "5974446523ab87f7b36a9a924e004487e985ff29",
        "author": "Jon Evans",
        "date": "2021-04-17T21:37:11-04:00",
        "message": "PNS: Let's make the r-tree work for us\n\nI'm not sure where the magic number of \"4x worst\" came from, but it's\nbeen around forever.  This is extremely inefficient as it negates much\nof the power of r-tree filtering in dense designs.  If we really trusted\nit, we could set this just to worstClearance.  Keeping it above the worst\nclearance by a little bit seems to provide enough of a speed improvement\nto resolve the test cases I have, so I'll go with that for now.\n\nFixes https://gitlab.com/kicad/code/kicad/-/issues/7777",
        "modified_files_count": 1,
        "modified_files": [
            "pcbnew/router/pns_kicad_iface.cpp"
        ],
        "github_commit_url": "https://github.com/KiCad/kicad-source-mirror/commit/5974446523ab87f7b36a9a924e004487e985ff29",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PNS_KICAD_IFACE_BASE::SyncWorld"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces inefficiency by adjusting a heuristic multiplier in the r-tree filtering logic to better leverage its spatial indexing capabilities.",
            "The optimization reduces inefficiency by adjusting a heuristic multiplier in the r-tree filtering logic to better leverage its spatial indexing capabilities.",
            "The optimization reduces inefficiency in r-tree filtering by adjusting a heuristic parameter to better leverage spatial indexing in dense designs.",
            "The optimization reduces inefficiency in r-tree filtering by adjusting a clearance threshold to better leverage spatial indexing in dense designs.",
            "The optimization reduces inefficiency in r-tree filtering by adjusting a heuristic parameter to better leverage spatial indexing in dense designs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces inefficiency in r-tree filtering by adjusting a heuristic parameter to better leverage spatial indexing in dense designs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cheribsd",
        "hash": "47eb9e91e4cef40c34486f99c1fe7584fc41e91c",
        "author": "loos",
        "date": "2015-08-17T19:06:14+00:00",
        "message": "MFC r286260:\n  Remove the mtx_sleep() from the kqueue f_event filter.\n\n  The filter is called from the network hot path and must not sleep.\n\n  The filter runs with the descriptor lock held and does not manipulate the\n  buffers, so it is not necessary sleep when the hold buffer is in use.\n\n  Just ignore the hold buffer contents when it is being copied to user space\n  (when hold buffer in use is set).\n\n  This fix the \"Sleeping thread owns a non-sleepable lock\" panic when the\n  userland thread is too busy reading the packets from bpf(4).\n\n  PR:           200323\n  Sponsored by: Rubicon Communications (Netgate)",
        "modified_files_count": 1,
        "modified_files": [
            "sys/net/bpf.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/47eb9e91e4cef40c34486f99c1fe7584fc41e91c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "filt_bpfread"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes a blocking sleep operation from a critical network path to prevent unnecessary delays and potential deadlocks.",
            "The optimization removes a blocking sleep operation from a network hot path to prevent performance bottlenecks and potential deadlocks.",
            "The optimization removes a blocking sleep operation from a critical network path to prevent performance bottlenecks and potential deadlocks.",
            "The optimization removes a blocking sleep operation from a critical network processing path to prevent performance bottlenecks and potential deadlocks.",
            "The optimization removes a blocking sleep operation from a network hot path to prevent performance bottlenecks and potential deadlocks."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes a blocking sleep operation from a critical network path to prevent performance bottlenecks and potential deadlocks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lime3ds-archive",
        "hash": "a234e4c2009b08039d0698cbbcc8595a1f04a615",
        "author": "Huw Pascoe",
        "date": "2017-09-17T15:56:36+01:00",
        "message": "Improved performance of FromAttributeBuffer\n\nTernary operator is optimized by the compiler\nwhereas std::min() is meant to return a value.\n\nI've noticed a 5%-10% emulation speed increase.",
        "modified_files_count": 1,
        "modified_files": [
            "src/video_core/shader/shader.cpp"
        ],
        "github_commit_url": "https://github.com/Lime3DS/lime3ds-archive/commit/a234e4c2009b08039d0698cbbcc8595a1f04a615",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OutputVertex::FromAttributeBuffer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaced `std::min()` with a ternary operator to leverage compiler-level optimizations for improved performance.",
            "The optimization replaced `std::min()` with a ternary operator to leverage compiler optimizations for improved performance.",
            "The optimization replaced `std::min()` with a ternary operator to leverage compiler optimizations for improved performance in the `FromAttributeBuffer` function.",
            "The optimization replaced `std::min()` with a ternary operator to leverage compiler optimizations for improved performance.",
            "The optimization replaced `std::min()` with a ternary operator to leverage compiler optimizations for improved performance in the `FromAttributeBuffer` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaced `std::min()` with a ternary operator to leverage compiler-level optimizations for improved performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "anura",
        "hash": "c458019a3b810f48c4e526debc9ef6dacf2beb6c",
        "author": "Chris Beck",
        "date": "2015-05-02T23:36:08-04:00",
        "message": "lua: cause lists to map to 1-based lua tables (lua arrays)\n\nThis is more efficient than 0-based lua tables, which get\nimplemented with a hash component.\n\nWe might undo this commit later, who knows.",
        "modified_files_count": 1,
        "modified_files": [
            "src/lua_iface.cpp"
        ],
        "github_commit_url": "https://github.com/anura-engine/anura/commit/c458019a3b810f48c4e526debc9ef6dacf2beb6c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "variant_to_lua_value"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved changing the mapping of lists to 1-based Lua tables to avoid the hash component overhead associated with 0-based tables.",
            "The optimization strategy involved changing the mapping of lists to 1-based Lua tables instead of 0-based to avoid the hash component overhead in Lua arrays.",
            "The optimization strategy involved changing the mapping of lists to 1-based Lua tables instead of 0-based ones to avoid the hash component overhead in Lua arrays.",
            "The optimization strategy involved changing the indexing of Lua tables from 0-based to 1-based to leverage Lua's native array implementation and avoid the overhead of hash tables.",
            "The optimization strategy involved changing the mapping of lists to 1-based Lua tables to avoid the hash component overhead associated with 0-based Lua tables."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved changing the mapping of lists to 1-based Lua tables instead of 0-based ones to avoid the hash component overhead in Lua arrays.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "22028aa9ab27cf860b74d12e006f82ff551caee0",
        "author": "Vijay Nadimpalli",
        "date": "2019-06-21T21:31:49-07:00",
        "message": "Compaction Reads should read no more than compaction_readahead_size bytes, when set! (#5498)\n\nSummary:\nAs a result of https://github.com/facebook/rocksdb/issues/5431 the compaction_readahead_size given by a user was not used exactly, the reason being the code behind readahead for user-read and compaction-read was unified in the above PR and the behavior for user-read is to read readahead_size+n bytes (see FilePrefetchBuffer::TryReadFromCache method). Before the unification the ReadaheadRandomAccessFileReader used compaction_readahead_size as it is.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5498\n\nTest Plan:\nRan strace command : strace -e pread64 -f -T -t ./db_compaction_test --gtest_filter=DBCompactionTest.PartialManualCompaction\n\nIn the test the compaction_readahead_size was configured to 2MB and verified the pread syscall did indeed request 2MB. Before the change it was requesting more than 2MB.\n\nStrace Output:\nstrace: Process 3798982 attached\nNote: Google Test filter = DBCompactionTest.PartialManualCompaction\n[==========] Running 1 test from 1 test case.\n[----------] Global test environment set-up.\n[----------] 1 test from DBCompactionTest\n[ RUN      ] DBCompactionTest.PartialManualCompaction\nstrace: Process 3798983 attached\nstrace: Process 3798984 attached\nstrace: Process 3798985 attached\nstrace: Process 3798986 attached\nstrace: Process 3798987 attached\nstrace: Process 3798992 attached\n[pid 3798987] 12:07:05 +++ exited with 0 +++\nstrace: Process 3798993 attached\n[pid 3798993] 12:07:05 +++ exited with 0 +++\nstrace: Process 3798994 attached\nstrace: Process 3799008 attached\nstrace: Process 3799009 attached\n[pid 3799008] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799010 attached\n[pid 3799009] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799011 attached\n[pid 3799010] 12:07:05 +++ exited with 0 +++\n[pid 3799011] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799012 attached\n[pid 3799012] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799013 attached\nstrace: Process 3799014 attached\n[pid 3799013] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799015 attached\n[pid 3799014] 12:07:05 +++ exited with 0 +++\n[pid 3799015] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799016 attached\n[pid 3799016] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799017 attached\n[pid 3799017] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799019 attached\n[pid 3799019] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799020 attached\nstrace: Process 3799021 attached\n[pid 3799020] 12:07:05 +++ exited with 0 +++\n[pid 3799021] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799022 attached\n[pid 3799022] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799023 attached\n[pid 3799023] 12:07:05 +++ exited with 0 +++\nstrace: Process 3799047 attached\nstrace: Process 3799048 attached\n[pid 3799047] 12:07:06 +++ exited with 0 +++\n[pid 3799048] 12:07:06 +++ exited with 0 +++\n[pid 3798994] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799052 attached\n[pid 3799052] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799054 attached\nstrace: Process 3799069 attached\nstrace: Process 3799070 attached\n[pid 3799069] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799071 attached\n[pid 3799070] 12:07:06 +++ exited with 0 +++\n[pid 3799071] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799072 attached\nstrace: Process 3799073 attached\n[pid 3799072] 12:07:06 +++ exited with 0 +++\n[pid 3799073] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799074 attached\n[pid 3799074] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799075 attached\n[pid 3799075] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799076 attached\n[pid 3799076] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799077 attached\n[pid 3799077] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799078 attached\n[pid 3799078] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799079 attached\n[pid 3799079] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799080 attached\n[pid 3799080] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799081 attached\n[pid 3799081] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799082 attached\n[pid 3799082] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799083 attached\n[pid 3799083] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799086 attached\nstrace: Process 3799087 attached\n[pid 3798984] 12:07:06 pread64(9, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000121>\n[pid 3798984] 12:07:06 pread64(9, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000106>\n[pid 3798984] 12:07:06 pread64(9, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000081>\n[pid 3798984] 12:07:06 pread64(9, \"\\0\\v\\3foo\\2\\7\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2\\3\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000138>\n[pid 3798984] 12:07:06 pread64(11, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000097>\n[pid 3798984] 12:07:06 pread64(11, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000086>\n[pid 3798984] 12:07:06 pread64(11, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000064>\n[pid 3798984] 12:07:06 pread64(11, \"\\0\\v\\3foo\\2\\21\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2\\r\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000064>\n[pid 3798984] 12:07:06 pread64(12, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000080>\n[pid 3798984] 12:07:06 pread64(12, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000090>\n[pid 3798984] 12:07:06 pread64(12, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000059>\n[pid 3798984] 12:07:06 pread64(12, \"\\0\\v\\3foo\\2\\33\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2\\27\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000065>\n[pid 3798984] 12:07:06 pread64(13, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000070>\n[pid 3798984] 12:07:06 pread64(13, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000059>\n[pid 3798984] 12:07:06 pread64(13, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000061>\n[pid 3798984] 12:07:06 pread64(13, \"\\0\\v\\3foo\\2%\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2!\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000065>\n[pid 3798984] 12:07:06 pread64(14, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000118>\n[pid 3798984] 12:07:06 pread64(14, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000093>\n[pid 3798984] 12:07:06 pread64(14, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000050>\n[pid 3798984] 12:07:06 pread64(14, \"\\0\\v\\3foo\\2/\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2+\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000082>\n[pid 3798984] 12:07:06 pread64(15, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000080>\n[pid 3798984] 12:07:06 pread64(15, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000086>\n[pid 3798984] 12:07:06 pread64(15, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000091>\n[pid 3798984] 12:07:06 pread64(15, \"\\0\\v\\3foo\\0029\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\0025\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000174>\n[pid 3798984] 12:07:06 pread64(16, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000080>\n[pid 3798984] 12:07:06 pread64(16, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000093>\n[pid 3798984] 12:07:06 pread64(16, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000194>\n[pid 3798984] 12:07:06 pread64(16, \"\\0\\v\\3foo\\2C\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2?\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000086>\n[pid 3798984] 12:07:06 pread64(17, \"\\1\\203W!\\241QE\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 11177) = 53 <0.000079>\n[pid 3798984] 12:07:06 pread64(17, \"\\0\\22\\4rocksdb.properties\\353Q\\223\\5\\0\\0\\0\\0\\1\\0\\0\"..., 38, 11139) = 38 <0.000047>\n[pid 3798984] 12:07:06 pread64(17, \"\\0$\\4rocksdb.block.based.table.ind\"..., 664, 10475) = 664 <0.000045>\n[pid 3798984] 12:07:06 pread64(17, \"\\0\\v\\3foo\\2M\\0\\0\\0\\0\\0\\0\\0\\270 \\0\\v\\4foo\\2I\\0\\0\\0\\0\\0\\0\\275\"..., 74, 10401) = 74 <0.000107>\n[pid 3798983] 12:07:06 pread64(17, \"\\0\\v\\200\\10foo\\2P\\0\\0\\0\\0\\0\\0)U?MSg_)j(roFn($e\"..., 2097152, 0) = 11230 <0.000091>\n[pid 3798983] 12:07:06 pread64(17, \"\", 2085922, 11230) = 0 <0.000073>\n[pid 3798983] 12:07:06 pread64(16, \"\\0\\v\\200\\10foo\\2F\\0\\0\\0\\0\\0\\0k[h3%.OPH_^:\\\\S7T&\"..., 2097152, 0) = 11230 <0.000083>\n[pid 3798983] 12:07:06 pread64(16, \"\", 2085922, 11230) = 0 <0.000078>\n[pid 3798983] 12:07:06 pread64(15, \"\\0\\v\\200\\10foo\\2<\\0\\0\\0\\0\\0\\0+qToi_c{*S+4:N(:\"..., 2097152, 0) = 11230 <0.000095>\n[pid 3798983] 12:07:06 pread64(15, \"\", 2085922, 11230) = 0 <0.000067>\n[pid 3798983] 12:07:06 pread64(14, \"\\0\\v\\200\\10foo\\0022\\0\\0\\0\\0\\0\\0%hw%OMa\\\"}9I609Q!B\"..., 2097152, 0) = 11230 <0.000111>\n[pid 3798983] 12:07:06 pread64(14, \"\", 2085922, 11230) = 0 <0.000093>\n[pid 3798983] 12:07:06 pread64(13, \"\\0\\v\\200\\10foo\\2(\\0\\0\\0\\0\\0\\0p}Y&mu^DcaSGb2&nP\"..., 2097152, 0) = 11230 <0.000128>\n[pid 3798983] 12:07:06 pread64(13, \"\", 2085922, 11230) = 0 <0.000076>\n[pid 3798983] 12:07:06 pread64(12, \"\\0\\v\\200\\10foo\\2\\36\\0\\0\\0\\0\\0\\0YIyW#]oSs^6VHfB<`\"..., 2097152, 0) = 11230 <0.000092>\n[pid 3798983] 12:07:06 pread64(12, \"\", 2085922, 11230) = 0 <0.000073>\n[pid 3798983] 12:07:06 pread64(11, \"\\0\\v\\200\\10foo\\2\\24\\0\\0\\0\\0\\0\\0mfF8Jel/*Zf :-#s(\"..., 2097152, 0) = 11230 <0.000088>\n[pid 3798983] 12:07:06 pread64(11, \"\", 2085922, 11230) = 0 <0.000067>\n[pid 3798983] 12:07:06 pread64(9, \"\\0\\v\\200\\10foo\\2\\n\\0\\0\\0\\0\\0\\0\\\\X'cjiHX)D,RSj1X!\"..., 2097152, 0) = 11230 <0.000115>\n[pid 3798983] 12:07:06 pread64(9, \"\", 2085922, 11230) = 0 <0.000073>\n[pid 3798983] 12:07:06 pread64(8, \"\\1\\315\\5 \\36\\30\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\"..., 53, 754) = 53 <0.000098>\n[pid 3798983] 12:07:06 pread64(8, \"\\0\\22\\3rocksdb.properties;\\215\\5\\0\\0\\0\\0\\1\\0\\0\\0\"..., 37, 717) = 37 <0.000064>\n[pid 3798983] 12:07:06 pread64(8, \"\\0$\\4rocksdb.block.based.table.ind\"..., 658, 59) = 658 <0.000074>\n[pid 3798983] 12:07:06 pread64(8, \"\\0\\v\\2foo\\1\\0\\0\\0\\0\\0\\0\\0\\0\\31\\0\\0\\0\\0\\1\\0\\0\\0\\0\\212\\216\\222P\", 29, 30) = 29 <0.000064>\n[pid 3799086] 12:07:06 +++ exited with 0 +++\n[pid 3799087] 12:07:06 +++ exited with 0 +++\n[pid 3799054] 12:07:06 +++ exited with 0 +++\nstrace: Process 3799104 attached\n[pid 3799104] 12:07:06 +++ exited with 0 +++\n[       OK ] DBCompactionTest.PartialManualCompaction (757 ms)\n[----------] 1 test from DBCompactionTest (758 ms total)\n\n[----------] Global test environment tear-down\n[==========] 1 test from 1 test case ran. (759 ms total)\n[  PASSED  ] 1 test.\n[pid 3798983] 12:07:06 +++ exited with 0 +++\n[pid 3798984] 12:07:06 +++ exited with 0 +++\n[pid 3798992] 12:07:06 +++ exited with 0 +++\n[pid 3798986] 12:07:06 +++ exited with 0 +++\n[pid 3798982] 12:07:06 +++ exited with 0 +++\n[pid 3798985] 12:07:06 +++ exited with 0 +++\n12:07:06 +++ exited with 0 +++\n\nDifferential Revision: D15948422\n\nPulled By: vjnadimpalli\n\nfbshipit-source-id: 9b189d1e8675d290c7784e4b33e5d3b5761d2ac8",
        "modified_files_count": 1,
        "modified_files": [
            "util/file_reader_writer.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/22028aa9ab27cf860b74d12e006f82ff551caee0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FilePrefetchBuffer::TryReadFromCache"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization ensures that compaction reads strictly adhere to the user-specified `compaction_readahead_size` by preventing additional bytes from being read, aligning behavior with user expectations and reducing unnecessary I/O overhead.",
            "The optimization ensures that compaction reads adhere strictly to the user-configured `compaction_readahead_size` by avoiding additional read overhead.",
            "The optimization ensures that compaction readahead operations strictly adhere to the configured `compaction_readahead_size` by avoiding additional bytes being read, which was a side effect of unifying user-read and compaction-read logic.",
            "The optimization ensures that compaction reads adhere strictly to the user-configured `compaction_readahead_size` by avoiding additional read overhead.",
            "The optimization ensures that compaction reads strictly adhere to the user-specified `compaction_readahead_size` by avoiding additional bytes being read, which was a side effect of unifying readahead logic for user and compaction reads."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures that compaction reads strictly adhere to the user-specified `compaction_readahead_size` by preventing additional bytes from being read, aligning behavior with user expectations and reducing unnecessary I/O overhead.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "18eeb7b90e45af4bbac0777021711d8547f41eca",
        "author": "Mike Kolupaev",
        "date": "2017-02-21T16:09:10-08:00",
        "message": "Fix interference between max_total_wal_size and db_write_buffer_size checks\n\nSummary:\nThis is a trivial fix for OOMs we've seen a few days ago in logdevice.\n\nRocksDB get into the following state:\n(1) Write throughput is too high for flushes to keep up. Compactions are out of the picture - automatic compactions are disabled, and for manual compactions we don't care that much if they fall behind. We write to many CFs, with only a few L0 sst files in each, so compactions are not needed most of the time.\n(2) total_log_size_ is consistently greater than GetMaxTotalWalSize(). It doesn't get smaller since flushes are falling ever further behind.\n(3) Total size of memtables is way above db_write_buffer_size and keeps growing. But the write_buffer_manager_->ShouldFlush() is not checked because (2) prevents it (for no good reason, afaict; this is what this commit fixes).\n(4) Every call to WriteImpl() hits the MaybeFlushColumnFamilies() path. This keeps flushing the memtables one by one in order of increasing log file number.\n(5) No write stalling trigger is hit. We rely on max_write_buffer_number\nCloses https://github.com/facebook/rocksdb/pull/1893\n\nDifferential Revision: D4593590\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: af79c5f",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/18eeb7b90e45af4bbac0777021711d8547f41eca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::WriteImpl"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved removing an unnecessary condition that prevented checking if memtables should be flushed, thereby allowing more timely flushes to prevent excessive memory growth.",
            "The optimization strategy involved removing an unnecessary condition that prevented flushing when total log size exceeded the maximum WAL size, allowing more efficient memory management.",
            "The optimization strategy involved removing an unnecessary condition that prevented flushing when total log size exceeded the maximum WAL size, allowing more efficient memory management.",
            "The optimization strategy involved removing an unnecessary condition that prevented checking whether memtables should be flushed, allowing more timely flushes to prevent excessive memory growth.",
            "The optimization strategy involved removing an unnecessary condition that prevented flushing when total log size exceeded the maximum WAL size, allowing more timely memory table flushes to prevent out-of-memory issues."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing an unnecessary condition that prevented flushing when total log size exceeded the maximum WAL size, allowing more efficient memory management.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "3DWorld",
        "hash": "e967a7602f838eeae2a9f1bc7c2d0a8d86d4e4e9",
        "author": "Frank E. Gennari",
        "date": "2013-07-10T07:46:51+00:00",
        "message": "More efficient glDrawArrays() version of sd_sphere_d::draw_ndiv_pow2(). -FG",
        "modified_files_count": 1,
        "modified_files": [
            "src/draw_primitives.cpp"
        ],
        "github_commit_url": "https://github.com/fegennari/3DWorld/commit/e967a7602f838eeae2a9f1bc7c2d0a8d86d4e4e9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sd_sphere_d::draw_ndiv_pow2"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a less efficient drawing method with a more efficient `glDrawArrays()` implementation for rendering spheres.",
            "The optimization strategy involved replacing a less efficient drawing method with a more efficient `glDrawArrays()` call to improve rendering performance.",
            "The optimization strategy involved replacing a less efficient drawing method with a more efficient `glDrawArrays()` call to improve rendering performance.",
            "The optimization strategy involved replacing a less efficient drawing method with a more efficient `glDrawArrays()` call to improve rendering performance.",
            "The optimization strategy involved replacing a less efficient drawing method with a more efficient `glDrawArrays()` implementation for rendering spheres."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a less efficient drawing method with a more efficient `glDrawArrays()` call to improve rendering performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "5e22b757a82a29269bfba7b1828ba8d078331c95",
        "author": "Chris Wilson",
        "date": "2024-08-09T22:15:29+03:00",
        "message": "drm/i915/gem: Use large rings for compute contexts\n\nAllow compute contexts to submit the maximal amount of work without\nblocking userspace.\n\nThe original size for user LRC ring's (SZ_16K) was chosen to minimise\nmemory consumption, without being so small as to frequently stall in the\nmiddle of workloads. With the main consumers being GL / media pipelines\nof 2 or 3 batches per frame, we want to support ~10 requests in flight\nto allow for the application to control throttling without stalling\nwithin a frame.\n\nv2:\n  - cover with else part\n\nSigned-off-by: Chris Wilson <chris.p.wilson@intel.com>\nSigned-off-by: Tejas Upadhyay <tejas.upadhyay@intel.com>\nReviewed-by: Andi Shyti <andi.shyti@linux.intel.com>\nSigned-off-by: Andi Shyti <andi.shyti@linux.intel.com>\nLink: https://patchwork.freedesktop.org/patch/msgid/20230517135754.1110291-1-tejas.upadhyay@intel.com",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/i915/gem/i915_gem_context.c"
        ],
        "github_commit_url": "https://github.com/freebsd/drm-kmod/commit/5e22b757a82a29269bfba7b1828ba8d078331c95",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "intel_context_set_gem"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "drm-kmod",
        "optimization_summary": [
            "Increased the size of user LRC rings to allow compute contexts to submit more work without blocking userspace, reducing stalls during workload execution.",
            "Increased the size of user LRC rings to allow compute contexts to submit more work without blocking userspace, reducing stalls during workload execution.",
            "Increased the size of user LRC rings to allow compute contexts to submit more work without blocking userspace, reducing stalls during workload execution.",
            "Increased the size of user LRC rings to allow compute contexts to submit more work without blocking userspace, reducing stalls during workload execution.",
            "Increased the size of user LRC rings to allow compute contexts to submit more work without blocking userspace, reducing stalls during workload execution."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "Increased the size of user LRC rings to allow compute contexts to submit more work without blocking userspace, reducing stalls during workload execution.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libopenshot",
        "hash": "89d1667dae6621ba7a9a5d341789f2b522063d80",
        "author": "FeRD (Frank Dana)",
        "date": "2020-02-05T21:56:25-05:00",
        "message": "Hue: Optimize and parallelize",
        "modified_files_count": 1,
        "modified_files": [
            "src/effects/Hue.cpp"
        ],
        "github_commit_url": "https://github.com/OpenShot/libopenshot/commit/89d1667dae6621ba7a9a5d341789f2b522063d80",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Hue::GetFrame"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved parallelizing the hue adjustment calculations to improve performance by utilizing multiple CPU cores.",
            "The optimization strategy involved parallelizing the hue adjustment computation to improve performance by utilizing multiple threads.",
            "The optimization strategy involved parallelizing the hue adjustment computation to improve performance by utilizing multiple threads.",
            "The optimization strategy involved parallelizing the hue adjustment calculations to improve performance.",
            "The optimization strategy involved parallelizing the hue adjustment computation to improve performance by utilizing multiple threads."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved parallelizing the hue adjustment computation to improve performance by utilizing multiple threads.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libevent",
        "hash": "557990cad33f1b06a1e2a416231d79590237dd2e",
        "author": "Cœur",
        "date": "2023-03-02T07:51:14+01:00",
        "message": "Optimize arc4random_uniform() (by syncing with OpenBSD implementation)\n\n1. In d4de062, in Feb 2010, libevent adopted OpenBSD implementation of\n   arc4random_uniform.\n2. In\n   https://github.com/openbsd/src/commit/728918cba93e0418bea2a73c9784f6b80c2a9dbd,\n   in Jun 2012, OpenBSD improved their implementation to be faster, by\n   changing arc4random_uniform() to calculate ``2**32 % upper_bound'' as\n   ``-upper_bound % upper_bound''.\n\nAlternatively we can simply remove arc4random_uniform() since it is not\nused by libevent anyway, but let's just sync the header for now.",
        "modified_files_count": 1,
        "modified_files": [
            "arc4random.c"
        ],
        "github_commit_url": "https://github.com/libevent/libevent/commit/557990cad33f1b06a1e2a416231d79590237dd2e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "arc4random_uniform"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used a mathematical transformation to replace an expensive modulo operation with a cheaper equivalent expression.",
            "The optimization strategy used a mathematical transformation to replace an expensive modulo operation with a cheaper equivalent expression.",
            "The optimization strategy used a mathematical transformation to replace an expensive modulo operation with a cheaper equivalent expression.",
            "The optimization strategy used a mathematical transformation to replace an expensive modulo operation with a cheaper equivalent expression.",
            "The optimization strategy used a mathematical transformation to replace an expensive modulo operation with a cheaper equivalent expression."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used a mathematical transformation to replace an expensive modulo operation with a cheaper equivalent expression.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "20dc5e74f276bdcb26c44c13bced506a2d920d3f",
        "author": "Sagar Vemuri",
        "date": "2017-08-05T00:15:35-07:00",
        "message": "Optimize range-delete aggregator call in merge helper.\n\nSummary:\nIn the condition:\n```\nif (range_del_agg != nullptr &&\n    range_del_agg->ShouldDelete(\n        iter->key(),\n        RangeDelAggregator::RangePositioningMode::kForwardTraversal) &&\n    filter != CompactionFilter::Decision::kRemoveAndSkipUntil) {\n...\n}\n```\nit could be possible that all the work done in `range_del_agg->ShouldDelete` is wasted due to not having the right `filter` value later on.\nInstead, check `filter` value before even calling `range_del_agg->ShouldDelete`, which is a much more involved function.\nCloses https://github.com/facebook/rocksdb/pull/2690\n\nDifferential Revision: D5568931\n\nPulled By: sagar0\n\nfbshipit-source-id: 17512d52360425c7ae9de7675383f5d7bc3dad58",
        "modified_files_count": 1,
        "modified_files": [
            "db/merge_helper.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/20dc5e74f276bdcb26c44c13bced506a2d920d3f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MergeHelper::MergeUntil"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves reordering condition checks to evaluate a less computationally expensive condition first, avoiding unnecessary calls to a more expensive function.",
            "The optimization strategy involves reordering conditional checks to evaluate a less computationally expensive condition first, avoiding unnecessary calls to a more expensive function.",
            "The optimization strategy involves reordering condition checks to evaluate a less computationally expensive condition first, avoiding unnecessary calls to a more expensive function.",
            "The optimization strategy involves reordering conditional checks to evaluate a less computationally expensive condition first, avoiding unnecessary calls to a more expensive function.",
            "The optimization strategy involves reordering conditional checks to evaluate a less computationally expensive condition first, avoiding unnecessary calls to a more expensive function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves reordering conditional checks to evaluate a less computationally expensive condition first, avoiding unnecessary calls to a more expensive function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "llvm-leg",
        "hash": "45ecdf96ee5c1bc5ce3881518ac8fb0bda07ed06",
        "author": "Chandler Carruth",
        "date": "2015-08-30T09:54:34+00:00",
        "message": "Stop calling the flat out insane ARM target parsing code unless the\narchitecture string is something quite weird. Similarly delay calling\nthe BPF parsing code, although that is more reasonable.\n\nTo understand why I was motivated to make this change, it cuts the time\nfor running the ADT TripleTest unittests by a factor of two in\nnon-optimized builds (the developer default) and reduces my 'check-llvm'\ntime by a full 15 seconds. The implementation of parseARMArch is *that*\nslow. I tried to fix it in the prior series of commits, but frankly,\nI have no idea how to finish fixing it. The entire premise of the\nfunction (to allow 'v7a-unknown-linux' or some such to parse as an\n'arm-unknown-linux' triple) seems completely insane to me, but I'll let\nthe ARM folks sort that out. At least it is now out of the critical path\nof every developer working on LLVM. It also will likely make some other\nfolks' code significantly faster as I've heard reports of 2% of time\nspent in triple parsing even in optimized builds!\n\nI'm not done making this code faster, but I am done trying to improve\nthe ARM target parsing code.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@246378 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Support/Triple.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/45ecdf96ee5c1bc5ce3881518ac8fb0bda07ed06",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "parseArch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves delaying expensive parsing operations until necessary by checking for common cases first, thus avoiding unnecessary calls to slow functions.",
            "The optimization strategy avoids calling slow target-specific parsing code unless absolutely necessary by adding early checks for common cases.",
            "The optimization strategy avoids calling slow parsing code for uncommon architecture strings by delaying or skipping unnecessary executions.",
            "The optimization strategy delays expensive parsing operations by adding conditional checks to avoid unnecessary calls for common cases.",
            "The optimization strategy avoids calling slow target-specific parsing code unless absolutely necessary by adding early checks for common cases."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids calling slow target-specific parsing code unless absolutely necessary by adding early checks for common cases.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "536e9973e30d70fd510e5ab6e423ef75248ed582",
        "author": "Igor Canadi",
        "date": "2014-08-27T11:05:41-07:00",
        "message": "Remove assert in vector rep\n\nSummary: This assert makes Insert O(n^2) instead of O(n) in debug mode. Memtable insert is in the critical path. No need to assert uniqunnes of the key here, since we're adding a sequence number to it anyway.\n\nTest Plan: none\n\nReviewers: sdong, ljin\n\nReviewed By: ljin\n\nSubscribers: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D22443",
        "modified_files_count": 1,
        "modified_files": [
            "util/vectorrep.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/536e9973e30d70fd510e5ab6e423ef75248ed582",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VectorRep::Insert"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization removes an unnecessary assertion in a critical path function to reduce time complexity from O(n²) to O(n) in debug mode.",
            "The optimization removes an unnecessary assert statement that caused quadratic time complexity in debug mode, improving performance by ensuring linear time complexity for insert operations.",
            "The optimization removes an unnecessary assertion in a critical path to reduce the time complexity of insert operations from O(n²) to O(n) in debug mode.",
            "The optimization removes an unnecessary assert statement to reduce the time complexity of insert operations in debug mode from O(n²) to O(n).",
            "The optimization removes an unnecessary assertion in debug mode to reduce the time complexity of insert operations from O(n²) to O(n)."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes an unnecessary assertion in a critical path to reduce the time complexity of insert operations from O(n²) to O(n) in debug mode.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_xiaomi_marble",
        "hash": "4f9882194b2e32ba61055308917004eb23c5965f",
        "author": "Chaitanya Pratapa",
        "date": "2021-03-29T15:42:56-07:00",
        "message": "msm: ipa: use separate event ring for WAN producer\n\nTo acheieve better performance use separate event ring\nfor WAN producer.\n\nChange-Id: I79fcb275f4d578acce7ffedbd85f991646cbfd90\nSigned-off-by: Chaitanya Pratapa <cpratapa@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/platform/msm/ipa/ipa_v3/ipa_dp.c"
        ],
        "github_commit_url": "https://github.com/Pzqqt/android_kernel_xiaomi_marble/commit/4f9882194b2e32ba61055308917004eb23c5965f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ipa3_assign_policy"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves using a separate event ring for the WAN producer to improve performance by reducing contention or improving resource allocation.",
            "The optimization strategy involves using a separate event ring for the WAN producer to improve performance by reducing contention or improving resource allocation.",
            "The optimization strategy involves using a separate event ring for the WAN producer to improve performance by reducing contention or improving resource allocation.",
            "The optimization strategy involves using a separate event ring for the WAN producer to improve performance by reducing contention or improving resource allocation.",
            "The optimization strategy involves using a separate event ring for the WAN producer to improve performance by reducing contention or improving resource allocation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves using a separate event ring for the WAN producer to improve performance by reducing contention or improving resource allocation.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "4634c735a8bb4f83b8099928fb12b50ad8df7b88",
        "author": "Alex Robinson",
        "date": "2017-12-04T01:56:15-08:00",
        "message": "Update DBOptions::IncreaseParallelism to use newer background settings\n\nSummary:\nThe Options header file recommends using max_background_jobs rather than\ndirectly setting max_background_compactions or max_background_flushes.\n\nI've personally seen a performance problem where stalls were happening\nbecause the one background flushing thread was blocked that was fixed\nby this change -\nhttps://github.com/cockroachdb/cockroach/issues/19699#issuecomment-347672485\nCloses https://github.com/facebook/rocksdb/pull/3208\n\nDifferential Revision: D6473178\n\nPulled By: ajkr\n\nfbshipit-source-id: 67c892ceb7b1909d251492640cb15a0f2262b7ed",
        "modified_files_count": 1,
        "modified_files": [
            "options/options.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4634c735a8bb4f83b8099928fb12b50ad8df7b88",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBOptions::IncreaseParallelism"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved updating the `IncreaseParallelism` function to use the newer `max_background_jobs` setting instead of directly configuring `max_background_compactions` or `max_background_flushes`, improving thread utilization and reducing stalls.",
            "The optimization strategy involved updating the `IncreaseParallelism` function to use the newer `max_background_jobs` setting instead of directly configuring `max_background_compactions` or `max_background_flushes`, improving thread utilization and reducing stalls.",
            "The optimization strategy involved updating the `IncreaseParallelism` function to use the newer `max_background_jobs` setting instead of directly configuring `max_background_compactions` or `max_background_flushes`, improving thread utilization and reducing stalls.",
            "The optimization strategy involved updating the `IncreaseParallelism` function to use the newer `max_background_jobs` setting instead of directly configuring `max_background_compactions` or `max_background_flushes`, aiming to improve thread utilization and reduce stalls.",
            "The optimization strategy involved updating the `IncreaseParallelism` function to use the newer `max_background_jobs` setting instead of directly configuring `max_background_compactions` or `max_background_flushes`, improving thread utilization and reducing stalls."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved updating the `IncreaseParallelism` function to use the newer `max_background_jobs` setting instead of directly configuring `max_background_compactions` or `max_background_flushes`, improving thread utilization and reducing stalls.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "slurm",
        "hash": "0d706a22479dd972f47a680a6a4bc78d49e3cea2",
        "author": "Moe Jette",
        "date": "2002-12-06T01:15:03+00:00",
        "message": "Slight optimization in copying node addresses (do all in one memcpy).",
        "modified_files_count": 1,
        "modified_files": [
            "src/srun/job.c"
        ],
        "github_commit_url": "https://github.com/SchedMD/slurm/commit/0d706a22479dd972f47a680a6a4bc78d49e3cea2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "job_create"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was to replace multiple individual memory copy operations with a single `memcpy` call to improve efficiency.",
            "The optimization strategy used was to replace multiple individual memory copy operations with a single `memcpy` call to improve efficiency.",
            "The optimization strategy used was to replace multiple individual memory copy operations with a single `memcpy` call to improve efficiency.",
            "The optimization strategy used was to replace multiple individual memory copy operations with a single `memcpy` call to improve efficiency.",
            "The optimization strategy used was to replace multiple individual memory copy operations with a single `memcpy` call to reduce overhead and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was to replace multiple individual memory copy operations with a single `memcpy` call to improve efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "haiku",
        "hash": "0a66a3e039b398ea34f9ff94c19a5dea4f8dce87",
        "author": "beveloper",
        "date": "2004-02-14T21:24:55+00:00",
        "message": "wrote a optimized C conversation from yuv420p (which is really YCbCr to RGB32)\nI'm not sure if I really understood the 420p format, so the conversion might\nbe wrong. But it really looks nice\n\n\ngit-svn-id: file:///srv/svn/repos/haiku/trunk/current@6590 a95241bf-73f2-0310-859d-f6bbb57e9c96",
        "modified_files_count": 1,
        "modified_files": [
            "src/add-ons/media/plugins/avcodec/gfx_conv_c.cpp"
        ],
        "github_commit_url": "https://github.com/haiku/haiku/commit/0a66a3e039b398ea34f9ff94c19a5dea4f8dce87",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gfx_conv_yuv420p_rgb32_c"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved rewriting the YUV420p to RGB32 conversion in C to improve performance, potentially by reducing unnecessary computations or improving memory access patterns.",
            "The optimization strategy involved rewriting the YUV420p to RGB32 conversion in C to improve performance, potentially by reducing unnecessary computations or improving memory access patterns.",
            "The optimization strategy involved rewriting the YUV420p to RGB32 conversion in C to improve performance, potentially by reducing unnecessary computations or improving memory access patterns.",
            "The optimization strategy involved rewriting the YUV420p to RGB32 conversion in C to improve performance, potentially by reducing computational overhead or improving memory access patterns.",
            "The optimization strategy involved rewriting the YUV420p to RGB32 conversion in C to improve performance, potentially by reducing unnecessary computations or improving memory access patterns."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved rewriting the YUV420p to RGB32 conversion in C to improve performance, potentially by reducing unnecessary computations or improving memory access patterns.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pygame-ce",
        "hash": "07e4522c993a77ad6dbc74ef71db519b6f4b7e09",
        "author": "Alberto",
        "date": "2024-06-28T12:53:50+02:00",
        "message": "Improve `PixelArray.make_surface()` performance (#2953)\n\n* optimized PixelArray make_surface() both when making a same sized surf from the array and when slicing.\r\n\r\n* fix comment",
        "modified_files_count": 1,
        "modified_files": [
            "src_c/pixelarray_methods.c"
        ],
        "github_commit_url": "https://github.com/pygame-community/pygame-ce/commit/07e4522c993a77ad6dbc74ef71db519b6f4b7e09",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_make_surface"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations and memory allocations in the `_make_surface` function by reusing existing dimensions and avoiding unnecessary surface creation.",
            "The optimization strategy involved reducing redundant computations and memory allocations in the `PixelArray.make_surface()` function by reusing existing data and avoiding unnecessary operations when creating a surface from an array or slicing.",
            "The optimization strategy involved reducing redundant computations and memory allocations in the `PixelArray.make_surface()` function by reusing existing data structures and avoiding unnecessary operations.",
            "The optimization strategy involved reducing unnecessary computations and memory operations when creating a surface from a PixelArray, particularly by handling sliced arrays more efficiently.",
            "The optimization strategy involved reducing redundant computations and memory allocations in the `PixelArray.make_surface()` function by reusing existing data and avoiding unnecessary operations when creating a surface from an array or slice."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations and memory allocations in the `PixelArray.make_surface()` function by reusing existing data and avoiding unnecessary operations when creating a surface from an array or slice.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "openvino",
        "hash": "e1fdf7b3f0046b87bbf6d3464a0fe2b8ab9f6f59",
        "author": "Nesterov Alexander",
        "date": "2024-11-11T12:07:38+00:00",
        "message": "[CPU][ARM] Fix performance issues in deconvolution layer (#27466)\n\n### Details:\n - Perf degradation - Noise Suppression Poconet-Like FP16\n\n### Tickets:\n - CVS-156953",
        "modified_files_count": 1,
        "modified_files": [
            "src/plugins/intel_cpu/src/nodes/executors/acl/acl_deconv.cpp"
        ],
        "github_commit_url": "https://github.com/openvinotoolkit/openvino/commit/e1fdf7b3f0046b87bbf6d3464a0fe2b8ab9f6f59",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AclDeconvExecutorBuilder::customIsSupported"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved refining the logic in the `customIsSupported` function to improve performance by reducing unnecessary checks or computations.",
            "The optimization strategy involved refining the logic in the `customIsSupported` function to reduce unnecessary computations and improve performance for deconvolution layer execution.",
            "The optimization strategy involved refining the logic in the `customIsSupported` function to reduce unnecessary computations and improve performance for deconvolution layer execution.",
            "The optimization strategy involved refining the logic in the `customIsSupported` function to improve performance by reducing unnecessary checks or computations.",
            "The optimization strategy involved refining the logic in the `customIsSupported` function to improve performance by reducing unnecessary checks or computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved refining the logic in the `customIsSupported` function to improve performance by reducing unnecessary checks or computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "amgcl",
        "hash": "d90850170e6468831a559be3ef3189fc64b338d5",
        "author": "Denis Demidov",
        "date": "2017-09-06T15:57:10+03:00",
        "message": "Slight improvement of subdomain deflation setup performance",
        "modified_files_count": 1,
        "modified_files": [
            "amgcl/mpi/subdomain_deflation.hpp"
        ],
        "github_commit_url": "https://github.com/ddemidov/amgcl/commit/d90850170e6468831a559be3ef3189fc64b338d5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "comm"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the communication logic to reduce redundant data exchanges during subdomain deflation setup.",
            "The optimization strategy involved restructuring the communication logic to reduce redundant data exchanges during subdomain deflation setup.",
            "The optimization strategy involved restructuring the communication logic to reduce redundant data exchanges during subdomain deflation setup.",
            "The optimization strategy involved restructuring the communication logic to reduce redundant data exchanges during subdomain deflation setup.",
            "The optimization strategy involved restructuring the communication logic to reduce redundant data exchanges during subdomain deflation setup."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the communication logic to reduce redundant data exchanges during subdomain deflation setup.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "partclone",
        "hash": "165dfbdaafd188b1250d288289983b5f54795f10",
        "author": "Patryck Rouleau",
        "date": "2013-06-06T19:37:41-04:00",
        "message": "Optimize crc32 computation\n\nMove the crc table initialization outside of the loop to avoid to check the\ninit flag for every byte.\n\nMy benchmark show a gain of 26% to clone a partition of 17G with 10G used:\n\ninit crc32 table inside the loop:\nreal   4m23.649s\nuser   2m20.301s\nsys    1m34.782s\n\ninit crc32 table outside the loop:\nreal   3m13.169s\nuser   1m15.269s\nsys    1m30.966s\n\nSigned-off-by: Patryck Rouleau <pfrouleau@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/partclone.c"
        ],
        "github_commit_url": "https://github.com/Thomas-Tsai/partclone/commit/165dfbdaafd188b1250d288289983b5f54795f10",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "crc32"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy moves the initialization of the CRC32 table outside of the loop to eliminate redundant checks of the initialization flag for every byte.",
            "The optimization strategy moves the initialization of the CRC32 table outside of the loop to eliminate redundant checks of the initialization flag for every byte.",
            "The optimization strategy involved moving the initialization of the CRC32 table outside of the loop to eliminate redundant checks of the init flag for every byte.",
            "The optimization strategy moves the initialization of the CRC32 table outside of the loop to eliminate redundant checks of the init flag for every byte.",
            "The optimization strategy moves the initialization of the CRC32 table outside of the loop to eliminate redundant checks of the init flag for every byte."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy moves the initialization of the CRC32 table outside of the loop to eliminate redundant checks of the init flag for every byte.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "4192bce91b2c4baf36d3cec47eeb33b2ef93648b",
        "author": "Chris Lattner",
        "date": "2009-03-04T04:46:18+00:00",
        "message": "add a special case for codegen that improves the case where we have\nmultiple sequential cases to a) not create tons of fall-through basic blocks\nand b) not recurse deeply.  This fixes codegen on 100K deep cases, and improves\ncodegen on moderate cases from this:\n\n        switch i32 %tmp, label %sw.epilog [\n                i32 1000, label %sw.bb\n                i32 1001, label %sw.bb1\n                i32 1002, label %sw.bb2\n                i32 1003, label %sw.bb3\n                i32 1004, label %sw.bb4\n...\nsw.bb:          ; preds = %entry\n        br label %sw.bb1\n\nsw.bb1:         ; preds = %entry, %sw.bb\n        br label %sw.bb2\n\nsw.bb2:         ; preds = %entry, %sw.bb1\n        br label %sw.bb3\n\nsw.bb3:         ; preds = %entry, %sw.bb2\n        br label %sw.bb4\n\nto:\n\n        switch i32 %tmp, label %sw.epilog [\n                i32 1000, label %sw.bb\n                i32 1001, label %sw.bb\n                i32 1002, label %sw.bb\n                i32 1003, label %sw.bb\n                i32 1004, label %sw.bb\nsw.bb:  ;; many preds\n\nllvm-svn: 66015",
        "modified_files_count": 1,
        "modified_files": [
            "clang/lib/CodeGen/CGStmt.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/4192bce91b2c4baf36d3cec47eeb33b2ef93648b",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces the creation of unnecessary fall-through basic blocks and deep recursion in switch-case code generation by consolidating multiple sequential cases into a single target block.",
            "The optimization strategy reduces the creation of unnecessary fall-through basic blocks and deep recursion in switch-case code generation by consolidating sequential cases into a single target block.",
            "The optimization strategy reduces the creation of unnecessary fall-through basic blocks and deep recursion in switch-case code generation by consolidating multiple sequential cases into a single target block.",
            "The optimization strategy reduces recursion depth and eliminates unnecessary fall-through basic blocks in switch-case code generation by consolidating sequential cases into a single target block.",
            "The optimization strategy reduces the creation of unnecessary fall-through basic blocks and deep recursion in switch-case code generation by consolidating sequential cases into a single target block."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the creation of unnecessary fall-through basic blocks and deep recursion in switch-case code generation by consolidating multiple sequential cases into a single target block.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "b5b4a2f76b5de723606c0e8f30eb0f930d4a3c21",
        "author": "Chris Lattner",
        "date": "2004-09-30T16:35:08+00:00",
        "message": "Use more efficient map operations.  Fix a bug that would affect hypothetical\ntargets that supported multiple memory operands.\n\nllvm-svn: 16614",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/VirtRegMap.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/b5b4a2f76b5de723606c0e8f30eb0f930d4a3c21",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing less efficient map operations with more efficient ones to improve performance.",
            "The optimization strategy involved replacing less efficient map operations with more efficient ones to improve performance.",
            "The optimization strategy involved replacing less efficient map operations with more efficient ones to improve performance.",
            "The optimization strategy involved replacing less efficient map operations with more efficient ones to improve performance.",
            "The optimization strategy involved replacing less efficient map operations with more efficient ones to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing less efficient map operations with more efficient ones to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "clang",
        "hash": "b2011f870be4a78aac8561319c7c3944cd92cedf",
        "author": "David Majnemer",
        "date": "2016-07-07T04:43:11+00:00",
        "message": "[AST] Tighten up the bitfield in TemplateSpecializationType\n\nOptimize the bitfield types to conserve space for the MSVC ABI.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@274733 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "include/clang/AST/Type.h"
        ],
        "github_commit_url": "https://github.com/llvm-mirror/clang/commit/b2011f870be4a78aac8561319c7c3944cd92cedf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LLVM_ALIGNAS"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the size of bitfields in a data structure to conserve memory space for the MSVC ABI.",
            "The optimization strategy involved reducing the size of bitfields in a structure to conserve memory space for the MSVC ABI.",
            "The optimization strategy involved reducing the size of bitfields in a data structure to conserve memory space for the MSVC ABI.",
            "The optimization strategy involved reducing the size of bitfields in the TemplateSpecializationType to conserve memory space specifically for the MSVC ABI.",
            "The optimization strategy involved reducing the size of bitfields in a data structure to conserve memory space for the MSVC ABI."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the size of bitfields in a data structure to conserve memory space for the MSVC ABI.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "c938e65768e0a80e7ea24899795878072e79b152",
        "author": "David Jeffery",
        "date": "2021-07-28T14:35:48+02:00",
        "message": "usb: ehci: Prevent missed ehci interrupts with edge-triggered MSI\n\ncommit 0b60557230adfdeb8164e0b342ac9cd469a75759 upstream.\n\nWhen MSI is used by the ehci-hcd driver, it can cause lost interrupts which\nresults in EHCI only continuing to work due to a polling fallback. But the\nreliance of polling drastically reduces performance of any I/O through EHCI.\n\nInterrupts are lost as the EHCI interrupt handler does not safely handle\nedge-triggered interrupts. It fails to ensure all interrupt status bits are\ncleared, which works with level-triggered interrupts but not the\nedge-triggered interrupts typical from using MSI.\n\nTo fix this problem, check if the driver may have raced with the hardware\nsetting additional interrupt status bits and clear status until it is in a\nstable state.\n\nFixes: 306c54d0edb6 (\"usb: hcd: Try MSI interrupts on PCI devices\")\nTested-by: Laurence Oberman <loberman@redhat.com>\nReviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>\nAcked-by: Alan Stern <stern@rowland.harvard.edu>\nSigned-off-by: David Jeffery <djeffery@redhat.com>\nLink: https://lore.kernel.org/r/20210715213744.GA44506@redhat\nCc: stable <stable@vger.kernel.org>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/usb/host/ehci-hcd.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/c938e65768e0a80e7ea24899795878072e79b152",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ehci_irq"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy ensures all interrupt status bits are cleared in a stable state to prevent missed edge-triggered MSI interrupts in the EHCI driver.",
            "The optimization ensures all interrupt status bits are cleared in a stable state to prevent missed edge-triggered MSI interrupts in the EHCI driver.",
            "The optimization strategy ensures all interrupt status bits are cleared in a stable state to prevent missed edge-triggered MSI interrupts in the EHCI driver.",
            "The optimization ensures all interrupt status bits are cleared in a stable state to prevent missed edge-triggered MSI interrupts in the EHCI driver.",
            "The optimization ensures all interrupt status bits are cleared in a stable state to prevent missed edge-triggered MSI interrupts in the EHCI driver."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures all interrupt status bits are cleared in a stable state to prevent missed edge-triggered MSI interrupts in the EHCI driver.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sc3-plugins",
        "hash": "890b380b039cc8615d52dc91a85571af178e8bd8",
        "author": "Tim Blechmann",
        "date": "2013-01-15T18:42:36+01:00",
        "message": "Nova UGens: GendyI - ensure inlining of Gendyn_distribution\n\nSigned-off-by: Tim Blechmann <tim@klingt.org>",
        "modified_files_count": 1,
        "modified_files": [
            "source/NovaUGens/NovaGendy.cpp"
        ],
        "github_commit_url": "https://github.com/supercollider/sc3-plugins/commit/890b380b039cc8615d52dc91a85571af178e8bd8",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is ensuring the inlining of the `Gendyn_distribution` function to reduce function call overhead.",
            "The optimization strategy used is ensuring the inlining of the `Gendyn_distribution` function to reduce function call overhead.",
            "The optimization strategy used is ensuring the inlining of the `Gendyn_distribution` function to reduce function call overhead.",
            "The optimization strategy used is ensuring the inlining of the `Gendyn_distribution` function to reduce function call overhead.",
            "The optimization strategy used is ensuring the inlining of the `Gendyn_distribution` function to reduce function call overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is ensuring the inlining of the `Gendyn_distribution` function to reduce function call overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "OpenTESArena",
        "hash": "d451fb9a6257e1cc93baf1b2b9bcd52dc4a762e1",
        "author": "Aaron",
        "date": "2020-05-14T23:17:37-07:00",
        "message": "Cache voxel grid dimensions.\n\nThe getter calls don't seem to get inlined even in a release build except with link time optimization. The generated assembly in the DDA step lambda no longer has call instructions, so that's a plus.",
        "modified_files_count": 1,
        "modified_files": [
            "OpenTESArena/src/Rendering/SoftwareRenderer.cpp"
        ],
        "github_commit_url": "https://github.com/afritz1/OpenTESArena/commit/d451fb9a6257e1cc93baf1b2b9bcd52dc4a762e1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SoftwareRenderer::rayCast2DInternal"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization caches voxel grid dimensions to avoid repeated getter calls, reducing function call overhead in performance-critical code.",
            "The optimization strategy involved caching voxel grid dimensions to avoid repeated getter calls, thereby reducing function call overhead in performance-critical code.",
            "The optimization caches voxel grid dimensions to avoid repeated getter calls, reducing function call overhead in performance-critical code.",
            "The optimization caches voxel grid dimensions to avoid repeated getter calls, reducing function call overhead in performance-critical code.",
            "The optimization caches voxel grid dimensions to avoid repeated getter calls, reducing function call overhead in performance-critical code."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization caches voxel grid dimensions to avoid repeated getter calls, reducing function call overhead in performance-critical code.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "john",
        "hash": "645a378764d19a78f027e2c3b2e31a11696a944c",
        "author": "Solar Designer",
        "date": "2020-11-01T20:31:33+01:00",
        "message": "Use OpenMP in DES_bs_cmp_all()\n\nWe should actually have this with SIMD inside the 3 crypt_all() functions,\nbut even doing it here provides good speedup on massively parallel devices\nsuch as Xeon Phi and high-end server CPUs, at the expense of occasional\nslight slowdown when running only 1 or 2 threads.",
        "modified_files_count": 1,
        "modified_files": [
            "src/DES_bs.c"
        ],
        "github_commit_url": "https://github.com/openwall/john/commit/645a378764d19a78f027e2c3b2e31a11696a944c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DES_bs_cmp_all"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is parallelizing the computation in the DES_bs_cmp_all() function by leveraging OpenMP to utilize multiple threads on parallel hardware.",
            "The optimization strategy used is parallelizing the computation in the `DES_bs_cmp_all` function using OpenMP to leverage multiple CPU threads for improved performance on parallel hardware.",
            "The optimization strategy used is parallelizing the `DES_bs_cmp_all` function using OpenMP to leverage multiple threads for improved performance on parallel hardware.",
            "The optimization strategy used is parallelizing the `DES_bs_cmp_all` function using OpenMP to leverage multiple CPU threads for improved performance on parallel hardware.",
            "The optimization strategy used is parallelizing the computation in the DES_bs_cmp_all() function by leveraging OpenMP to improve performance on multi-threaded hardware."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is parallelizing the computation in the `DES_bs_cmp_all` function using OpenMP to leverage multiple CPU threads for improved performance on parallel hardware.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "seqtk",
        "hash": "ba10dad8a5cc983c6d26fb4bb47251defe286d24",
        "author": "Fabian Klötzl",
        "date": "2018-11-21T12:20:12+01:00",
        "message": "improve parsing performance\n\nDoubles throughput; can now parse FASTA at 2GB/s.",
        "modified_files_count": 1,
        "modified_files": [
            "kseq.h"
        ],
        "github_commit_url": "https://github.com/lh3/seqtk/commit/ba10dad8a5cc983c6d26fb4bb47251defe286d24",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ks_getuntil2"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the parsing logic to minimize unnecessary memory operations and improve cache efficiency.",
            "The optimization strategy involved improving parsing performance by doubling throughput to achieve 2GB/s for FASTA parsing.",
            "The optimization strategy involved modifying the parsing logic to reduce unnecessary memory operations and improve efficiency in processing FASTA files.",
            "The optimization strategy involved restructuring the parsing logic to minimize unnecessary memory operations and improve loop efficiency.",
            "The optimization strategy involved restructuring the parsing logic to minimize unnecessary memory operations and improve cache efficiency."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the parsing logic to minimize unnecessary memory operations and improve cache efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "0a5ce0831d04382aa9e2420e33dff958ddade542",
        "author": "Yury Norov",
        "date": "2017-09-08T18:26:49-07:00",
        "message": "lib/bitmap.c: make bitmap_parselist() thread-safe and much faster\n\nCurrent implementation of bitmap_parselist() uses a static variable to\nsave local state while setting bits in the bitmap.  It is obviously wrong\nif we assume execution in multiprocessor environment.  Fortunately, it's\npossible to rewrite this portion of code to avoid using the static\nvariable.\n\nIt is also possible to set bits in the mask per-range with bitmap_set(),\nnot per-bit, as it is implemented now, with set_bit(); which is way\nfaster.\n\nThe important side effect of this change is that setting bits in this\nfunction from now is not per-bit atomic and less memory-ordered.  This is\nbecause set_bit() guarantees the order of memory accesses, while\nbitmap_set() does not.  I think that it is the advantage of the new\napproach, because the bitmap_parselist() is intended to initialise bit\narrays, and user should protect the whole bitmap during initialisation if\nneeded.  So protecting individual bits looks expensive and useless.  Also,\nother range-oriented functions in lib/bitmap.c don't worry much about\natomicity.\n\nWith all that, setting 2k bits in map with the pattern like 0-2047:128/256\nbecomes ~50 times faster after applying the patch in my testing\nenvironment (arm64 hosted on qemu).\n\nThe second patch of the series adds the test for bitmap_parselist().  It's\nnot intended to cover all tricky cases, just to make sure that I didn't\nscrew up during rework.\n\nLink: http://lkml.kernel.org/r/20170807225438.16161-1-ynorov@caviumnetworks.com\nSigned-off-by: Yury Norov <ynorov@caviumnetworks.com>\nCc: Noam Camus <noamca@mellanox.com>\nCc: Rasmus Villemoes <linux@rasmusvillemoes.dk>\nCc: Matthew Wilcox <mawilcox@microsoft.com>\nCc: Mauro Carvalho Chehab <mchehab@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/bitmap.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/0a5ce0831d04382aa9e2420e33dff958ddade542",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__bitmap_parselist"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced per-bit operations with per-range operations and removed the use of a static variable to improve thread safety and performance.",
            "The optimization strategy replaced per-bit operations with per-range operations and removed a static variable to improve thread safety and performance.",
            "The optimization strategy replaced per-bit operations with per-range operations and removed a static variable to improve thread safety and performance.",
            "The optimization strategy replaced per-bit operations with per-range operations and removed a static variable to improve thread safety and performance.",
            "The optimization strategy replaced per-bit operations with per-range operations and removed a static variable to improve thread safety and performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced per-bit operations with per-range operations and removed a static variable to improve thread safety and performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "699badd56b4c1472dbab552917842d9587effc5f",
        "author": "Toon Verwaest",
        "date": "2019-06-06T15:48:18+00:00",
        "message": "[scanner] Add fast path for converting utf8 that's ascii to utf16\n\nChange-Id: I386261bc012d0d4556b0f9417b2880cc7f44bf2c\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/1647697\nCommit-Queue: Toon Verwaest <verwaest@chromium.org>\nReviewed-by: Leszek Swirski <leszeks@chromium.org>\nCr-Commit-Position: refs/heads/master@{#62029}",
        "modified_files_count": 1,
        "modified_files": [
            "src/parsing/scanner-character-streams.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/699badd56b4c1472dbab552917842d9587effc5f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Utf8ExternalStreamingStream::FillBufferFromCurrentChunk"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization introduces a fast path for converting UTF-8 ASCII data to UTF-16 by directly processing ASCII characters without full UTF-8 decoding.",
            "The optimization introduces a fast path for converting UTF-8 ASCII data to UTF-16 by directly processing ASCII characters without full UTF-8 decoding.",
            "The optimization introduces a fast path for converting UTF-8 ASCII data to UTF-16, reducing unnecessary computations by directly handling ASCII characters without full UTF-8 decoding.",
            "The optimization introduces a fast path for converting UTF-8 ASCII data to UTF-16, reducing unnecessary computations by directly handling ASCII characters without full UTF-8 decoding.",
            "The optimization introduces a fast path for converting UTF-8 ASCII data to UTF-16, reducing unnecessary computations by directly handling ASCII characters."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization introduces a fast path for converting UTF-8 ASCII data to UTF-16, reducing unnecessary computations by directly handling ASCII characters without full UTF-8 decoding.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "TranslucentTB",
        "hash": "2eb6e70e26b61891c159ff74a1eca381e2a567a5",
        "author": "Charles Milette",
        "date": "2018-02-10T14:26:53-05:00",
        "message": "Use PixelBuffers everywhere, greatly improves drawing speed",
        "modified_files_count": 1,
        "modified_files": [
            "CPicker/Main.cpp"
        ],
        "github_commit_url": "https://github.com/TranslucentTB/TranslucentTB/commit/2eb6e70e26b61891c159ff74a1eca381e2a567a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ColourPickerDlgProc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing direct pixel manipulation with PixelBuffers to enhance drawing speed by leveraging more efficient memory handling.",
            "The optimization strategy involved replacing direct pixel manipulation with PixelBuffers to enhance drawing speed by leveraging more efficient memory handling.",
            "The optimization strategy involved replacing direct pixel manipulation with PixelBuffers to enhance drawing speed by leveraging more efficient memory handling.",
            "The optimization strategy involved replacing direct pixel manipulation with PixelBuffers to enhance drawing speed by leveraging more efficient memory handling.",
            "The optimization strategy involved replacing direct pixel manipulation with PixelBuffers to enhance drawing speed by leveraging more efficient memory handling."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing direct pixel manipulation with PixelBuffers to enhance drawing speed by leveraging more efficient memory handling.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kdevelop",
        "hash": "1d1849febc34535b4c957233a89a07095a46cd81",
        "author": "David Nolden",
        "date": "2008-11-11T13:06:30+00:00",
        "message": "Don't follow proxy-contexts when searching importers. This greatly reduces the complexity, since those build a completely parallel and much more complex structure to the content-contexts.\nThis fixes the extremely long UI-blocking phases that used to happen when using use-searching or global renaming with central classes.",
        "modified_files_count": 1,
        "modified_files": [
            "language/duchain/navigation/usescollector.cpp"
        ],
        "github_commit_url": "https://github.com/KDE/kdevelop/commit/1d1849febc34535b4c957233a89a07095a46cd81",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "collectImporters"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids traversing complex proxy-context structures when searching for importers, reducing computational complexity.",
            "The optimization avoids traversing proxy-contexts when collecting importers, significantly reducing complexity and UI-blocking delays.",
            "The optimization avoids traversing proxy-contexts when collecting importers, reducing complexity by focusing only on relevant content-contexts.",
            "The optimization avoids traversing proxy-contexts when collecting importers, significantly reducing complexity and UI-blocking delays.",
            "The optimization avoids traversing proxy-contexts when collecting importers, significantly reducing complexity and UI-blocking delays."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids traversing proxy-contexts when collecting importers, significantly reducing complexity and UI-blocking delays.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "LuaJIT",
        "hash": "3bdc6498c4c012a8fbf9cfa2756a5b07f56f1540",
        "author": "Mike Pall",
        "date": "2024-08-15T00:07:34+02:00",
        "message": "Limit CSE for IR_CARG to fix loop optimizations.\n\nThanks to Peter Cawley. #1244",
        "modified_files_count": 1,
        "modified_files": [
            "src/lj_opt_fold.c"
        ],
        "github_commit_url": "https://github.com/LuaJIT/LuaJIT/commit/3bdc6498c4c012a8fbf9cfa2756a5b07f56f1540",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LJFOLD"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization limits Common Subexpression Elimination (CSE) for IR_CARG to improve loop optimization effectiveness.",
            "The optimization limits Common Subexpression Elimination (CSE) for IR_CARG to improve loop optimization effectiveness.",
            "The optimization limits Common Subexpression Elimination (CSE) for IR_CARG to improve loop optimization effectiveness.",
            "The optimization limits common subexpression elimination (CSE) for IR_CARG to improve loop optimizations by avoiding unnecessary folding.",
            "The optimization limits Common Subexpression Elimination (CSE) for IR_CARG to improve loop optimization effectiveness."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization limits Common Subexpression Elimination (CSE) for IR_CARG to improve loop optimization effectiveness.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "e94eea4527f2d7de82a6bf3303177977011e5dd9",
        "author": "Haobo Xu",
        "date": "2013-12-20T16:29:05-08:00",
        "message": "[RocksDB] [Performance Branch] Minor fix, Remove string resize from WriteBatch::Clear\n\nSummary: tmp_batch_ will get re-allocated for every merged write batch because of the existing resize in WriteBatch::Clear. Note that in DBImpl::BuildBatchGroup, we have a hard coded upper limit of batch size 1<<20 = 1MB already.\n\nTest Plan: make check\n\nReviewers: dhruba, sdong\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14787",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_batch.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e94eea4527f2d7de82a6bf3303177977011e5dd9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatch::Clear"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization removes an unnecessary string resize operation in WriteBatch::Clear to avoid redundant memory reallocations.",
            "The optimization strategy involved removing an unnecessary string resize operation in WriteBatch::Clear to avoid repeated memory reallocations.",
            "The optimization removes an unnecessary string resize operation in WriteBatch::Clear to avoid repeated memory reallocation for tmp_batch_.",
            "The optimization removes an unnecessary string resize operation in WriteBatch::Clear to avoid repeated memory reallocation for tmp_batch_.",
            "The optimization removes an unnecessary string resize operation in WriteBatch::Clear to avoid redundant memory reallocation for every merged write batch."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes an unnecessary string resize operation in WriteBatch::Clear to avoid redundant memory reallocations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "1535e9dbb6d66647f3f64d307b07abd41c8973c5",
        "author": "Thanos Makatos",
        "date": "2022-05-09T20:45:04+00:00",
        "message": "nvmf/vfio-user: reduce libvfio-user socket poll frequency\n\nConstantly polling the socket degrades performance significantly.\nPolling the socket at a much lower frequency, every 1ms, is good enough\nfor now.\n\nfixes #2494\n\nSigned-off-by: Thanos Makatos <thanos.makatos@nutanix.com>\nCo-authored-by: John Levon <john.levon@nutanix.com>\nChange-Id: I4a7d35c45ece863b9df756324c23f41736df49f8\nReviewed-on: https://review.spdk.io/gerrit/c/spdk/spdk/+/12494\nCommunity-CI: Broadcom CI <spdk-ci.pdl@broadcom.com>\nTested-by: SPDK CI Jenkins <sys_sgci@intel.com>\nReviewed-by: Changpeng Liu <changpeng.liu@intel.com>\nReviewed-by: Jim Harris <james.r.harris@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/nvmf/vfio_user.c"
        ],
        "github_commit_url": "https://github.com/spdk/spdk/commit/1535e9dbb6d66647f3f64d307b07abd41c8973c5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "handle_queue_connect_rsp"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "spdk",
        "optimization_summary": [
            "The optimization strategy reduces performance overhead by lowering the frequency of socket polling from constant to every 1ms.",
            "The optimization strategy reduces performance overhead by lowering the frequency of socket polling from constant to every 1ms.",
            "The optimization strategy reduces performance overhead by lowering the frequency of socket polling from constant to every 1ms.",
            "The optimization strategy reduces performance overhead by lowering the frequency of socket polling from constant to every 1ms.",
            "The optimization strategy reduces performance overhead by lowering the frequency of socket polling from constant to every 1ms."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces performance overhead by lowering the frequency of socket polling from constant to every 1ms.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "athena",
        "hash": "e30965acdd51056d0f72fad9687771652c47d3fa",
        "author": "James Stone",
        "date": "2018-02-14T19:30:57-05:00",
        "message": "Added Error in case there are more OpenMP threads than MeshBlocks.  Code runs\nin this case, but threads sit idle and this is very inefficient.",
        "modified_files_count": 1,
        "modified_files": [
            "src/mesh/mesh.cpp"
        ],
        "github_commit_url": "https://github.com/PrincetonUniversity/athena/commit/e30965acdd51056d0f72fad9687771652c47d3fa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Mesh::LoadBalance"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding an error check to prevent inefficient resource usage when the number of OpenMP threads exceeds the number of MeshBlocks, ensuring threads do not sit idle.",
            "The optimization strategy involves adding an error check to prevent inefficient resource usage when the number of OpenMP threads exceeds the number of MeshBlocks, ensuring threads do not sit idle.",
            "The optimization strategy involves adding an error check to prevent inefficient resource usage when the number of OpenMP threads exceeds the number of MeshBlocks, ensuring threads do not sit idle.",
            "The optimization strategy involves adding an error check to prevent inefficient resource usage when the number of OpenMP threads exceeds the number of MeshBlocks, ensuring threads do not sit idle.",
            "The optimization strategy involves adding an error check to prevent inefficient resource usage when the number of OpenMP threads exceeds the number of MeshBlocks, ensuring threads do not sit idle."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding an error check to prevent inefficient resource usage when the number of OpenMP threads exceeds the number of MeshBlocks, ensuring threads do not sit idle.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "simc",
        "hash": "66546b03d2b4ccc439216dfd8a401106da893d0b",
        "author": "pkaskaround",
        "date": "2017-01-15T18:25:22+01:00",
        "message": "[Shaman] Elemental APL optimized for IF (FS uptime)",
        "modified_files_count": 1,
        "modified_files": [
            "engine/class_modules/sc_shaman.cpp"
        ],
        "github_commit_url": "https://github.com/simulationcraft/simc/commit/66546b03d2b4ccc439216dfd8a401106da893d0b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "shaman_t::init_action_list_elemental"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the Elemental APL (Action Priority List) for Shamans to improve the handling of Flame Shock uptime by refining conditional checks and action ordering.",
            "The optimization strategy involved restructuring the Elemental APL (Action Priority List) for Shamans to improve the uptime of Flame Shock by reordering or refining conditional checks and action logic.",
            "The optimization strategy involved restructuring the Elemental APL (Action Priority List) for Shamans to improve the uptime of Flame Shock by reordering or refining conditions in the IF statements.",
            "The optimization strategy involved restructuring the Elemental APL (Action Priority List) for Shamans to improve the uptime of Flame Shock by reordering or refining conditions.",
            "The optimization strategy involved restructuring the Elemental APL (Action Priority List) for Shamans to improve the uptime of Flame Shock by reordering or refining conditional checks."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the Elemental APL (Action Priority List) for Shamans to improve the uptime of Flame Shock by reordering or refining conditional checks and action logic.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f1339763f9c8f48be5e4a1bba908d14d6a5fcc78",
        "author": "John Thacker",
        "date": "2023-10-23T13:51:14+00:00",
        "message": "Qt: Improve FollowStreamText scroll performance\n\nWe turn on mouse tracking in FollowStreamText so that mouse\nmoves without any buttons pressed will cause the hint text\nto update showing to what packet it will jump if clicked.\n\nHowever, we don't want to send the mouse moves with no buttons\npressed to the base QPlainTextEdit class, which causes a large\nnumber of calculations for no reason that slow down scrolling\nespecially in large documents.\n\nIgnore those events, effectively turning off mouse tracking for\nthe base QPlainTextEdit.",
        "modified_files_count": 1,
        "modified_files": [
            "ui/qt/widgets/follow_stream_text.cpp"
        ],
        "github_commit_url": "https://github.com/wireshark/wireshark/commit/f1339763f9c8f48be5e4a1bba908d14d6a5fcc78",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FollowStreamText::mouseMoveEvent"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "wireshark",
        "optimization_summary": [
            "The optimization strategy involves ignoring unnecessary mouse move events in the base class to reduce redundant calculations and improve scroll performance.",
            "The optimization strategy involves ignoring unnecessary mouse move events in the base class to reduce redundant calculations and improve scroll performance.",
            "The optimization strategy involves ignoring unnecessary mouse move events in the base class to reduce redundant calculations and improve scroll performance.",
            "The optimization strategy involves ignoring unnecessary mouse move events in the base class to reduce redundant calculations and improve scroll performance.",
            "The optimization strategy involves ignoring unnecessary mouse move events in the base class to reduce redundant calculations and improve scroll performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves ignoring unnecessary mouse move events in the base class to reduce redundant calculations and improve scroll performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "redis",
        "hash": "f0fab99d6fd7b4310f03a2c84b465fae98d31bc0",
        "author": "Huang Zhw",
        "date": "2021-09-23T17:12:11+03:00",
        "message": "Minor optimize getMaxmemoryState, when server.maxmemory is not set (#9533)\n\nMinor optimize getMaxmemoryState, when server.maxmemory is not set,\r\ndon't count AOF and replicas buffers.\r\n\r\nCo-authored-by: Viktor Söderqvist <viktor@zuiderkwast.se>",
        "modified_files_count": 1,
        "modified_files": [
            "src/evict.c"
        ],
        "github_commit_url": "https://github.com/redis/redis/commit/f0fab99d6fd7b4310f03a2c84b465fae98d31bc0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "getMaxmemoryState"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary calculations of AOF and replicas buffer memory usage when the `server.maxmemory` setting is not configured.",
            "The optimization avoids unnecessary calculations of AOF and replicas buffers when the `server.maxmemory` setting is not configured, reducing computational overhead.",
            "The optimization avoids unnecessary calculations for AOF and replicas buffers when the `server.maxmemory` setting is not configured.",
            "The optimization avoids unnecessary calculations of AOF and replicas buffers when `server.maxmemory` is not set, reducing computational overhead.",
            "The optimization avoids unnecessary calculations for AOF and replicas buffers when the `server.maxmemory` setting is not configured."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary calculations of AOF and replicas buffers when the `server.maxmemory` setting is not configured, reducing computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "athena",
        "hash": "2d3c819f95c5b1d53eaecfae2d85a51047fbf6cb",
        "author": "tomo-ono",
        "date": "2020-11-21T00:09:06+09:00",
        "message": "remove inefficient pragma",
        "modified_files_count": 1,
        "modified_files": [
            "src/orbital_advection/calculate_orbital_advection.cpp"
        ],
        "github_commit_url": "https://github.com/PrincetonUniversity/athena/commit/2d3c819f95c5b1d53eaecfae2d85a51047fbf6cb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OrbitalAdvection::CalculateOrbitalAdvectionCC"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing an inefficient pragma to improve compilation efficiency and potentially enhance runtime performance.",
            "The optimization strategy involved removing an inefficient pragma to improve compilation efficiency and potentially enhance runtime performance.",
            "The optimization strategy involved removing an inefficient pragma to improve compilation efficiency and potentially enhance runtime performance.",
            "The optimization strategy involved removing an inefficient pragma to improve compilation efficiency and potentially enhance runtime performance.",
            "The optimization strategy involved removing an inefficient pragma to improve compilation efficiency and potentially enhance runtime performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing an inefficient pragma to improve compilation efficiency and potentially enhance runtime performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kdeconnect-kde",
        "hash": "f8674db931c9b743874ae9d09d5cf48029dcec4b",
        "author": "Nicolas Fella",
        "date": "2020-04-08T10:25:34+02:00",
        "message": "Don't recreate QRegularExpression for leading zeroes each time\n\nCreating a QRegularExpression is quite expensive and we use the same expression for each run. Sharing it between the runs leads to a significant performance improvement.",
        "modified_files_count": 1,
        "modified_files": [
            "smsapp/smshelper.cpp"
        ],
        "github_commit_url": "https://github.com/KDE/kdeconnect-kde/commit/f8674db931c9b743874ae9d09d5cf48029dcec4b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SmsHelper::canonicalizePhoneNumber"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves caching and reusing a QRegularExpression object instead of recreating it for each function call to reduce overhead.",
            "The optimization strategy involves caching and reusing a QRegularExpression object instead of recreating it for each function call to reduce overhead.",
            "The optimization strategy involves caching and reusing a QRegularExpression object to avoid the repeated cost of recreating it for each function call.",
            "The optimization strategy involves caching and reusing a QRegularExpression object instead of recreating it for each function call to reduce overhead.",
            "The optimization strategy involves caching and reusing a QRegularExpression object instead of recreating it for each function call to reduce overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves caching and reusing a QRegularExpression object instead of recreating it for each function call to reduce overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "OpenCPN",
        "hash": "65e69dcf3e4803a8e60f888dba68cf0db4a55e6f",
        "author": "David Register",
        "date": "2014-12-14T20:53:50-05:00",
        "message": "Improve performance of OpenGL pattern rendering.",
        "modified_files_count": 1,
        "modified_files": [
            "src/s52plib.cpp"
        ],
        "github_commit_url": "https://github.com/OpenCPN/OpenCPN/commit/65e69dcf3e4803a8e60f888dba68cf0db4a55e6f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "s52plib::RenderToGLAP"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing immediate mode OpenGL calls with vertex buffer objects to reduce rendering overhead.",
            "The optimization strategy involved reducing redundant OpenGL state changes by caching and reusing pattern rendering settings.",
            "The optimization strategy involved reducing redundant OpenGL state changes by caching and reusing pattern rendering states.",
            "The optimization strategy involved reducing redundant OpenGL state changes by caching and reusing pattern rendering settings.",
            "The optimization strategy involved reducing redundant OpenGL state changes by caching and reusing pattern rendering states."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant OpenGL state changes by caching and reusing pattern rendering settings.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qt-creator",
        "hash": "c074b18f8d4510713f6d66149213510428eae6f1",
        "author": "Christian Kamm",
        "date": "2011-09-07T09:32:24+02:00",
        "message": "C++: Improve Literal::hashCode.\n\nThis can have a dramatic impact on performance when a file contains lots\nof unique literals.\n\nChange-Id: I5309b28f704d7f53e164dc8084ae08354c09354b\nReviewed-on: http://codereview.qt.nokia.com/4312\nReviewed-by: Roberto Raggi <roberto.raggi@nokia.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/libs/3rdparty/cplusplus/Literals.cpp"
        ],
        "github_commit_url": "https://github.com/qt-creator/qt-creator/commit/c074b18f8d4510713f6d66149213510428eae6f1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Literal::hashCode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the hash code generation for literals to reduce performance overhead when handling numerous unique literals.",
            "The optimization strategy involved improving the hash code generation for literals to reduce performance overhead when handling numerous unique literals.",
            "The optimization strategy involved improving the hash code generation for literals to reduce performance overhead when handling numerous unique literals.",
            "The optimization strategy involved improving the hash code generation for literals to reduce computational overhead when handling numerous unique literals.",
            "The optimization strategy involved improving the hash code generation for literals to reduce performance overhead when handling numerous unique literals."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the hash code generation for literals to reduce performance overhead when handling numerous unique literals.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "scanner",
        "hash": "736af4b3d7af165f268850219e3d467e30db4848",
        "author": "Alex Poms",
        "date": "2017-12-27T21:49:58-08:00",
        "message": "Also prefetch uncommitted tables",
        "modified_files_count": 1,
        "modified_files": [
            "scanner/engine/master.cpp"
        ],
        "github_commit_url": "https://github.com/scanner-research/scanner/commit/736af4b3d7af165f268850219e3d467e30db4848",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MasterImpl::recover_and_init_database"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved prefetching uncommitted tables to improve database recovery and initialization performance by reducing latency.",
            "The optimization strategy involved prefetching uncommitted tables to improve database recovery and initialization performance.",
            "The optimization strategy involved prefetching uncommitted tables to improve database recovery and initialization performance.",
            "The optimization strategy involved prefetching uncommitted tables to improve database recovery and initialization performance.",
            "The optimization strategy involved prefetching uncommitted tables to improve database recovery and initialization performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved prefetching uncommitted tables to improve database recovery and initialization performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "82e8e9e26bb16d1af07a26741bcf63d8342e4336",
        "author": "JiYou",
        "date": "2018-09-14T19:43:04-07:00",
        "message": "VersionBuilder: optmize SaveTo() to linear time. (#4366)\n\nSummary:\nBecause `base_files` and `added_files` both are sorted, using a merge\noperation to these two sorted arrays is more effective. The complexity\nis reduced to linear time.\n\n    - optmize the merge complexity.\n    - move the `NDEBUG` of sorted `added_files` out of merge process.\n\nSigned-off-by: JiYou <jiyou09@gmail.com>\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4366\n\nDifferential Revision: D9833592\n\nPulled By: ajkr\n\nfbshipit-source-id: dd32b67ebdca4c20e5e9546ab8082cecefe99fd0",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_builder.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/82e8e9e26bb16d1af07a26741bcf63d8342e4336",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SaveTo"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy used a merge operation on two sorted arrays to reduce the time complexity of the `SaveTo()` function to linear time.",
            "The optimization strategy used a merge operation on two sorted arrays to reduce the time complexity of the `SaveTo()` function to linear time.",
            "The optimization strategy used a merge operation on two sorted arrays to reduce the time complexity of the `SaveTo()` function to linear time.",
            "The optimization strategy used a merge operation on two sorted arrays to reduce the time complexity of the `SaveTo()` function to linear time.",
            "The optimization strategy used a merge operation on two sorted arrays to reduce the time complexity of the `SaveTo()` function to linear time."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used a merge operation on two sorted arrays to reduce the time complexity of the `SaveTo()` function to linear time.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "meshoptimizer",
        "hash": "8688bbfb8f7f2cb847f711ceed73c89f9aaece6c",
        "author": "Arseny Kapoulkine",
        "date": "2021-01-13T21:18:52-08:00",
        "message": "clusterizer: Replace Hoare partition with branchless Lomuto partition\n\nThe branchless variant is shorter and faster for our workloads, and also\neasy to reason about. Note that this isn't exactly equivalent to a\nLomuto partition because we always swap the element but sometimes swap\nit into the >= half, which means that the resulting partitioning isn't\nstable.",
        "modified_files_count": 1,
        "modified_files": [
            "src/clusterizer.cpp"
        ],
        "github_commit_url": "https://github.com/zeux/meshoptimizer/commit/8688bbfb8f7f2cb847f711ceed73c89f9aaece6c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "kdtreePartition"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a Hoare partition with a branchless Lomuto partition to improve performance for specific workloads.",
            "The optimization strategy replaced a Hoare partition with a branchless Lomuto partition to improve performance for specific workloads.",
            "The optimization strategy replaced a Hoare partition with a branchless Lomuto partition to improve performance for specific workloads by reducing branching overhead.",
            "The optimization strategy replaced a Hoare partition with a branchless Lomuto partition to improve performance for specific workloads by reducing branching overhead and simplifying reasoning.",
            "The optimization replaces a Hoare partition with a branchless Lomuto partition to improve performance for specific workloads by reducing branching overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a Hoare partition with a branchless Lomuto partition to improve performance for specific workloads by reducing branching overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "60588bfa223ff675b95f866249f90616613fbe31",
        "author": "Cheng Jian",
        "date": "2019-12-17T13:32:51+01:00",
        "message": "sched/fair: Optimize select_idle_cpu\n\nselect_idle_cpu() will scan the LLC domain for idle CPUs,\nit's always expensive. so the next commit :\n\n\t1ad3aaf3fcd2 (\"sched/core: Implement new approach to scale select_idle_cpu()\")\n\nintroduces a way to limit how many CPUs we scan.\n\nBut it consume some CPUs out of 'nr' that are not allowed\nfor the task and thus waste our attempts. The function\nalways return nr_cpumask_bits, and we can't find a CPU\nwhich our task is allowed to run.\n\nCpumask may be too big, similar to select_idle_core(), use\nper_cpu_ptr 'select_idle_mask' to prevent stack overflow.\n\nFixes: 1ad3aaf3fcd2 (\"sched/core: Implement new approach to scale select_idle_cpu()\")\nSigned-off-by: Cheng Jian <cj.chengjian@huawei.com>\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nReviewed-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>\nReviewed-by: Vincent Guittot <vincent.guittot@linaro.org>\nReviewed-by: Valentin Schneider <valentin.schneider@arm.com>\nLink: https://lkml.kernel.org/r/20191213024530.28052-1-cj.chengjian@huawei.com",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/sched/fair.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/60588bfa223ff675b95f866249f90616613fbe31",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cost"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy limits the number of CPUs scanned in `select_idle_cpu()` by using a per-CPU mask to avoid unnecessary checks and potential stack overflow.",
            "The optimization strategy limits the number of CPUs scanned in `select_idle_cpu()` by using a per-CPU mask to avoid unnecessary checks and potential stack overflow.",
            "The optimization strategy limits the number of CPUs scanned in `select_idle_cpu()` by using a per-CPU mask to avoid unnecessary checks and potential stack overflow.",
            "The optimization strategy limits the number of CPUs scanned in `select_idle_cpu()` by using a per-CPU mask to avoid unnecessary checks and potential stack overflow.",
            "The optimization strategy limits the number of CPUs scanned in `select_idle_cpu()` by using a per-CPU mask to avoid unnecessary checks and potential stack overflow."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy limits the number of CPUs scanned in `select_idle_cpu()` by using a per-CPU mask to avoid unnecessary checks and potential stack overflow.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "rondb",
        "hash": "2a857a4db36c50d42cc0aca8046c1101324d9948",
        "author": "konstantin@mysql.com",
        "date": "2004-06-10T01:30:39+04:00",
        "message": "Fix for Bug#3904 \"COUNT DISTINCT performance anomaly in 4.1\"\nThe bug was caused by error in hash calculation function: it\nalways returned hash value for last field in a composite key, so \nfor keys like (a text, b char(1)) we were always\ngetting bad hash values.",
        "modified_files_count": 1,
        "modified_files": [
            "myisam/mi_unique.c"
        ],
        "github_commit_url": "https://github.com/logicalclocks/rondb/commit/2a857a4db36c50d42cc0aca8046c1101324d9948",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mi_unique_hash"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy fixed a bug in the hash calculation function to ensure correct hash values for composite keys, improving the performance of COUNT DISTINCT operations.",
            "The optimization strategy fixed a bug in the hash calculation function to ensure correct hash values for composite keys, improving the performance of COUNT DISTINCT operations.",
            "The optimization strategy fixed a bug in the hash calculation function to ensure correct hash values for composite keys, improving the performance of COUNT DISTINCT operations.",
            "The optimization strategy fixed a bug in the hash calculation function to ensure correct hash values for composite keys, improving the performance of COUNT DISTINCT operations.",
            "The optimization strategy fixed a bug in the hash calculation function to ensure correct hash values for composite keys, improving the performance of COUNT DISTINCT operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy fixed a bug in the hash calculation function to ensure correct hash values for composite keys, improving the performance of COUNT DISTINCT operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "magnum",
        "hash": "bc5d127bd6b1fef4cf9888b92b2f09acea57bff3",
        "author": "Vladimír Vondruš",
        "date": "2023-05-19T16:23:25+02:00",
        "message": "sceneconverter: don't query Arguments value unnecessarily often.\n\nIt's an --info output which doesn't have to be the fastest ever, but it\nalso doesn't have to waste time for no reason.",
        "modified_files_count": 1,
        "modified_files": [
            "src/Magnum/SceneTools/Implementation/sceneConverterUtilities.h"
        ],
        "github_commit_url": "https://github.com/mosra/magnum/commit/bc5d127bd6b1fef4cf9888b92b2f09acea57bff3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "printInfo"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces redundant queries to the Arguments value by caching or reusing the result.",
            "The optimization strategy reduces redundant queries to the Arguments value by caching or restructuring access within the function.",
            "The optimization strategy reduces redundant queries to the Arguments value by caching or reusing the result within the function.",
            "The optimization strategy reduces redundant queries to the Arguments value by caching or restructuring access within the function.",
            "The optimization strategy reduces redundant queries to the Arguments value by caching or restructuring access within the function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy reduces redundant queries to the Arguments value by caching or restructuring access within the function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "mangos-wotlk",
        "hash": "f833421b70019f8a3c05854693f6db9775015fb3",
        "author": "killerwife",
        "date": "2018-06-28T15:16:54+02:00",
        "message": "Optimize RemoveSpellsCausingAura\n\nNow we won't senselessly iterate over and over and skip one step.",
        "modified_files_count": 1,
        "modified_files": [
            "src/game/Entities/Unit.cpp"
        ],
        "github_commit_url": "https://github.com/cmangos/mangos-wotlk/commit/f833421b70019f8a3c05854693f6db9775015fb3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Unit::RemoveSpellsCausingAura"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids redundant iterations by skipping unnecessary steps in the loop that removes spells causing a specific aura.",
            "The optimization strategy avoids redundant iterations by skipping unnecessary steps in the loop that removes spells causing a specific aura.",
            "The optimization strategy avoids redundant iterations by skipping unnecessary steps in the loop that removes spells causing a specific aura.",
            "The optimization strategy avoids redundant iterations by skipping unnecessary steps in the loop that removes spells causing a specific aura.",
            "The optimization strategy avoids redundant iterations by skipping unnecessary steps in the loop."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids redundant iterations by skipping unnecessary steps in the loop that removes spells causing a specific aura.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "8052d043a48f733905e8ea8f900bf58b441a317f",
        "author": "Christophe Leroy",
        "date": "2022-05-22T15:58:27+10:00",
        "message": "powerpc/ftrace: Don't use copy_from_kernel_nofault() in module_trampoline_target()\n\nmodule_trampoline_target() is quite a hot path used when\nactivating/deactivating function tracer.\n\nAvoid the heavy copy_from_kernel_nofault() by doing four calls\nto copy_inst_from_kernel_nofault().\n\nUse __copy_inst_from_kernel_nofault() for the 3 last calls. First call\nis done to copy_from_kernel_nofault() to check address is within\nkernel space. No risk to wrap out the top of kernel space because the\nlast page is never mapped so if address is in last page the first copy\nwill fails and the other ones will never be performed.\n\nAnd also make it notrace just like all functions that call it.\n\nSigned-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://lore.kernel.org/r/c55559103e014b7863161559d340e8e9484eaaa6.1652074503.git.christophe.leroy@csgroup.eu",
        "modified_files_count": 1,
        "modified_files": [
            "arch/powerpc/kernel/module_32.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/8052d043a48f733905e8ea8f900bf58b441a317f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "module_trampoline_target"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces a heavy `copy_from_kernel_nofault()` call with four lighter calls to `copy_inst_from_kernel_nofault()` and avoids unnecessary checks for kernel space addresses.",
            "The optimization strategy replaces a heavy function call with multiple lighter calls to reduce overhead in a hot path.",
            "The optimization strategy replaces a heavy function call with multiple lighter calls to reduce overhead in a hot path.",
            "The optimization strategy replaces a heavy function call with multiple lighter calls to reduce overhead in a hot path.",
            "The optimization strategy replaces a heavy function call with multiple lighter calls to reduce overhead in a hot path."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaces a heavy function call with multiple lighter calls to reduce overhead in a hot path.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Paddle-Lite",
        "hash": "2356e47b9b6f7486373b3da0b1a5d2902fe0839c",
        "author": "xiehanlin",
        "date": "2021-04-26T10:34:33+08:00",
        "message": "[XPU] matmul improvement (#5934)",
        "modified_files_count": 1,
        "modified_files": [
            "lite/kernels/xpu/matmul_compute.cc"
        ],
        "github_commit_url": "https://github.com/PaddlePaddle/Paddle-Lite/commit/2356e47b9b6f7486373b3da0b1a5d2902fe0839c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MatMulCompute::Run"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the matrix multiplication (matmul) implementation for the XPU by leveraging more efficient computation techniques or reducing unnecessary overhead.",
            "The optimization strategy involved restructuring the matrix multiplication operation to improve cache locality and reduce memory access overhead on the XPU architecture.",
            "The optimization strategy involved restructuring the matrix multiplication logic to improve cache locality and reduce redundant computations.",
            "The optimization strategy involved improving the matrix multiplication (matmul) implementation for the XPU by leveraging more efficient computation techniques or reducing unnecessary overhead.",
            "The optimization strategy involved improving the matrix multiplication implementation for XPU by leveraging more efficient memory access patterns or hardware-specific optimizations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the matrix multiplication implementation for XPU by leveraging more efficient memory access patterns or hardware-specific optimizations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "c3c13db346749c3dfe45e167db2129c645377e9e",
        "author": "Haobo Xu",
        "date": "2013-05-21T13:40:38-07:00",
        "message": "[RocksDB] [Performance Bug] MemTable::Get Slow\n\nSummary:\nThe merge operator diff introduced a performance problem in MemTable::Get.\nAn exit condition is missed when the current key does not match the user key.\nThis could lead to full memtable scan if the user key is not found.\n\nTest Plan: make check; db_bench\n\nReviewers: dhruba\n\nReviewed By: dhruba\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D10851",
        "modified_files_count": 1,
        "modified_files": [
            "db/memtable.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/c3c13db346749c3dfe45e167db2129c645377e9e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MemTable::Get"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved adding an early exit condition in the MemTable::Get function to prevent unnecessary full memtable scans when the current key does not match the user key.",
            "The optimization strategy involved adding an early exit condition in the MemTable::Get function to prevent unnecessary full memtable scans when the current key does not match the user key.",
            "The optimization strategy involved adding an early exit condition in the MemTable::Get function to prevent unnecessary full scans when the current key does not match the user key.",
            "The optimization strategy involved adding an early exit condition in the MemTable::Get function to prevent unnecessary full memtable scans when the current key does not match the user key.",
            "The optimization strategy involved adding an early exit condition in the MemTable::Get function to prevent unnecessary full memtable scans when the current key does not match the user key."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adding an early exit condition in the MemTable::Get function to prevent unnecessary full memtable scans when the current key does not match the user key.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "intel-graphics-compiler",
        "hash": "6b74539efb3bf7e9409204da73a17436b4fad0ae",
        "author": "Yury Plyakhin",
        "date": "2024-06-28T13:43:51+02:00",
        "message": "Tune joint_matrix_apply unroll threshold\n\nFully unrolling joint_matrix_apply implementation loop doesn't work,\nwhen using sycl::stream from joint_matrix_apply. It causes very huge code size\nand compilation time is not practical.\nHence introducing the threshold, so that performance is still good,\nbut cases with sycl::stream can also work.",
        "modified_files_count": 1,
        "modified_files": [
            "IGC/Compiler/GenTTI.cpp"
        ],
        "github_commit_url": "https://github.com/intel/intel-graphics-compiler/commit/6b74539efb3bf7e9409204da73a17436b4fad0ae",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy introduces a threshold to limit loop unrolling in the joint_matrix_apply implementation to balance performance and code size/compilation time.",
            "The optimization strategy introduces a threshold to limit loop unrolling in the joint_matrix_apply implementation to balance performance and code size/compilation time.",
            "The optimization strategy introduces a threshold to limit loop unrolling in the joint_matrix_apply implementation to balance performance and code size/compilation time.",
            "The optimization strategy introduces a threshold to limit loop unrolling in the joint_matrix_apply implementation to balance performance and code size.",
            "The optimization strategy introduces a threshold to limit loop unrolling in the joint_matrix_apply implementation to balance performance and code size."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy introduces a threshold to limit loop unrolling in the joint_matrix_apply implementation to balance performance and code size/compilation time.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cheribsd",
        "hash": "85237d203bc9dfe549218c72686a611cff6368b4",
        "author": "maxim",
        "date": "2005-01-24T13:27:24+00:00",
        "message": "o Try hard to guess a buffer size for a fast growing routing table.\nAn approach taken from killall/killall.c.\n\nPR:\t\tbin/76075\nSubmitted by:\tDmitrij Tejblum\nMFC after:\t3 weeks",
        "modified_files_count": 1,
        "modified_files": [
            "usr.sbin/arp/arp.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/85237d203bc9dfe549218c72686a611cff6368b4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "search"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved dynamically estimating a buffer size to accommodate a rapidly growing routing table, reducing the need for frequent reallocations.",
            "The optimization strategy involved dynamically adjusting buffer size to accommodate a rapidly growing routing table.",
            "The optimization strategy involved dynamically adjusting buffer size to accommodate a rapidly growing routing table.",
            "The optimization strategy involved dynamically adjusting buffer size to accommodate a rapidly growing routing table, reducing the need for frequent reallocations.",
            "The optimization strategy involved dynamically adjusting buffer size to accommodate a rapidly growing routing table, reducing the need for frequent reallocations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved dynamically adjusting buffer size to accommodate a rapidly growing routing table, reducing the need for frequent reallocations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "vg",
        "hash": "14a6f862dce4ed1db61279d2912f99bdf1b63a6d",
        "author": "Adam Novak",
        "date": "2018-11-13T11:49:59-08:00",
        "message": "Adopt the new bin finding interface and speed up IndexedVG",
        "modified_files_count": 1,
        "modified_files": [
            "src/stream_index.cpp"
        ],
        "github_commit_url": "https://github.com/vgteam/vg/commit/14a6f862dce4ed1db61279d2912f99bdf1b63a6d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "StreamIndexBase::find"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adopting a new bin finding interface to improve the efficiency of the `IndexedVG` class by reducing unnecessary computations.",
            "The optimization strategy involved adopting a new bin finding interface to improve the speed of IndexedVG by reducing unnecessary computations.",
            "The optimization strategy involved adopting a new bin finding interface to improve the efficiency of the `IndexedVG` operations.",
            "The optimization strategy involved adopting a new bin finding interface to improve the speed of IndexedVG by reducing unnecessary computations.",
            "The optimization strategy involved adopting a new bin finding interface to improve the efficiency of the `IndexedVG` class by reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adopting a new bin finding interface to improve the speed of IndexedVG by reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "openvino",
        "hash": "d70d7b2171e34cc0132353104d7996df93e4d329",
        "author": "Roman Kazantsev",
        "date": "2022-08-23T11:56:48+04:00",
        "message": "[TF FE] Add Transpose Sinking for additional unary elementwise Operations (#12698)\n\n* [TF FE] Add Transpose Sinking for additional unary-wise Operations\r\n\r\nIt helps to fix performance degradation for MobileNet models\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add LogicalNot for Transpose sinking\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/frontends/tensorflow/src/pass/transpose_sinking.cpp"
        ],
        "github_commit_url": "https://github.com/openvinotoolkit/openvino/commit/d70d7b2171e34cc0132353104d7996df93e4d329",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ov::frontend::tensorflow::pass::TransposeSinking::run_on_model"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding transpose sinking for additional unary elementwise operations to reduce unnecessary data movement and improve performance.",
            "The optimization strategy involves adding transpose sinking support for additional unary elementwise operations to reduce unnecessary data rearrangements and improve performance for models like MobileNet.",
            "The optimization strategy involves adding transpose sinking for additional unary elementwise operations to reduce unnecessary data rearrangements and improve performance in MobileNet models.",
            "The optimization strategy involves adding transpose sinking for additional unary elementwise operations to reduce unnecessary data movement and improve performance.",
            "The optimization strategy involves adding transpose sinking for additional unary elementwise operations to reduce unnecessary data movement and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding transpose sinking for additional unary elementwise operations to reduce unnecessary data movement and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "selinux-kernel",
        "hash": "5b881c1f83792f5db421124171b06f1b8f1fe075",
        "author": "David Wang",
        "date": "2024-11-10T22:33:52+11:00",
        "message": "powerpc/irq: use seq_put_decimal_ull_width() for decimal values\n\nOn a system with n CPUs and m interrupts, there will be n*m decimal\nvalues yielded via seq_printf(..\"%10u \"..) which is less efficient\nthan seq_put_decimal_ull_width(), stress reading /proc/interrupts\nindicates ~30% performance improvement with this patch.\n\nSigned-off-by: David Wang <00107082@163.com>\n[mpe: Flesh out change log based on original submission]\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://lore.kernel.org/all/20241103080552.4787-1-00107082@163.com\nLink: https://patch.msgid.link/20241108162327.9887-1-00107082@163.com",
        "modified_files_count": 1,
        "modified_files": [
            "arch/powerpc/kernel/irq.c"
        ],
        "github_commit_url": "https://github.com/SELinuxProject/selinux-kernel/commit/5b881c1f83792f5db421124171b06f1b8f1fe075",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "arch_show_interrupts"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces `seq_printf` with `seq_put_decimal_ull_width` to improve the efficiency of formatting and outputting decimal values in `/proc/interrupts`.",
            "The optimization replaces `seq_printf` with `seq_put_decimal_ull_width` to improve the efficiency of formatting and outputting decimal values in `/proc/interrupts`.",
            "The optimization strategy replaces `seq_printf` with `seq_put_decimal_ull_width` to improve the efficiency of formatting and outputting decimal values in `/proc/interrupts`.",
            "The optimization replaces `seq_printf` with `seq_put_decimal_ull_width` to improve the efficiency of formatting and outputting decimal values in `/proc/interrupts`.",
            "The optimization replaces `seq_printf` with `seq_put_decimal_ull_width` to improve the efficiency of formatting and outputting decimal values in `/proc/interrupts`."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaces `seq_printf` with `seq_put_decimal_ull_width` to improve the efficiency of formatting and outputting decimal values in `/proc/interrupts`.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "192ad80d14ee5478e23fe4b7bed55f203748aec3",
        "author": "Subhash Jadavani",
        "date": "2016-03-22T10:57:38-07:00",
        "message": "scsi: ufs: change clock gating timeout to 50ms\n\nClock gating timeout is generally choosen such a way that it doesn't\nimpact storage benchmark performance numbers. Although current timeout\nvalue of 150ms seems high hence this change reduces it to 50ms to save\npower clock gating timeout. Reducing it to 50ms doesn't affect the\nstorage performance benchmark numbers.\n\nChange-Id: Ia131fc420995f44d8446f3800c19de40fedea504\nSigned-off-by: Subhash Jadavani <subhashj@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/scsi/ufs/ufshcd.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/192ad80d14ee5478e23fe4b7bed55f203748aec3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ufshcd_init_clk_gating"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy reduces the clock gating timeout from 150ms to 50ms to save power without impacting storage performance benchmark numbers.",
            "The optimization strategy reduces the clock gating timeout from 150ms to 50ms to save power without impacting storage performance benchmark numbers.",
            "The optimization strategy reduces the clock gating timeout from 150ms to 50ms to save power without impacting storage performance benchmark numbers.",
            "The optimization strategy reduces the clock gating timeout from 150ms to 50ms to save power without impacting storage performance benchmark numbers.",
            "The optimization strategy reduces the clock gating timeout from 150ms to 50ms to save power without impacting storage performance benchmark numbers."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the clock gating timeout from 150ms to 50ms to save power without impacting storage performance benchmark numbers.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_brcm_rpi",
        "hash": "59b49457fbd870b4d033159698c452f7248b57b1",
        "author": "Johannes Berg",
        "date": "2022-01-27T11:04:37+01:00",
        "message": "iwlwifi: mvm: synchronize with FW after multicast commands\n\n[ Upstream commit db66abeea3aefed481391ecc564fb7b7fb31d742 ]\n\nIf userspace installs a lot of multicast groups very quickly, then\nwe may run out of command queue space as we send the updates in an\nasynchronous fashion (due to locking concerns), and the CPU can\ncreate them faster than the firmware can process them. This is true\neven when mac80211 has a work struct that gets scheduled.\n\nFix this by synchronizing with the firmware after sending all those\ncommands - outside of the iteration we can send a synchronous echo\ncommand that just has the effect of the CPU waiting for the prior\nasynchronous commands to finish. This also will cause fewer of the\ncommands to be sent to the firmware overall, because the work will\nonly run once when rescheduled multiple times while it's running.\n\nLink: https://bugzilla.kernel.org/show_bug.cgi?id=213649\nSuggested-by: Emmanuel Grumbach <emmanuel.grumbach@intel.com>\nReported-by: Maximilian Ernestus <maximilian@ernestus.de>\nSigned-off-by: Johannes Berg <johannes.berg@intel.com>\nSigned-off-by: Luca Coelho <luciano.coelho@intel.com>\nLink: https://lore.kernel.org/r/iwlwifi.20211204083238.51aea5b79ea4.I88a44798efda16e9fe480fb3e94224931d311b29@changeid\nSigned-off-by: Luca Coelho <luciano.coelho@intel.com>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c"
        ],
        "github_commit_url": "https://github.com/lineage-rpi/android_kernel_brcm_rpi/commit/59b49457fbd870b4d033159698c452f7248b57b1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "iwl_mvm_recalc_multicast"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy synchronizes with the firmware after sending multicast commands to prevent command queue overflow by ensuring the CPU waits for the firmware to process asynchronous commands before proceeding.",
            "The optimization strategy synchronizes with the firmware after sending multicast commands to prevent command queue overflow and reduce the number of commands sent.",
            "The optimization strategy synchronizes with the firmware after sending multicast commands to prevent command queue overflow and reduce redundant commands.",
            "The optimization strategy synchronizes with the firmware after sending multicast commands to prevent command queue overflow by ensuring the CPU waits for the firmware to process asynchronous commands before proceeding.",
            "The optimization strategy synchronizes with the firmware after sending multicast commands to prevent command queue overflow and reduce the number of commands sent."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy synchronizes with the firmware after sending multicast commands to prevent command queue overflow and reduce the number of commands sent.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "c5c71fdbb6f4883c0729cd8f9c7498e8c2f5c647",
        "author": "Keith Bostic",
        "date": "2015-05-27T13:42:36-04:00",
        "message": "We were checking the wrong flags value for WT_SKIP_UPDATE_RESTORE; I\nthink the only result of this is that we refuse to evict some pages\nthat we can theoretically evict, so this may lead to failures and/or\nperformance improvements.",
        "modified_files_count": 1,
        "modified_files": [
            "src/evict/evict_page.c"
        ],
        "github_commit_url": "https://github.com/wiredtiger/wiredtiger/commit/c5c71fdbb6f4883c0729cd8f9c7498e8c2f5c647",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__evict_review"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "wiredtiger",
        "optimization_summary": [
            "The optimization fixes a logical error by checking the correct flags value for WT_SKIP_UPDATE_RESTORE, potentially allowing more pages to be evicted.",
            "The optimization fixes a logical error by checking the correct flags value for WT_SKIP_UPDATE_RESTORE, potentially allowing more pages to be evicted.",
            "The optimization fixes a logical error by checking the correct flags value for WT_SKIP_UPDATE_RESTORE, potentially allowing more pages to be evicted.",
            "The optimization fixes a logical error by checking the correct flags value for WT_SKIP_UPDATE_RESTORE, potentially allowing more pages to be evicted.",
            "The optimization fixes a logical error by checking the correct flags value for WT_SKIP_UPDATE_RESTORE, potentially allowing more pages to be evicted."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization fixes a logical error by checking the correct flags value for WT_SKIP_UPDATE_RESTORE, potentially allowing more pages to be evicted.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gambatte-libretro",
        "hash": "6c5cb46be6dd39a7d987c475b8d39415615a9bcc",
        "author": "sinamas",
        "date": "2008-10-15T00:10:50+00:00",
        "message": "Skip resampling when fast-forwarding\n\n\ngit-svn-id: https://gambatte.svn.sourceforge.net/svnroot/gambatte@169 9dfb2916-2d38-0410-aef4-c5fe6c9ffc24",
        "modified_files_count": 1,
        "modified_files": [
            "gambatte_sdl/src/gambatte_sdl.cpp"
        ],
        "github_commit_url": "https://github.com/libretro/gambatte-libretro/commit/6c5cb46be6dd39a7d987c475b8d39415615a9bcc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GambatteSdl::exec"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips resampling during fast-forwarding to reduce unnecessary computational overhead.",
            "The optimization strategy skips resampling during fast-forwarding to reduce unnecessary computational overhead.",
            "The optimization strategy skips resampling during fast-forwarding to reduce unnecessary computational overhead.",
            "The optimization strategy skips resampling during fast-forwarding to reduce unnecessary computational overhead.",
            "The optimization skips resampling during fast-forwarding to reduce unnecessary computational overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips resampling during fast-forwarding to reduce unnecessary computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "intel-graphics-compiler",
        "hash": "72334282a29ed09c28a5205339ec333bac869906",
        "author": "Dmitrichenko, Aleksei",
        "date": "2024-05-10T13:11:54+02:00",
        "message": "Improve CodeLoopSinking compilation time\n\nAdd a heuristic to check the candidates size on every iteration before\nrerunning the liveness analysis. Skip the rerun if the candidates size\nis too small to achieve the needed register pressure",
        "modified_files_count": 1,
        "modified_files": [
            "IGC/Compiler/CISACodeGen/CodeSinking.cpp"
        ],
        "github_commit_url": "https://github.com/intel/intel-graphics-compiler/commit/72334282a29ed09c28a5205339ec333bac869906",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization introduces a heuristic to skip unnecessary liveness analysis reruns by checking the candidate size on each iteration, reducing redundant computations.",
            "The optimization introduces a heuristic to skip unnecessary liveness analysis reruns by checking the candidate size on each iteration, reducing redundant computations.",
            "The optimization introduces a heuristic to skip unnecessary liveness analysis reruns by checking the candidate size, reducing compilation time.",
            "The optimization introduces a heuristic to skip unnecessary liveness analysis reruns by checking the candidate size on each iteration, reducing redundant computations.",
            "The optimization introduces a heuristic to skip unnecessary liveness analysis reruns by checking the candidate size on each iteration, reducing redundant computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization introduces a heuristic to skip unnecessary liveness analysis reruns by checking the candidate size on each iteration, reducing redundant computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_brcm_rpi",
        "hash": "30909f865bd6ad07653089736540115e3cda11ae",
        "author": "Pavel Begunkov",
        "date": "2023-03-01T11:38:25+00:00",
        "message": "UPSTREAM: io_uring: cmpxchg for poll arm refs release\n\n[ upstream commit 2f3893437a4ebf2e892ca172e9e122841319d675 ]\n\nReplace atomically substracting the ownership reference at the end of\narming a poll with a cmpxchg. We try to release ownership by setting 0\nassuming that poll_refs didn't change while we were arming. If it did\nchange, we keep the ownership and use it to queue a tw, which is fully\ncapable to process all events and (even tolerates spurious wake ups).\n\nIt's a bit more elegant as we reduce races b/w setting the cancellation\nflag and getting refs with this release, and with that we don't have to\nworry about any kinds of underflows. It's not the fastest path for\npolling. The performance difference b/w cmpxchg and atomic dec is\nusually negligible and it's not the fastest path.\n\nCc: stable@vger.kernel.org\nFixes: aa43477b04025 (\"io_uring: poll rework\")\nChange-Id: I31a129be59fb1a30e806b5c839e6b7c10224502e\nSigned-off-by: Pavel Begunkov <asml.silence@gmail.com>\nLink: https://lore.kernel.org/r/0c95251624397ea6def568ff040cad2d7926fd51.1668963050.git.asml.silence@gmail.com\nSigned-off-by: Jens Axboe <axboe@kernel.dk>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\n(cherry picked from commit 1d58849ac26f8bafd4aeb71d2b38a761c89186ae)\nBug: 268174392\nSigned-off-by: Greg Kroah-Hartman <gregkh@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fs/io_uring.c"
        ],
        "github_commit_url": "https://github.com/lineage-rpi/android_kernel_brcm_rpi/commit/30909f865bd6ad07653089736540115e3cda11ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__io_arm_poll_handler"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces an atomic subtraction operation with a compare-and-swap (cmpxchg) to reduce race conditions and improve correctness when releasing ownership references during poll arming.",
            "The optimization replaces an atomic subtraction operation with a cmpxchg operation to reduce race conditions and improve elegance in handling poll arm references.",
            "The optimization replaces an atomic subtraction operation with a compare-and-swap (cmpxchg) to reduce race conditions and simplify handling of ownership references during poll arming.",
            "The optimization replaces an atomic subtraction operation with a compare-and-swap (cmpxchg) to reduce race conditions and simplify handling of ownership references during poll arming.",
            "The optimization replaces an atomic subtraction operation with a compare-and-swap (cmpxchg) to reduce race conditions and simplify handling of ownership references during poll arming."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization replaces an atomic subtraction operation with a compare-and-swap (cmpxchg) to reduce race conditions and simplify handling of ownership references during poll arming.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "df4663be6a9dd427ee0b73a1ea47d6791e5dfc53",
        "author": "Matt Arsenault",
        "date": "2014-07-17T06:13:41+00:00",
        "message": "R600: Short circuit alloca check if address space isn't private.\n\nSkip calling GetUnderlyingObject in cases where it obviously\nisn't from an alloca. This should only be a compile time improvement.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@213229 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Target/R600/AMDGPUTargetTransformInfo.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/df4663be6a9dd427ee0b73a1ea47d6791e5dfc53",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AMDGPUTTI::getUnrollingPreferences"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves skipping unnecessary calls to `GetUnderlyingObject` by checking the address space upfront, reducing redundant computations during compilation.",
            "The optimization strategy short-circuits unnecessary calls to `GetUnderlyingObject` by checking the address space beforehand, reducing redundant computations during compilation.",
            "The optimization strategy involves skipping unnecessary calls to `GetUnderlyingObject` by checking the address space upfront, reducing redundant computations during compilation.",
            "The optimization strategy involves skipping unnecessary calls to `GetUnderlyingObject` by checking the address space upfront, reducing redundant computations during compilation.",
            "The optimization strategy short-circuits an unnecessary function call by checking the address space beforehand, reducing redundant computations during compilation."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves skipping unnecessary calls to `GetUnderlyingObject` by checking the address space upfront, reducing redundant computations during compilation.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "brltty",
        "hash": "bbea256f4e88987dde81b3eeecb9c72449381be1",
        "author": "Dave Mielke",
        "date": "2021-03-14T04:03:52-04:00",
        "message": "Improve the efficiency of not blinking capital letters. (dm)",
        "modified_files_count": 1,
        "modified_files": [
            "Programs/update.c"
        ],
        "github_commit_url": "https://github.com/brltty/brltty/commit/bbea256f4e88987dde81b3eeecb9c72449381be1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "translateScreenCharacterText"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary blinking of capital letters by directly checking character attributes instead of relying on a more computationally expensive method.",
            "The optimization avoids unnecessary blinking of capital letters by directly setting the text attribute without toggling.",
            "The optimization avoids unnecessary blinking of capital letters by directly setting the text attribute without toggling.",
            "The optimization avoids unnecessary blinking of capital letters by directly setting the text attribute without toggling.",
            "The optimization avoids unnecessary blinking of capital letters by directly setting the text attribute without toggling."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary blinking of capital letters by directly setting the text attribute without toggling.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "b6dad11d9cb105681abbfc3d57aae4b21bd0c8c4",
        "author": "Yury Norov",
        "date": "2022-06-03T06:52:57-07:00",
        "message": "arch/ia64: replace cpumask_weight with cpumask_empty where appropriate\n\nsetup_arch() calls cpumask_weight() to check if any bit of a given cpumask\nis set. We can do it more efficiently with cpumask_empty() because\ncpumask_empty() stops traversing the cpumask as soon as it finds first set\nbit, while cpumask_weight() counts all bits unconditionally.\n\nSigned-off-by: Yury Norov <yury.norov@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/ia64/kernel/setup.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/b6dad11d9cb105681abbfc3d57aae4b21bd0c8c4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "setup_arch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces a function that counts all set bits in a bitmask with one that stops traversal upon finding the first set bit, reducing unnecessary computation.",
            "The optimization replaces a function that counts all set bits in a bitmask with a more efficient one that stops traversal upon finding the first set bit.",
            "The optimization replaces a full bit-counting function with a short-circuiting check for any set bit to improve efficiency.",
            "The optimization replaces a full bit-counting function with a short-circuiting check for any set bit to improve efficiency.",
            "The optimization replaces a full bit-counting function with a short-circuiting check for any set bit to improve efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaces a full bit-counting function with a short-circuiting check for any set bit to improve efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "OpenMS",
        "hash": "9d00c20ae6169bf7aeaae6611063d7e88ff243ef",
        "author": "Samuel Wein",
        "date": "2019-03-08T13:09:36-05:00",
        "message": "[fix] Fixed RNaseDigestion::digest performance of unspecific cleavage on long RNAs.",
        "modified_files_count": 1,
        "modified_files": [
            "src/openms/source/CHEMISTRY/RNaseDigestion.cpp"
        ],
        "github_commit_url": "https://github.com/OpenMS/OpenMS/commit/9d00c20ae6169bf7aeaae6611063d7e88ff243ef",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations in the RNaseDigestion::digest function by improving the handling of unspecific cleavage on long RNAs.",
            "The optimization strategy involved reducing unnecessary computations in the RNaseDigestion::digest function by improving the logic for handling unspecific cleavage on long RNAs.",
            "The optimization strategy involved reducing unnecessary computations in the RNaseDigestion::digest function by improving the logic for handling unspecific cleavage on long RNAs.",
            "The optimization strategy involved reducing unnecessary computations in the RNaseDigestion::digest function by improving the logic for handling unspecific cleavage on long RNAs.",
            "The optimization strategy involved reducing unnecessary computations in the RNaseDigestion::digest function by improving the handling of unspecific cleavage on long RNAs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations in the RNaseDigestion::digest function by improving the logic for handling unspecific cleavage on long RNAs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "XRT",
        "hash": "6890d40225538860002a12f30a42d68b3de5c8bd",
        "author": "Saifuddin Kaijar",
        "date": "2024-10-24T14:25:03+05:30",
        "message": "Removed a debug msg which is a overhead of the performance for async operation. (#8565)\n\n* Removed some debug msg which is a overhead of the performance.\r\n\r\nSigned-off-by: Saifuddin <saifuddi@xilinx.com>\r\n\r\n* Commenting out debug msg which is a overhead of the performance.\r\n\r\nSigned-off-by: Saifuddin <saifuddi@xilinx.com>\r\n\r\n---------\r\n\r\nSigned-off-by: Saifuddin <saifuddi@xilinx.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/runtime_src/core/edge/user/aie/common_layer/adf_runtime_api.cpp"
        ],
        "github_commit_url": "https://github.com/Xilinx/XRT/commit/6890d40225538860002a12f30a42d68b3de5c8bd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gmio_api::enqueueBD"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing or commenting out debug messages to reduce performance overhead during asynchronous operations.",
            "The optimization strategy involved removing or commenting out debug messages to reduce performance overhead during asynchronous operations.",
            "The optimization strategy involved removing or commenting out debug messages to reduce performance overhead during asynchronous operations.",
            "The optimization strategy involved removing or commenting out debug messages to reduce performance overhead during asynchronous operations.",
            "The optimization strategy involved removing or commenting out debug messages to reduce performance overhead during asynchronous operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing or commenting out debug messages to reduce performance overhead during asynchronous operations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "151c99b1de34c0308c444dd3fd9c78b037bb7620",
        "author": "Sean Risser",
        "date": "2021-08-02T18:09:00+00:00",
        "message": "Optimize Lod and Grad texture sampling\n\nIf the Lod doesn't vary across any sample, then we can get away with\nperforming a single texture sample call. The added cost of a reactor If\nis balanced by potentially removing 3 calls altogether.\n\nBug: b/133868964\nBug: b/163791974\nTests: dEQP-VK.texture.subgroup_lod.texelfetch\nTests: dEQP-VK.glsl.texture_functions.texelfetch.*\nTests: dEQP-VK.glsl.texture_functions.texturelod.*\nTests: dEQP-VK.glsl.texture_functions.texturegrad.*\n\nChange-Id: Ib637653f78d3d5aa149352648c710d5f48526ede\nReviewed-on: https://swiftshader-review.googlesource.com/c/SwiftShader/+/55908\nTested-by: Sean Risser <srisser@google.com>\nCommit-Queue: Sean Risser <srisser@google.com>\nReviewed-by: Nicolas Capens <nicolascapens@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/Pipeline/SpirvShaderSampling.cpp"
        ],
        "github_commit_url": "https://github.com/google/swiftshader/commit/151c99b1de34c0308c444dd3fd9c78b037bb7620",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SpirvShader::emitSamplerRoutine"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "swiftshader",
        "optimization_summary": [
            "The optimization strategy avoids redundant texture sampling calls by performing a single sample when the Lod value is uniform across all samples.",
            "The optimization strategy avoids redundant texture sampling calls by performing a single sample when the Lod value is uniform across all samples.",
            "The optimization strategy avoids redundant texture sampling calls by performing a single sample when the Lod value is uniform across all samples.",
            "The optimization strategy avoids redundant texture sampling calls by performing a single sample when the Lod value is uniform across all samples.",
            "The optimization strategy avoids redundant texture sampling calls by performing a single sample when the Lod value is uniform across all samples."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids redundant texture sampling calls by performing a single sample when the Lod value is uniform across all samples.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "5082af8f2563848eb84e905cefb744f473de602b",
        "author": "Jonas Hahnfeld",
        "date": "2020-03-23T11:40:02+01:00",
        "message": "Implement xoutput_buffer::xsputn()\n\nThis outputs a string of characters which can be appendded more\nefficiently.",
        "modified_files_count": 1,
        "modified_files": [
            "include/xeus-cling/xbuffer.hpp"
        ],
        "github_commit_url": "https://github.com/jupyter-xeus/xeus-cling/commit/5082af8f2563848eb84e905cefb744f473de602b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "overflow"
        ],
        "is_opt_ds": "false",
        "is_opt_ds_simple": "true",
        "repository_name": "xeus-cling",
        "optimization_summary": [
            "The optimization strategy involved implementing a more efficient method for appending characters in bulk to reduce overhead.",
            "The optimization strategy involved implementing a more efficient `xsputn()` method to append strings in bulk rather than character by character.",
            "The optimization strategy involved implementing a more efficient method for appending characters in bulk to reduce overhead.",
            "The optimization strategy involved implementing a more efficient method for appending characters in bulk to reduce overhead.",
            "The optimization strategy involved implementing a more efficient method for appending characters in bulk to reduce overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved implementing a more efficient method for appending characters in bulk to reduce overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "c6d3ee209b9e863c6251f72101511340451ca324",
        "author": "Don Brace",
        "date": "2021-04-05T23:02:28-04:00",
        "message": "scsi: smartpqi: Use host-wide tag space\n\nCorrect SCSI midlayer sending more requests than exposed host queue depth\ncausing firmware ASSERT and lockup issues by enabling host-wide tags.\n\nNote: This also results in better performance.\n\nLink: https://lore.kernel.org/r/161549369787.25025.8975999483518581619.stgit@brunhilda\nSuggested-by: Ming Lei <ming.lei@redhat.com>\nSuggested-by: John Garry <john.garry@huawei.com>\nReviewed-by: Scott Benesh <scott.benesh@microchip.com>\nReviewed-by: Scott Teel <scott.teel@microchip.com>\nReviewed-by: Mike McGowen <mike.mcgowen@microchip.com>\nReviewed-by: Kevin Barnett <kevin.barnett@microchip.com>\nSigned-off-by: Don Brace <don.brace@microchip.com>\nSigned-off-by: Martin K. Petersen <martin.petersen@oracle.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/scsi/smartpqi/smartpqi_init.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/c6d3ee209b9e863c6251f72101511340451ca324",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pqi_register_scsi"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved enabling host-wide tags to prevent the SCSI midlayer from sending more requests than the host queue depth could handle, thereby avoiding firmware ASSERT and lockup issues while improving performance.",
            "The optimization strategy involved enabling host-wide tags to prevent the SCSI midlayer from sending more requests than the host queue depth could handle, thereby avoiding firmware ASSERT and lockup issues while improving performance.",
            "The optimization strategy involved enabling host-wide tags to prevent the SCSI midlayer from sending more requests than the host queue depth could handle, thereby avoiding firmware ASSERT and lockup issues while improving performance.",
            "The optimization strategy involved enabling host-wide tags to prevent the SCSI midlayer from sending more requests than the host queue depth could handle, thereby avoiding firmware ASSERT and lockup issues while improving performance.",
            "The optimization strategy involved enabling host-wide tags to prevent the SCSI midlayer from sending more requests than the host queue depth could handle, thereby avoiding firmware ASSERT and lockup issues while improving performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved enabling host-wide tags to prevent the SCSI midlayer from sending more requests than the host queue depth could handle, thereby avoiding firmware ASSERT and lockup issues while improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "server",
        "hash": "a3814e36356fb339f0d22d19a886a7bb68a9161f",
        "author": "Konstantin Osipov",
        "date": "2009-12-11T14:18:59+03:00",
        "message": "Backport of:\n-----------------------------------------------------------\n2630.28.28 Magne Mahre  2008-12-05\nBug #38661 'all threads hang in \"opening tables\" or \"waiting for table\"\n            and cpu is at 100%'\n                      \nConcurrent execution of FLUSH TABLES statement and at least two statements\nusing the same table might have led to live-lock which caused all three\nconnections to stall and hog 100% of CPU.\n        \ntdc_wait_for_old_versions() wrongly assumed that there cannot be a share\nwith an old version and no used TABLE instances and thus was failing to\nperform wait in situation when such old share was cached in MDL subsystem\nthanks to a still active metadata lock on the table. So it might have\nhappened that two or more connections simultaneously executing statements\nwhich involve table being flushed managed to prevent each other from\nwaiting in this function by keeping shared metadata lock on the table \nconstantly active (i.e. one of the statements managed to take/hold this\nlock while other statements were calling tdc_wait_for_old_versions()).\nThus they were forcing each other to loop infinitely in open_tables() - \nclose_thread_tables_for_reopen() - tdc_wait_for_old_versions() cycle\ncausing CPU hogging.\n        \nThis patch fixes this problem by removing this false assumption from\ntdc_wait_for_old_versions().\n \nNote that the problem is specific only for server versions >= 6.0.\n        \nNo test case is submitted for this test, as the test infrastructure\nhasn't got the necessary primitives to test the behaviour.  The\nmanifestation is that throughput will decrease to a low level\n(possibly 0) after some time, and stay at that level. Several\ntransactions will not complete. \n        \nManual testing can be done by running the code submitted by Shane \nBester attached to the bug report.  If the bug persists, the \ntransaction thruput will almost immediately drop to near zero \n(shown as the transaction count output from the test program staying \non a close to constant value, instead of increasing rapidly).",
        "modified_files_count": 1,
        "modified_files": [
            "sql/sql_base.cc"
        ],
        "github_commit_url": "https://github.com/MariaDB/server/commit/a3814e36356fb339f0d22d19a886a7bb68a9161f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tdc_wait_for_old_versions"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved correcting a false assumption in the `tdc_wait_for_old_versions` function to prevent live-lock conditions during concurrent table operations.",
            "The optimization strategy involved correcting a false assumption in the `tdc_wait_for_old_versions` function to prevent live-lock conditions during concurrent table operations.",
            "The optimization strategy involved correcting a false assumption in the `tdc_wait_for_old_versions` function to prevent live-lock conditions during concurrent table operations.",
            "The optimization strategy involved fixing a false assumption in the `tdc_wait_for_old_versions` function to prevent live-lock and infinite looping during concurrent table operations.",
            "The optimization strategy involved correcting a false assumption in the `tdc_wait_for_old_versions` function to prevent live-lock conditions during concurrent table operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved correcting a false assumption in the `tdc_wait_for_old_versions` function to prevent live-lock conditions during concurrent table operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mesos",
        "hash": "5253531a5d510f7962e964255103fb232d267ba2",
        "author": "haosdent huang",
        "date": "2016-07-12T16:56:39+02:00",
        "message": "Speeded up GarbageCollectorIntegrationTest.Restart.\n\nSpeed up GarbageCollectorIntegrationTest.Restart by\nreducing `executor_shutdown_grace_period`.\n\nReview: https://reviews.apache.org/r/43520/",
        "modified_files_count": 1,
        "modified_files": [
            "src/tests/gc_tests.cpp"
        ],
        "github_commit_url": "https://github.com/apache/mesos/commit/5253531a5d510f7962e964255103fb232d267ba2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the `executor_shutdown_grace_period` to decrease test execution time by allowing faster shutdowns.",
            "The optimization strategy involved reducing the `executor_shutdown_grace_period` to decrease test execution time by allowing faster shutdowns.",
            "The optimization strategy involved reducing the `executor_shutdown_grace_period` to decrease test execution time by allowing faster shutdowns.",
            "The optimization strategy involved reducing the `executor_shutdown_grace_period` to decrease test execution time by allowing faster shutdowns.",
            "The optimization strategy involved reducing the `executor_shutdown_grace_period` to decrease test execution time by allowing faster shutdowns."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the `executor_shutdown_grace_period` to decrease test execution time by allowing faster shutdowns.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "yugabyte-db",
        "hash": "ccaa910c3540a89beb078f1dd5f344fac7080441",
        "author": "Hamid Akhtar",
        "date": "2023-02-23T02:41:39+05:00",
        "message": "PG-542: Performance improvement of pg_stat_monitor.\n\nSaving the client IP address once per the lifetime of a backend. This avoid\nthe expensive operation multiple times, and hence improving performance\nsignificantly.",
        "modified_files_count": 1,
        "modified_files": [
            "pg_stat_monitor.c"
        ],
        "github_commit_url": "https://github.com/yugabyte/yugabyte-db/commit/ccaa910c3540a89beb078f1dd5f344fac7080441",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pgsm_create_hash_entry"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids redundant computation by caching the client IP address once per backend lifetime instead of recalculating it multiple times.",
            "The optimization strategy involves caching the client IP address once per backend lifetime to avoid repeated expensive operations.",
            "The optimization strategy avoids redundant computation by caching the client IP address once per backend lifetime instead of recalculating it multiple times.",
            "The optimization strategy involves caching the client IP address once per backend lifetime to avoid repeated expensive operations.",
            "The optimization strategy involves caching the client IP address once per backend lifetime to avoid repeated expensive operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves caching the client IP address once per backend lifetime to avoid repeated expensive operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gdal",
        "hash": "6f95bcec53aa9e83b8158d41b047d9063c584d10",
        "author": "Even Rouault",
        "date": "2017-03-04T18:11:13+00:00",
        "message": "Rasterlite: more efficient detection of Rasterlite compliant files\n\ngit-svn-id: https://svn.osgeo.org/gdal/trunk@37600 f0d54148-0727-0410-94bb-9a71ac55c965",
        "modified_files_count": 1,
        "modified_files": [
            "gdal/frmts/rasterlite/rasterlitedataset.cpp"
        ],
        "github_commit_url": "https://github.com/OSGeo/gdal/commit/6f95bcec53aa9e83b8158d41b047d9063c584d10",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RasterliteDataset::Open"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of detecting Rasterlite compliant files by refining the logic used in the detection process.",
            "The optimization strategy involved improving the efficiency of detecting Rasterlite compliant files by likely reducing unnecessary checks or iterations.",
            "The optimization strategy involved improving the efficiency of detecting Rasterlite compliant files by refining the logic used in the detection process.",
            "The optimization strategy involved improving the efficiency of detecting Rasterlite compliant files by likely refining the logic or reducing unnecessary operations in the detection process.",
            "The optimization strategy involved improving the efficiency of detecting Rasterlite compliant files by refining the logic used in the detection process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of detecting Rasterlite compliant files by refining the logic used in the detection process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dxvk-remix",
        "hash": "55007b042dc1a2d488dcefcfba16264f57ea89a8",
        "author": "Philip Rebohle",
        "date": "2018-03-23T11:54:19+01:00",
        "message": "[d3d11] Reset busy flag after emitting the Flush command\n\nFixes a general performance regression in games\nthat call WaitForResources a lot.",
        "modified_files_count": 1,
        "modified_files": [
            "src/d3d11/d3d11_context_imm.cpp"
        ],
        "github_commit_url": "https://github.com/NVIDIAGameWorks/dxvk-remix/commit/55007b042dc1a2d488dcefcfba16264f57ea89a8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "D3D11ImmediateContext::Flush"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves resetting a busy flag immediately after emitting a Flush command to prevent unnecessary stalls caused by frequent WaitForResources calls.",
            "The optimization strategy involves resetting a busy flag immediately after emitting a Flush command to prevent unnecessary stalls in games that frequently call WaitForResources.",
            "The optimization strategy involves resetting a busy flag immediately after emitting a Flush command to prevent unnecessary stalls in games that frequently call WaitForResources.",
            "The optimization strategy involves resetting a busy flag immediately after emitting a Flush command to prevent unnecessary stalls in games that frequently call WaitForResources.",
            "The optimization strategy involves resetting a busy flag immediately after emitting a Flush command to prevent unnecessary stalls in games that frequently call WaitForResources."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves resetting a busy flag immediately after emitting a Flush command to prevent unnecessary stalls in games that frequently call WaitForResources.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SPIRV-Tools",
        "hash": "51ecc7318f7aea8472cf49be768eac7f3236eeaa",
        "author": "Steven Perron",
        "date": "2018-02-21T09:50:47-05:00",
        "message": "Reduce instruction create and deletion during inlining.\n\nWhen inlining a function call the instructions in the same basic block\nas the call get cloned.  The clone is added to the set of new blocks\ncontaining the inlined code, and the original instructions are deleted.\n\nThis PR will change this so that we simply move the instructions to the\nnew blocks.  This saves on the creation and deletion of the\ninstructions.\n\nContributes to #1328.",
        "modified_files_count": 1,
        "modified_files": [
            "source/opt/inline_pass.cpp"
        ],
        "github_commit_url": "https://github.com/KhronosGroup/SPIRV-Tools/commit/51ecc7318f7aea8472cf49be768eac7f3236eeaa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "InlinePass::GenInlineCode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids redundant instruction creation and deletion by moving instructions instead of cloning and deleting them during function inlining.",
            "The optimization strategy avoids redundant instruction creation and deletion by directly moving instructions during inlining instead of cloning and deleting them.",
            "The optimization strategy avoids redundant instruction creation and deletion by directly moving instructions during inlining instead of cloning and deleting them.",
            "The optimization strategy avoids redundant instruction creation and deletion by directly moving instructions during inlining instead of cloning and deleting them.",
            "The optimization strategy avoids redundant instruction creation and deletion by moving instructions instead of cloning and deleting them during function inlining."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids redundant instruction creation and deletion by directly moving instructions during inlining instead of cloning and deleting them.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "geeqie",
        "hash": "a871f2934cd24dd852a1810a82d7029cf8cfb3e9",
        "author": "Vladimir Nadvornik",
        "date": "2008-06-08T20:24:46+00:00",
        "message": "vficon_sync speed-up",
        "modified_files_count": 1,
        "modified_files": [
            "src/view_file_icon.c"
        ],
        "github_commit_url": "https://github.com/BestImageViewer/geeqie/commit/a871f2934cd24dd852a1810a82d7029cf8cfb3e9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vficon_sync"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations inside a loop by caching results of expensive operations.",
            "The optimization strategy involved reducing redundant computations within the `vficon_sync` function by caching and reusing previously computed values.",
            "The optimization strategy involved reducing redundant computations inside a loop by caching results of expensive operations.",
            "The optimization strategy involved reducing redundant computations by caching and reusing previously calculated values within the function.",
            "The optimization strategy involved reducing redundant computations inside a loop by caching results of expensive operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations inside a loop by caching results of expensive operations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cheribsd",
        "hash": "69b475fb98d11a550e8751ebe27b9e40ff741eb7",
        "author": "Justin Hibbits",
        "date": "2021-10-18T22:32:01+01:00",
        "message": "powerpc: Optimize copyinstr() to avoid repeatedly mapping user strings\n\nCurrently copyinstr() uses fubyte() to read each byte from userspace.\nHowever, this means that for each byte, it calls pmap_map_user_ptr() to\nmap the string into memory.  This is needlessly wasteful, since the\nstring will rarely ever cross a segment boundary.  Instead, map a\nsegment at a time, and copy as much from that segment as possible at a\ntime.\n\nMeasured with the HPT pmap on powerpc64, this saves roughly 8% time on\nbuildkernel, and 5% on buildworld, in wallclock time.",
        "modified_files_count": 1,
        "modified_files": [
            "sys/powerpc/powerpc/copyinout.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/69b475fb98d11a550e8751ebe27b9e40ff741eb7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "REMAP"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces overhead by mapping larger memory segments at once instead of repeatedly mapping individual bytes.",
            "The optimization strategy reduces overhead by mapping entire memory segments at once instead of mapping individual bytes repeatedly.",
            "The optimization strategy reduces overhead by mapping larger memory segments at once instead of repeatedly mapping individual bytes.",
            "The optimization strategy reduces overhead by mapping larger memory segments at once instead of repeatedly mapping individual bytes.",
            "The optimization strategy reduces overhead by mapping larger memory segments at once instead of repeatedly mapping individual bytes from user space."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces overhead by mapping larger memory segments at once instead of repeatedly mapping individual bytes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "magnum",
        "hash": "00dbbd5ce2f2b7c65e13589424263ba32cd068f1",
        "author": "Vladimír Vondruš",
        "date": "2010-12-29T21:34:09+01:00",
        "message": "Optimization: using dot product for computing vector length.",
        "modified_files_count": 1,
        "modified_files": [
            "src/Math/Vector.h"
        ],
        "github_commit_url": "https://github.com/mosra/magnum/commit/00dbbd5ce2f2b7c65e13589424263ba32cd068f1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "length"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces a potentially more expensive vector length computation with a dot product, which is computationally simpler.",
            "The optimization strategy replaces a potentially more expensive vector length computation with a dot product-based approach to improve performance.",
            "The optimization strategy replaces a potentially more expensive vector length computation with a dot product, which is computationally simpler.",
            "The optimization strategy replaces a potentially more expensive vector length computation with a dot product, which is computationally simpler.",
            "The optimization strategy replaces a potentially more expensive vector length computation with a dot product, which is computationally simpler."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces a potentially more expensive vector length computation with a dot product, which is computationally simpler.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "clboss",
        "hash": "08336691e511ea540fda5684bb3172c07f098ead",
        "author": "ZmnSCPxj jxPCSnmZ",
        "date": "2020-10-27T21:26:21+08:00",
        "message": "Boss/Mod/FundsMover/Attempter.cpp: Speed up backing off on fuzzpercent.",
        "modified_files_count": 1,
        "modified_files": [
            "Boss/Mod/FundsMover/Attempter.cpp"
        ],
        "github_commit_url": "https://github.com/ZmnSCPxj/clboss/commit/08336691e511ea540fda5684bb3172c07f098ead",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fee_failed"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations by directly returning early when a condition is met, avoiding further processing.",
            "The optimization strategy involved reducing unnecessary computations by directly returning early when a condition is met, avoiding further processing.",
            "The optimization strategy involved reducing unnecessary computations by directly returning early when a condition is met, avoiding further processing.",
            "The optimization strategy involved reducing unnecessary computations by directly returning early when a condition is met, avoiding further processing.",
            "The optimization strategy involved reducing unnecessary computations by directly returning early when a condition is met, avoiding further processing."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations by directly returning early when a condition is met, avoiding further processing.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "scribus",
        "hash": "d3cebd9ed6dee55fd4ec06d182e518ead255bde3",
        "author": "Franz Schmid",
        "date": "2010-04-10T12:03:12+00:00",
        "message": "Optimized encoding of tensor patch data.\n\ngit-svn-id: svn://scribus.net/trunk/Scribus@14955 11d20701-8431-0410-a711-e3c959e3b870",
        "modified_files_count": 1,
        "modified_files": [
            "scribus/pdflib_core.cpp"
        ],
        "github_commit_url": "https://github.com/scribusproject/scribus/commit/d3cebd9ed6dee55fd4ec06d182e518ead255bde3",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of encoding tensor patch data by reducing redundant computations or iterations.",
            "The optimization strategy involved improving the encoding process for tensor patch data to reduce computational overhead.",
            "The optimization strategy involved improving the encoding process of tensor patch data to reduce computational overhead.",
            "The optimization strategy involved improving the efficiency of encoding tensor patch data by reducing redundant computations or streamlining the encoding process.",
            "The optimization strategy involved improving the efficiency of encoding tensor patch data by reducing redundant computations or streamlining the encoding process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of encoding tensor patch data by reducing redundant computations or streamlining the encoding process.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "169c935c243782ba615de0b36947b45fa3259623",
        "author": "Miika Pekkarinen",
        "date": "2005-10-30T07:38:52+00:00",
        "message": "Optimizations to the FLAC-codec buffer requesting to eliminate the\nneed of extra copying.\n\n\ngit-svn-id: svn://svn.rockbox.org/rockbox/trunk@7685 a1c6a512-1295-4272-9138-f99709370657",
        "modified_files_count": 1,
        "modified_files": [
            "apps/codecs/flac.c"
        ],
        "github_commit_url": "https://github.com/Rockbox/rockbox/commit/169c935c243782ba615de0b36947b45fa3259623",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "codec_start"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rockbox",
        "optimization_summary": [
            "The optimization strategy involved restructuring the FLAC-codec buffer handling to avoid unnecessary data copying by directly managing memory allocation and usage.",
            "The optimization strategy involved restructuring the FLAC-codec buffer handling to avoid unnecessary data copying by directly managing memory allocation and usage.",
            "The optimization strategy involved restructuring the FLAC-codec buffer handling to avoid unnecessary data copying by directly managing memory allocation and usage.",
            "The optimization strategy involved restructuring the FLAC-codec buffer handling to avoid unnecessary data copying by directly managing memory allocation and usage.",
            "The optimization strategy involved restructuring the FLAC-codec buffer handling to avoid unnecessary data copying by directly managing memory allocation and usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the FLAC-codec buffer handling to avoid unnecessary data copying by directly managing memory allocation and usage.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "951b8c875ac905aa9d348c825c380e7ce66c0f62",
        "author": "Ivan T. Ivanov",
        "date": "2015-08-17T11:32:43+02:00",
        "message": "mmc: sdhci-msm: Boost controller core clock\n\nEnsure SDCC is working with maximum clock otherwise card\ndetection could be extremely slow, up to 7 seconds.\n\nSigned-off-by: Ivan T. Ivanov <ivan.ivanov@linaro.org>\nReviewed-by: Georgi Djakov <georgi.djakov@linaro.org>\nAcked-by: Stephen Boyd <sboyd@codeaurora.org>\nSigned-off-by: Ulf Hansson <ulf.hansson@linaro.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/mmc/host/sdhci-msm.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/951b8c875ac905aa9d348c825c380e7ce66c0f62",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sdhci_msm_probe"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involves boosting the controller core clock to ensure faster card detection by operating SDCC at its maximum clock speed.",
            "The optimization strategy involves increasing the controller core clock speed to improve card detection performance.",
            "The optimization strategy involved increasing the SDCC controller's core clock speed to improve card detection performance.",
            "The optimization strategy involves boosting the controller core clock to ensure faster card detection by operating SDCC at its maximum clock speed.",
            "The optimization strategy involves increasing the controller core clock speed to improve card detection performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves boosting the controller core clock to ensure faster card detection by operating SDCC at its maximum clock speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mpv",
        "hash": "7ac154065f3acbb38afba7fc0eccd3adf8208ced",
        "author": "Uoti Urpala",
        "date": "2011-12-06T07:47:46+02:00",
        "message": "commands: playback speed: better responsiveness without audio\n\nAdjust the scheduled time until next frame when changing playback\nspeed (only affects behavior without audio). The main case where this\nmakes a difference is when it would take a noticeably long time to\nswitch frames with the previous speed and you switch to a faster\nspeed.",
        "modified_files_count": 1,
        "modified_files": [
            "command.c"
        ],
        "github_commit_url": "https://github.com/mpv-player/mpv/commit/7ac154065f3acbb38afba7fc0eccd3adf8208ced",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mp_property_playback_speed"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization adjusts the scheduled time for the next frame when changing playback speed to improve responsiveness during faster playback without audio.",
            "The optimization adjusts the scheduled time for the next frame when changing playback speed to improve responsiveness during faster playback without audio.",
            "The optimization adjusts the scheduled time for the next frame when changing playback speed to improve responsiveness during faster playback without audio.",
            "The optimization adjusts the scheduled time for the next frame when changing playback speed to improve responsiveness during faster playback without audio.",
            "The optimization adjusts the scheduling of frame updates when changing playback speed to improve responsiveness in audio-less playback by reducing delays during speed transitions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization adjusts the scheduled time for the next frame when changing playback speed to improve responsiveness during faster playback without audio.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "9862717afe19e2a2481006c09145cc6d1377d87a",
        "author": "Jeff Roberson",
        "date": "2007-08-20T06:34:20+00:00",
        "message": "- Set steal_thresh to log2(ncpus).  This improves idle-time load balancing\n   on 2cpu machines by reducing it to 1 by default.  This improves loaded\n   operation on 8cpu machines by increasing it to 3 where the extra idle\n   time is not as critical.\n\nApproved by:\tre",
        "modified_files_count": 1,
        "modified_files": [
            "sys/kern/sched_ule.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/9862717afe19e2a2481006c09145cc6d1377d87a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sched_initticks"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization adjusts the `steal_thresh` parameter to be dynamically set based on the logarithm of the number of CPUs, improving load balancing efficiency across different CPU configurations.",
            "The optimization adjusts the `steal_thresh` parameter to scale logarithmically with the number of CPUs, improving load balancing efficiency across varying CPU counts.",
            "The optimization strategy adjusts the `steal_thresh` parameter based on the logarithm of the number of CPUs to improve load balancing efficiency across different machine configurations.",
            "The optimization adjusts the `steal_thresh` parameter to be dynamically set based on the logarithm of the number of CPUs, improving load balancing efficiency across different machine configurations.",
            "The optimization adjusts the `steal_thresh` parameter to scale logarithmically with the number of CPUs, improving load balancing efficiency across varying CPU counts."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization adjusts the `steal_thresh` parameter to be dynamically set based on the logarithm of the number of CPUs, improving load balancing efficiency across different CPU configurations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "1a624832a06b465d0e5651901bcbc3680c78d374",
        "author": "Neil Horman",
        "date": "2010-03-16T21:23:23-07:00",
        "message": "tipc: Increase frequency of load distribution over broadcast link\n\nForward port commit 29eb572941501c40ac6e62dbc5043bf9ee76ee56\nfrom git://tipc.cslab.ericsson.net/pub/git/people/allan/tipc.git\n\nOrigional commit message:\nIncrease frequency of load distribution over broadcast link\n\nThis patch enhances the behavior of TIPC's broadcast link so that it\nalternates between redundant bearers (if available) after every\nmessage sent, rather than after every 10 messages.  This change helps\nto speed up delivery of retransmitted messages by ensuring that\nthey are not sent repeatedly over a bearer that is no longer working,\nbut not yet recognized as failed.\n\nTested by myself in the latest net-2.6 tree using the tipc sanity test suite\n\nOrigionally-signed-off-by: Allan Stephens <allan.stephens@windriver.com>\nSigned-off-by: Neil Horman <nhorman@tuxdriver.com>\n\nbcast.c |   35 ++++++++++++++---------------------\n1 file changed, 14 insertions(+), 21 deletions(-)\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "net/tipc/bcast.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/1a624832a06b465d0e5651901bcbc3680c78d374",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tipc_bcbearer_send"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy alternates between redundant bearers after every message sent instead of every 10 messages to improve load distribution and speed up retransmission delivery.",
            "The optimization strategy alternates between redundant bearers after every message sent instead of every 10 messages to improve load distribution and speed up retransmission delivery.",
            "The optimization strategy alternates between redundant bearers after every message sent instead of every 10 messages to improve load distribution and speed up retransmission delivery.",
            "The optimization strategy alternates between redundant bearers after every message sent instead of every 10 messages to improve load distribution and speed up retransmission delivery.",
            "The optimization strategy alternates between redundant bearers after every message sent instead of every 10 messages to improve load distribution and speed up retransmission delivery."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy alternates between redundant bearers after every message sent instead of every 10 messages to improve load distribution and speed up retransmission delivery.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qt",
        "hash": "628fd7d141013dcda06d13fa644f44029f317a8c",
        "author": "Ritt Konstantin",
        "date": "2011-06-09T17:34:14+02:00",
        "message": "get rid of extra copying (another one)\n\nin the static toCFStringRef(const QString &string) method, the string's lifecycle\nis unkown and thus, to ensure the data consistency, it copies the string's data\nto the newly created CFStringRef object.\n\nbut operator CFStringRef() is an other case - here we know that the source string's\nlifetime is limited by the same QCFString object as the resulting CFStringRef;\nso, we could use the string's internal buffer as a CFStringRef's one w/o any\nvisible changes (well, except of some speed-up :) )\n\nMerge-request: 2615\nReviewed-by: Denis Dzyubenko <denis.dzyubenko@nokia.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/corelib/kernel/qcore_mac.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qt/commit/628fd7d141013dcda06d13fa644f44029f317a8c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CFStringRef"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary copying by directly using the internal buffer of a QString when converting to CFStringRef, leveraging lifetime guarantees within the same object.",
            "The optimization avoids unnecessary copying by directly using the internal buffer of a QString when converting to CFStringRef, leveraging knowledge of the string's lifetime.",
            "The optimization avoids unnecessary copying of string data by directly using the internal buffer when the source string's lifetime is guaranteed to match the resulting CFStringRef.",
            "The optimization avoids unnecessary copying of string data by directly using the internal buffer of the source string when the lifetimes of the source and target are known to align.",
            "The optimization avoids unnecessary copying by directly using the internal buffer of a QString when creating a CFStringRef, leveraging knowledge of the string's lifecycle."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary copying by directly using the internal buffer of a QString when converting to CFStringRef, leveraging knowledge of the string's lifetime.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Quake3e",
        "hash": "75f36180fe1eabdb72b346a460dccfbcb81836bf",
        "author": "eugene",
        "date": "2011-05-02T09:03:08+00:00",
        "message": "Add: and/or x86 qvm optimizations",
        "modified_files_count": 1,
        "modified_files": [
            "code/qcommon/vm_x86.c"
        ],
        "github_commit_url": "https://github.com/ec-/Quake3e/commit/75f36180fe1eabdb72b346a460dccfbcb81836bf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VM_Compile"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved implementing x86-specific QVM (Quake Virtual Machine) optimizations to improve performance by leveraging architecture-specific features.",
            "The optimization strategy involved implementing x86-specific QVM (Quake Virtual Machine) optimizations to improve performance by leveraging architecture-specific features.",
            "The optimization strategy involved improving the x86 QVM compiler to generate more efficient bytecode, likely by reducing unnecessary operations or improving instruction selection.",
            "The optimization strategy involved enhancing the x86 QVM compiler to generate more efficient machine code, likely by improving instruction selection or reducing unnecessary operations.",
            "The optimization strategy involved implementing x86-specific QVM (Quake Virtual Machine) optimizations to improve performance by leveraging architecture-specific features."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved implementing x86-specific QVM (Quake Virtual Machine) optimizations to improve performance by leveraging architecture-specific features.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "AdaptiveCpp",
        "hash": "fc29646db1886c4300c0eaa77ca3f9bdbdeeb243",
        "author": "Joachim Meyer",
        "date": "2021-04-09T15:24:20+02:00",
        "message": "[LoopSplit] Add vectorization MD to latch terminator.\n\nThis should tell the vectorizer to vectorize the work-item loops.",
        "modified_files_count": 1,
        "modified_files": [
            "src/compiler/LoopSplitter.cpp"
        ],
        "github_commit_url": "https://github.com/AdaptiveCpp/AdaptiveCpp/commit/fc29646db1886c4300c0eaa77ca3f9bdbdeeb243",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "inlineSplitterCallTree"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding metadata to the loop latch terminator to enable vectorization of work-item loops by the compiler.",
            "The optimization strategy involves adding metadata to the loop latch terminator to enable vectorization of work-item loops by the compiler.",
            "The optimization strategy involves adding metadata to the loop latch terminator to enable vectorization of work-item loops by the compiler.",
            "The optimization strategy involves adding metadata to the loop latch terminator to enable vectorization of work-item loops by the compiler.",
            "The optimization strategy involves adding metadata to the loop latch terminator to enable vectorization of work-item loops."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves adding metadata to the loop latch terminator to enable vectorization of work-item loops by the compiler.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "darktable",
        "hash": "85868b2c4cf39e468b960b0f7a09cd5c03f7df2b",
        "author": "Aurélien PIERRE",
        "date": "2020-10-05T12:53:34+02:00",
        "message": "fast_guided_filter.h : improve vectorization with early buffer copying\n\nReduce I/O and improve data-locality\nAdd more comments",
        "modified_files_count": 1,
        "modified_files": [
            "src/common/fast_guided_filter.h"
        ],
        "github_commit_url": "https://github.com/darktable-org/darktable/commit/85868b2c4cf39e468b960b0f7a09cd5c03f7df2b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "variance_analyse"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving vectorization and data locality by performing early buffer copying to reduce I/O overhead.",
            "The optimization strategy involved improving vectorization by performing early buffer copying to reduce I/O operations and enhance data locality.",
            "The optimization strategy involved improving vectorization by copying buffers earlier to reduce I/O operations and enhance data locality.",
            "The optimization strategy involved improving vectorization by copying buffers earlier to reduce I/O operations and enhance data locality.",
            "The optimization strategy involved improving vectorization by copying buffers earlier to reduce I/O overhead and enhance data locality."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved improving vectorization by copying buffers earlier to reduce I/O operations and enhance data locality.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "scummvm",
        "hash": "db19310ad106db774f752383fea54c8c3af26ebb",
        "author": "Nicola Mettifogo",
        "date": "2007-10-15T19:00:46+00:00",
        "message": "Cut down screen updates when palette is not animated: should lead to performance increase on systems with low resources\n\nsvn-id: r29225",
        "modified_files_count": 1,
        "modified_files": [
            "engines/parallaction/graphics.cpp"
        ],
        "github_commit_url": "https://github.com/scummvm/scummvm/commit/db19310ad106db774f752383fea54c8c3af26ebb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Gfx::animatePalette"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces unnecessary screen updates by checking if the palette is animated before performing updates, thus saving computational resources.",
            "The optimization reduces unnecessary screen updates by checking if the palette is animated before performing updates, thus saving computational resources.",
            "The optimization reduces unnecessary screen updates by checking if the palette is animated before performing updates, thus saving resources on low-performance systems.",
            "The optimization reduces unnecessary screen updates by checking if the palette is animated before performing updates, thus saving computational resources.",
            "The optimization reduces unnecessary screen updates by checking if the palette is animated before performing updates, thus saving computational resources."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces unnecessary screen updates by checking if the palette is animated before performing updates, thus saving computational resources.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "6abe341558abec40c9c44d76e7fb4fb3978e894b",
        "author": "Jonathan Wakely",
        "date": "2022-06-14T21:07:48+01:00",
        "message": "libstdc++: Check lengths first in operator== for basic_string [PR62187]\n\nAs confirmed by LWG 2852, the calls to traits_type::compare do not need\nto be obsvervable, so we can make operator== compare string lengths\nfirst and return immediately for non-equal lengths. This avoids doing a\nslow string comparison for \"abc...xyz\" == \"abc...xy\". Previously we only\ndid this optimization for std::char_traits<char>, but we can enable it\nunconditionally thanks to LWG 2852.\n\nFor comparisons with a const char* we can call traits_type::length right\naway to do the same optimization. That strlen call can be folded away\nfor constant arguments, making it very efficient.\n\nFor the pre-C++20 operator== and operator!= overloads we can swap the\norder of the arguments to take advantage of the operator== improvements.\n\nlibstdc++-v3/ChangeLog:\n\n\tPR libstdc++/62187\n\t* include/bits/basic_string.h (operator==): Always compare\n\tlengths before checking string contents.\n\t[!__cpp_lib_three_way_comparison] (operator==, operator!=):\n\tReorder arguments.",
        "modified_files_count": 1,
        "modified_files": [
            "libstdc++-v3/include/bits/basic_string.h"
        ],
        "github_commit_url": "https://github.com/Rust-GCC/gccrs/commit/6abe341558abec40c9c44d76e7fb4fb3978e894b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_GLIBCXX_VISIBILITY"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "gccrs",
        "optimization_summary": [
            "The optimization strategy involves comparing string lengths before performing a full content comparison to avoid unnecessary slow operations.",
            "The optimization strategy involves comparing string lengths before performing a full content comparison to avoid unnecessary slow operations.",
            "The optimization strategy involves comparing string lengths before performing a full content comparison to avoid unnecessary slow operations.",
            "The optimization strategy involves comparing string lengths before performing a full content comparison to avoid unnecessary slow operations.",
            "The optimization strategy involves comparing string lengths before performing a full content comparison to avoid unnecessary slow operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves comparing string lengths before performing a full content comparison to avoid unnecessary slow operations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qtbase",
        "hash": "36aaf851ff2814e9e5c024e21b866c403137ff26",
        "author": "John Lindgren",
        "date": "2016-05-24T10:39:00+00:00",
        "message": "Optimize QIconLoader::findIconHelper()\n\nProfiling QIconLoader::findIconHelper() shows that a significant portion of CPU time is being spent in\nQDir::exists(), which creates a new QFileInfo object for the sole purpose of determining whether the passed-in\nfile path is relative or absolute, and then calls QFile::exists(). In this context, we can just as easily\ngenerate the absolute path and call QFile::exists() directly, avoiding the creation of extra QDir and QFileInfo\nobjects.\n\nChange-Id: Ib0b4568b6c16d423eb6c1b15158e44ff141e6175\nTask-number: QTBUG-46767\nReviewed-by: Gunnar Sletta <gunnar@sletta.org>",
        "modified_files_count": 1,
        "modified_files": [
            "src/gui/image/qiconloader.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qtbase/commit/36aaf851ff2814e9e5c024e21b866c403137ff26",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "QIconLoader::findIconHelper"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary object creation by directly generating the absolute path and calling QFile::exists() instead of using QDir::exists().",
            "The optimization avoids unnecessary object creation by directly generating the absolute path and calling QFile::exists() instead of using QDir::exists().",
            "The optimization avoids unnecessary object creation by directly generating the absolute path and calling QFile::exists() instead of using QDir::exists().",
            "The optimization avoids unnecessary object creation by directly generating the absolute path and calling QFile::exists() instead of using QDir::exists().",
            "The optimization avoids unnecessary object creation by directly generating the absolute path and calling QFile::exists() instead of using QDir::exists()."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary object creation by directly generating the absolute path and calling QFile::exists() instead of using QDir::exists().",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "wget-lua",
        "hash": "8610b0b355b56c87b9326a71beb21934b15dd17d",
        "author": "Tim Rühsen",
        "date": "2020-02-14T11:14:02+01:00",
        "message": "* src/main.c (main): Code clean, reduce allocations",
        "modified_files_count": 1,
        "modified_files": [
            "src/main.c"
        ],
        "github_commit_url": "https://github.com/ArchiveTeam/wget-lua/commit/8610b0b355b56c87b9326a71beb21934b15dd17d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary memory allocations by reusing existing variables or structures within the `main` function.",
            "The optimization strategy involved reducing unnecessary memory allocations by reusing existing variables or structures within the `main` function.",
            "The optimization strategy involved reducing unnecessary memory allocations by reusing existing variables or structures within the `main` function.",
            "The optimization strategy involved reducing memory allocations by reusing existing variables and minimizing dynamic memory operations within the `main` function.",
            "The optimization strategy involved reducing unnecessary memory allocations by reusing existing variables or structures within the `main` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary memory allocations by reusing existing variables or structures within the `main` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qmcpack",
        "hash": "a75e0d22a37f4ef7e1243da38031549f6de20dde",
        "author": "Jeongnim Kim",
        "date": "2005-11-29T15:50:12+00:00",
        "message": "Do not add in-memory data for optimization. Use the data set by setStatus.\n\n\ngit-svn-id: https://subversion.assembla.com/svn/qmcdev/trunk@824 e5b18d87-469d-4833-9cc0-8cdfa06e9491",
        "modified_files_count": 1,
        "modified_files": [
            "src/QMCApp/QMCMain.cpp"
        ],
        "github_commit_url": "https://github.com/QMCPACK/qmcpack/commit/a75e0d22a37f4ef7e1243da38031549f6de20dde",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary in-memory data addition by reusing pre-set status data.",
            "The optimization avoids unnecessary in-memory data addition by reusing pre-existing data set via `setStatus`.",
            "The optimization avoids unnecessary in-memory data addition by reusing pre-set data from `setStatus`.",
            "The optimization avoids unnecessary in-memory data addition by reusing pre-existing data set via `setStatus`.",
            "The optimization avoids unnecessary in-memory data addition by reusing pre-existing data set via `setStatus`."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary in-memory data addition by reusing pre-existing data set via `setStatus`.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pipewire",
        "hash": "8608c03b76b20aa4a1e4786e32799f13d82e9e25",
        "author": "Dimitrios Katsaros",
        "date": "2024-02-14T15:03:31+00:00",
        "message": "alsa: Reduce jitter in irq based software timestamping\n\nWe would timestamp within an unlikely block, which would introduce\nadditional jitter to current_time, which would have an impact on\nthe performance of the timer sensitive code.",
        "modified_files_count": 1,
        "modified_files": [
            "spa/plugins/alsa/alsa-pcm.c"
        ],
        "github_commit_url": "https://github.com/PipeWire/pipewire/commit/8608c03b76b20aa4a1e4786e32799f13d82e9e25",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "alsa_wakeup_event"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved moving timestamping outside of an unlikely block to reduce jitter in IRQ-based software timestamping, improving timer-sensitive code performance.",
            "The optimization strategy involved moving the timestamping operation outside of an unlikely block to reduce jitter in IRQ-based software timestamping.",
            "The optimization strategy involved moving the timestamping operation outside of an unlikely block to reduce jitter in irq-based software timestamping.",
            "The optimization strategy involved moving timestamping outside of an unlikely block to reduce jitter in IRQ-based software timestamping, improving timer-sensitive code performance.",
            "The optimization strategy involved moving timestamping outside of an unlikely block to reduce jitter in timer-sensitive code."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved moving timestamping outside of an unlikely block to reduce jitter in IRQ-based software timestamping, improving timer-sensitive code performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MoarVM",
        "hash": "543258ab10120c1cefcec86cda62b408f740c164",
        "author": "Stefan Seifert",
        "date": "2021-04-17T15:00:38+02:00",
        "message": "Propagate spesh facts after eliminating unuseed log guards\n\nWhen turning unused log guards into plain sets (with the goal of getting rid of\nthem completely via set elimination) copy the input facts to the output to\nunlock further optimization between log guard and set elimination.",
        "modified_files_count": 1,
        "modified_files": [
            "src/spesh/optimize.c"
        ],
        "github_commit_url": "https://github.com/MoarVM/MoarVM/commit/543258ab10120c1cefcec86cda62b408f740c164",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "eliminate_unused_log_guards"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves propagating specialization facts after eliminating unused log guards to enable further optimizations.",
            "The optimization strategy involves propagating specialization facts after eliminating unused log guards to enable further optimizations.",
            "The optimization propagates specialization facts after eliminating unused log guards to enable further optimizations.",
            "The optimization propagates spesh facts after eliminating unused log guards to enable further optimizations through fact-based reasoning.",
            "The optimization strategy involves propagating specialization facts after eliminating unused log guards to enable further optimizations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves propagating specialization facts after eliminating unused log guards to enable further optimizations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "QGIS",
        "hash": "b759fc924af554dcaad7f2c2613e6123bbf7bbbb",
        "author": "Nyall Dawson",
        "date": "2018-02-19T16:56:44+11:00",
        "message": "Prepare expression for faster field calculation in attribute table dialog",
        "modified_files_count": 1,
        "modified_files": [
            "src/app/qgsattributetabledialog.cpp"
        ],
        "github_commit_url": "https://github.com/qgis/QGIS/commit/b759fc924af554dcaad7f2c2613e6123bbf7bbbb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "QgsAttributeTableDialog::runFieldCalculation"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved preparing expressions in advance to reduce redundant calculations during field computations in the attribute table dialog.",
            "The optimization strategy involved preparing expressions in advance to reduce redundant calculations during field computations in the attribute table dialog.",
            "The optimization strategy involved preparing expressions in advance to reduce redundant calculations during field computation in the attribute table dialog.",
            "The optimization strategy involved preparing expressions in advance to reduce redundant calculations during field computation in the attribute table dialog.",
            "The optimization strategy involved preparing expressions in advance to reduce redundant calculations during field computations in the attribute table dialog."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved preparing expressions in advance to reduce redundant calculations during field computations in the attribute table dialog.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_xiaomi_sm8150",
        "hash": "553679474b531a17f27d39bca2c30715df06c2f0",
        "author": "Vinayak Menon",
        "date": "2018-07-05T11:41:47-07:00",
        "message": "lowmemorykiller: avoid false adaptive LMK triggers\n\nIn vmpressure notifier of LMK, shift_adj would have been set\nby a previous invocation of notifier, which is not followed by\na lowmem_shrink yet. If this is follwed by a lower vmpressure,\nand then by a lowmem_shrink, ALMK still triggers because of the\nprevious higher vmpressure notification. This is wrong.\nSince vmpressure has improved, reset shift_adj to avoid false\nadaptive LMK trigger.\n\nChange-Id: I2d77103d7c8f4d8a66e4652cba78e619a7bcef9a\nSigned-off-by: Vinayak Menon <vinmenon@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/staging/android/lowmemorykiller.c"
        ],
        "github_commit_url": "https://github.com/Laulan56/android_kernel_xiaomi_sm8150/commit/553679474b531a17f27d39bca2c30715df06c2f0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "lmk_vmpressure_notifier"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy resets the `shift_adj` value in the vmpressure notifier to prevent false triggers of the adaptive Low Memory Killer (LMK) due to stale state from previous notifications.",
            "The optimization strategy resets the `shift_adj` variable in the vmpressure notifier to prevent false triggers of the adaptive lowmemorykiller (ALMK) due to stale state from previous notifications.",
            "The optimization strategy resets the `shift_adj` variable in the vmpressure notifier to prevent false triggers of the adaptive lowmemorykiller (ALMK) due to stale state from previous notifications.",
            "The optimization strategy resets the `shift_adj` variable in the vmpressure notifier to prevent false triggers of the adaptive lowmemorykiller (ALMK) due to stale state from previous notifications.",
            "The optimization strategy resets the `shift_adj` variable in the vmpressure notifier to prevent false triggers of the adaptive lowmemorykiller (ALMK) due to stale state from previous notifications."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy resets the `shift_adj` variable in the vmpressure notifier to prevent false triggers of the adaptive lowmemorykiller (ALMK) due to stale state from previous notifications.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "barebox",
        "hash": "e48141941199a1a8a05880e95fc8d2455484f135",
        "author": "Sascha Hauer",
        "date": "2025-02-24T10:09:29+01:00",
        "message": "fip: Store image data in single buffer\n\nRight now in fip_parse() we read the whole FIP image into an allocated\nbuffer, then allocate buffers for the different blobs contained in the\nFIP image and memcpy the blobs there from the full buffer. Let's\noptimize this a bit by keeping the full buffer. Instead of allocating\nseparate buffers for the blobs, just put pointers to the full buffers\ninto struct fip_image and set the buf_no_free flag indicating that they\nshould not be freed.\n\nLink: https://lore.kernel.org/r/20250217122538.3216703-1-s.hauer@pengutronix.de\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/fip.c"
        ],
        "github_commit_url": "https://github.com/barebox/barebox/commit/e48141941199a1a8a05880e95fc8d2455484f135",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fip_parse"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy eliminates redundant memory allocations and copies by storing image data in a single buffer and using pointers to reference specific sections.",
            "The optimization strategy eliminates redundant memory allocations and copies by reusing a single buffer for image data and referencing its segments instead of creating separate buffers.",
            "The optimization strategy eliminates redundant memory allocations and copies by storing image data in a single buffer and using pointers to reference specific sections.",
            "The optimization strategy eliminates redundant memory allocations and copies by storing image data in a single buffer and using pointers to reference specific sections.",
            "The optimization strategy eliminates redundant memory allocations and copies by storing image data in a single buffer and using pointers to reference specific sections."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy eliminates redundant memory allocations and copies by storing image data in a single buffer and using pointers to reference specific sections.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "treesheets",
        "hash": "f8bacf728184bf1533048e0c7d21d7d883e50a33",
        "author": "Tobias Predel",
        "date": "2023-10-14T11:59:03-07:00",
        "message": "Tune the input for the hash (#542)\n\nProfiling TreeSheets shows that hashing the entire image data\r\ntakes up a lot of time.\r\n\r\nThis commit tweaks this by just hashing a specific chunk of the image\r\ndata at its beginning.",
        "modified_files_count": 1,
        "modified_files": [
            "src/system.h"
        ],
        "github_commit_url": "https://github.com/aardappel/treesheets/commit/f8bacf728184bf1533048e0c7d21d7d883e50a33",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AddImageToList"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces hashing time by limiting the input to only a specific chunk of the image data at its beginning instead of hashing the entire image data.",
            "The optimization strategy reduces hashing time by limiting the input to a specific chunk of the image data at its beginning instead of hashing the entire image data.",
            "The optimization strategy reduces hashing time by limiting the input to only a specific chunk of the image data at its beginning instead of hashing the entire image data.",
            "The optimization strategy reduces hashing time by limiting the input to only a specific chunk of the image data at its beginning instead of hashing the entire image data.",
            "The optimization strategy reduces hashing time by limiting the input to a specific chunk of the image data at its beginning instead of hashing the entire image data."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces hashing time by limiting the input to only a specific chunk of the image data at its beginning instead of hashing the entire image data.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "poedit",
        "hash": "6b893be6e7c383df45ae9cc2dac886d29c74d5f9",
        "author": "Václav Slavík",
        "date": "2024-05-06T18:52:05+02:00",
        "message": "Optimize writing POT files\n\nBe more efficient when writing POT files - don't retrieve and format translation which is known\nto be \"\".\n\nCoincidentally this fixes a crash introduced by 1ed2ac37.",
        "modified_files_count": 1,
        "modified_files": [
            "src/catalog_po.cpp"
        ],
        "github_commit_url": "https://github.com/vslavik/poedit/commit/6b893be6e7c383df45ae9cc2dac886d29c74d5f9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "POCatalog::DoSaveOnly"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids retrieving and formatting translations known to be empty strings when writing POT files.",
            "The optimization avoids retrieving and formatting translations known to be empty strings when writing POT files.",
            "The optimization avoids retrieving and formatting translations known to be empty strings when writing POT files.",
            "The optimization avoids unnecessary retrieval and formatting of empty translations when writing POT files.",
            "The optimization avoids unnecessary retrieval and formatting of empty translations when writing POT files."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids retrieving and formatting translations known to be empty strings when writing POT files.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dealii",
        "hash": "723f41aa2dd617dad4529463225c400cd2075bce",
        "author": "Daniel Arndt",
        "date": "2019-01-29T11:01:49+01:00",
        "message": "performance-unnecessary-value-param",
        "modified_files_count": 1,
        "modified_files": [
            "source/base/hdf5.cc"
        ],
        "github_commit_url": "https://github.com/dealii/dealii/commit/723f41aa2dd617dad4529463225c400cd2075bce",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HDF5Object::set_attribute"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a value parameter with a reference parameter to avoid unnecessary copying of data.",
            "The optimization strategy involved replacing a value parameter with a reference parameter to avoid unnecessary copying of data.",
            "The optimization strategy involved replacing a value parameter with a reference parameter to avoid unnecessary copying of data.",
            "The optimization strategy involved replacing a value parameter with a reference parameter to avoid unnecessary copying of data.",
            "The optimization strategy involved replacing a value parameter with a reference parameter to avoid unnecessary copying of data."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a value parameter with a reference parameter to avoid unnecessary copying of data.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "JankyBorders",
        "hash": "5e7fa9d13737407b768bafae894352cc1d714bbc",
        "author": "Felix Kratz",
        "date": "2024-02-08T11:55:28+01:00",
        "message": "limit blur radius for performance reasons",
        "modified_files_count": 1,
        "modified_files": [
            "src/parse.c"
        ],
        "github_commit_url": "https://github.com/FelixKratz/JankyBorders/commit/5e7fa9d13737407b768bafae894352cc1d714bbc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "parse_settings"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved limiting the blur radius to reduce computational overhead during image processing.",
            "The optimization strategy involved limiting the blur radius to reduce computational overhead during image processing.",
            "The optimization strategy involved limiting the blur radius to reduce computational overhead during image processing.",
            "The optimization strategy involved limiting the blur radius to reduce computational overhead during image processing.",
            "The optimization strategy involved limiting the blur radius to reduce computational overhead during image processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved limiting the blur radius to reduce computational overhead during image processing.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "1d7912955b3abc434d9d0e6aa73b2c142df9f0b8",
        "author": "Nils Wallménius",
        "date": "2007-10-05T21:03:56+00:00",
        "message": "Get rid of unnecessary memory acesses in a loop, gives slight speedup\n\ngit-svn-id: svn://svn.rockbox.org/rockbox/trunk@14996 a1c6a512-1295-4272-9138-f99709370657",
        "modified_files_count": 1,
        "modified_files": [
            "apps/plugins/midi/midiplay.c"
        ],
        "github_commit_url": "https://github.com/Rockbox/rockbox/commit/1d7912955b3abc434d9d0e6aa73b2c142df9f0b8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "synthbuf"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rockbox",
        "optimization_summary": [
            "The optimization strategy eliminates redundant memory accesses within a loop to improve performance.",
            "The optimization strategy eliminates redundant memory accesses within a loop to improve performance.",
            "The optimization strategy eliminates redundant memory accesses within a loop to improve performance.",
            "The optimization strategy eliminates redundant memory accesses within a loop to improve performance.",
            "The optimization strategy eliminates redundant memory accesses within a loop to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy eliminates redundant memory accesses within a loop to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "samsung-exynos9820",
        "hash": "4515bbc4e284066d4e2f4a66eccf13813f6e7206",
        "author": "Tetsuo Handa",
        "date": "2018-12-13T09:18:50+01:00",
        "message": "mm: don't warn about allocations which stall for too long\n\n[ Upstream commit 400e22499dd92613821374c8c6c88c7225359980 ]\n\nCommit 63f53dea0c98 (\"mm: warn about allocations which stall for too\nlong\") was a great step for reducing possibility of silent hang up\nproblem caused by memory allocation stalls.  But this commit reverts it,\nfor it is possible to trigger OOM lockup and/or soft lockups when many\nthreads concurrently called warn_alloc() (in order to warn about memory\nallocation stalls) due to current implementation of printk(), and it is\ndifficult to obtain useful information due to limitation of synchronous\nwarning approach.\n\nCurrent printk() implementation flushes all pending logs using the\ncontext of a thread which called console_unlock().  printk() should be\nable to flush all pending logs eventually unless somebody continues\nappending to printk() buffer.\n\nSince warn_alloc() started appending to printk() buffer while waiting\nfor oom_kill_process() to make forward progress when oom_kill_process()\nis processing pending logs, it became possible for warn_alloc() to force\noom_kill_process() loop inside printk().  As a result, warn_alloc()\nsignificantly increased possibility of preventing oom_kill_process()\nfrom making forward progress.\n\n---------- Pseudo code start ----------\nBefore warn_alloc() was introduced:\n\n  retry:\n    if (mutex_trylock(&oom_lock)) {\n      while (atomic_read(&printk_pending_logs) > 0) {\n        atomic_dec(&printk_pending_logs);\n        print_one_log();\n      }\n      // Send SIGKILL here.\n      mutex_unlock(&oom_lock)\n    }\n    goto retry;\n\nAfter warn_alloc() was introduced:\n\n  retry:\n    if (mutex_trylock(&oom_lock)) {\n      while (atomic_read(&printk_pending_logs) > 0) {\n        atomic_dec(&printk_pending_logs);\n        print_one_log();\n      }\n      // Send SIGKILL here.\n      mutex_unlock(&oom_lock)\n    } else if (waited_for_10seconds()) {\n      atomic_inc(&printk_pending_logs);\n    }\n    goto retry;\n---------- Pseudo code end ----------\n\nAlthough waited_for_10seconds() becomes true once per 10 seconds,\nunbounded number of threads can call waited_for_10seconds() at the same\ntime.  Also, since threads doing waited_for_10seconds() keep doing\nalmost busy loop, the thread doing print_one_log() can use little CPU\nresource.  Therefore, this situation can be simplified like\n\n---------- Pseudo code start ----------\n  retry:\n    if (mutex_trylock(&oom_lock)) {\n      while (atomic_read(&printk_pending_logs) > 0) {\n        atomic_dec(&printk_pending_logs);\n        print_one_log();\n      }\n      // Send SIGKILL here.\n      mutex_unlock(&oom_lock)\n    } else {\n      atomic_inc(&printk_pending_logs);\n    }\n    goto retry;\n---------- Pseudo code end ----------\n\nwhen printk() is called faster than print_one_log() can process a log.\n\nOne of possible mitigation would be to introduce a new lock in order to\nmake sure that no other series of printk() (either oom_kill_process() or\nwarn_alloc()) can append to printk() buffer when one series of printk()\n(either oom_kill_process() or warn_alloc()) is already in progress.\n\nSuch serialization will also help obtaining kernel messages in readable\nform.\n\n---------- Pseudo code start ----------\n  retry:\n    if (mutex_trylock(&oom_lock)) {\n      mutex_lock(&oom_printk_lock);\n      while (atomic_read(&printk_pending_logs) > 0) {\n        atomic_dec(&printk_pending_logs);\n        print_one_log();\n      }\n      // Send SIGKILL here.\n      mutex_unlock(&oom_printk_lock);\n      mutex_unlock(&oom_lock)\n    } else {\n      if (mutex_trylock(&oom_printk_lock)) {\n        atomic_inc(&printk_pending_logs);\n        mutex_unlock(&oom_printk_lock);\n      }\n    }\n    goto retry;\n---------- Pseudo code end ----------\n\nBut this commit does not go that direction, for we don't want to\nintroduce a new lock dependency, and we unlikely be able to obtain\nuseful information even if we serialized oom_kill_process() and\nwarn_alloc().\n\nSynchronous approach is prone to unexpected results (e.g.  too late [1],\ntoo frequent [2], overlooked [3]).  As far as I know, warn_alloc() never\nhelped with providing information other than \"something is going wrong\".\nI want to consider asynchronous approach which can obtain information\nduring stalls with possibly relevant threads (e.g.  the owner of\noom_lock and kswapd-like threads) and serve as a trigger for actions\n(e.g.  turn on/off tracepoints, ask libvirt daemon to take a memory dump\nof stalling KVM guest for diagnostic purpose).\n\nThis commit temporarily loses ability to report e.g.  OOM lockup due to\nunable to invoke the OOM killer due to !__GFP_FS allocation request.\nBut asynchronous approach will be able to detect such situation and emit\nwarning.  Thus, let's remove warn_alloc().\n\n[1] https://bugzilla.kernel.org/show_bug.cgi?id=192981\n[2] http://lkml.kernel.org/r/CAM_iQpWuPVGc2ky8M-9yukECtS+zKjiDasNymX7rMcBjBFyM_A@mail.gmail.com\n[3] commit db73ee0d46379922 (\"mm, vmscan: do not loop on too_many_isolated for ever\"))\n\nLink: http://lkml.kernel.org/r/1509017339-4802-1-git-send-email-penguin-kernel@I-love.SAKURA.ne.jp\nSigned-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>\nReported-by: Cong Wang <xiyou.wangcong@gmail.com>\nReported-by: yuwang.yuwang <yuwang.yuwang@alibaba-inc.com>\nReported-by: Johannes Weiner <hannes@cmpxchg.org>\nAcked-by: Michal Hocko <mhocko@suse.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Vlastimil Babka <vbabka@suse.cz>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Dave Hansen <dave.hansen@intel.com>\nCc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>\nCc: Petr Mladek <pmladek@suse.com>\nCc: Steven Rostedt <rostedt@goodmis.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\n\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\n\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/page_alloc.c"
        ],
        "github_commit_url": "https://github.com/CruelKernel/samsung-exynos9820/commit/4515bbc4e284066d4e2f4a66eccf13813f6e7206",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__alloc_pages_slowpath"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing synchronous warning mechanisms in memory allocation stalls to prevent potential deadlocks and improve system responsiveness under concurrent thread execution.",
            "The optimization strategy involved removing synchronous warning mechanisms in memory allocation stalls to prevent potential deadlocks and improve system responsiveness during high contention scenarios.",
            "The optimization strategy involved removing synchronous warning mechanisms to prevent potential deadlocks and performance issues caused by concurrent memory allocation stalls.",
            "The optimization strategy involved removing synchronous warning mechanisms to prevent potential deadlocks and improve system responsiveness during memory allocation stalls.",
            "The optimization strategy removes synchronous warning mechanisms in memory allocation stalls to prevent potential deadlocks and improve system responsiveness by avoiding printk buffer contention."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing synchronous warning mechanisms to prevent potential deadlocks and improve system responsiveness during memory allocation stalls.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SkyEmu",
        "hash": "3e23c26d5a82fccf4b40bb07055566f8b54553f4",
        "author": "kylon",
        "date": "2023-09-30T23:01:35-07:00",
        "message": "tinydir: tinydir_readfile: minor optimization\n\ndon't strlen the same string multiple times",
        "modified_files_count": 1,
        "modified_files": [
            "src/tinydir.h"
        ],
        "github_commit_url": "https://github.com/skylersaleh/SkyEmu/commit/3e23c26d5a82fccf4b40bb07055566f8b54553f4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tinydir_open"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant calls to `strlen` on the same string by caching its result.",
            "The optimization strategy avoids redundant calls to `strlen` on the same string by caching its result.",
            "The optimization strategy avoids redundant calls to `strlen` on the same string by caching its result.",
            "The optimization avoids redundant calls to `strlen` on the same string by caching its result.",
            "The optimization strategy avoids redundant calls to `strlen` on the same string by caching its result."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids redundant calls to `strlen` on the same string by caching its result.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "6ffd24a8832690534281b0563d99340fd8783bc2",
        "author": "Porteries Tristan",
        "date": "2016-10-24T17:29:26+00:00",
        "message": "UPBGE: Don't sort object for transparency object in shadow render.\n\nPreviously the transparent object render for simple shadow was using\na sort. But sorting object for the shadow render is useless because\nonly alpha clip will have effect on the shadows, and alpha clip is\norder independant.\n\nRemoving the object sort optimize by two the render time of a transparent\nobject.",
        "modified_files_count": 1,
        "modified_files": [
            "source/gameengine/Rasterizer/RAS_BucketManager.cpp"
        ],
        "github_commit_url": "https://github.com/UPBGE/upbge/commit/6ffd24a8832690534281b0563d99340fd8783bc2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RAS_BucketManager::Renderbuckets"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "upbge",
        "optimization_summary": [
            "The optimization removes an unnecessary sort operation for transparent objects during shadow rendering, as alpha clipping (which affects shadows) is order-independent.",
            "The optimization removes an unnecessary sort operation for transparent objects during shadow rendering, as sorting does not affect the outcome for alpha-clipped shadows.",
            "The optimization removes an unnecessary sort operation for transparent objects during shadow rendering, as alpha clipping (which affects shadows) is order-independent.",
            "The optimization removes an unnecessary sort operation for transparent objects during shadow rendering, as alpha clipping (which affects shadows) is order-independent.",
            "The optimization removes an unnecessary sort operation for transparent objects during shadow rendering, as alpha clipping (which affects shadows) is order-independent."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes an unnecessary sort operation for transparent objects during shadow rendering, as alpha clipping (which affects shadows) is order-independent.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "05d4234208df0777ea8d8da9dceda200222d5a58",
        "author": "Ashod Nakashian",
        "date": "2016-11-02T13:21:44+00:00",
        "message": "loolwsd: more efficient client message forwarding\n\nChange-Id: I10f880059380599cf0187064e1009bef5fa693b1\nReviewed-on: https://gerrit.libreoffice.org/30492\nReviewed-by: Ashod Nakashian <ashnakash@gmail.com>\nTested-by: Ashod Nakashian <ashnakash@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "loolwsd/DocumentBroker.cpp"
        ],
        "github_commit_url": "https://github.com/CollaboraOnline/online/commit/05d4234208df0777ea8d8da9dceda200222d5a58",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DocumentBroker::forwardToClient"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "online",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant message copying and improving the efficiency of client message forwarding by directly referencing shared data structures.",
            "The optimization strategy involved reducing redundant message processing by directly forwarding client messages in a more efficient manner.",
            "The optimization strategy involved reducing redundant message processing by directly forwarding client messages in a more efficient manner.",
            "The optimization strategy involved reducing redundant message processing by directly forwarding client messages in a more efficient manner.",
            "The optimization strategy involved reducing redundant data copying and improving message forwarding efficiency by directly referencing client messages."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant message processing by directly forwarding client messages in a more efficient manner.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "b71a94aa1891db7333dbd3b48d6b03ab6c980295",
        "author": "Thibaud Michaud",
        "date": "2023-08-01T13:20:10+00:00",
        "message": "Reland^3 \"[wasm] Do not inline export wrappers for JSPI\"\n\nThis is a reland of commit 9b7d2a9cd9bbcec35d5008a43056bfd1e1914a81\nAlso make the write to the Code::builtin_id field atomic to fix\nthe last tsan failure.\n\nOriginal change's description:\n> Reland \"Reland \"[wasm] Do not inline export wrappers for JSPI\"\"\n>\n> This is a reland of commit 9ee1ba176a52b9ba6f8a773f7b0a5f1d9c77e4af\n> Change: also load the builtin ID of the wrapper code object with\n> an atomic relaxed load to avoid another data race. (Note: the failure\n> that caused the revert is actually not caused by this CL. This is an\n> unrelated fix for v8:14220).\n>\n> Original change's description:\n> > Reland \"[wasm] Do not inline export wrappers for JSPI\"\n> >\n> > This is a reland of commit f43a566ce60a5e22be10ed77ebea807dcdd82a18\n> >\n> > The issue was a data race between a background compilation thread\n> > reading the wrapper_code field to check if we can inline it, and the\n> > generic wrapper tier-up trying to update the wrapper_code.\n> >\n> > It does not matter whether we read the value before or after the\n> > tier-up, so just get the field with a relaxed load.\n> >\n> > Original change's description:\n> > > [wasm] Do not inline export wrappers for JSPI\n> > >\n> > > To preserve the \"JSPI behavior\" of the exported function, do not inline\n> > > the optimized js-to-wasm wrapper at the call site. Keep using the\n> > > special WasmReturnPromiseOnSuspend builtin.\n> > >\n> > > R=ahaas@chromium.org\n> > >\n> > > Bug: v8:12191,v8:14200\n> > > Change-Id: I93a8b0293c0c96541c336a90317cee03410dcfd6\n> > > Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4711685\n> > > Commit-Queue: Thibaud Michaud <thibaudm@chromium.org>\n> > > Reviewed-by: Andreas Haas <ahaas@chromium.org>\n> > > Cr-Commit-Position: refs/heads/main@{#89151}\n> >\n> > Bug: v8:12191,v8:14200\n> > Change-Id: I30459d98dd9f1942780cba344dee118011fa98bd\n> > Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4714608\n> > Reviewed-by: Andreas Haas <ahaas@chromium.org>\n> > Reviewed-by: Tobias Tebbi <tebbi@chromium.org>\n> > Commit-Queue: Thibaud Michaud <thibaudm@chromium.org>\n> > Cr-Commit-Position: refs/heads/main@{#89195}\n>\n> Bug: v8:12191,v8:14200,v8:14220\n> Change-Id: Ifed60ad4b246ab8190fc511bc3b2bf182004c43a\n> Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4720865\n> Commit-Queue: Thibaud Michaud <thibaudm@chromium.org>\n> Reviewed-by: Andreas Haas <ahaas@chromium.org>\n> Cr-Commit-Position: refs/heads/main@{#89230}\n\nBug: v8:12191,v8:14200,v8:14220,v8:14227\nChange-Id: I28468f35c6e91d966a030bc40eab25d254c8e516\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4727683\nCommit-Queue: Thibaud Michaud <thibaudm@chromium.org>\nReviewed-by: Tobias Tebbi <tebbi@chromium.org>\nCr-Commit-Position: refs/heads/main@{#89286}",
        "modified_files_count": 1,
        "modified_files": [
            "src/objects/code-inl.h"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/b71a94aa1891db7333dbd3b48d6b03ab6c980295",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Code::set_builtin_id"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids inlining export wrappers for JSPI to preserve specific behavior and uses atomic relaxed loads to prevent data races.",
            "The optimization strategy avoids inlining export wrappers for JSPI to preserve specific behavior and uses atomic relaxed loads to prevent data races.",
            "The optimization strategy avoids inlining export wrappers for JSPI to preserve specific behavior and uses atomic operations to prevent data races.",
            "The optimization strategy avoids inlining export wrappers for JSPI to preserve specific behavior and uses atomic relaxed loads to prevent data races.",
            "The optimization strategy avoids inlining export wrappers for JSPI to preserve specific behavior and uses atomic relaxed loads to prevent data races."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids inlining export wrappers for JSPI to preserve specific behavior and uses atomic relaxed loads to prevent data races.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gcc",
        "hash": "43b8153c26655a7a00f1584fcb4f511dc5e45fab",
        "author": "Jonathan Wakely",
        "date": "2024-08-23T13:39:35+01:00",
        "message": "libstdc++: Only use std::time_put in std::format for non-C locales\n\nWhen testing on Solaris I noticed that std/time/year/io.cc was FAILing\nbecause the year 1642 was being formatted as \"+(\" by %Ey. This turns out\nto be because we defer to std::time_put for modified conversion specs,\nand std::time_put uses std::strftime, and that's undefined for years\nbefore 1970. In particular, years before 1900 mean that the tm_year\nfield is negative, which then causes incorrect results from strftime on\nat least Solaris and AIX.\n\nI've raised the general problem with LWG, but we can fix the FAILing\ntest case (and probably improve performance slightly) by ignoring the E\nand O modifiers when the formatting locale is the \"C\" locale. The\nmodifiers have no effect for the C locale, so we can just treat %Ey as\n%y and format it directly. This doesn't fix anything when the formatting\nlocale isn't the C locale, but that case is not adequately tested, so\ndoesn't cause any FAIL right now!\n\nThe naïve fix would be simply:\n\n  if (__mod)\n    if (auto __loc = _M_locale(__ctx); __loc != locale::classic())\n      // ...\n\nHowever when the format string doesn't use the 'L' option, _M_locale\nalways returns locale::classic(). In that case, we make a copy of the\nclassic locale (which calls the non-inline copy constructor in\nthe library), then make another copy of the classic locale, then compare\nthe two. We can avoid all that by checking for the 'L' option first,\ninstead of letting _M_locale do that:\n\n  if (__mod && _M_spec._M_localized)\n    if (auto __loc = __ctx.locale(); __loc != locale::classic())\n      // ...\n\nWe could optimize this further if we had a __is_classic(__loc) function\nthat would do the __loc == locale::classic() check without making any\ncopies or non-inline calls. That would require examining the locale's\n_M_impl member, and probably require checking its name, because the\nlocale::_S_classic singleton is not exported from the library.\n\nFor _M_S the change is slightly different from the other functions,\nbecause if we skip using std::time_put for %OS then we fall through to\nthe code that potentially prints fractional seconds, but the %OS format\nonly prints whole seconds. So we need to format whole seconds directly\nwhen not using std::time_put, instead of falling through to the code\nbelow.\n\nlibstdc++-v3/ChangeLog:\n\n\t* include/bits/chrono_io.h (__formatter_chrono::_M_C_y_Y):\n\tIgnore modifiers unless the formatting locale is not the C\n\tlocale.\n\t(__formatter_chrono::_M_d_e): Likewise.\n\t(__formatter_chrono::_M_H_I): Likewise.\n\t(__formatter_chrono::_M_m): Likewise.\n\t(__formatter_chrono::_M_M): Likewise.\n\t(__formatter_chrono::_M_S): Likewise.\n\t(__formatter_chrono::_M_u_w): Likewise.\n\t(__formatter_chrono::_M_U_V_W): Likewise.",
        "modified_files_count": 1,
        "modified_files": [
            "libstdc++-v3/include/bits/chrono_io.h"
        ],
        "github_commit_url": "https://github.com/gcc-mirror/gcc/commit/43b8153c26655a7a00f1584fcb4f511dc5e45fab",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_GLIBCXX_VISIBILITY"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary locale object copies and comparisons by checking for the 'L' option and directly handling formatting for the \"C\" locale without using `std::time_put`.",
            "The optimization avoids unnecessary locale object copies and comparisons by checking for the 'L' option and directly comparing with the classic locale before invoking `std::time_put`.",
            "The optimization avoids unnecessary locale object copies and comparisons by checking for the 'L' option and directly comparing with the classic locale before invoking `std::time_put`.",
            "The optimization avoids unnecessary locale object copies and comparisons by checking for the 'L' option and directly handling formatting for the \"C\" locale without using `std::time_put`.",
            "The optimization avoids unnecessary locale object copies and comparisons by checking for the 'L' option and directly comparing with the classic locale before invoking `std::time_put`."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary locale object copies and comparisons by checking for the 'L' option and directly comparing with the classic locale before invoking `std::time_put`.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llpc",
        "hash": "763e6a5d4837d350fcb6d74fc6289deb2e7fa389",
        "author": "rtayl",
        "date": "2019-08-01T15:41:24+08:00",
        "message": "Add !invariant.load to load descriptor sets\n\nThis adds the !invariant.load metadata to load descriptor sets\nin order for opts like cse to better optimize these loads\n\nAdd !invariant.load to load descriptor sets\n\nThis adds the !invariant.load metadata to load descriptor sets\nin order for opts like cse to better optimize these loads",
        "modified_files_count": 1,
        "modified_files": [
            "patch/llpcPatchDescriptorLoad.cpp"
        ],
        "github_commit_url": "https://github.com/GPUOpen-Drivers/llpc/commit/763e6a5d4837d350fcb6d74fc6289deb2e7fa389",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PatchDescriptorLoad::LoadDescriptor"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding `!invariant.load` metadata to descriptor set loads to enable compiler optimizations like common subexpression elimination (CSE).",
            "The optimization strategy involves adding `!invariant.load` metadata to descriptor set loads to enable compiler optimizations like Common Subexpression Elimination (CSE).",
            "The optimization strategy involves adding `!invariant.load` metadata to descriptor set loads to enable compiler optimizations like Common Subexpression Elimination (CSE).",
            "The optimization strategy involves adding `!invariant.load` metadata to descriptor set loads to enable compiler optimizations like Common Subexpression Elimination (CSE).",
            "The optimization strategy involves adding `!invariant.load` metadata to descriptor set loads to enable compiler optimizations like common subexpression elimination (CSE)."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves adding `!invariant.load` metadata to descriptor set loads to enable compiler optimizations like common subexpression elimination (CSE).",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "restbed",
        "hash": "8e15cbcb2ad397a8f3c2e54e32dcf9311f3e61be",
        "author": "developer",
        "date": "2016-10-28T11:48:36+11:00",
        "message": "Improved speed of ServiceImpl::parse_request.",
        "modified_files_count": 1,
        "modified_files": [
            "source/corvusoft/restbed/uri.cpp"
        ],
        "github_commit_url": "https://github.com/Corvusoft/restbed/commit/8e15cbcb2ad397a8f3c2e54e32dcf9311f3e61be",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Uri::is_valid"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the URI validation logic to reduce unnecessary computations and improve parsing speed.",
            "The optimization strategy involved simplifying the URI validation logic to reduce unnecessary computations and improve parsing speed.",
            "The optimization strategy involved simplifying the URI validation logic to reduce unnecessary computations and improve parsing speed.",
            "The optimization strategy involved simplifying the URI validation logic to reduce unnecessary computations and improve parsing speed.",
            "The optimization strategy involved simplifying the URI validation logic to reduce unnecessary computations and improve parsing speed."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the URI validation logic to reduce unnecessary computations and improve parsing speed.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "71212e0c81cedda0b918c095bd79b9eb98affcbf",
        "author": "Robin Gareus",
        "date": "2020-09-29T16:46:29+02:00",
        "message": "Remove debug/profile message in optimized builds",
        "modified_files_count": 1,
        "modified_files": [
            "libs/ardour/session_transport.cc"
        ],
        "github_commit_url": "https://github.com/Ardour/ardour/commit/71212e0c81cedda0b918c095bd79b9eb98affcbf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Session::non_realtime_locate"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "ardour",
        "optimization_summary": [
            "The optimization strategy removes debug/profile messages in optimized builds to reduce unnecessary overhead.",
            "The optimization strategy involves removing debug/profile messages in optimized builds to reduce unnecessary overhead.",
            "The optimization strategy involves removing debug/profile messages in optimized builds to reduce unnecessary overhead.",
            "The optimization strategy involves removing debug/profile messages in optimized builds to reduce unnecessary overhead.",
            "The optimization strategy involves removing debug/profile messages in optimized builds to reduce unnecessary overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves removing debug/profile messages in optimized builds to reduce unnecessary overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ODE",
        "hash": "7bac210f051b3ffcfaf9a168db3d7c302f7a49a4",
        "author": "Russell Smith",
        "date": "2004-05-29T19:17:17+00:00",
        "message": "minor speed improvement",
        "modified_files_count": 1,
        "modified_files": [
            "ode/test/test_crash.cpp"
        ],
        "github_commit_url": "https://github.com/thomasmarsh/ODE/commit/7bac210f051b3ffcfaf9a168db3d7c302f7a49a4",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary iterations or operations in the test code to improve execution speed.",
            "The optimization strategy involved reducing the number of iterations in a loop to decrease computational overhead.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the test function to improve execution speed.",
            "The optimization strategy involved reducing unnecessary computations or iterations within a specific test function to improve execution speed.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the test function to improve execution speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations or iterations within a specific test function to improve execution speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "67d1a71aa4d55c2f82cc9b70f5afc2016e3daf69",
        "author": "Jakob Stoklund Olesen",
        "date": "2010-11-28T06:14:33+00:00",
        "message": "Speed up simple insertions into an unbranched tree by not creating an iterator.\n\nllvm-svn: 120232",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/include/llvm/ADT/IntervalMap.h"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/67d1a71aa4d55c2f82cc9b70f5afc2016e3daf69",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "insert"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids creating an iterator for simple insertions into an unbranched tree to reduce overhead.",
            "The optimization avoids creating an iterator for simple insertions into an unbranched tree to reduce overhead.",
            "The optimization avoids creating an iterator for simple insertions into an unbranched tree, reducing unnecessary overhead.",
            "The optimization avoids creating an iterator for simple insertions into an unbranched tree, reducing unnecessary overhead.",
            "The optimization avoids creating an iterator for simple insertions into an unbranched tree to reduce overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids creating an iterator for simple insertions into an unbranched tree to reduce overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "platform_system_core",
        "hash": "23eaecf02dedf0a5a25e1cdbfdfc7b8c70c17a56",
        "author": "Dave Sparks",
        "date": "2009-05-20T19:12:58-07:00",
        "message": "Mount SD card synchronous. This is an experimental change intended to\ngive us another data point on the system performance regressions that\nseem to revolved around SD card access.",
        "modified_files_count": 1,
        "modified_files": [
            "vold/volmgr_vfat.c"
        ],
        "github_commit_url": "https://github.com/aosp-mirror/platform_system_core/commit/23eaecf02dedf0a5a25e1cdbfdfc7b8c70c17a56",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vfat_mount"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves changing the SD card mounting process to be synchronous to gather performance data related to system regressions.",
            "The optimization strategy involves changing the SD card mounting process to be synchronous to gather performance data related to system regressions.",
            "The optimization strategy involves changing the SD card mounting process to be synchronous to gather performance data related to system regressions.",
            "The optimization strategy involves changing the SD card mounting process to be synchronous to gather performance data related to system regressions.",
            "The optimization strategy involves changing the SD card mounting process to be synchronous to gather performance data related to system regressions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves changing the SD card mounting process to be synchronous to gather performance data related to system regressions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cheribsd",
        "hash": "5da6b5db2fa57e638f58570c4ca3931213815d06",
        "author": "nwhitehorn",
        "date": "2014-05-11T01:58:56+00:00",
        "message": "Make ofwfb not be painfully slow. This reduces the time for a verbose boot\non my G4 iBook by more than half. Still 10% slower than syscons, but that's\nmuch better than a factor of 2.\n\nThe slowness had to do with pathological write performance on 8-bit\nframebuffers, which are almost universally used on Open Firmware systems.\nWriting 1 byte at a time, potentially nonconsecutively, resulted in many\nextra PCI write cycles. This patch, in the common case where it's writing\none or several characters in an 8x8 font, gangs the writes together into\na set of 32-bit writes. This is a port of r143830 to vt(4).\n\nThe EFI framebuffer is also extremely slow, probably for the same reason,\nand the same patch will likely help there.",
        "modified_files_count": 1,
        "modified_files": [
            "sys/dev/vt/hw/ofwfb/ofwfb.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/5da6b5db2fa57e638f58570c4ca3931213815d06",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ofwfb_bitbltchr"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved batching individual byte writes into 32-bit writes to reduce the number of PCI write cycles for improved performance on 8-bit framebuffers.",
            "The optimization strategy involved batching individual byte writes into 32-bit writes to reduce the number of PCI write cycles for improved performance on 8-bit framebuffers.",
            "The optimization strategy involved batching individual byte writes into 32-bit writes to reduce the number of PCI write cycles for improved performance on 8-bit framebuffers.",
            "The optimization strategy used was to batch individual byte writes into 32-bit writes to reduce the number of PCI write cycles for improved performance on 8-bit framebuffers.",
            "The optimization strategy involved batching individual byte writes into 32-bit writes to reduce the number of PCI write cycles for improved performance on 8-bit framebuffers."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved batching individual byte writes into 32-bit writes to reduce the number of PCI write cycles for improved performance on 8-bit framebuffers.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "haiku",
        "hash": "961a96a9875cac296e96dbc7246cd7435b5ed9b0",
        "author": "Michael Lotz",
        "date": "2011-06-29T18:03:42+00:00",
        "message": "Optimize the configuration of the port heap. Previously the max bin size was\n512 bytes with a heap page of 2048 bytes resulting in excessive waste for\nallocations between 512 and 1023 bytes. Also tune the requested alignment so\nthat sizeof(port_message) (currently 28 bytes) can occupy one allocation unit\nwithout waste.\n\n\ngit-svn-id: file:///srv/svn/repos/haiku/haiku/trunk@42340 a95241bf-73f2-0310-859d-f6bbb57e9c96",
        "modified_files_count": 1,
        "modified_files": [
            "src/system/kernel/port.cpp"
        ],
        "github_commit_url": "https://github.com/haiku/haiku/commit/961a96a9875cac296e96dbc7246cd7435b5ed9b0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "port_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adjusting the memory allocation parameters to reduce waste for specific allocation sizes and improve alignment efficiency.",
            "The optimization strategy involved tuning memory allocation parameters to reduce waste and improve alignment efficiency for specific allocation sizes.",
            "The optimization strategy involved adjusting the memory allocation parameters (max bin size and alignment) to reduce waste and improve efficiency for specific allocation sizes.",
            "The optimization strategy involved adjusting the memory allocation parameters (max bin size and alignment) to reduce waste and improve efficiency for specific allocation sizes.",
            "The optimization strategy involved adjusting the memory allocation parameters (max bin size and alignment) to reduce waste and improve efficiency for specific allocation sizes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting the memory allocation parameters (max bin size and alignment) to reduce waste and improve efficiency for specific allocation sizes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sssd",
        "hash": "5d9e2328ce1706acf87e09b588e134e0f2b761c8",
        "author": "ikerexxe",
        "date": "2020-07-21T13:09:45+02:00",
        "message": "responder/common/responder_packet: get packet length only once\n\nPacket length variable was read and then read again without using the\npreviously read value. So, I have refactored the code a little bit to\nread the value once and use it everywhere else. Moreover, I have\nimplemented some improvements in sss_packet_recv() function pointed by\nAlexey.\n\nCoverity errors:\n```\nError: CLANG_WARNING:\nsssd-2.3.0/src/responder/common/responder_packet.c:217:21: warning:\nAlthough the value stored to 'new_len' is used in the enclosing\nexpression, the value is never actually read from 'new_len'\n #                && (new_len = sss_packet_get_len(packet))\n #                    ^         ~~~~~~~~~~~~~~~~~~~~~~~~~~\nsssd-2.3.0/src/responder/common/responder_packet.c:217:21: note:\nAlthough the value stored to 'new_len' is used in the enclosing\nexpression, the value is never actually read from 'new_len'\n #                && (new_len = sss_packet_get_len(packet))\n #                    ^         ~~~~~~~~~~~~~~~~~~~~~~~~~~\n #  215|                       || sss_packet_get_cmd(packet) == SSS_NSS_GETLISTBYCERT)\n #  216|                   && packet->memsize < SSS_CERT_PACKET_MAX_RECV_SIZE\n #  217|->                 && (new_len = sss_packet_get_len(packet))\n #  218|                                      < SSS_CERT_PACKET_MAX_RECV_SIZE) {\n #  219|               new_len = sss_packet_get_len(packet);\n```\n\nReviewed-by: Alexey Tikhonov <atikhono@redhat.com>\nReviewed-by: Pavel Březina <pbrezina@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/responder/common/responder_packet.c"
        ],
        "github_commit_url": "https://github.com/SSSD/sssd/commit/5d9e2328ce1706acf87e09b588e134e0f2b761c8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sss_packet_recv"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved caching the packet length value to avoid redundant calls to `sss_packet_get_len()` and improve efficiency by reusing the computed value.",
            "The optimization strategy involved caching the packet length value to avoid redundant calls to `sss_packet_get_len()` and improve efficiency by reusing the computed value.",
            "The optimization strategy involved caching the packet length value to avoid redundant calls to `sss_packet_get_len()` and improve efficiency by reusing the computed value.",
            "The optimization strategy involved caching the packet length value to avoid redundant calls to `sss_packet_get_len()` and improve efficiency by reusing the computed value.",
            "The optimization strategy involved caching the packet length value to avoid redundant calls to `sss_packet_get_len()` and improve efficiency by reusing the computed value."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved caching the packet length value to avoid redundant calls to `sss_packet_get_len()` and improve efficiency by reusing the computed value.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "meow_hash",
        "hash": "2facef3bb66847f546418584a6033187d4dfc1ed",
        "author": "Casey Muratori",
        "date": "2018-11-01T01:36:12-07:00",
        "message": "Merge pull request #32 from mmozeiko/v0.3-armv8\n\nImprove short input hashing performance on ARMv8",
        "modified_files_count": 1,
        "modified_files": [
            "meow_hash.h"
        ],
        "github_commit_url": "https://github.com/cmuratori/meow_hash/commit/2facef3bb66847f546418584a6033187d4dfc1ed",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MeowHash1"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving short input hashing performance on ARMv8 by likely leveraging architecture-specific instructions or optimizations.",
            "The optimization strategy involved improving short input hashing performance on ARMv8 by likely leveraging architecture-specific instructions or optimizations.",
            "The optimization strategy involved improving short input hashing performance on ARMv8 by likely leveraging architecture-specific instructions or optimizations.",
            "The optimization strategy involved improving short input hashing performance on ARMv8 by likely leveraging architecture-specific instructions or optimizations.",
            "The optimization strategy involved improving short input hashing performance on ARMv8 by likely leveraging architecture-specific instructions or optimizations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving short input hashing performance on ARMv8 by likely leveraging architecture-specific instructions or optimizations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lustre-release",
        "hash": "1ada2c947b894f97ac4e7e9c6435a8b4e42ca1fa",
        "author": "Hongchao Zhang",
        "date": "2018-11-13T06:17:27+00:00",
        "message": "LU-11390 quota: mark over-quota flag correctly\n\nCurrently, if the current granted quota space is less than or\nequal to the usage + pending_write + waiting_write, the over-quota\nflag will be marked and sent back to OSC, it will damage the write\nperformance drastically. this patch will compare the current pending\nand the waiting space to the threshold of over-quota check, and the\nthreshold will be taken into account only if the remain margin quota\nspace is larger than the threshold.\n\nTest-Parameters: mdtfilesystemtype=zfs ostfilesystemtype=zfs \\\ntestlist=sanity-quota,sanity-quota,sanity-quota,sanity-quota,sanity-quota\n\nChange-Id: I0ecd134c3119ec1d86dbaa6e668091a68b7f5f54\nSigned-off-by: Hongchao Zhang <hongchao@whamcloud.com>\nReviewed-on: https://review.whamcloud.com/33238\nTested-by: Jenkins\nTested-by: Maloo <hpdd-maloo@intel.com>\nReviewed-by: Wang Shilong <wshilong@ddn.com>\nReviewed-by: Andreas Dilger <adilger@whamcloud.com>\nReviewed-by: Oleg Drokin <green@whamcloud.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lustre/quota/qsd_handler.c"
        ],
        "github_commit_url": "https://github.com/lustre/lustre-release/commit/1ada2c947b894f97ac4e7e9c6435a8b4e42ca1fa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "qsd_op_begin0"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy adjusts the over-quota flag logic to reduce unnecessary performance penalties by introducing a threshold-based check for remaining quota space.",
            "The optimization strategy adjusts the over-quota flag logic to reduce unnecessary performance penalties by introducing a threshold-based check for pending and waiting quota space.",
            "The optimization strategy adjusts the over-quota flag logic to reduce unnecessary performance penalties by introducing a threshold-based check for remaining quota space.",
            "The optimization strategy adjusts the over-quota flag logic to reduce unnecessary performance penalties by introducing a threshold-based check for remaining quota space.",
            "The optimization strategy adjusts the over-quota flag logic by introducing a threshold to reduce unnecessary flagging, thereby improving write performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy adjusts the over-quota flag logic to reduce unnecessary performance penalties by introducing a threshold-based check for remaining quota space.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "radare2",
        "hash": "c5208b84e4ea8178ce7a9bccd7229eaf0a3109f6",
        "author": "pancake",
        "date": "2018-08-06T09:39:57+02:00",
        "message": "Use io.pcache.write instead of io.cache for performance reasons",
        "modified_files_count": 1,
        "modified_files": [
            "libr/core/cmd_anal.c"
        ],
        "github_commit_url": "https://github.com/radareorg/radare2/commit/c5208b84e4ea8178ce7a9bccd7229eaf0a3109f6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "type_cmd_afta"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing `io.cache` with `io.pcache.write` to improve performance by leveraging a more efficient caching mechanism.",
            "The optimization strategy involved replacing a less efficient caching mechanism (`io.cache`) with a more performant one (`io.pcache.write`) to improve write performance.",
            "The optimization strategy involved replacing a less efficient caching mechanism (`io.cache`) with a more performant one (`io.pcache.write`) to improve write performance.",
            "The optimization strategy involved replacing `io.cache` with `io.pcache.write` to improve performance by leveraging a more efficient caching mechanism.",
            "The optimization strategy involved replacing a less efficient caching mechanism (`io.cache`) with a more performant one (`io.pcache.write`) to improve write performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a less efficient caching mechanism (`io.cache`) with a more performant one (`io.pcache.write`) to improve write performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "5de22343b2303b278ab562e5d166ffe306566d30",
        "author": "Maciej Sosnowski",
        "date": "2009-03-04T16:04:40-07:00",
        "message": "I/OAT: set tcp_dma_copybreak to 256k for I/OAT ver.3\n\nUpcoming server platforms from Intel based on the Nehalem performance\nhave significantly improved CPU based copy performance.\nHowever, the DMA engine can still be effective at higher I/O sizes\nfor TCP traffic and at this time copybreak\nshould be set to 256k for TCP traffic only.\n\nSigned-off-by: Maciej Sosnowski <maciej.sosnowski@intel.com>\nSigned-off-by: Shannon Nelson <shannon.nelson@intel.com>\nAcked-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>\nSigned-off-by: Dan Williams <dan.j.williams@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/dma/ioatdma.h"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/5de22343b2303b278ab562e5d166ffe306566d30",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ioat_set_tcp_copy_break"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy adjusts the TCP DMA copybreak threshold to 256k for I/OAT version 3 to leverage DMA engine efficiency for larger I/O sizes while accounting for improved CPU-based copy performance.",
            "The optimization strategy adjusts the TCP DMA copybreak threshold to 256k for I/OAT version 3 to leverage DMA engine efficiency for larger I/O sizes while accounting for improved CPU-based copy performance on newer platforms.",
            "The optimization strategy adjusts the TCP DMA copybreak threshold to 256k for I/OAT version 3 to better utilize DMA engines for larger I/O sizes on specific Intel platforms.",
            "The optimization strategy adjusts the TCP DMA copybreak threshold to 256k for I/OAT version 3 to better utilize DMA engines for larger I/O sizes.",
            "The optimization strategy adjusts the TCP DMA copybreak threshold to 256k for I/OAT version 3 to leverage DMA engine efficiency for larger I/O sizes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy adjusts the TCP DMA copybreak threshold to 256k for I/OAT version 3 to leverage DMA engine efficiency for larger I/O sizes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "93c27871936c797380aef9d47a969c088edb0bff",
        "author": "Craig Topper",
        "date": "2019-08-19T18:02:24+00:00",
        "message": "[CGP] Remove ModifiedDT from the makeBitReverse loop\n\nI don't think anything in this loop modifies the control flow and we don't restart any iteration after setting the flag.\n\nThis code was added in http://reviews.llvm.org/D16893 but looking at the test case added there the code that caused the dominator tree to change was merging blocks with their predecessor not the bitreverse optimization.\n\nDifferential Revision: https://reviews.llvm.org/D66366\n\nllvm-svn: 369283",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/CodeGenPrepare.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/93c27871936c797380aef9d47a969c088edb0bff",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes a flag check and modification inside a loop, assuming the control flow remains unaffected and no iteration restarts occur.",
            "The optimization removes a flag check and modification inside a loop, assuming the control flow remains unaffected and no iteration restarts occur.",
            "The optimization removes a flag check and modification inside a loop, assuming the control flow remains unchanged and no iteration restarts are needed.",
            "The optimization removes a flag check and modification inside a loop, assuming control flow remains unaffected and no iteration restarts occur.",
            "The optimization removes a flag check and modification inside a loop, assuming control flow remains unaffected and no iteration restarts occur."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes a flag check and modification inside a loop, assuming the control flow remains unaffected and no iteration restarts occur.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_xiaomi_sm8150",
        "hash": "04ac7bd853039968c42d0752ed5c6e691994e4ce",
        "author": "Veerabhadrarao Badiganti",
        "date": "2019-02-04T12:44:58+05:30",
        "message": "mmc: core: Ignore CRC errors with CMD13 while executing tuning\n\nWhile executing tuning in case CMD19 fails, the driver sends CMD13\nmultiple times to ensure the card is ready to receive the next tuning\ncommand. If this status command fails with CRC error, it will trigger\ntuning. This will result in back to back tuning multiple times.\n\nTo avoid this situation, ignore CRCs error generated with CMD13 while\nexecuting tuning.\n\nChange-Id: Ife338768264ebebebc655fe11874e905abdf7482\nSigned-off-by: Veerabhadrarao Badiganti <vbadigan@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/mmc/host/sdhci.c"
        ],
        "github_commit_url": "https://github.com/Laulan56/android_kernel_xiaomi_sm8150/commit/04ac7bd853039968c42d0752ed5c6e691994e4ce",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sdhci_execute_tuning"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves ignoring CRC errors on CMD13 during tuning to prevent unnecessary repeated tuning operations.",
            "The optimization strategy involves ignoring CRC errors on CMD13 during tuning to prevent unnecessary repeated tuning operations.",
            "The optimization strategy involves ignoring CRC errors on CMD13 during tuning to prevent unnecessary repeated tuning operations.",
            "The optimization strategy involves ignoring CRC errors on CMD13 during tuning to prevent unnecessary repeated tuning operations.",
            "The optimization strategy involves ignoring CRC errors on CMD13 during tuning to prevent unnecessary repeated tuning operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves ignoring CRC errors on CMD13 during tuning to prevent unnecessary repeated tuning operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Q2RTX",
        "hash": "bd91eafb73453d04d6997a4aca8f926cdf20f06a",
        "author": "Alexey Panteleev",
        "date": "2020-12-10T14:02:58-08:00",
        "message": "Use cached memory for image readbacks - this makes taking screenshots much faster.",
        "modified_files_count": 1,
        "modified_files": [
            "src/refresh/vkpt/textures.c"
        ],
        "github_commit_url": "https://github.com/NVIDIA/Q2RTX/commit/bd91eafb73453d04d6997a4aca8f926cdf20f06a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "create_readback_image"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved caching memory for image readbacks to reduce the overhead of repeated memory allocations during screenshot operations.",
            "The optimization strategy involved caching memory for image readbacks to reduce the overhead of repeatedly allocating and deallocating memory during screenshot operations.",
            "The optimization strategy involved caching memory for image readbacks to reduce the overhead of repeatedly allocating and deallocating memory during screenshot operations.",
            "The optimization strategy involved caching memory for image readbacks to reduce the overhead of repeatedly allocating and deallocating memory during screenshot operations.",
            "The optimization strategy involved caching memory for image readbacks to reduce the overhead of repeated memory allocations during screenshot operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved caching memory for image readbacks to reduce the overhead of repeatedly allocating and deallocating memory during screenshot operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "IBAMR",
        "hash": "0798becabfaf56761e7a5fbd888a90247d29363b",
        "author": "David Wells",
        "date": "2019-03-22T17:07:39-04:00",
        "message": "Add some other small optimizations.\n\nThis avoids two virtual function calls.",
        "modified_files_count": 1,
        "modified_files": [
            "ibtk/src/lagrangian/FEDataManager.cpp"
        ],
        "github_commit_url": "https://github.com/IBAMR/IBAMR/commit/0798becabfaf56761e7a5fbd888a90247d29363b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "getQuadratureKey"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids two virtual function calls by directly accessing the required data.",
            "The optimization strategy avoids two virtual function calls by directly accessing the required data.",
            "The optimization strategy avoids two virtual function calls by directly accessing the required data.",
            "The optimization strategy avoids two virtual function calls by directly accessing the required data.",
            "The optimization strategy avoids two virtual function calls by directly accessing the required data."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids two virtual function calls by directly accessing the required data.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "mongo",
        "hash": "6b67db1f230512d757d5ffa0e09d3d8283354580",
        "author": "Eliot Horowitz",
        "date": "2010-02-16T10:18:26-05:00",
        "message": "optimize findOne memory usage",
        "modified_files_count": 1,
        "modified_files": [
            "db/query.cpp"
        ],
        "github_commit_url": "https://github.com/mongodb/mongo/commit/6b67db1f230512d757d5ffa0e09d3d8283354580",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "runQuery"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory allocations by reusing existing data structures in the `findOne` query execution.",
            "The optimization strategy involved reducing memory allocations by reusing existing data structures in the `runQuery` function.",
            "The optimization strategy involved reducing memory usage in the `findOne` operation by avoiding unnecessary data copying or allocation during query execution.",
            "The optimization strategy involved reducing memory allocations by reusing existing data structures in the `runQuery` function.",
            "The optimization strategy involved reducing memory allocations by reusing existing data structures in the query execution path."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory allocations by reusing existing data structures in the `findOne` query execution.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "3DWorld",
        "hash": "1a0ad33b16946d4f86f07fb0c64b88050e7dbdd1",
        "author": "Frank E. Gennari",
        "date": "2011-09-30T07:46:36+00:00",
        "message": "Set the global locale to C in the object file reader to improve load times slightly. -FG",
        "modified_files_count": 1,
        "modified_files": [
            "src/object_file_reader.cpp"
        ],
        "github_commit_url": "https://github.com/fegennari/3DWorld/commit/1a0ad33b16946d4f86f07fb0c64b88050e7dbdd1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "read_object_file"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved setting the global locale to \"C\" in the object file reader to reduce overhead during string and I/O operations, thereby improving load times.",
            "The optimization strategy involved setting the global locale to \"C\" in the object file reader to reduce load times by minimizing locale-related overhead during file parsing.",
            "The optimization strategy involved setting the global locale to \"C\" in the object file reader to reduce overhead during string processing and improve load times.",
            "The optimization strategy involved setting the global locale to \"C\" in the object file reader to reduce load times by improving string processing efficiency.",
            "The optimization strategy involved setting the global locale to \"C\" in the object file reader to reduce overhead during string and I/O operations, thereby improving load times."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved setting the global locale to \"C\" in the object file reader to reduce overhead during string processing and improve load times.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ClickHouse",
        "hash": "2ae9e2224800777de8f893e733ab7df6e3986674",
        "author": "jinjunzh",
        "date": "2022-05-16T16:22:13-04:00",
        "message": "Improve CompressedWriteBuffer to avoid unnecessary memcpy",
        "modified_files_count": 1,
        "modified_files": [
            "src/Compression/CompressedWriteBuffer.cpp"
        ],
        "github_commit_url": "https://github.com/ClickHouse/ClickHouse/commit/2ae9e2224800777de8f893e733ab7df6e3986674",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CompressedWriteBuffer::nextImpl"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary memory copying by directly writing compressed data to the buffer.",
            "The optimization avoids unnecessary memory copying by directly writing compressed data to the buffer.",
            "The optimization avoids unnecessary memory copying by directly writing compressed data to the buffer.",
            "The optimization avoids unnecessary memory copying by directly writing compressed data to the buffer.",
            "The optimization avoids unnecessary memory copying by directly writing compressed data to the buffer."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary memory copying by directly writing compressed data to the buffer.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ppsspp",
        "hash": "fc3688d273b2d9ea62070f6e21d80b20c0014f72",
        "author": "Unknown W. Brackets",
        "date": "2021-12-31T08:10:04-08:00",
        "message": "samplerjit: Small AVX optimization to modulate.\n\nOnly gives about 0.5% but it's still something.",
        "modified_files_count": 1,
        "modified_files": [
            "GPU/Software/SamplerX86.cpp"
        ],
        "github_commit_url": "https://github.com/hrydgard/ppsspp/commit/fc3688d273b2d9ea62070f6e21d80b20c0014f72",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SamplerJitCache::Jit_ApplyTextureFunc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit optimizes AVX instructions in the texture modulation function to reduce computational overhead.",
            "The commit optimizes AVX instructions in the texture modulation function to reduce computational overhead.",
            "The optimization leverages AVX instructions to improve the efficiency of texture modulation operations.",
            "The commit optimizes the modulation operation by leveraging AVX instructions to improve performance.",
            "The optimization leverages AVX instructions to improve the performance of texture modulation operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit optimizes AVX instructions in the texture modulation function to reduce computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "forestdb",
        "hash": "9a3ef4b53bc45515b6cd1f92b11aaca407b5ea7f",
        "author": "Sundar Sridharan",
        "date": "2015-10-01T16:35:44-07:00",
        "message": "MB-16422: Keep auto compacted files warm in cache for faster reopen\n\nIf auto compactor closes new file after compaction the default option\nof cleanup_cache_onclose results in wiping out buffercache and freeing\nthe filemgr object memory which not only causes slowdowns when front end\nthread re-opens the file but also crashes if front-end thread closes\nthe old file.\n\nChange-Id: Ie85eef5a98a61591186a6c3dfbb34d196bc099a3",
        "modified_files_count": 1,
        "modified_files": [
            "src/compactor.cc"
        ],
        "github_commit_url": "https://github.com/couchbase/forestdb/commit/9a3ef4b53bc45515b6cd1f92b11aaca407b5ea7f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "compactor_register_file"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids clearing the buffer cache and freeing file manager memory during auto-compaction to keep files warm in the cache for faster reopening.",
            "The optimization strategy involves keeping auto-compacted files in the cache to avoid the performance cost of re-opening and potential crashes caused by freeing resources prematurely.",
            "The optimization strategy involves keeping auto-compacted files in the cache to avoid the performance cost of re-opening and potential crashes caused by freeing resources prematurely.",
            "The optimization strategy avoids clearing the buffer cache and freeing file manager memory during auto-compaction to maintain cached files for faster reopening.",
            "The optimization strategy involves keeping auto-compacted files in the cache to avoid the performance overhead of re-opening and potential crashes caused by freeing file manager objects."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves keeping auto-compacted files in the cache to avoid the performance cost of re-opening and potential crashes caused by freeing resources prematurely.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "asterisk",
        "hash": "3da361ee77ac5b3daf90f7c91765e85eccd6a18a",
        "author": "Kevin P. Fleming",
        "date": "2005-04-01T21:31:12+00:00",
        "message": "optimize file reading in pbx_spool (bug #3927)\n\n\ngit-svn-id: https://origsvn.digium.com/svn/asterisk/trunk@5351 65c4cc65-6c06-0410-ace0-fbb531ad65f3",
        "modified_files_count": 1,
        "modified_files": [
            "pbx/pbx_spool.c"
        ],
        "github_commit_url": "https://github.com/asterisk/asterisk/commit/3da361ee77ac5b3daf90f7c91765e85eccd6a18a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "apply_outgoing"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant file reads by caching the file content in memory during the `apply_outgoing` function execution.",
            "The optimization strategy involved reducing redundant file reads by caching the file content in memory during the `apply_outgoing` function execution.",
            "The optimization strategy involved reducing redundant file reads by caching the file content in memory during the `apply_outgoing` function execution.",
            "The optimization strategy involved reducing redundant file reads by caching the file content in memory during the `apply_outgoing` function execution.",
            "The optimization strategy involved reducing redundant file reads by caching the file content in memory during the `apply_outgoing` function execution."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant file reads by caching the file content in memory during the `apply_outgoing` function execution.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenMS",
        "hash": "2ee639f7e30934c577c14b6b3535d4300ce39ac7",
        "author": "Chris Bielow",
        "date": "2018-09-04T16:06:16+02:00",
        "message": "optimize loop end condition",
        "modified_files_count": 1,
        "modified_files": [
            "src/openms/include/OpenMS/FORMAT/DATAACCESS/SwathFileConsumer.h"
        ],
        "github_commit_url": "https://github.com/OpenMS/OpenMS/commit/2ee639f7e30934c577c14b6b3535d4300ce39ac7",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying or improving the loop end condition to reduce computational overhead.",
            "The optimization strategy involved simplifying or improving the loop end condition to reduce computational overhead.",
            "The optimization strategy involved simplifying or improving the loop end condition to reduce computational overhead.",
            "The optimization strategy involved simplifying or improving the loop end condition to reduce computational overhead.",
            "The optimization strategy involved simplifying or improving the loop end condition to reduce computational overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying or improving the loop end condition to reduce computational overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "06d9e908b2248f983b186aaf569c58e1430db85d",
        "author": "venkatesh.pallipadi@intel.com",
        "date": "2008-08-15T21:25:35+02:00",
        "message": "cpuidle: Make ladder governor honor latency requirements fully\n\nladder governor only honored latency requirement when promoting C-states.\nInstead. it should check for latency requirement on each idle call,\nand demote to appropriate C-state when there is a latency requirement change.\n\nSigned-off-by: Venkatesh Pallipadi <venkatesh.pallipadi@intel.com>\nSigned-off-by: Andi Kleen <ak@linux.intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/cpuidle/governors/ladder.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/06d9e908b2248f983b186aaf569c58e1430db85d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ladder_select_state"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization ensures the ladder governor consistently checks and respects latency requirements during each idle call, rather than only during C-state promotions.",
            "The optimization ensures the ladder governor consistently checks and respects latency requirements during each idle call, rather than only during C-state promotion.",
            "The optimization ensures the ladder governor consistently checks latency requirements on every idle call, enabling appropriate C-state demotion when latency demands change.",
            "The optimization ensures the ladder governor consistently checks and respects latency requirements during each idle call, rather than only during C-state promotions.",
            "The optimization ensures the ladder governor consistently checks and respects latency requirements during each idle call, rather than only during C-state promotions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures the ladder governor consistently checks and respects latency requirements during each idle call, rather than only during C-state promotions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "vpp",
        "hash": "22b5be06fae6f9a8b71c53fec548aabbdf69026b",
        "author": "Steven",
        "date": "2018-04-12T10:59:31+00:00",
        "message": "bond: 1 packet/frame == bad performance [VPP-1236]\n\nWhile https://gerrit.fd.io/r/#/c/11316/ took care of 1 packet/frame for\nmost of the bonding modes, it missed the broadcast mode. This patch is\nto fix the 1 packet/frame for the broadcast mode.\n\nChange-Id: Iac48a2977c7f702f341479cc712a6448090dbc60\nSigned-off-by: Steven <sluong@cisco.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/vnet/bonding/device.c"
        ],
        "github_commit_url": "https://github.com/FDio/vpp/commit/22b5be06fae6f9a8b71c53fec548aabbdf69026b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bond_load_balance_broadcast"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved modifying the broadcast mode in bonding to handle multiple packets per frame, improving performance by avoiding single-packet inefficiencies.",
            "The optimization strategy involved batching multiple packets per frame in the broadcast bonding mode to improve performance by reducing per-packet overhead.",
            "The optimization strategy involved batching multiple packets per frame in the broadcast bonding mode to improve performance by reducing per-packet overhead.",
            "The optimization strategy involved batching multiple packets per frame in the broadcast bonding mode to improve performance by reducing per-packet overhead.",
            "The optimization strategy involved batching multiple packets per frame in the broadcast bonding mode to improve performance by reducing per-packet overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved batching multiple packets per frame in the broadcast bonding mode to improve performance by reducing per-packet overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Server",
        "hash": "1bf24273d286c7a9d6e158d639d2d624e059d15e",
        "author": "Alex King",
        "date": "2023-02-12T22:16:39-06:00",
        "message": "[Quest API] (Performance) Check event exists before export and execute EVENT_TICK (#2919)\n\n# Notes\r\n- Optionally parse this event instead of always doing so.",
        "modified_files_count": 1,
        "modified_files": [
            "zone/npc.cpp"
        ],
        "github_commit_url": "https://github.com/EQEmu/Server/commit/1bf24273d286c7a9d6e158d639d2d624e059d15e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "NPC::Process"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding a conditional check to verify the existence of an event before exporting and executing it, reducing unnecessary processing.",
            "The optimization strategy involves adding a conditional check to verify the existence of an event before exporting and executing it, reducing unnecessary processing.",
            "The optimization strategy involves adding a conditional check to verify the existence of an event before exporting and executing it, reducing unnecessary processing.",
            "The optimization strategy involves adding a conditional check to verify the existence of an event before exporting and executing it, reducing unnecessary processing.",
            "The optimization strategy involves adding a conditional check to verify the existence of an event before exporting and executing it, reducing unnecessary processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding a conditional check to verify the existence of an event before exporting and executing it, reducing unnecessary processing.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "03fc3070457dc0e6a717a2e732af93ef1cb2ae51",
        "author": "Antonio Quartulli",
        "date": "2011-12-07T03:12:55+08:00",
        "message": "batman-adv: in case of roaming mark the client with TT_CLIENT_ROAM\n\nIn case of a client roaming from node A to node B, the latter have to mark the\ncorresponding global entry with TT_CLIENT_ROAM (instead of TT_CLIENT_PENDING).\n\nMarking a global entry with TT_CLIENT_PENDING will end up in keeping such entry\nforever (because this flag is only meant to be used with local entries and it is\nnever checked on global ones).\n\nIn the worst case (all the clients roaming to the same node A) the local and the\nglobal table will contain exactly the same clients. Batman-adv will continue to\nwork, but the memory usage is duplicated.\n\nSigned-off-by: Antonio Quartulli <ordex@autistici.org>",
        "modified_files_count": 1,
        "modified_files": [
            "net/batman-adv/translation-table.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/03fc3070457dc0e6a717a2e732af93ef1cb2ae51",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tt_local_add"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization avoids memory duplication by correctly marking roaming clients with TT_CLIENT_ROAM instead of TT_CLIENT_PENDING in the global translation table.",
            "The optimization avoids memory duplication by correctly marking roaming clients with TT_CLIENT_ROAM instead of TT_CLIENT_PENDING in the global translation table.",
            "The optimization avoids memory duplication by correctly marking roaming clients with TT_CLIENT_ROAM instead of TT_CLIENT_PENDING in the global translation table.",
            "The optimization avoids memory duplication by correctly marking roaming clients with TT_CLIENT_ROAM instead of TT_CLIENT_PENDING in the global translation table.",
            "The optimization avoids memory duplication by correctly marking roaming clients with TT_CLIENT_ROAM instead of TT_CLIENT_PENDING in the global translation table."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids memory duplication by correctly marking roaming clients with TT_CLIENT_ROAM instead of TT_CLIENT_PENDING in the global translation table.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "30ba0a0c950a0cdf23a70fce6c16d501c5f238c8",
        "author": "David Major",
        "date": "2019-01-09T23:36:32+00:00",
        "message": "Don't require a null terminator when loading objects\n\nWhen a null terminator is required and the file size is a multiple of the system page size, MemoryBuffer will prefer pread() over mmap(), which can result in excessive memory usage.\n\nPatch by Mike Hommey!\n\nDifferential Revision: https://reviews.llvm.org/D56475\n\nllvm-svn: 350774",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Object/Binary.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/30ba0a0c950a0cdf23a70fce6c16d501c5f238c8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "object::createBinary"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids requiring a null terminator when loading objects, preventing excessive memory usage caused by preferring pread() over mmap().",
            "The optimization avoids requiring a null terminator when loading objects, preventing excessive memory usage caused by preferring pread() over mmap().",
            "The optimization avoids requiring a null terminator when loading objects, preventing excessive memory usage caused by preferring pread() over mmap().",
            "The optimization avoids requiring a null terminator when loading objects, preventing excessive memory usage caused by preferring pread() over mmap() in certain cases.",
            "The optimization avoids requiring a null terminator when loading objects, preventing excessive memory usage caused by preferring pread() over mmap()."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids requiring a null terminator when loading objects, preventing excessive memory usage caused by preferring pread() over mmap().",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "bitcoin-abc",
        "hash": "966fa58918e3bccf7325f3ef4ae5bb21642f1980",
        "author": "Luke Dashjr",
        "date": "2019-09-05T16:19:59-03:00",
        "message": "During IBD, when doing pruning, prune 10% extra to avoid pruning again soon after\n\nSummary:\nPruning forces a chainstate flush, which can defeat the dbcache and harm performance significantly.\n\nBackport of Bitcoin Core PR11658\nhttps://github.com/bitcoin/bitcoin/pull/11658\n\nTest Plan:\n```\nmake check\n```\n\nReviewers: Fabien, #bitcoin_abc, deadalnix, jasonbcox\n\nReviewed By: #bitcoin_abc, jasonbcox\n\nDifferential Revision: https://reviews.bitcoinabc.org/D3986",
        "modified_files_count": 1,
        "modified_files": [
            "src/validation.cpp"
        ],
        "github_commit_url": "https://github.com/Bitcoin-ABC/bitcoin-abc/commit/966fa58918e3bccf7325f3ef4ae5bb21642f1980",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "distance"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves pruning an additional 10% of data during Initial Block Download (IBD) to reduce the frequency of subsequent pruning operations and minimize performance degradation caused by chainstate flushes.",
            "The optimization strategy involves pruning an additional 10% of data during Initial Block Download (IBD) to reduce the frequency of subsequent pruning operations and minimize performance degradation caused by chainstate flushes.",
            "The optimization strategy involves pruning an additional 10% of data during Initial Block Download (IBD) to reduce the frequency of subsequent pruning operations and avoid performance degradation caused by frequent chainstate flushes.",
            "The optimization strategy involves pruning an additional 10% of data during Initial Block Download (IBD) to reduce the frequency of subsequent pruning operations and minimize performance degradation caused by chainstate flushes.",
            "The optimization strategy involves pruning an additional 10% of data during Initial Block Download (IBD) to reduce the frequency of subsequent pruning operations and avoid performance degradation caused by frequent chainstate flushes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves pruning an additional 10% of data during Initial Block Download (IBD) to reduce the frequency of subsequent pruning operations and minimize performance degradation caused by chainstate flushes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "firebird",
        "hash": "afc3d38954d1f8b43a42b11a6c4b74b567b288ee",
        "author": "arnobrinkman",
        "date": "2003-02-15T01:35:19+00:00",
        "message": "More optimizer enhancements.\nWhen an equal-node and other nodes (geq, leq, between...) are available for an index retrieval, then use the equal node always instead of the others.",
        "modified_files_count": 1,
        "modified_files": [
            "src/jrd/opt.cpp"
        ],
        "github_commit_url": "https://github.com/FirebirdSQL/firebird/commit/afc3d38954d1f8b43a42b11a6c4b74b567b288ee",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "match_index"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy prioritizes using an equal-node for index retrieval over other node types (geq, leq, between) when available, to improve query performance by leveraging more efficient indexing.",
            "The optimization strategy prioritizes using an equal-node for index retrieval over other node types (geq, leq, between) when available, to improve query performance.",
            "The optimization strategy prioritizes using an equal-node for index retrieval over other node types (geq, leq, between) when available, to improve query performance by leveraging more efficient indexing.",
            "The optimization strategy prioritizes using an equal-node for index retrieval over other comparison nodes (geq, leq, between, etc.) to improve query performance by leveraging more efficient indexing.",
            "The optimization strategy prioritizes using an equal-node for index retrieval over other node types (e.g., geq, leq, between) to improve query performance by leveraging more efficient indexing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy prioritizes using an equal-node for index retrieval over other node types (geq, leq, between) when available, to improve query performance by leveraging more efficient indexing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "vg",
        "hash": "1dd5c618242b73fadb2f0e226cbe8f8af12bd647",
        "author": "Erik Garrison",
        "date": "2017-07-25T15:50:36-04:00",
        "message": "improve performance by generating candidate mate rescues after primary alignment",
        "modified_files_count": 1,
        "modified_files": [
            "src/mapper.cpp"
        ],
        "github_commit_url": "https://github.com/vgteam/vg/commit/1dd5c618242b73fadb2f0e226cbe8f8af12bd647",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Mapper::align_paired_multi"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves deferring the generation of candidate mate rescues until after primary alignment to reduce unnecessary computations.",
            "The optimization strategy involves deferring the generation of candidate mate rescues until after primary alignment to reduce unnecessary computations.",
            "The optimization strategy involves deferring the generation of candidate mate rescues until after primary alignment to reduce unnecessary computations.",
            "The optimization strategy involves deferring the generation of candidate mate rescues until after primary alignment to reduce unnecessary computations.",
            "The optimization strategy involves deferring the generation of candidate mate rescues until after primary alignment to reduce unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves deferring the generation of candidate mate rescues until after primary alignment to reduce unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow-directml",
        "hash": "1ba4c37cee105d1fdfa6bda88079904beddef831",
        "author": "A. Unique TensorFlower",
        "date": "2017-12-14T13:30:05-08:00",
        "message": "Don't generate Reciprocal nodes for integer types.\nEnable Reciprocal optimizations for complex types.\n\nPiperOrigin-RevId: 179086680",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/core/grappler/optimizers/constant_folding.cc"
        ],
        "github_commit_url": "https://github.com/microsoft/tensorflow-directml/commit/1ba4c37cee105d1fdfa6bda88079904beddef831",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ConstantFolding::SimplifyGraph"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids generating Reciprocal nodes for integer types and enables Reciprocal optimizations for complex types to improve performance by reducing unnecessary operations.",
            "The optimization avoids generating Reciprocal nodes for integer types and enables Reciprocal optimizations for complex types to improve performance by reducing unnecessary operations.",
            "The optimization avoids generating unnecessary Reciprocal nodes for integer types and enables Reciprocal optimizations for complex types to improve graph simplification efficiency.",
            "The optimization avoids generating Reciprocal nodes for integer types and enables Reciprocal optimizations for complex types to improve performance by reducing unnecessary operations.",
            "The optimization avoids generating Reciprocal nodes for integer types and enables Reciprocal optimizations for complex types to improve performance by reducing unnecessary operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids generating Reciprocal nodes for integer types and enables Reciprocal optimizations for complex types to improve performance by reducing unnecessary operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "calligra",
        "hash": "71258981c116a51930dddde4bac6c1d2a3601dd5",
        "author": "Casper Boemann",
        "date": "2005-12-04T22:33:50+00:00",
        "message": "make mixColors faster and a little bit more \naccurate\n\nsvn path=/trunk/koffice/; revision=485564",
        "modified_files_count": 1,
        "modified_files": [
            "krita/colorspaces/rgb_u8/kis_rgb_colorspace.cc"
        ],
        "github_commit_url": "https://github.com/KDE/calligra/commit/71258981c116a51930dddde4bac6c1d2a3601dd5",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency and accuracy of the `mixColors` function by refining its algorithm or reducing unnecessary computations.",
            "The optimization strategy involved improving the efficiency and accuracy of the `mixColors` function by refining its internal computation logic.",
            "The optimization strategy involved improving the efficiency and accuracy of the `mixColors` function by refining its algorithm or reducing unnecessary computations.",
            "The optimization strategy involved improving the efficiency and accuracy of the `mixColors` function by refining its algorithm or reducing unnecessary computations.",
            "The optimization strategy involved improving the efficiency and accuracy of the `mixColors` function by refining its algorithm or reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency and accuracy of the `mixColors` function by refining its algorithm or reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ompi",
        "hash": "0ecef1750dd9bf4be09ced1cf3315defa7a1b4ca",
        "author": "Jelena Pjesivac-Grbovic",
        "date": "2007-06-26T20:14:03+00:00",
        "message": "Modifying the default reduce decision function to use binomial algorithm\nfor single-element reduce (segmented algorithms make no sense in this case\nand can cause performance degradation). \n\nThis commit was SVN r15209.",
        "modified_files_count": 1,
        "modified_files": [
            "ompi/mca/coll/tuned/coll_tuned_decision_fixed.c"
        ],
        "github_commit_url": "https://github.com/open-mpi/ompi/commit/0ecef1750dd9bf4be09ced1cf3315defa7a1b4ca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ompi_coll_tuned_reduce_intra_dec_fixed"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing segmented algorithms with a binomial algorithm for single-element reductions to avoid unnecessary overhead and improve performance.",
            "The optimization strategy involved replacing segmented algorithms with a binomial algorithm for single-element reduce operations to avoid unnecessary overhead and improve performance.",
            "The optimization strategy involved replacing segmented algorithms with a binomial algorithm for single-element reductions to avoid unnecessary overhead and improve performance.",
            "The optimization strategy involved replacing segmented algorithms with a binomial algorithm for single-element reductions to avoid unnecessary overhead and improve performance.",
            "The optimization strategy involved replacing segmented algorithms with a binomial algorithm for single-element reductions to avoid unnecessary overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing segmented algorithms with a binomial algorithm for single-element reductions to avoid unnecessary overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lix",
        "hash": "3efea3d28ad522f947bacd30b74bc388c0dffa5e",
        "author": "Sidharth Kshatriya",
        "date": "2022-06-09T16:25:26+05:30",
        "message": "nix-store: small std::move() optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/nix-store/nix-store.cc"
        ],
        "github_commit_url": "https://github.com/lix-project/lix/commit/3efea3d28ad522f947bacd30b74bc388c0dffa5e",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved using `std::move()` to eliminate unnecessary copy operations for objects, improving performance by enabling move semantics.",
            "The optimization strategy involved using `std::move()` to eliminate unnecessary copy operations for improved performance.",
            "The optimization strategy involved using `std::move()` to eliminate unnecessary copy operations for objects, improving performance by enabling move semantics.",
            "The optimization strategy involved using `std::move()` to eliminate unnecessary copy operations for objects, improving performance by enabling move semantics.",
            "The optimization strategy involved using `std::move()` to eliminate unnecessary copy operations for objects that can be moved instead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved using `std::move()` to eliminate unnecessary copy operations for objects, improving performance by enabling move semantics.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "7dd968163f7c12bcb2132792bf873133b397a2d2",
        "author": "Martin Schwidefsky",
        "date": "2016-06-13T15:58:21+02:00",
        "message": "bitmap: bitmap_equal memcmp optimization\n\nThe bitmap_equal function has optimized code for small bitmaps with less\nthan BITS_PER_LONG bits. For larger bitmaps the out-of-line function\n__bitmap_equal is called.\n\nFor a constant number of bits divisible by BITS_PER_LONG the memcmp\nfunction can be used. For s390 gcc knows how to optimize this function,\nmemcmp calls with up to 256 bytes / 2048 bits are translated into a\nsingle instruction.\n\nReviewed-by: David Hildenbrand <dahi@linux.vnet.ibm.com>\nSigned-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>",
        "modified_files_count": 1,
        "modified_files": [
            "include/linux/bitmap.h"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/7dd968163f7c12bcb2132792bf873133b397a2d2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bitmap_equal"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces the generic __bitmap_equal function with memcmp for large bitmaps where the size is a multiple of BITS_PER_LONG, leveraging architecture-specific optimizations for improved performance.",
            "The optimization strategy replaces the generic __bitmap_equal function with memcmp for large bitmaps where the size is a multiple of BITS_PER_LONG, leveraging architecture-specific optimizations for improved performance.",
            "The optimization strategy replaces the generic __bitmap_equal function with memcmp for large bitmaps where the size is a multiple of BITS_PER_LONG, leveraging architecture-specific optimizations for improved performance.",
            "The optimization strategy replaces the generic __bitmap_equal function with memcmp for large bitmaps where the size is a multiple of BITS_PER_LONG, leveraging architecture-specific optimizations for improved performance.",
            "The optimization strategy replaces the generic __bitmap_equal function with memcmp for large bitmaps where the size is a multiple of BITS_PER_LONG, leveraging architecture-specific optimizations for improved performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaces the generic __bitmap_equal function with memcmp for large bitmaps where the size is a multiple of BITS_PER_LONG, leveraging architecture-specific optimizations for improved performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gstreamer-vaapi",
        "hash": "7f61ad79389fcd28c82f068701c3fff18bc3e4b6",
        "author": "Víctor Manuel Jáquez Leal",
        "date": "2020-02-02T18:04:35+01:00",
        "message": "vaapivideobufferpool: dmabuf implies allocator\n\nSome code can be optimized since only if the dmabuf allocator is set,\nthe internal flag of dmabuf is TRUE, thus there's no need to evaluate\nthe allocator address.",
        "modified_files_count": 1,
        "modified_files": [
            "gst/vaapi/gstvaapivideobufferpool.c"
        ],
        "github_commit_url": "https://github.com/GStreamer/gstreamer-vaapi/commit/7f61ad79389fcd28c82f068701c3fff18bc3e4b6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gst_vaapi_video_buffer_pool_set_config"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization eliminates redundant checks by leveraging the implication that a set dmabuf allocator guarantees the internal dmabuf flag is TRUE.",
            "The optimization eliminates redundant checks by leveraging the implication that a set dmabuf allocator guarantees the internal dmabuf flag is TRUE.",
            "The optimization eliminates redundant checks by leveraging the implication that a set dmabuf allocator guarantees the internal dmabuf flag is TRUE.",
            "The optimization eliminates redundant checks by leveraging the fact that a dmabuf allocator being set inherently implies the internal dmabuf flag is TRUE, thus avoiding unnecessary evaluation of the allocator address.",
            "The optimization eliminates redundant checks by leveraging the implication that a set dmabuf allocator guarantees the internal dmabuf flag is TRUE."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization eliminates redundant checks by leveraging the implication that a set dmabuf allocator guarantees the internal dmabuf flag is TRUE.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ppsspp",
        "hash": "4f6aaea1e88a092a143e37a7b99949800c320f35",
        "author": "Unknown W. Brackets",
        "date": "2021-04-25T16:49:52-07:00",
        "message": "Core: Correct thread dependency in relocations.\n\nDidn't realize it was looking at the later value before relocation.\nThis still remains about as much faster as before and still beneficial to\nthread.",
        "modified_files_count": 1,
        "modified_files": [
            "Core/ELF/ElfReader.cpp"
        ],
        "github_commit_url": "https://github.com/hrydgard/ppsspp/commit/4f6aaea1e88a092a143e37a7b99949800c320f35",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ElfReader::LoadRelocations"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy corrected a thread dependency issue in relocations by ensuring proper ordering of value access before relocation.",
            "The optimization strategy corrected a thread dependency issue in relocations by ensuring proper ordering of value access, improving thread safety and performance.",
            "The optimization corrected a thread dependency issue in relocations by ensuring proper ordering of value access before relocation.",
            "The optimization corrected a thread dependency issue in relocations by ensuring proper ordering of value access during relocation processing.",
            "The optimization corrected a thread dependency issue in relocations by ensuring proper ordering of value access, improving thread safety and performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy corrected a thread dependency issue in relocations by ensuring proper ordering of value access before relocation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "02e355469d233df46bdc4b83b34f1befc9c1bd97",
        "author": "Toon Verwaest",
        "date": "2022-06-02T16:40:41+00:00",
        "message": "[code-cache] Keep code alive for a little longer\n\nCode ageing too early can have a bad impact on performance. Let's\nevaluate keeping code alive a little longer. Later we can look at more\nelaborate heuristics.\n\nChange-Id: Ib220c4dcd24165d6b6e5020cb1829c669ed3e736\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/3686416\nCommit-Queue: Toon Verwaest <verwaest@chromium.org>\nReviewed-by: Hannes Payer <hpayer@chromium.org>\nCr-Commit-Position: refs/heads/main@{#80920}",
        "modified_files_count": 1,
        "modified_files": [
            "src/objects/code.h"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/02e355469d233df46bdc4b83b34f1befc9c1bd97",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DEFINE_OPERATORS_FOR_FLAGS"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy delays the ageing of code to prevent premature eviction from the cache, aiming to improve performance by keeping frequently used code alive longer.",
            "The optimization strategy delays the ageing of code to prevent premature eviction from the code cache, aiming to improve performance by keeping frequently used code alive longer.",
            "The optimization strategy delays the ageing of code to prevent premature eviction from the cache, aiming to improve performance by keeping frequently used code alive longer.",
            "The optimization strategy delays the ageing of code to prevent premature eviction from the cache, aiming to improve performance by keeping frequently used code alive longer.",
            "The optimization strategy delays the ageing of code to prevent premature eviction from the cache, aiming to improve performance by keeping frequently used code alive longer."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy delays the ageing of code to prevent premature eviction from the cache, aiming to improve performance by keeping frequently used code alive longer.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "welle.io",
        "hash": "610149af42eecbe95413a80e3be5627914e4830b",
        "author": "Adrien Michel",
        "date": "2024-12-01T03:15:06+01:00",
        "message": "phase_sync : find peak and average at the same time (lower complexity)",
        "modified_files_count": 1,
        "modified_files": [
            "src/backend/phasereference.cpp"
        ],
        "github_commit_url": "https://github.com/AlbrechtL/welle.io/commit/610149af42eecbe95413a80e3be5627914e4830b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PhaseReference::findIndex"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy combines two separate loops into a single loop to reduce computational complexity by finding the peak and calculating the average simultaneously.",
            "The optimization strategy combines two separate loops into one to reduce computational complexity by finding the peak and calculating the average simultaneously.",
            "The optimization strategy combines two separate loops into a single loop to reduce computational complexity by finding the peak and calculating the average simultaneously.",
            "The optimization strategy combines two separate loops into a single loop to reduce computational complexity by finding the peak and calculating the average simultaneously.",
            "The optimization strategy combines two separate loops into a single loop to reduce computational complexity by finding the peak and calculating the average simultaneously."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy combines two separate loops into a single loop to reduce computational complexity by finding the peak and calculating the average simultaneously.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "MoarVM",
        "hash": "29f571264da1e88ec3eb0612643b63accb966be1",
        "author": "Jonathan Worthington",
        "date": "2017-07-21T18:06:17+02:00",
        "message": "Kick out osrpoint instructions in optimize.",
        "modified_files_count": 1,
        "modified_files": [
            "src/spesh/optimize.c"
        ],
        "github_commit_url": "https://github.com/MoarVM/MoarVM/commit/29f571264da1e88ec3eb0612643b63accb966be1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "optimize_bb"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes unnecessary OSR (On-Stack Replacement) point instructions during the optimization phase to reduce overhead.",
            "The optimization strategy removes unnecessary OSR (On-Stack Replacement) point instructions during the optimization phase to reduce overhead.",
            "The optimization strategy removes unnecessary OSR (On-Stack Replacement) point instructions during the optimization phase to reduce overhead.",
            "The optimization strategy removes unnecessary OSR (On-Stack Replacement) point instructions during the optimization phase to reduce overhead.",
            "The optimization strategy removes unnecessary OSR (On-Stack Replacement) point instructions during the optimization phase to reduce overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy removes unnecessary OSR (On-Stack Replacement) point instructions during the optimization phase to reduce overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "swipl-devel",
        "hash": "ca50fedd06d93e3942609d947700d559561e07da",
        "author": "Jan Wielemaker",
        "date": "2011-03-12T15:36:20+01:00",
        "message": "ENHANCED: Move atom-hash computation outside locked area.",
        "modified_files_count": 1,
        "modified_files": [
            "src/pl-atom.c"
        ],
        "github_commit_url": "https://github.com/SWI-Prolog/swipl-devel/commit/ca50fedd06d93e3942609d947700d559561e07da",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PL_handle_signals"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved relocating the computation of atom-hash values outside of a locked section to reduce contention and improve concurrency.",
            "The optimization strategy involved relocating the computation of atom-hash outside of a locked section to reduce contention and improve concurrency.",
            "The optimization strategy involved relocating the computation of atom-hash outside of a locked section to reduce contention and improve concurrency.",
            "The optimization strategy moves the computation of atom-hash outside a locked area to reduce contention and improve concurrency.",
            "The optimization strategy involved relocating the computation of atom-hash values outside of a locked section to reduce contention and improve concurrency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved relocating the computation of atom-hash outside of a locked section to reduce contention and improve concurrency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "frequensea",
        "hash": "d8ecb7e7dcd153b757b48b5666a13bbe5c509cc3",
        "author": "Frederik De Bleser",
        "date": "2015-02-17T17:09:07+01:00",
        "message": "Optimize pixel_inc function.\n\nAccording to gprof this is the bottleneck of the code.",
        "modified_files_count": 1,
        "modified_files": [
            "rpi-fdb/iqvis_lines.c"
        ],
        "github_commit_url": "https://github.com/fdb/frequensea/commit/d8ecb7e7dcd153b757b48b5666a13bbe5c509cc3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pixel_inc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the loop logic and reducing unnecessary computations within the `pixel_inc` function to improve performance.",
            "The optimization strategy involved simplifying the loop logic and reducing unnecessary computations within the `pixel_inc` function to improve performance.",
            "The optimization strategy involved simplifying the logic in the `pixel_inc` function to reduce unnecessary computations and improve its efficiency.",
            "The optimization strategy involved simplifying the loop logic and reducing unnecessary computations within the `pixel_inc` function to improve performance.",
            "The optimization strategy involved simplifying the loop logic and reducing unnecessary computations within the `pixel_inc` function to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the loop logic and reducing unnecessary computations within the `pixel_inc` function to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "0366e02b3e6b3304b4ea95d06c9ed7683ae5c7ec",
        "author": "Ruslan Ermilov",
        "date": "2013-05-21T12:54:27+04:00",
        "message": "Upstream: slightly optimized ngx_http_upstream_process_header().\n\n--HG--\nbranch : nginx",
        "modified_files_count": 1,
        "modified_files": [
            "src/http/ngx_http_upstream.c"
        ],
        "github_commit_url": "https://github.com/webserver-llc/angie/commit/0366e02b3e6b3304b4ea95d06c9ed7683ae5c7ec",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ngx_http_upstream_process_header"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "angie",
        "optimization_summary": [
            "The optimization strategy involved restructuring the logic in ngx_http_upstream_process_header() to reduce redundant checks and improve the efficiency of header processing.",
            "The optimization strategy involved restructuring the logic in `ngx_http_upstream_process_header()` to reduce redundant checks and improve the efficiency of header processing.",
            "The optimization strategy involved restructuring the logic in ngx_http_upstream_process_header() to reduce redundant checks and improve the efficiency of header processing.",
            "The optimization strategy involved restructuring the logic in ngx_http_upstream_process_header() to reduce redundant checks and improve the efficiency of header processing.",
            "The optimization strategy involved reducing redundant header processing by improving the logic for handling upstream headers."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the logic in ngx_http_upstream_process_header() to reduce redundant checks and improve the efficiency of header processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "overwitch",
        "hash": "ee05b0a83df7464448f52aa2b2b3f3ae90c3eb47",
        "author": "Jan Lentfer",
        "date": "2021-11-12T22:43:19+01:00",
        "message": "Optimize two loops in jclient_process_cb\n\n    With grpof I found that jclient_process_cb\n    was taking most time by far (which maybe expected).\n    Here I am merging two seperate loops into one, which\n    according to gprof reduced cpu time quite a bit.",
        "modified_files_count": 1,
        "modified_files": [
            "src/jclient.c"
        ],
        "github_commit_url": "https://github.com/dagargo/overwitch/commit/ee05b0a83df7464448f52aa2b2b3f3ae90c3eb47",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "jclient_process_cb"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was merging two separate loops into a single loop to reduce CPU time.",
            "The optimization strategy used was merging two separate loops into a single loop to reduce CPU time.",
            "The optimization strategy used was merging two separate loops into a single loop to reduce CPU time.",
            "The optimization strategy used was merging two separate loops into a single loop to reduce CPU time.",
            "The optimization strategy used was merging two separate loops into a single loop to reduce CPU time."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was merging two separate loops into a single loop to reduce CPU time.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "c-blosc2",
        "hash": "4a727370b1c2e9746434c00bf2236db86c31ea5c",
        "author": "Francesc Alted",
        "date": "2021-04-22T08:46:23+02:00",
        "message": "Fast path for memcpyed and special chunks in getitem",
        "modified_files_count": 1,
        "modified_files": [
            "blosc/blosc2.c"
        ],
        "github_commit_url": "https://github.com/Blosc/c-blosc2/commit/4a727370b1c2e9746434c00bf2236db86c31ea5c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_blosc_getitem"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization introduces a fast path for handling memcpyed and special chunks in the `_blosc_getitem` function to reduce unnecessary computations.",
            "The commit introduces a fast path for handling memcpyed and special chunks in the `_blosc_getitem` function to reduce unnecessary computations and improve performance.",
            "The commit introduces a fast path for handling memcpyed and special chunks in the `_blosc_getitem` function to reduce unnecessary computations and improve performance.",
            "The commit introduces a fast path for handling memcpyed and special chunks in the `_blosc_getitem` function to reduce unnecessary computations and improve performance.",
            "The commit introduces a fast path for handling memcpyed and special chunks in the `_blosc_getitem` function to reduce unnecessary computations and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit introduces a fast path for handling memcpyed and special chunks in the `_blosc_getitem` function to reduce unnecessary computations and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "wildmeshing-toolkit",
        "hash": "0b353083fee3581d62d3ce70542ab8122a7311bb",
        "author": "Michael Tao",
        "date": "2024-06-03T15:30:17-04:00",
        "message": "decreasing split count due to new performance changes making this too slow",
        "modified_files_count": 1,
        "modified_files": [
            "tests/operations/split_2d.cpp"
        ],
        "github_commit_url": "https://github.com/wildmeshing/wildmeshing-toolkit/commit/0b353083fee3581d62d3ce70542ab8122a7311bb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_CASE"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of split operations in a test case to mitigate performance degradation caused by recent changes.",
            "The optimization strategy involved reducing the number of split operations in a test case to mitigate performance degradation caused by recent changes.",
            "The optimization strategy involved reducing the number of split operations in a test case to mitigate performance degradation caused by recent changes.",
            "The optimization strategy involved reducing the number of split operations in a test case to mitigate performance degradation caused by recent changes.",
            "The optimization strategy involved reducing the number of split operations in a test case to mitigate performance degradation caused by recent changes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of split operations in a test case to mitigate performance degradation caused by recent changes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "musique",
        "hash": "830a37bec5622aec9fd954e537c45594e1b66770",
        "author": "Flavio Tordini",
        "date": "2018-11-22T18:23:09+01:00",
        "message": "Minor string optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/mainwindow.cpp"
        ],
        "github_commit_url": "https://github.com/flaviotordini/musique/commit/830a37bec5622aec9fd954e537c45594e1b66770",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MainWindow::createActions"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing repeated string concatenation with a more efficient single-pass string construction method.",
            "The optimization strategy involved replacing repeated string concatenation with a more efficient approach, likely using a single assignment or a precomputed value to minimize redundant operations.",
            "The optimization strategy involved replacing a string concatenation operation with a more efficient approach to reduce unnecessary memory allocations.",
            "The optimization strategy involved replacing a string concatenation operation with a more efficient approach to reduce unnecessary memory allocations.",
            "The optimization strategy involved replacing repeated string concatenation with a more efficient approach, likely using a single assignment or precomputed value to reduce unnecessary memory allocations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing repeated string concatenation with a more efficient approach, likely using a single assignment or precomputed value to reduce unnecessary memory allocations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "QGIS",
        "hash": "5765cabb951bc1f82da2b883635cc9b1c74e6d44",
        "author": "i-s-o",
        "date": "2020-01-10T12:49:58+13:00",
        "message": "Speed up reading the field list from clipboard",
        "modified_files_count": 1,
        "modified_files": [
            "src/app/qgsclipboard.cpp"
        ],
        "github_commit_url": "https://github.com/qgis/QGIS/commit/5765cabb951bc1f82da2b883635cc9b1c74e6d44",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "QgsClipboard::retrieveFields"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations by caching and reusing previously calculated field values during clipboard data processing.",
            "The optimization strategy involved reducing redundant computations by caching intermediate results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing previously calculated results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing previously calculated field values when reading from the clipboard.",
            "The optimization strategy involved reducing redundant computations by caching and reusing previously calculated field values during clipboard data processing."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations by caching and reusing previously calculated field values during clipboard data processing.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "fwupd",
        "hash": "c446211b10ade47a60c56aae65378cbf607acea3",
        "author": "Denis Pynkin",
        "date": "2022-12-14T23:23:21+03:00",
        "message": "ti-tps6598x: remove the delay on write\n\nSpeed up the write by removing the delay after SFWd write:\n- 100ms (current): 3m 16s\n- no delays: 1m 45s",
        "modified_files_count": 1,
        "modified_files": [
            "plugins/ti-tps6598x/fu-ti-tps6598x-device.c"
        ],
        "github_commit_url": "https://github.com/fwupd/fwupd/commit/c446211b10ade47a60c56aae65378cbf607acea3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fu_ti_tps6598x_device_write_chunks"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing an unnecessary delay after a write operation to significantly reduce execution time.",
            "The optimization strategy removed an unnecessary delay after a write operation to significantly reduce execution time.",
            "The optimization strategy involved removing an unnecessary delay after a write operation to significantly reduce execution time.",
            "The optimization strategy involved removing an unnecessary delay after a write operation to significantly reduce overall execution time.",
            "The optimization strategy involved removing an unnecessary delay after a write operation to significantly reduce overall execution time."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing an unnecessary delay after a write operation to significantly reduce execution time.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "7c2f709b7e5990e188382ba01dc5e4175cd742a0",
        "author": "Samuel Gomes",
        "date": "2022-11-11T18:50:59+05:30",
        "message": "Change blockSampleFrames for reduced latency",
        "modified_files_count": 1,
        "modified_files": [
            "internal/c/parts/audio/audio.cpp"
        ],
        "github_commit_url": "https://github.com/QB64-Phoenix-Edition/QB64pe/commit/7c2f709b7e5990e188382ba01dc5e4175cd742a0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SampleFrameBlockQueue"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "QB64pe",
        "optimization_summary": [
            "The optimization strategy involved modifying the blockSampleFrames function to reduce latency by adjusting how audio frames are processed or queued.",
            "The optimization strategy involved modifying the block sampling logic to reduce latency by adjusting how frames are queued and processed.",
            "The optimization strategy involved modifying the blockSampleFrames function to reduce latency by adjusting how audio frames are queued and processed.",
            "The optimization strategy involved modifying the blockSampleFrames function to reduce latency by adjusting how audio frames are queued and processed.",
            "The optimization strategy involved modifying the block sampling process to reduce latency by adjusting how frames are queued and processed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved modifying the blockSampleFrames function to reduce latency by adjusting how audio frames are processed or queued.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "DSI-Studio",
        "hash": "a13c61bb149dc179b7b4f137cd2ea794f248d50d",
        "author": "frankyeh",
        "date": "2015-12-10T19:27:28-05:00",
        "message": "improve  qsdr efficiency",
        "modified_files_count": 1,
        "modified_files": [
            "libs/dsi/dsi_interface_imp.cpp"
        ],
        "github_commit_url": "https://github.com/frankyeh/DSI-Studio/commit/a13c61bb149dc179b7b4f137cd2ea794f248d50d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "reconstruction"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
            "The optimization strategy involved improving efficiency by reducing redundant computations or unnecessary operations within the qsdr-related logic.",
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
            "The optimization strategy involved improving efficiency by reducing redundant computations or unnecessary operations within the qsdr-related logic."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "tensorflow",
        "hash": "6c04b3ae15889eeaa7cf85a3e9b81c6d8cb7d2f9",
        "author": "TensorFlower Gardener",
        "date": "2019-10-21T16:42:32-07:00",
        "message": "Merge pull request #33405 from Intel-tensorflow:feature/wenxizhu/improve-resnet50-fp32-inference\n\nPiperOrigin-RevId: 275932641\nChange-Id: Iba71c736fade4032466a49d9b46eccbe96fcf003",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/core/kernels/mkl_conv_ops.cc"
        ],
        "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/6c04b3ae15889eeaa7cf85a3e9b81c6d8cb7d2f9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AllocateOutputTensor"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the allocation of output tensors in the MKL convolution operations to enhance performance for ResNet-50 FP32 inference.",
            "The optimization strategy involved improving memory allocation and tensor handling in the MKL convolution operations to enhance performance for ResNet-50 FP32 inference.",
            "The optimization strategy involved improving the allocation logic for output tensors to enhance performance during inference.",
            "The optimization strategy involved improving the allocation logic for output tensors in MKL-based convolution operations to enhance performance during ResNet-50 FP32 inference.",
            "The optimization strategy involved improving the allocation logic for output tensors to enhance performance during inference."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the allocation logic for output tensors in MKL-based convolution operations to enhance performance during ResNet-50 FP32 inference.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "FastDoom",
        "hash": "ddc8a443125b3006d75b3bc424f9793952d3d7eb",
        "author": "viti95",
        "date": "2022-06-14T11:16:26+02:00",
        "message": "Small optimization for P_CrossSubsector",
        "modified_files_count": 1,
        "modified_files": [
            "FASTDOOM/p_sight.c"
        ],
        "github_commit_url": "https://github.com/viti95/FastDoom/commit/ddc8a443125b3006d75b3bc424f9793952d3d7eb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "P_CrossSubsector"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "gnome-builder",
        "hash": "db3a7dc72b56c2fb1dc18d1954c5861333e18dd9",
        "author": "Christian Hergert",
        "date": "2016-12-30T19:29:10-08:00",
        "message": "build-tools: avoid va_args for property sets\n\nTo avoid copying the string into a new GValue, we just create the gvalue\nup front and allow it to own the generated string. This allows us to\nalso avoid the va_list g_object_set() calls for a very slight performance\nimprovement.",
        "modified_files_count": 1,
        "modified_files": [
            "plugins/build-tools/gbp-build-panel.c"
        ],
        "github_commit_url": "https://github.com/GNOME/gnome-builder/commit/db3a7dc72b56c2fb1dc18d1954c5861333e18dd9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gbp_build_panel_text_func"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids using `va_args` and `g_object_set()` by directly creating a `GValue` to own the string, reducing overhead from copying and variadic argument processing.",
            "The optimization avoids using `va_args` and `g_object_set()` by directly creating a `GValue` to own the string, reducing overhead from copying and variadic argument processing.",
            "The optimization avoids using `va_args` and `g_object_set()` by directly creating a `GValue` to own the string, reducing overhead from copying and variadic function calls.",
            "The optimization avoids using `va_args` and `g_object_set()` by directly creating a `GValue` to own the string, reducing overhead from copying and variadic function calls.",
            "The optimization avoids using `va_args` and `g_object_set()` by directly creating a `GValue` to own the string, reducing overhead from copying and variadic argument processing."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids using `va_args` and `g_object_set()` by directly creating a `GValue` to own the string, reducing overhead from copying and variadic argument processing.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ZeroTierOne",
        "hash": "13b39a0c3e11ae44277599dc01512d620197b407",
        "author": "Adam Ierymenko",
        "date": "2016-02-04T14:03:37-08:00",
        "message": "SQLite perf tuning",
        "modified_files_count": 1,
        "modified_files": [
            "controller/SqliteNetworkController.cpp"
        ],
        "github_commit_url": "https://github.com/zerotier/ZeroTierOne/commit/13b39a0c3e11ae44277599dc01512d620197b407",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SqliteNetworkController::SqliteNetworkController"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit optimizes SQLite performance by tuning its configuration parameters for better efficiency.",
            "The optimization strategy involved tuning SQLite performance by adjusting database connection settings or query execution parameters.",
            "The commit optimizes SQLite performance by tuning its configuration parameters for better efficiency.",
            "The commit optimizes SQLite performance by tuning its configuration parameters for better efficiency.",
            "The commit optimizes SQLite performance by tuning its configuration parameters for better efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit optimizes SQLite performance by tuning its configuration parameters for better efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "HPCC-Platform",
        "hash": "c9eb186bbdb99adc21f13a503f37ffbbfe903bd9",
        "author": "Richard Chapman",
        "date": "2018-11-29T16:01:54+00:00",
        "message": "Merge pull request #11955 from ghalliday/issue20961\n\nHPCC-20961 Optimize removing a memory callback\r\n\r\nReviewed-By: Shamser Ahmed <shamser.ahmed@lexisnexis.co.uk>\r\nReviewed-By: Richard Chapman <rchapman@hpccsystems.com>",
        "modified_files_count": 1,
        "modified_files": [
            "roxie/roxiemem/roxiemem.cpp"
        ],
        "github_commit_url": "https://github.com/hpcc-systems/HPCC-Platform/commit/c9eb186bbdb99adc21f13a503f37ffbbfe903bd9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "removeRowBuffer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the logic for removing a memory callback to reduce unnecessary operations and improve efficiency.",
            "The optimization strategy involved improving the efficiency of removing a memory callback by reducing unnecessary operations or iterations.",
            "The optimization strategy involved reducing the overhead of removing a memory callback by minimizing unnecessary operations or checks within the `removeRowBuffer` function.",
            "The optimization strategy involved improving the efficiency of removing a memory callback by reducing unnecessary operations or iterations.",
            "The optimization strategy involved reducing the overhead of removing a memory callback by improving the efficiency of the associated data structure operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of removing a memory callback by reducing unnecessary operations or iterations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kvm-guest-drivers-windows",
        "hash": "65d5232209cae7d131fd97dba624b3ee7e3ad447",
        "author": "Ladi Prosek",
        "date": "2016-07-22T10:49:37+10:00",
        "message": "vioscsi: Adjust queue memory allocation\n\nAllocating memory for max_cpus queues is too pessimistic.\nWe know that in addition to max_cpus, the number of queues\nis also bounded by the actual number of queues offered by\nthe device.\n\nThis commit reduces the memory footprint in cases where the\nVM runs with a lot of CPUs but only a small number of queues.",
        "modified_files_count": 1,
        "modified_files": [
            "vioscsi/vioscsi.c"
        ],
        "github_commit_url": "https://github.com/virtio-win/kvm-guest-drivers-windows/commit/65d5232209cae7d131fd97dba624b3ee7e3ad447",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VioScsiFindAdapter"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces memory allocation by bounding the number of queues based on the actual device-offered queues rather than solely relying on the maximum CPU count.",
            "The optimization strategy reduces memory allocation by limiting the number of queues to the actual number offered by the device instead of the maximum possible CPUs.",
            "The optimization strategy reduces memory allocation by limiting the number of queues to the actual number offered by the device instead of the maximum possible CPUs.",
            "The optimization strategy reduces memory allocation by bounding the number of queues based on the actual device-offered queues rather than the maximum CPUs.",
            "The optimization strategy reduces memory allocation by bounding the number of queues based on the actual device-offered queues rather than the maximum CPUs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces memory allocation by bounding the number of queues based on the actual device-offered queues rather than the maximum CPUs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "plasma-desktop",
        "hash": "7e758c5ab5ac88863299e8a4643fba68115f5fd7",
        "author": "Eike Hein",
        "date": "2014-05-02T14:01:29+02:00",
        "message": "More efficient runner matches model updates.",
        "modified_files_count": 1,
        "modified_files": [
            "applets/kicker/plugin/runnermatchesmodel.cpp"
        ],
        "github_commit_url": "https://github.com/KDE/plasma-desktop/commit/7e758c5ab5ac88863299e8a4643fba68115f5fd7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RunnerMatchesModel::setMatches"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "descartes",
        "hash": "0646096b64013d404767af62c0db94ed7b426920",
        "author": "Jonathan Meyer",
        "date": "2016-06-18T11:05:07-05:00",
        "message": "Merge pull request #168 from davetcoleman/getShortestPathSpeedup\n\nSpeed up search of planning graph",
        "modified_files_count": 1,
        "modified_files": [
            "descartes_planner/src/planning_graph.cpp"
        ],
        "github_commit_url": "https://github.com/ros-industrial-consortium/descartes/commit/0646096b64013d404767af62c0db94ed7b426920",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PlanningGraph::getShortestPath"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the search algorithm in the planning graph to reduce redundant computations and improve pathfinding efficiency.",
            "The optimization strategy involved restructuring the search algorithm in the planning graph to reduce unnecessary computations during the shortest path calculation.",
            "The optimization strategy involved restructuring the search algorithm in the planning graph to reduce unnecessary computations and improve the efficiency of finding the shortest path.",
            "The optimization strategy involved restructuring the search algorithm in the planning graph to reduce unnecessary computations during the shortest path calculation.",
            "The optimization strategy involved restructuring the search algorithm in the planning graph to reduce unnecessary computations during the shortest path calculation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the search algorithm in the planning graph to reduce unnecessary computations during the shortest path calculation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cheribsd",
        "hash": "b86875b94424de60c259d87ce78ddde5b1d9cbc1",
        "author": "cg",
        "date": "2001-09-18T15:19:44+00:00",
        "message": "when setting blocksize, fix blockcount to 2 to reduce latency with smaller\nblock sizes.",
        "modified_files_count": 1,
        "modified_files": [
            "sys/dev/sound/isa/mss.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/b86875b94424de60c259d87ce78ddde5b1d9cbc1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "msschan_setblocksize"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy fixes the block count to 2 when setting block size to reduce latency for smaller block sizes.",
            "The optimization strategy fixes the block count to 2 when setting block size to reduce latency for smaller block sizes.",
            "The optimization strategy fixes the block count to 2 when setting block size to reduce latency for smaller block sizes.",
            "The optimization strategy fixes the block count to 2 when setting block size to reduce latency for smaller block sizes.",
            "The optimization strategy fixes the block count to 2 when setting block size to reduce latency for smaller block sizes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy fixes the block count to 2 when setting block size to reduce latency for smaller block sizes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mutter",
        "hash": "b30c907ef95644c0adec45d599fd31c48ad0a4d2",
        "author": "Carlos Garnacho",
        "date": "2018-08-27T08:38:13+00:00",
        "message": "wayland: Use geometry_scale on opaque regions\n\nThis was done for input regions in commit 718a89eb2f4 (Thanks Jonas\nfor the archaeology!) but opaque regions follow the same scaling.\nThis brings less evident issues as opaque regions are just used for\nculling optimizations.",
        "modified_files_count": 1,
        "modified_files": [
            "src/wayland/meta-wayland-actor-surface.c"
        ],
        "github_commit_url": "https://github.com/GNOME/mutter/commit/b30c907ef95644c0adec45d599fd31c48ad0a4d2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "meta_wayland_actor_surface_real_sync_actor_state"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved applying a scaling factor (`geometry_scale`) to opaque regions to align their handling with input regions, reducing unnecessary computations during culling operations.",
            "The optimization strategy involved applying a scaling factor (`geometry_scale`) to opaque regions to align their behavior with input regions, reducing unnecessary computations during culling operations.",
            "The optimization strategy involved applying a scaling factor (`geometry_scale`) to opaque regions to align their handling with input regions, reducing unnecessary computations during culling operations.",
            "The optimization strategy involved applying a scaling factor (`geometry_scale`) to opaque regions to align their handling with input regions, reducing unnecessary computations during culling operations.",
            "The optimization strategy involved applying a scaling factor (`geometry_scale`) to opaque regions to align their handling with input regions, reducing unnecessary computations during culling operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved applying a scaling factor (`geometry_scale`) to opaque regions to align their handling with input regions, reducing unnecessary computations during culling operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BambuStudio",
        "hash": "94b4194b11a6f04a056b05d504b734492c4967ad",
        "author": "qing.zhang",
        "date": "2023-11-01T09:11:19+08:00",
        "message": "ENH: arachne overhang efficiency optimization\n\nSigned-off-by: qing.zhang <qing.zhang@bambulab.com>\nChange-Id: I9b0954e24867b5f4a29e0e5d24708cd977ec22aa",
        "modified_files_count": 1,
        "modified_files": [
            "src/libslic3r/PerimeterGenerator.cpp"
        ],
        "github_commit_url": "https://github.com/bambulab/BambuStudio/commit/94b4194b11a6f04a056b05d504b734492c4967ad",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "traverse_extrusions"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of traversing extrusions by reducing redundant calculations or iterations in the `traverse_extrusions` function.",
            "The optimization strategy involved improving the efficiency of traversing extrusions by reducing redundant calculations or iterations in the `traverse_extrusions` function.",
            "The optimization strategy involved improving the efficiency of traversing extrusions by reducing redundant calculations and optimizing the order of operations.",
            "The optimization strategy involved improving the efficiency of traversing extrusions by reducing redundant calculations or iterations in the `traverse_extrusions` function.",
            "The optimization strategy involved improving the efficiency of traversing extrusions by reducing redundant calculations or iterations in the `traverse_extrusions` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of traversing extrusions by reducing redundant calculations or iterations in the `traverse_extrusions` function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "urho3d",
        "hash": "ecdfec3e8049325a9da1966cbb8ab9cbd39243c6",
        "author": "Lasse Öörni",
        "date": "2012-04-28T17:50:30+00:00",
        "message": "Small optimization to drawable collecting.",
        "modified_files_count": 1,
        "modified_files": [
            "Engine/Graphics/View.cpp"
        ],
        "github_commit_url": "https://github.com/urho3d/urho3d/commit/ecdfec3e8049325a9da1966cbb8ab9cbd39243c6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "View::GetDrawables"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant drawable collection by caching and reusing previously collected data.",
            "The optimization strategy involved reducing redundant drawable collection by caching and reusing previously collected data.",
            "The optimization strategy involved reducing redundant drawable collection by caching and reusing previously collected data.",
            "The optimization strategy involved reducing redundant drawable collection by caching and reusing previously collected data.",
            "The optimization strategy involved reducing redundant drawable collection by caching and reusing previously collected data."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant drawable collection by caching and reusing previously collected data.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "bibletime",
        "hash": "69d648c556b65d1e4600837274997162f7245a2c",
        "author": "Jaak Ristioja",
        "date": "2022-10-30T23:45:51+02:00",
        "message": "frontend, BtModelViewReadDisplay: Minor QString-related optimizations",
        "modified_files_count": 1,
        "modified_files": [
            "src/frontend/display/btmodelviewreaddisplay.cpp"
        ],
        "github_commit_url": "https://github.com/bibletime/bibletime/commit/69d648c556b65d1e4600837274997162f7245a2c",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary QString operations to improve performance.",
            "The optimization strategy involved reducing unnecessary QString operations by directly using existing string references.",
            "The optimization strategy involved reducing unnecessary QString operations to improve performance.",
            "The optimization strategy involved reducing unnecessary QString operations to improve performance.",
            "The optimization strategy involved reducing unnecessary QString operations by directly using existing string references."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary QString operations to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "tensorflow-directml",
        "hash": "707b0c9cc4d5335d04fce4addb8ed2f158cbd1c0",
        "author": "A. Unique TensorFlower",
        "date": "2018-05-01T15:06:01-07:00",
        "message": "Minor JNI performance improvement.\n\nPiperOrigin-RevId: 195002949",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/contrib/lite/java/src/main/native/tensor_jni.cc"
        ],
        "github_commit_url": "https://github.com/microsoft/tensorflow-directml/commit/707b0c9cc4d5335d04fce4addb8ed2f158cbd1c0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Java_org_tensorflow_lite_Tensor_shape"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a loop that repeatedly accessed a Java array with a single direct access to improve JNI performance.",
            "The optimization strategy involved replacing a loop that repeatedly accessed a Java array with a single direct access to reduce JNI overhead.",
            "The optimization strategy involved replacing a loop that repeatedly accessed a Java array with a single direct access to improve JNI performance.",
            "The optimization strategy involved replacing a loop that repeatedly accessed a Java array with a single direct access to improve JNI performance.",
            "The optimization strategy involved reducing JNI call overhead by caching the result of a method lookup."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a loop that repeatedly accessed a Java array with a single direct access to improve JNI performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "darktable",
        "hash": "7089c0b8074867c6ad023e7b0dec56a147b40dc5",
        "author": "ralfbrown",
        "date": "2020-12-05T11:36:34-05:00",
        "message": "merge loops\n\nPerform the pixel inversion/desaturation as part of actually applying\nthe shadows/highlights adjustments instead of as as separate pass.\nReduces memory traffic for ~10% speedup with 32 threads.",
        "modified_files_count": 1,
        "modified_files": [
            "src/iop/shadhi.c"
        ],
        "github_commit_url": "https://github.com/darktable-org/darktable/commit/7089c0b8074867c6ad023e7b0dec56a147b40dc5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "process"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization merges two separate loops into one to reduce memory traffic and improve cache utilization by performing pixel inversion/desaturation during the shadows/highlights adjustment pass.",
            "The optimization merges two separate loops into one to reduce memory traffic and improve cache utilization by performing pixel inversion/desaturation during the shadows/highlights adjustment pass.",
            "The optimization merges two separate loops into one to reduce memory traffic and improve cache utilization by performing pixel inversion/desaturation during the shadows/highlights adjustment pass.",
            "The optimization merges two separate loops into one to reduce memory traffic and improve cache utilization by performing pixel inversion/desaturation during the shadows/highlights adjustment pass.",
            "The optimization merges two separate loops into one to reduce memory traffic and improve cache utilization by performing pixel inversion/desaturation during the shadows/highlights adjustment pass."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization merges two separate loops into one to reduce memory traffic and improve cache utilization by performing pixel inversion/desaturation during the shadows/highlights adjustment pass.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ffmpeg",
        "hash": "621561cdf37057d45e38cf1b4404e5de870b1683",
        "author": "Michael Niedermayer",
        "date": "2008-12-18T00:46:54+00:00",
        "message": "Skip chroma handling when there is no coded chroma.\n0.5% overall speedup for the cathedral sample.\n\nOriginally committed as revision 16201 to svn://svn.ffmpeg.org/ffmpeg/trunk",
        "modified_files_count": 1,
        "modified_files": [
            "libavcodec/h264.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/621561cdf37057d45e38cf1b4404e5de870b1683",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hl_decode_mb_internal"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization skips chroma handling when there is no coded chroma, reducing unnecessary computations.",
            "The optimization skips chroma handling when there is no coded chroma, reducing unnecessary computations.",
            "The optimization skips chroma handling when there is no coded chroma, reducing unnecessary computations.",
            "The optimization skips chroma handling when there is no coded chroma, reducing unnecessary computations.",
            "The optimization skips chroma handling when there is no coded chroma, reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization skips chroma handling when there is no coded chroma, reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "transmission",
        "hash": "e8c2f6cf154458e263f733f76bbf503f730fd1af",
        "author": "Charles Kerr",
        "date": "2010-12-21T22:07:15+00:00",
        "message": "(trunk libT) #3836 \"libevent2 support\" -- optimize serialization of json strings for libevent2's new evbuffer API.  This also fixes #3843",
        "modified_files_count": 1,
        "modified_files": [
            "libtransmission/bencode.c"
        ],
        "github_commit_url": "https://github.com/transmission/transmission/commit/e8c2f6cf154458e263f733f76bbf503f730fd1af",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "jsonStringFunc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved leveraging libevent2's evbuffer API to improve the efficiency of JSON string serialization by reducing unnecessary memory operations.",
            "The optimization strategy involved improving the efficiency of JSON string serialization by leveraging libevent2's evbuffer API to reduce memory operations and improve performance.",
            "The optimization strategy involved replacing manual string serialization with a more efficient API call from libevent2's evbuffer to improve performance.",
            "The optimization strategy involved leveraging libevent2's evbuffer API to improve the efficiency of JSON string serialization by reducing unnecessary memory operations.",
            "The optimization strategy involved improving the efficiency of JSON string serialization by leveraging libevent2's evbuffer API to reduce memory operations and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved leveraging libevent2's evbuffer API to improve the efficiency of JSON string serialization by reducing unnecessary memory operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "epiphany",
        "hash": "216bf531440434b7ce51ba0d8ce35db6a4359781",
        "author": "Patrick Griffis",
        "date": "2022-07-13T17:23:50+00:00",
        "message": "WebExtensions: Disable hardware acceleration to lower memory usage\n\nOn my machine this takes it from 110-120 MB to 65-70 MB\n\nPart-of: <https://gitlab.gnome.org/GNOME/epiphany/-/merge_requests/1170>",
        "modified_files_count": 1,
        "modified_files": [
            "src/webextension/ephy-web-extension-manager.c"
        ],
        "github_commit_url": "https://github.com/GNOME/epiphany/commit/216bf531440434b7ce51ba0d8ce35db6a4359781",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ephy_web_extensions_manager_create_web_extensions_webview"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy disables hardware acceleration to reduce memory usage by lowering the resource demands of the webview component.",
            "The optimization strategy disables hardware acceleration to reduce memory usage by lowering the resource demands of the webview component.",
            "The optimization strategy disables hardware acceleration to reduce memory usage by lowering the resource demands of the webview component.",
            "The optimization strategy disables hardware acceleration to reduce memory usage by lowering the resource demands of the webview component.",
            "The optimization strategy disables hardware acceleration to reduce memory usage by lowering the resource demands of the WebExtensions webview."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy disables hardware acceleration to reduce memory usage by lowering the resource demands of the webview component.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SLiM",
        "hash": "b8747538a529a5e51638181eedb9f3df9cbdfdca",
        "author": "Ben Haller",
        "date": "2019-02-16T21:48:33-05:00",
        "message": "speed up single-codon case",
        "modified_files_count": 1,
        "modified_files": [
            "core/slim_global.cpp"
        ],
        "github_commit_url": "https://github.com/MesserLab/SLiM/commit/b8747538a529a5e51638181eedb9f3df9cbdfdca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "NucleotideArray::NucleotidesAsCodonVector"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to reduce unnecessary computations by directly returning results for single-codon cases instead of iterating through the entire codon vector.",
            "The optimization strategy used is to reduce unnecessary computations by directly returning results for single-codon cases instead of iterating through all codons.",
            "The optimization strategy used is to reduce unnecessary computations by directly returning results for single-codon cases instead of iterating through the entire codon vector.",
            "The optimization strategy used is to reduce unnecessary computations by directly returning results for single-codon cases instead of iterating through all codons.",
            "The optimization strategy used is to reduce unnecessary computations by directly returning results for single-codon cases instead of iterating through all codons."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is to reduce unnecessary computations by directly returning results for single-codon cases instead of iterating through all codons.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cheribsd",
        "hash": "012f478c8162413e5e8320ff346dfd57a40ca9d1",
        "author": "jkim",
        "date": "2010-08-07T03:45:45+00:00",
        "message": "Optimize interrupt vector lookup.  There is no need to check the page table.",
        "modified_files_count": 1,
        "modified_files": [
            "sys/compat/x86bios/x86bios.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/012f478c8162413e5e8320ff346dfd57a40ca9d1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "x86bios_get_intr"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy eliminates unnecessary page table checks during interrupt vector lookup to reduce overhead.",
            "The optimization strategy eliminates unnecessary page table checks during interrupt vector lookup to reduce overhead.",
            "The optimization strategy eliminates unnecessary page table checks during interrupt vector lookup to reduce overhead.",
            "The optimization strategy eliminates unnecessary page table checks during interrupt vector lookup to reduce overhead.",
            "The optimization strategy eliminates unnecessary page table checks during interrupt vector lookup to reduce overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy eliminates unnecessary page table checks during interrupt vector lookup to reduce overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MediaInfoLib",
        "hash": "ea3d0070d96b17b8e4dd76a668f063f4a084661d",
        "author": "JeromeMartinez",
        "date": "2014-02-20T11:21:37+00:00",
        "message": "+ VC-3: Some speed improvement after VC-3 is detected\n\ngit-svn-id: svn://svn.code.sf.net/p/mediainfo/code/MediaInfoLib/trunk@6108 45c5ae6f-87cc-4fd0-92ee-e4f023fd80da",
        "modified_files_count": 1,
        "modified_files": [
            "Source/MediaInfo/Video/File_Vc3.cpp"
        ],
        "github_commit_url": "https://github.com/MediaArea/MediaInfoLib/commit/ea3d0070d96b17b8e4dd76a668f063f4a084661d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "File_Vc3::Data_Parse"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations or checks after VC-3 detection to improve parsing speed.",
            "The optimization strategy involved reducing unnecessary computations or checks after VC-3 detection to improve parsing speed.",
            "The optimization strategy involved reducing unnecessary computations or checks after VC-3 detection to improve parsing speed.",
            "The optimization strategy involved reducing unnecessary computations or checks after VC-3 detection to improve parsing speed.",
            "The optimization strategy involved reducing unnecessary computations or checks after VC-3 detection to improve parsing speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations or checks after VC-3 detection to improve parsing speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mame2003-plus-libretro",
        "hash": "bdf262379fb8b01ae42594b08466a7fe738031b1",
        "author": "mahoneyt944",
        "date": "2024-07-04T17:03:09-04:00",
        "message": "Test multi32 speedup",
        "modified_files_count": 1,
        "modified_files": [
            "src/drivers/segas32.c"
        ],
        "github_commit_url": "https://github.com/libretro/mame2003-plus-libretro/commit/bdf262379fb8b01ae42594b08466a7fe738031b1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WRITE16_HANDLER"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a series of individual bit-shift operations with a more efficient combined operation to improve performance.",
            "The optimization strategy involved simplifying conditional checks and reducing redundant operations within the WRITE16_HANDLER function to improve performance.",
            "The optimization strategy involved replacing a series of individual bit-shift operations with a more efficient combined operation to improve performance.",
            "The optimization strategy involved replacing a series of individual bit-shift operations with a more efficient combined operation to improve performance.",
            "The optimization strategy involved simplifying or streamlining the logic within the WRITE16_HANDLER function to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a series of individual bit-shift operations with a more efficient combined operation to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "android_kernel_brcm_rpi",
        "hash": "efb61a71854014bf2705d48454885f58ec6ed62e",
        "author": "Nicholas Kazlauskas",
        "date": "2023-07-23T13:46:57+02:00",
        "message": "drm/amd/display: Explicitly specify update type per plane info change\n\n[ Upstream commit 710cc1e7cd461446a9325c9bd1e9a54daa462952 ]\n\n[Why]\nThe bit for flip addr is being set causing the determination for\nFAST vs MEDIUM to always return MEDIUM when plane info is provided\nas a surface update. This causes extreme stuttering for the typical\natomic update path on Linux.\n\n[How]\nDon't use update_flags->raw for determining FAST vs MEDIUM. It's too\nfragile to changes like this.\n\nExplicitly specify the update type per update flag instead. It's not\nas clever as checking the bits itself but at least it's correct.\n\nFixes: aa5fdb1ab5b6 (\"drm/amd/display: Explicitly specify update type per plane info change\")\nReviewed-by: Rodrigo Siqueira <Rodrigo.Siqueira@amd.com>\nSigned-off-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>\nTested-by: Daniel Wheeler <daniel.wheeler@amd.com>\nSigned-off-by: Alex Deucher <alexander.deucher@amd.com>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/amd/display/dc/core/dc.c"
        ],
        "github_commit_url": "https://github.com/lineage-rpi/android_kernel_brcm_rpi/commit/efb61a71854014bf2705d48454885f58ec6ed62e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "det_surface_update"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy explicitly specifies the update type per plane info change instead of relying on fragile bit-flag checks to avoid incorrect update type determination.",
            "The optimization strategy explicitly specifies the update type per plane info change instead of relying on fragile bit-flag checks to determine FAST vs MEDIUM updates.",
            "The optimization explicitly specifies the update type per plane info change instead of relying on fragile bit checks to avoid incorrect performance-degrading decisions.",
            "The optimization strategy explicitly specifies the update type per plane info change to avoid incorrect determination of FAST vs MEDIUM updates, reducing stuttering in the atomic update path.",
            "The optimization explicitly specifies the update type per plane info change instead of relying on fragile bit-flag checks to avoid incorrect update determinations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy explicitly specifies the update type per plane info change instead of relying on fragile bit-flag checks to determine FAST vs MEDIUM updates.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cycles",
        "hash": "b5f81608ccf5c47793949a97f5d460a9e61116b2",
        "author": "Stephen Luce",
        "date": "2023-07-05T18:18:39+02:00",
        "message": "Remove redundant bounds checks in cpu image sampling\n\nFor repeat / extend / mirror mode, both wrap and read_clip functions did\nthe bounds check. Removing it improves performance between 0.5% and 1.5%\nin the classroom scene in one test. Clip mode is unchanged.\n\nPull Request: https://projects.blender.org/blender/blender/pulls/109304",
        "modified_files_count": 1,
        "modified_files": [
            "src/kernel/device/cpu/image.h"
        ],
        "github_commit_url": "https://github.com/blender/cycles/commit/b5f81608ccf5c47793949a97f5d460a9e61116b2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "interp_linear"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes redundant bounds checks in image sampling for repeat, extend, and mirror modes by leveraging the fact that both wrap and read_clip functions already perform bounds checking.",
            "The optimization removes redundant bounds checks in image sampling for repeat, extend, and mirror modes by leveraging the fact that both wrap and read_clip functions already perform bounds checking.",
            "The optimization removes redundant bounds checks in image sampling for repeat, extend, and mirror modes by leveraging the fact that both wrap and read_clip functions already perform bounds checking.",
            "The optimization removes redundant bounds checks in image sampling for repeat, extend, and mirror modes by leveraging the fact that both wrap and read_clip functions already perform bounds checking.",
            "The optimization removes redundant bounds checks in image sampling for specific modes to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization removes redundant bounds checks in image sampling for repeat, extend, and mirror modes by leveraging the fact that both wrap and read_clip functions already perform bounds checking.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "openbor",
        "hash": "dea1551e4d117c6d5f7b8c9529de66e557b1950e",
        "author": "utunnels",
        "date": "2011-09-05T01:12:04+00:00",
        "message": "Optimize rgb gif copying speed a bit.",
        "modified_files_count": 1,
        "modified_files": [
            "engine/openbor.c"
        ],
        "github_commit_url": "https://github.com/DCurrent/openbor/commit/dea1551e4d117c6d5f7b8c9529de66e557b1950e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "update_backbuffer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a nested loop structure with a single loop to reduce iteration overhead and improve cache locality when copying RGB GIF data.",
            "The optimization strategy involved replacing a nested loop structure with a single loop to reduce iteration overhead and improve RGB GIF copying speed.",
            "The optimization strategy involved replacing a nested loop structure with a single loop to reduce iteration overhead and improve RGB GIF copying speed.",
            "The optimization strategy involved replacing a nested loop structure with a single loop to reduce iteration overhead and improve RGB GIF copying speed.",
            "The optimization strategy involved replacing a nested loop structure with a single loop to reduce iteration overhead and improve RGB GIF copying speed."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a nested loop structure with a single loop to reduce iteration overhead and improve RGB GIF copying speed.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "maps-core",
        "hash": "2410ade7e4e9431e31e8eb808d1883dbb55536a1",
        "author": "Christoph Maurhofer",
        "date": "2024-08-27T19:42:41+02:00",
        "message": "Optimize intertia speed in 3d mode",
        "modified_files_count": 1,
        "modified_files": [
            "shared/src/map/camera/MapCamera3d.cpp"
        ],
        "github_commit_url": "https://github.com/openmobilemaps/maps-core/commit/2410ade7e4e9431e31e8eb808d1883dbb55536a1",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adjusting the inertia speed calculation in 3D mode to reduce unnecessary computations or improve efficiency.",
            "The optimization strategy involved adjusting the inertia speed calculation in 3D mode to reduce unnecessary computations or improve efficiency.",
            "The optimization strategy involved adjusting the inertia speed calculation in 3D mode to improve performance by reducing unnecessary computations or iterations.",
            "The optimization strategy involved adjusting the inertia speed calculation in 3D mode to reduce unnecessary computations or improve efficiency.",
            "The optimization strategy involved adjusting the inertia speed calculation in 3D mode to reduce unnecessary computations or improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting the inertia speed calculation in 3D mode to reduce unnecessary computations or improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "bfdbc1155473af599081880289036def7f92e32a",
        "author": "Jakob Stoklund Olesen",
        "date": "2011-03-03T06:29:01+00:00",
        "message": "Renumber slot indexes uniformly instead of spacing according to the number of defs.\n\nThere are probably much larger speedups to be had by renumbering locally instead\nof looping over the whole function. For now, the greedy register allocator is\n25% faster.\n\nllvm-svn: 126926",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/SlotIndexes.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/bfdbc1155473af599081880289036def7f92e32a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SlotIndexes::renumberIndexes"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy renumbers slot indexes uniformly to reduce computational overhead compared to spacing them based on the number of definitions.",
            "The optimization strategy renumbers slot indexes uniformly to reduce computational overhead compared to spacing them based on the number of definitions.",
            "The optimization strategy renumbers slot indexes uniformly to reduce computational overhead compared to spacing them based on the number of definitions.",
            "The optimization strategy renumbers slot indexes uniformly to reduce computational overhead compared to spacing them based on the number of definitions.",
            "The optimization strategy renumbers slot indexes uniformly to reduce computational overhead compared to spacing them based on the number of definitions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy renumbers slot indexes uniformly to reduce computational overhead compared to spacing them based on the number of definitions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "xenia",
        "hash": "bb15d2f62ff6d5a9468f1a85d9640d9758263e94",
        "author": "Ben Vanik",
        "date": "2015-01-02T17:44:15-08:00",
        "message": "Faster profiler drawing.",
        "modified_files_count": 1,
        "modified_files": [
            "src/xenia/gpu/gl4/gl4_profiler_display.cc"
        ],
        "github_commit_url": "https://github.com/xenia-project/xenia/commit/bb15d2f62ff6d5a9468f1a85d9640d9758263e94",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GL4ProfilerDisplay::SetupFont"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant texture binding operations in the font setup process to improve rendering performance.",
            "The optimization strategy involved reducing the number of OpenGL draw calls by batching font rendering operations.",
            "The optimization strategy involved reducing the number of OpenGL draw calls by batching font rendering operations.",
            "The optimization strategy involved reducing redundant font setup operations by caching and reusing previously loaded font data.",
            "The optimization strategy involved reducing redundant texture binding operations in the font setup process to improve rendering performance."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant texture binding operations in the font setup process to improve rendering performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "wesnoth",
        "hash": "9aa67226223b0c5239c910bc5fa3aa061c12784d",
        "author": "gfgtdf",
        "date": "2015-12-07T15:43:56+01:00",
        "message": "improve performance of wesnoth.delay(0)\n\nIn this case we don't need to call SDL_GetTicks() or\ngame_display_->delay(10)",
        "modified_files_count": 1,
        "modified_files": [
            "src/scripting/game_lua_kernel.cpp"
        ],
        "github_commit_url": "https://github.com/wesnoth/wesnoth/commit/9aa67226223b0c5239c910bc5fa3aa061c12784d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "game_lua_kernel::intf_delay"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization eliminates unnecessary calls to SDL_GetTicks() and game_display_->delay(10) when the delay is zero, reducing overhead in the wesnoth.delay(0) function.",
            "The optimization avoids unnecessary calls to SDL_GetTicks() and game_display_->delay(10) when the delay is zero, reducing overhead in the wesnoth.delay(0) function.",
            "The optimization strategy eliminates unnecessary function calls (SDL_GetTicks() and game_display_->delay(10)) when the delay is zero to reduce overhead.",
            "The optimization strategy eliminates unnecessary function calls (SDL_GetTicks and game_display_->delay) when the delay is zero to reduce overhead.",
            "The optimization strategy eliminates unnecessary function calls (SDL_GetTicks() and game_display_->delay(10)) when the delay is zero to reduce overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy eliminates unnecessary function calls (SDL_GetTicks() and game_display_->delay(10)) when the delay is zero to reduce overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "tensorflow-directml",
        "hash": "903e7d93bc0815e4c96ec6d51127bac26e49329b",
        "author": "A. Unique TensorFlower",
        "date": "2018-06-28T21:37:43-07:00",
        "message": "Improve the performance of ParseShapeStringInternal\n\nThe previous implementation recompiled the shape regex at every call\nwhat is an expensive opertaion. The new implementation improves the hlo\ntext parsing time for very large models for up to 9x by eliminating this\noverhead.\n\nPiperOrigin-RevId: 202454354",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/compiler/xla/shape_util.cc"
        ],
        "github_commit_url": "https://github.com/microsoft/tensorflow-directml/commit/903e7d93bc0815e4c96ec6d51127bac26e49329b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ParseShapeStringInternal"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved caching the compiled regex to avoid recompiling it on every function call, thereby reducing overhead.",
            "The optimization strategy involved caching the compiled regex to avoid recompiling it on every function call, thereby reducing overhead.",
            "The optimization strategy involved caching the compiled regex to avoid recompiling it on every function call, thereby reducing overhead.",
            "The optimization strategy involved caching the compiled regex to avoid recompiling it on every function call, thereby reducing overhead.",
            "The optimization strategy involved caching the compiled regex to avoid recompiling it on every function call, thereby reducing overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved caching the compiled regex to avoid recompiling it on every function call, thereby reducing overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "SIRIUS",
        "hash": "121bf54b822673237859486a2dea2863c3c14e06",
        "author": "toxa81",
        "date": "2016-11-08T08:46:29+01:00",
        "message": "switch back to faster method",
        "modified_files_count": 1,
        "modified_files": [
            "src/Band/solve.hpp"
        ],
        "github_commit_url": "https://github.com/electronic-structure/SIRIUS/commit/121bf54b822673237859486a2dea2863c3c14e06",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Band::solve_for_kset"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reverting to a previously used, faster algorithm or method for solving a specific problem within the `Band::solve_for_kset` function.",
            "The optimization strategy involved reverting to a previously used, faster computational method for solving a specific problem.",
            "The optimization strategy involved reverting to a previously faster method for solving a specific problem in the code.",
            "The optimization strategy involved reverting to a previously used, faster computational method for solving a specific problem in the code.",
            "The optimization strategy involved reverting to a previously used, faster computational method for solving a specific problem."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reverting to a previously used, faster computational method for solving a specific problem in the code.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "c23f397cc4e440742b2b27690694c9346f638800",
        "author": "Christian Borntraeger",
        "date": "2015-02-09T12:44:10+01:00",
        "message": "KVM: s390: reenable LPP facility\n\ncommit 7be81a46695d (\"KVM: s390/facilities: allow TOD-CLOCK steering\nfacility bit\") accidentially disabled the \"load program parameter\"\nfacility bit during rebase for upstream submission (my fault).\n\nRe-add that bit.\n\nAs this is only for a performance measurement helper instruction\n(used by KVM itself) cc stable is not necessary see\nhttp://www-01.ibm.com/support/docview.wss?uid=isg26fcd1cc32246f4c8852574ce0044734a\n(SA23-2260 The Load-Program-Parameter and CPU-Measurement Facilities)\nfor details about LPP and its usecase.\n\nSigned-off-by: Christian Borntraeger <borntraeger@de.ibm.com>\nReviewed-by: David Hildenbrand <dahi@linux.vnet.ibm.com>\nAcked-by: Cornelia Huck <cornelia.huck@de.ibm.com>\nFixes: 7be81a46695d (\"KVM: s390/facilities: allow TOD-CLOCK steering\")",
        "modified_files_count": 1,
        "modified_files": [
            "arch/s390/kvm/kvm-s390.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/c23f397cc4e440742b2b27690694c9346f638800",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "kvm_s390_init"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization re-enables the \"load program parameter\" facility bit to restore a performance measurement helper instruction for KVM on s390 architecture.",
            "The optimization re-enables the \"load program parameter\" facility bit to restore a performance measurement helper instruction for KVM on s390 architecture.",
            "The optimization strategy involved re-enabling a previously disabled CPU feature (LPP facility) to restore performance measurement capabilities.",
            "The optimization re-enables the \"load program parameter\" facility bit to restore a performance measurement helper instruction for KVM on s390 architecture.",
            "The optimization re-enables a previously disabled CPU performance measurement facility (LPP) to improve performance monitoring capabilities."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization re-enables the \"load program parameter\" facility bit to restore a performance measurement helper instruction for KVM on s390 architecture.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "7cb4fa20b5534decf527a6bfcc74bd79ea11cbb1",
        "author": "Cameron Zwarich",
        "date": "2011-01-03T06:33:01+00:00",
        "message": "Switch a worklist in CodeGenPrepare to SmallVector and increase the inline\ncapacity on the Visited SmallPtrSet. On 403.gcc, this is about a 4.5% speedup of\nCodeGenPrepare time (which itself is 10% of time spent in the backend).\n\nThis is progress towards PR8889.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@122741 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Transforms/Scalar/CodeGenPrepare.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/7cb4fa20b5534decf527a6bfcc74bd79ea11cbb1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CodeGenPrepare::OptimizeMemoryInst"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a worklist data structure with a more efficient SmallVector and increasing the inline capacity of a SmallPtrSet to reduce overhead and improve performance.",
            "The optimization strategy involved replacing a worklist data structure with a more efficient SmallVector and increasing the inline capacity of a SmallPtrSet to reduce overhead and improve performance.",
            "The optimization strategy involved replacing a worklist with a SmallVector and increasing the inline capacity of a SmallPtrSet to reduce overhead and improve performance.",
            "The optimization strategy involved replacing a worklist data structure with a more efficient SmallVector and increasing the inline capacity of a SmallPtrSet to reduce overhead and improve performance.",
            "The optimization strategy involved replacing a worklist data structure with a more efficient SmallVector and increasing the inline capacity of a SmallPtrSet to reduce overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a worklist data structure with a more efficient SmallVector and increasing the inline capacity of a SmallPtrSet to reduce overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "83b0967c1fe57ce9b59ab553d282090283ca09ed",
        "author": "Alexander Motin",
        "date": "2023-07-21T16:35:12-07:00",
        "message": "Do not request data L1 buffers on scan prefetch.\n\nSet ARC_FLAG_NO_BUF when prefetching data L1 buffers for scan.  We\r\ndo not prefetch data L0 buffers, so we do not need the L1 buffers,\r\nonly want them to be ready in ARC. This saves some CPU time on the\r\nbuffers decompression.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by:\tAlexander Motin <mav@FreeBSD.org>\r\nSponsored by:\tiXsystems, Inc.\r\nCloses #15029",
        "modified_files_count": 1,
        "modified_files": [
            "module/zfs/dsl_scan.c"
        ],
        "github_commit_url": "https://github.com/ghostbsd/ghostbsd-src/commit/83b0967c1fe57ce9b59ab553d282090283ca09ed",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dsl_scan_prefetch_thread"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "ghostbsd-src",
        "optimization_summary": [
            "The optimization avoids unnecessary prefetching of L1 buffers during scan operations by setting the ARC_FLAG_NO_BUF flag, reducing CPU overhead associated with buffer decompression.",
            "The optimization avoids unnecessary prefetching of L1 buffers during scan operations by setting a flag, reducing CPU overhead associated with decompression.",
            "The optimization avoids unnecessary prefetching of L1 buffers during scan operations by setting a flag, reducing CPU overhead associated with buffer decompression.",
            "The optimization avoids unnecessary prefetching of L1 buffers during scan operations by setting a flag, reducing CPU overhead associated with buffer decompression.",
            "The optimization avoids unnecessary prefetching of L1 buffers during scan operations by setting a flag, reducing CPU overhead associated with decompression."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary prefetching of L1 buffers during scan operations by setting a flag, reducing CPU overhead associated with buffer decompression.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "cf420cca572b061fdd63587cb90904c641b6e216",
        "author": "Chris Lattner",
        "date": "2006-10-28T17:32:47+00:00",
        "message": "improve deletion of blocks that just contain branches by knowing that\nthe pred block doesn't fall through into them if it's a jumptable.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@31263 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/CodeGen/BranchFolding.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/cf420cca572b061fdd63587cb90904c641b6e216",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BranchFolder::OptimizeBlock"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves improving block deletion by leveraging knowledge that predecessor blocks do not fall through into branch-only blocks if they are part of a jump table.",
            "The optimization strategy involves improving block deletion by leveraging knowledge that predecessor blocks do not fall through into branch-only blocks if they are part of a jumptable.",
            "The optimization strategy involves improving block deletion by leveraging knowledge that predecessor blocks do not fall through into branch-only blocks if they are part of a jumptable.",
            "The optimization strategy involves improving block deletion by leveraging knowledge that predecessor blocks do not fall through into branch-only blocks if they are part of a jump table.",
            "The optimization strategy involves improving block deletion by leveraging knowledge that predecessor blocks do not fall through into branch-only blocks if they are part of a jumptable."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves improving block deletion by leveraging knowledge that predecessor blocks do not fall through into branch-only blocks if they are part of a jumptable.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "intel-graphics-compiler",
        "hash": "6bc624b78369d4e8841f7b6d9effbc7e7831acb4",
        "author": "Mariusz Merecki",
        "date": "2022-06-02T14:39:42+02:00",
        "message": "Enable reassociate `mul` `add` optimization based on driver info\n\nThe `reassociateMulAdd()` optimization helps produce more `mad` instructions and\nmust be enbled when `mad` pattern match is enabled.",
        "modified_files_count": 1,
        "modified_files": [
            "IGC/Compiler/CustomUnsafeOptPass.cpp"
        ],
        "github_commit_url": "https://github.com/intel/intel-graphics-compiler/commit/6bc624b78369d4e8841f7b6d9effbc7e7831acb4",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization enables reassociation of multiplication and addition operations to produce more `mad` (multiply-add) instructions based on driver information.",
            "The optimization enables reassociation of multiplication and addition operations to produce more `mad` instructions based on driver information.",
            "The optimization enables reassociation of multiplication and addition operations to produce more `mad` instructions based on driver information.",
            "The optimization enables reassociation of multiplication and addition operations to produce more `mad` (multiply-add) instructions based on driver information.",
            "The optimization enables reassociation of multiplication and addition operations to produce more `mad` instructions based on driver information."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization enables reassociation of multiplication and addition operations to produce more `mad` instructions based on driver information.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "scummvm",
        "hash": "f1bc2b187c72d7fa165e48b0120a41f7caf4272f",
        "author": "elasota",
        "date": "2022-12-06T23:43:27+01:00",
        "message": "COMMON: Optimize some array ops by hoisting storage pointer to a local so the compiler doesn't have to reload it every iteration.",
        "modified_files_count": 1,
        "modified_files": [
            "common/array.h"
        ],
        "github_commit_url": "https://github.com/scummvm/scummvm/commit/f1bc2b187c72d7fa165e48b0120a41f7caf4272f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "time"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved hoisting a storage pointer to a local variable to prevent the compiler from reloading it during every iteration of array operations.",
            "The optimization strategy involved hoisting a storage pointer to a local variable to prevent the compiler from reloading it during every iteration of array operations.",
            "The optimization strategy involved hoisting the storage pointer of an array to a local variable to prevent the compiler from reloading it during each iteration.",
            "The optimization strategy involved hoisting a storage pointer to a local variable to prevent the compiler from reloading it during each iteration of array operations.",
            "The optimization strategy involved hoisting a storage pointer to a local variable to prevent the compiler from reloading it during each iteration of array operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved hoisting a storage pointer to a local variable to prevent the compiler from reloading it during each iteration of array operations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "8228f2b5465e41e537d6bd972123270fca484ced",
        "author": "Nicholas Kazlauskas",
        "date": "2022-02-17T09:57:00+01:00",
        "message": "drm/amd/display: Only revalidate bandwidth on medium and fast updates\n\n[Why]\nChanges that are fast don't require updating DLG parameters making\nthis call unnecessary. Considering this is an expensive call it should\nnot be done on every flip.\n\nDML touches clocks, p-state support, DLG params and a few other DC\ninternal flags and these aren't expected during fast. A hang has been\nreported with this change when called on every flip which suggests that\nmodifying these fields is not recommended behavior on fast updates.\n\n[How]\nGuard the validation to only happen if update type isn't FAST.\n\nBug: https://gitlab.freedesktop.org/drm/amd/-/issues/1191\nFixes: a24eaa5c51255b (\"drm/amd/display: Revalidate bandwidth before commiting DC updates\")\nSigned-off-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>\nAcked-by: Alex Deucher <alexander.deucher@amd.com>\nReviewed-by: Roman Li <Roman.Li@amd.com>\nSigned-off-by: Alex Deucher <alexander.deucher@amd.com>\nCc: stable@vger.kernel.org",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/amd/display/dc/core/dc.c"
        ],
        "github_commit_url": "https://github.com/freebsd/drm-kmod/commit/8228f2b5465e41e537d6bd972123270fca484ced",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dc_commit_updates_for_stream"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "drm-kmod",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
            "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary expensive bandwidth revalidation calls by restricting them to medium and fast updates only when required.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "media-driver",
        "hash": "901dc3eebe1f6fcab7b5c782e7d5f86de05705dd",
        "author": "weizhu-intel",
        "date": "2022-03-17T20:13:38+08:00",
        "message": "[Decode] optimize for write buffer\n\nSome compiler can't optimize read-modify-write, and get very poor\nperf via PCIE bus. Change to write DW4 per Dword on command buffer.",
        "modified_files_count": 1,
        "modified_files": [
            "media_driver/agnostic/gen12/hw/vdbox/mhw_vdbox_avp_g12_X.cpp"
        ],
        "github_commit_url": "https://github.com/intel/media-driver/commit/901dc3eebe1f6fcab7b5c782e7d5f86de05705dd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MhwVdboxAvpInterfaceG12::AddAvpDecodeSurfaceStateCmd"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved changing the write operation to write one DWORD at a time in the command buffer to avoid poor performance caused by compiler inefficiencies in handling read-modify-write operations over the PCIe bus.",
            "The optimization strategy involved changing the write operation to write one DWORD at a time in the command buffer to avoid poor performance caused by compiler inefficiencies in handling read-modify-write operations over the PCIe bus.",
            "The optimization strategy involved changing the write operation to write one DWORD at a time in the command buffer to avoid poor performance caused by compiler inefficiencies in handling read-modify-write operations over the PCIe bus.",
            "The optimization strategy involved changing the write operation to write one DWORD at a time in the command buffer to avoid poor performance caused by compiler inefficiencies in handling read-modify-write operations over the PCIe bus.",
            "The optimization strategy involved changing the write operation to write individual DWords instead of using read-modify-write to improve performance over the PCIe bus."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved changing the write operation to write one DWORD at a time in the command buffer to avoid poor performance caused by compiler inefficiencies in handling read-modify-write operations over the PCIe bus.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "musl",
        "hash": "1bdd5c8b9868ebc092074e078604acb80546e43f",
        "author": "Rich Felker",
        "date": "2012-04-11T14:11:47-04:00",
        "message": "optimize floatscan: avoid excessive upscaling\n\nupscaling by even one step too much creates 3-29 extra iterations for\nthe next loop. this is still suboptimal since it always goes by 2^29\nrather than using a smaller upscale factor when nearing the target,\nbut performance on common, small-magnitude, few-digit values has\nalready more than doubled with this change.\n\nmore optimizations on the way...",
        "modified_files_count": 1,
        "modified_files": [
            "src/internal/floatscan.c"
        ],
        "github_commit_url": "https://github.com/kraj/musl/commit/1bdd5c8b9868ebc092074e078604acb80546e43f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "decfloat"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids excessive upscaling in the floatscan function by reducing unnecessary iterations in the loop when processing small-magnitude, few-digit values.",
            "The optimization avoids excessive upscaling in the floatscan function by reducing unnecessary iterations in the loop, improving performance for small-magnitude, few-digit values.",
            "The optimization avoids excessive upscaling in the floatscan function by reducing unnecessary iterations in the loop when processing small-magnitude, few-digit values.",
            "The optimization strategy avoids excessive upscaling in the floatscan function by reducing unnecessary iterations in the loop when processing small-magnitude, few-digit values.",
            "The optimization avoids excessive upscaling in the floatscan function by reducing unnecessary iterations in the loop when processing small-magnitude, few-digit values."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids excessive upscaling in the floatscan function by reducing unnecessary iterations in the loop when processing small-magnitude, few-digit values.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "hhvm",
        "hash": "ac158f6d7a4a212201f5eb88c335e6ee9ad0ddfa",
        "author": "Katy Voor",
        "date": "2024-08-01T00:40:13-07:00",
        "message": "Optimize NewObjD\n\nSummary: Speculate Class* in NewObjD\n\nReviewed By: ricklavoie\n\nDifferential Revision: D59701921\n\nfbshipit-source-id: 3b3d8d9a09ef9c0fcc368a3a29f98adfa68d1025",
        "modified_files_count": 1,
        "modified_files": [
            "hphp/runtime/vm/jit/irgen-call.cpp"
        ],
        "github_commit_url": "https://github.com/facebook/hhvm/commit/ac158f6d7a4a212201f5eb88c335e6ee9ad0ddfa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "emitNewObjD"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy speculates the Class* in NewObjD to reduce runtime checks and improve performance.",
            "The optimization strategy speculates the Class* in NewObjD to reduce runtime overhead by avoiding unnecessary lookups or checks.",
            "The optimization strategy speculates the Class* in NewObjD to reduce runtime overhead by avoiding unnecessary lookups or checks.",
            "The optimization strategy speculates the Class* in NewObjD to reduce runtime checks and improve performance.",
            "The optimization strategy speculates the Class* in NewObjD to reduce runtime checks and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy speculates the Class* in NewObjD to reduce runtime checks and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "9eac3622a2b1159ab50b10540e822f3e58fdc383",
        "author": "Peter Lieven",
        "date": "2015-04-28T15:36:10+02:00",
        "message": "block/iscsi: use the allocationmap also if cache.direct=on\n\nthe allocationmap has only a hint character. The driver always\ndouble checks that blocks marked unallocated in the cache are\nstill unallocated before taking the fast path and return zeroes.\nSo using the allocationmap is migration safe and can\nalso be enabled with cache.direct=on.\n\nSigned-off-by: Peter Lieven <pl@kamp.de>\nMessage-id: 1429193313-4263-10-git-send-email-pl@kamp.de\nSigned-off-by: Stefan Hajnoczi <stefanha@redhat.com>\nSigned-off-by: Kevin Wolf <kwolf@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "block/iscsi.c"
        ],
        "github_commit_url": "https://github.com/eurecom-s3/symqemu/commit/9eac3622a2b1159ab50b10540e822f3e58fdc383",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "iscsi_open"
        ],
        "is_opt_ds": "false",
        "is_opt_ds_simple": "true",
        "repository_name": "symqemu",
        "optimization_summary": [
            "The optimization leverages the allocation map as a hint to reduce unnecessary checks, even when `cache.direct=on`, improving performance by avoiding redundant operations.",
            "The optimization leverages the allocation map as a hint to reduce unnecessary checks, even when `cache.direct=on`, improving performance by avoiding redundant operations.",
            "The optimization leverages the allocation map as a hint to reduce unnecessary checks, even when `cache.direct=on`, improving performance by avoiding redundant operations.",
            "The optimization strategy involves enabling the use of an allocation map as a hint to potentially return zeroes for unallocated blocks, even when cache.direct is enabled, reducing unnecessary checks.",
            "The optimization leverages the allocation map as a hint to avoid unnecessary checks, even when `cache.direct=on`, improving performance by reducing redundant operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization leverages the allocation map as a hint to reduce unnecessary checks, even when `cache.direct=on`, improving performance by avoiding redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "0ed7107373b48b67d05a6647248902a200236734",
        "author": "Nithin Dabilpuram",
        "date": "2022-10-18T12:59:55+02:00",
        "message": "net/cnxk: remove duplicate mempool debug checks\n\nRemove duplicate mempool debug checks for mbufs received.\n\nFixes: 592642c494b1 (\"net/cnxk: align prefetches to CN10K cache model\")\nCc: stable@dpdk.org\n\nSigned-off-by: Nithin Dabilpuram <ndabilpuram@marvell.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/cnxk/cn10k_rx.h"
        ],
        "github_commit_url": "https://github.com/DPDK/dpdk/commit/0ed7107373b48b67d05a6647248902a200236734",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RTE_MEMPOOL_CHECK_COOKIES"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "dpdk",
        "optimization_summary": [
            "The optimization removes redundant mempool debug checks for received mbufs to reduce unnecessary overhead.",
            "The optimization removes redundant mempool debug checks for received mbufs to reduce unnecessary overhead.",
            "The optimization removes redundant mempool debug checks for received mbufs to reduce unnecessary overhead.",
            "The optimization removes redundant mempool debug checks for received mbufs to reduce unnecessary overhead.",
            "The optimization removes redundant mempool debug checks for received mbufs to reduce unnecessary overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes redundant mempool debug checks for received mbufs to reduce unnecessary overhead.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "eb6a24816b247c0be6b2e97e68933072874bbe54",
        "author": "Eric Dumazet",
        "date": "2012-04-03T16:43:18-04:00",
        "message": "af_unix: reduce high order page allocations\n\nunix_dgram_sendmsg() currently builds linear skbs, and this can stress\npage allocator with high order page allocations. When memory gets\nfragmented, this can eventually fail.\n\nWe can try to use order-2 allocations for skb head (SKB_MAX_ALLOC) plus\nup to 16 page fragments to lower pressure on buddy allocator.\n\nThis patch has no effect on messages of less than 16064 bytes.\n(on 64bit arches with PAGE_SIZE=4096)\n\nFor bigger messages (from 16065 to 81600 bytes), this patch brings\nreliability at the expense of performance penalty because of extra pages\nallocations.\n\nnetperf -t DG_STREAM -T 0,2 -- -m 16064 -s 200000\n->4086040 Messages / 10s\n\nnetperf -t DG_STREAM -T 0,2 -- -m 16068 -s 200000\n->3901747 Messages / 10s\n\nSigned-off-by: Eric Dumazet <eric.dumazet@gmail.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "net/unix/af_unix.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/eb6a24816b247c0be6b2e97e68933072874bbe54",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "unix_dgram_sendmsg"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy reduces high-order page allocations by using smaller, more manageable allocations for skb head and fragments to alleviate pressure on the memory allocator.",
            "The optimization strategy reduces high-order page allocations by using smaller, more manageable allocations for skb head and fragments to alleviate pressure on the memory allocator.",
            "The optimization strategy reduces high-order page allocations by using order-2 allocations for skb head and up to 16 page fragments to alleviate pressure on the buddy allocator.",
            "The optimization strategy reduces high-order page allocations by using smaller, more manageable allocations for skb head and fragments to alleviate pressure on the memory allocator.",
            "The optimization strategy reduces high-order page allocations by using smaller, more manageable allocations for socket buffers to alleviate memory fragmentation pressure."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces high-order page allocations by using smaller, more manageable allocations for skb head and fragments to alleviate pressure on the memory allocator.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mpv",
        "hash": "66c47599923f2919756423d47f32f2186d15cef9",
        "author": "reimar",
        "date": "2007-11-18T17:44:11+00:00",
        "message": "Use \"long\" instead of \"int\" for innermost loop variable.\nAbout 12% faster on x86_64\n\n\ngit-svn-id: svn://svn.mplayerhq.hu/mplayer/trunk@25101 b3059339-0415-0410-9bf9-f77b7e298cf2",
        "modified_files_count": 1,
        "modified_files": [
            "libaf/af_scaletempo.c"
        ],
        "github_commit_url": "https://github.com/mpv-player/mpv/commit/66c47599923f2919756423d47f32f2186d15cef9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "best_overlap_offset_s16"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved changing the data type of the innermost loop variable from \"int\" to \"long\" to improve performance on x86_64 architecture.",
            "The optimization strategy involved changing the data type of the innermost loop variable from \"int\" to \"long\" to improve performance on x86_64 architecture.",
            "The optimization strategy involved changing the data type of the innermost loop variable from \"int\" to \"long\" to improve performance on x86_64 architecture.",
            "The optimization strategy involved changing the data type of the innermost loop variable from \"int\" to \"long\" to improve performance on x86_64 architecture.",
            "The optimization strategy involved changing the data type of the innermost loop variable from \"int\" to \"long\" to improve performance on x86_64 architecture."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved changing the data type of the innermost loop variable from \"int\" to \"long\" to improve performance on x86_64 architecture.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sycl",
        "hash": "2aed25cfc977df4cb795635ee4bfa574485bbf3b",
        "author": "Chris Lattner",
        "date": "2007-02-10T07:11:51+00:00",
        "message": "make the datastructure used in BytecodeWriter::outputValueSymbolTable\n*slightly* less abusive of memory.  This speeds up the bcwriter from\n1.83s to 1.32s (39% faster) on 447.dealII.\n\nllvm-svn: 34140",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Bytecode/Writer/Writer.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/2aed25cfc977df4cb795635ee4bfa574485bbf3b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BytecodeWriter::outputValueSymbolTable"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory abuse in the data structure used by `BytecodeWriter::outputValueSymbolTable`, leading to a significant speedup.",
            "The optimization strategy involved reducing memory abuse in the data structure used by `BytecodeWriter::outputValueSymbolTable`, leading to a significant speedup.",
            "The optimization strategy involved reducing memory abuse in the data structure used by `BytecodeWriter::outputValueSymbolTable`, leading to a significant speedup.",
            "The optimization strategy involved reducing memory abuse in the data structure used by `BytecodeWriter::outputValueSymbolTable`, leading to a significant speedup.",
            "The optimization strategy involved reducing memory abuse in the data structure used by `BytecodeWriter::outputValueSymbolTable`, leading to a significant speedup."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory abuse in the data structure used by `BytecodeWriter::outputValueSymbolTable`, leading to a significant speedup.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "ace9c5dfaf09430f10e677e3646eb8df9e9fe9a6",
        "author": "Chad Rosier",
        "date": "2013-03-25T16:29:20+00:00",
        "message": "[arm load/store optimizer] When trying to merge a base update load/store, make\nsure the base register and would-be writeback register don't conflict for\nstores.  This was already being done for loads.\n\nUnfortunately, it is rather difficult to create a test case for this issue.  It\nwas exposed in 450.soplex at LTO and requires unlucky register allocation.\n<rdar://13394908>\n\nllvm-svn: 177874",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Target/ARM/ARMLoadStoreOptimizer.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/ace9c5dfaf09430f10e677e3646eb8df9e9fe9a6",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization ensures that base register and writeback register conflicts are avoided for store operations during ARM load/store merging, similar to what was already done for loads.",
            "The optimization ensures that base register and writeback register conflicts are avoided during the merging of base update load/store operations for stores, similar to what was already implemented for loads.",
            "The optimization ensures that base register and writeback register conflicts are avoided during the merging of base update load/store operations for stores, similar to what was already implemented for loads.",
            "The optimization ensures that base register and writeback register conflicts are avoided for store operations during ARM load/store merging, similar to what was already done for loads.",
            "The optimization ensures that base register and writeback register conflicts are avoided for store operations during ARM load/store merging, similar to what was already done for loads."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures that base register and writeback register conflicts are avoided for store operations during ARM load/store merging, similar to what was already done for loads.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "084cbb2ec3af2d23be9de65fcc9493e21e265859",
        "author": "Tao Liu",
        "date": "2022-02-08T16:52:31-08:00",
        "message": "gve: Recording rx queue before sending to napi\n\nThis caused a significant performance degredation when using generic XDP\nwith multiple queues.\n\nFixes: f5cedc84a30d2 (\"gve: Add transmit and receive support\")\nSigned-off-by: Tao Liu <xliutaox@google.com>\nLink: https://lore.kernel.org/r/20220207175901.2486596-1-jeroendb@google.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/ethernet/google/gve/gve_rx.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/084cbb2ec3af2d23be9de65fcc9493e21e265859",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gve_rx"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved recording the RX queue before sending it to NAPI to avoid performance degradation in generic XDP with multiple queues.",
            "The optimization strategy involved recording the RX queue before sending it to NAPI to avoid performance degradation with generic XDP and multiple queues.",
            "The optimization strategy involved recording the RX queue before sending it to NAPI to avoid performance degradation with generic XDP and multiple queues.",
            "The optimization strategy involved recording the RX queue before sending it to NAPI to avoid performance degradation in generic XDP with multiple queues.",
            "The optimization strategy involved recording the RX queue before sending it to NAPI to avoid performance degradation in generic XDP with multiple queues."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved recording the RX queue before sending it to NAPI to avoid performance degradation in generic XDP with multiple queues.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "NanoShellOS",
        "hash": "631ff02e2f7a87ea2ccef102155fa01563c06f0e",
        "author": "iProgramMC",
        "date": "2022-12-25T00:03:19+02:00",
        "message": "* Optimize background drawing in one case\n\nIn the case of a full screen background, we can just VidBitBlit\nfrom the background itself. The checks were messed up which caused\nsome situations (such as the window being partly off screen to the\nright) to go to the 'grid pattern' checks below. This fixes these\noff-by-one checks.",
        "modified_files_count": 1,
        "modified_files": [
            "src/wm/bg.c"
        ],
        "github_commit_url": "https://github.com/iProgramMC/NanoShellOS/commit/631ff02e2f7a87ea2ccef102155fa01563c06f0e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RedrawBackground"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary grid pattern checks by directly using VidBitBlit for full-screen backgrounds when the window is partly off-screen.",
            "The optimization avoids unnecessary grid pattern checks by directly using VidBitBlit for full-screen backgrounds when the window is partly off-screen.",
            "The optimization avoids unnecessary grid pattern checks by directly using VidBitBlit for full-screen backgrounds when the window is partly off-screen.",
            "The optimization avoids unnecessary grid pattern checks by directly using VidBitBlit for full-screen backgrounds when applicable.",
            "The optimization avoids unnecessary grid pattern checks by directly using VidBitBlit for full-screen backgrounds when the window is partly off-screen."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary grid pattern checks by directly using VidBitBlit for full-screen backgrounds when the window is partly off-screen.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ImageMagick6",
        "hash": "1315776a6bc3999df21212cd314eb8c175aec4cf",
        "author": "dirk",
        "date": "2014-12-22T23:49:42+00:00",
        "message": "Improved performance of ReadProfile.",
        "modified_files_count": 1,
        "modified_files": [
            "coders/tiff.c"
        ],
        "github_commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/1315776a6bc3999df21212cd314eb8c175aec4cf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ReadProfile"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant memory allocations and copies by reusing buffers during profile reading.",
            "The optimization strategy involved reducing redundant memory allocations and copies by reusing buffers in the ReadProfile function.",
            "The optimization strategy involved reducing redundant memory allocations and copies by reusing existing buffers in the ReadProfile function.",
            "The optimization strategy involved reducing redundant memory allocations and copies by reusing buffers in the ReadProfile function.",
            "The optimization strategy involved reducing redundant memory allocations and copies by reusing existing buffers in the ReadProfile function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant memory allocations and copies by reusing buffers in the ReadProfile function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "freeorion",
        "hash": "2c8a0dbaf5d33c1d5b89b54839910a43cbae2180",
        "author": "geoffthemedio",
        "date": "2022-12-02T23:57:35+01:00",
        "message": "avoid copy",
        "modified_files_count": 1,
        "modified_files": [
            "client/human/GGHumanClientApp.cpp"
        ],
        "github_commit_url": "https://github.com/freeorion/freeorion/commit/2c8a0dbaf5d33c1d5b89b54839910a43cbae2180",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary copying of objects by directly referencing them.",
            "The optimization strategy avoids unnecessary copying of objects by utilizing references or pointers instead of passing by value.",
            "The optimization strategy avoids unnecessary copying of objects by utilizing references or pointers instead of value-based operations.",
            "The optimization strategy avoids unnecessary copying of objects by modifying the code to use references or move semantics.",
            "The optimization strategy avoids unnecessary copying of objects by using references or pointers instead of passing by value."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary copying of objects by utilizing references or pointers instead of passing by value.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "libarchive",
        "hash": "6302a9fba0778e63379a13946ccdfe0d257ed2d1",
        "author": "Tim Kientzle",
        "date": "2009-02-06T02:09:45-05:00",
        "message": "Very minor optimization:  If we already have enough data, we don't\nneed to keep calling down into archive_read_filter_ahead() to\nextend the read-ahead.\n\nSVN-Revision: 561",
        "modified_files_count": 1,
        "modified_files": [
            "libarchive/archive_read_support_compression_gzip.c"
        ],
        "github_commit_url": "https://github.com/libarchive/libarchive/commit/6302a9fba0778e63379a13946ccdfe0d257ed2d1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "peek_at_header"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary calls to a read-ahead function when sufficient data is already available.",
            "The optimization avoids unnecessary calls to a read-ahead function when sufficient data is already available.",
            "The optimization avoids unnecessary calls to a read-ahead function when sufficient data is already available.",
            "The optimization avoids unnecessary calls to a read-ahead function when sufficient data is already available.",
            "The optimization avoids unnecessary calls to a read-ahead function when sufficient data is already available."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary calls to a read-ahead function when sufficient data is already available.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "914ebccd2d8fa439e01fe93b5229534b9e179a69",
        "author": "Takuya Yoshikawa",
        "date": "2010-08-01T10:35:27+03:00",
        "message": "KVM: x86: avoid unnecessary bitmap allocation when memslot is clean\n\nAlthough we always allocate a new dirty bitmap in x86's get_dirty_log(),\nit is only used as a zero-source of copy_to_user() and freed right after\nthat when memslot is clean. This patch uses clear_user() instead of doing\nthis unnecessary zero-source allocation.\n\nPerformance improvement: as we can expect easily, the time needed to\nallocate a bitmap is completely reduced. In my test, the improved ioctl\nwas about 4 to 10 times faster than the original one for clean slots.\nFurthermore, reducing memory allocations and copies will produce good\neffects to caches too.\n\nSigned-off-by: Takuya Yoshikawa <yoshikawa.takuya@oss.ntt.co.jp>\nSigned-off-by: Avi Kivity <avi@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/kvm/x86.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/914ebccd2d8fa439e01fe93b5229534b9e179a69",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Get"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization avoids unnecessary memory allocation by replacing a zero-source bitmap allocation with a direct clear_user() call when the memory slot is clean.",
            "The optimization avoids unnecessary memory allocation by replacing a zero-source bitmap allocation with a direct `clear_user()` call when the memory slot is clean.",
            "The optimization avoids unnecessary memory allocation by replacing a zero-source bitmap allocation with a direct clear_user() call when the memslot is clean.",
            "The optimization avoids unnecessary memory allocation by replacing a zero-source bitmap allocation with a direct clear_user() call when the memslot is clean.",
            "The optimization avoids unnecessary memory allocation by replacing a zero-source bitmap allocation with a direct clear_user() call when the memslot is clean."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary memory allocation by replacing a zero-source bitmap allocation with a direct clear_user() call when the memslot is clean.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Pikafish",
        "hash": "4e7a898d7ebf82462d895827580009902496854f",
        "author": "Marco Costalba",
        "date": "2010-06-19T15:58:14+01:00",
        "message": "Optimize for king moves in see_sign()\n\nBecause we only test legal moves, a king move\ncannot have negative SEE.\n\nNo functional change.\n\nSigned-off-by: Marco Costalba <mcostalba@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/position.cpp"
        ],
        "github_commit_url": "https://github.com/official-pikafish/Pikafish/commit/4e7a898d7ebf82462d895827580009902496854f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Position::see_sign"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary computation in the SEE evaluation by recognizing that king moves cannot have negative SEE values due to their legality.",
            "The optimization avoids unnecessary computation in the SEE evaluation for king moves by leveraging the fact that legal king moves cannot have negative SEE values.",
            "The optimization avoids unnecessary computation in the SEE evaluation for king moves by leveraging the fact that legal king moves cannot have negative SEE values.",
            "The optimization avoids unnecessary computation in the SEE evaluation for king moves by leveraging the fact that legal king moves cannot have negative SEE values.",
            "The optimization avoids unnecessary computation in the SEE evaluation for king moves by leveraging the fact that legal king moves cannot have negative SEE values."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary computation in the SEE evaluation for king moves by leveraging the fact that legal king moves cannot have negative SEE values.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pinba2",
        "hash": "77d4eb75f9adf6f49fa413eb9b097ec0f407fc06",
        "author": "Anton Povarov",
        "date": "2017-05-26T16:37:06+03:00",
        "message": "minor stats optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/report_by_timer.cpp"
        ],
        "github_commit_url": "https://github.com/badoo/pinba2/commit/77d4eb75f9adf6f49fa413eb9b097ec0f407fc06",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "merge_ticks_into_data"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations by caching and reusing intermediate results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing intermediate results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing intermediate results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing intermediate results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing intermediate results within the function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations by caching and reusing intermediate results within the function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "notepad-plus-plus",
        "hash": "4b7e1ac7947e13746735ab5bfa069b08c0b0c0ae",
        "author": "Scott Sumner",
        "date": "2021-05-05T22:54:04+02:00",
        "message": "Improve performance of Search results Open all\n\nFix #9819, close #9820",
        "modified_files_count": 1,
        "modified_files": [
            "PowerEditor/src/ScintillaComponent/FindReplaceDlg.cpp"
        ],
        "github_commit_url": "https://github.com/notepad-plus-plus/notepad-plus-plus/commit/4b7e1ac7947e13746735ab5bfa069b08c0b0c0ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Finder::openAll"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant operations by caching and reusing results within the loop.",
            "The optimization strategy involved reducing redundant operations by caching and reusing results within the loop.",
            "The optimization strategy involved reducing redundant operations by caching and reusing results within the loop.",
            "The optimization strategy involved reducing redundant operations by caching and reusing results within the loop.",
            "The optimization strategy involved reducing redundant operations by caching and reusing results within the loop."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant operations by caching and reusing results within the loop.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sdrangel",
        "hash": "70d2ce6cec44b866dd211d9d8fd428698bcb0fd6",
        "author": "f4exb",
        "date": "2017-05-13T16:01:27+02:00",
        "message": "NFM demod: smoothersterp optimization",
        "modified_files_count": 1,
        "modified_files": [
            "plugins/channelrx/demodnfm/nfmdemod.h"
        ],
        "github_commit_url": "https://github.com/f4exb/sdrangel/commit/70d2ce6cec44b866dd211d9d8fd428698bcb0fd6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "smootherstep"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used a mathematical approximation to simplify the smootherstep function, reducing computational complexity.",
            "The optimization strategy used a more efficient mathematical formula for the smootherstep function to reduce computational overhead.",
            "The optimization strategy used a more efficient mathematical formula for the smootherstep function to reduce computational overhead.",
            "The optimization strategy used a more efficient mathematical formula for the `smootherstep` function to reduce computational overhead.",
            "The optimization strategy used a more efficient mathematical formula for the `smootherstep` function to reduce computational overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used a more efficient mathematical formula for the smootherstep function to reduce computational overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "hhvm",
        "hash": "7f985575b0900e4efdcb06bd8e504c5ac10dfc2e",
        "author": "Fred Emmott",
        "date": "2015-05-18T15:34:50-07:00",
        "message": "Optimize str_replace(string, string, string)\n\nSummary: Benchmark is /very/ noisy, but this looks like 1-5% on Mediawiki. Based on tbgs should be a win for www too.\n\nReviewed By: @jwatzman\n\nDifferential Revision: D2077728",
        "modified_files_count": 1,
        "modified_files": [
            "hphp/runtime/ext/string/ext_string.cpp"
        ],
        "github_commit_url": "https://github.com/facebook/hhvm/commit/7f985575b0900e4efdcb06bd8e504c5ac10dfc2e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HHVM_FUNCTION"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of string replacement by reducing unnecessary operations or iterations within the `str_replace` function.",
            "The optimization strategy involved improving the efficiency of string replacement operations by reducing unnecessary computations or memory usage in the `str_replace` function.",
            "The optimization strategy involved improving the efficiency of string replacement operations by reducing unnecessary computations or memory usage in the `str_replace` function.",
            "The optimization strategy involved improving the efficiency of string replacement operations by reducing unnecessary computations or memory usage in the `str_replace` function.",
            "The optimization strategy involved improving the efficiency of string replacement operations by reducing unnecessary computations or memory usage in the `str_replace` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of string replacement operations by reducing unnecessary computations or memory usage in the `str_replace` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cgal",
        "hash": "3feac5dc4cdfe0d447f3b34fbac3bd5f5c47c5f9",
        "author": "Christophe Delage",
        "date": "2007-09-05T13:57:52+00:00",
        "message": "Faster insert for iterator ranges in Triangulation_hierarchy_2.",
        "modified_files_count": 1,
        "modified_files": [
            "Triangulation_2/include/CGAL/Triangulation_hierarchy_2.h"
        ],
        "github_commit_url": "https://github.com/CGAL/cgal/commit/3feac5dc4cdfe0d447f3b34fbac3bd5f5c47c5f9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "insert"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was to improve the insertion performance for iterator ranges by reducing redundant operations in the triangulation hierarchy.",
            "The optimization strategy used is to directly insert elements into the triangulation hierarchy without unnecessary intermediate steps, reducing redundant operations.",
            "The optimization strategy used was to directly insert elements into the triangulation hierarchy without unnecessary intermediate steps, reducing overhead.",
            "The optimization strategy used was to directly insert elements into the triangulation hierarchy without unnecessary intermediate steps, reducing redundant operations.",
            "The optimization strategy used was to directly insert elements into the lowest level of the triangulation hierarchy and propagate them upwards, reducing redundant computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used was to directly insert elements into the triangulation hierarchy without unnecessary intermediate steps, reducing redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Indigo",
        "hash": "002feb3b26f1b66c0b57875b9e03ea883c08cbb9",
        "author": "Iurii Puzanov",
        "date": "2016-12-26T14:09:35+03:00",
        "message": "indigo-core: fix cml memory usage while saving",
        "modified_files_count": 1,
        "modified_files": [
            "molecule/src/cml_saver.cpp"
        ],
        "github_commit_url": "https://github.com/epam/Indigo/commit/002feb3b26f1b66c0b57875b9e03ea883c08cbb9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CmlSaver::_saveMolecule"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory usage by modifying how molecule data is processed and saved in the CML format.",
            "The optimization strategy involved reducing memory usage by avoiding unnecessary data duplication during the saving process.",
            "The optimization strategy involved reducing memory usage by modifying how molecule data is processed and saved in the CML format.",
            "The optimization strategy involved reducing memory usage by modifying how molecule data is processed and saved in the CML format.",
            "The optimization strategy involved reducing memory usage by modifying how molecule data is processed and saved in the CML format."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory usage by modifying how molecule data is processed and saved in the CML format.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "aseprite",
        "hash": "0d169fed751b1f69e0fd86accd0dd0461d6be9de",
        "author": "David Capello",
        "date": "2016-11-22T13:33:01-03:00",
        "message": "Improve ui::drawTextBox() performance",
        "modified_files_count": 1,
        "modified_files": [
            "src/ui/theme.cpp"
        ],
        "github_commit_url": "https://github.com/aseprite/aseprite/commit/0d169fed751b1f69e0fd86accd0dd0461d6be9de",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "drawTextBox"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant text measurements and drawing operations within the `drawTextBox` function to improve performance.",
            "The optimization strategy involved reducing redundant text measurements and layout calculations in the `drawTextBox` function by caching intermediate results.",
            "The optimization strategy involved reducing redundant text measurements and drawing operations within the `drawTextBox` function by caching and reusing calculated values.",
            "The optimization strategy involved reducing redundant text measurements and layout calculations within the `drawTextBox` function by caching intermediate results.",
            "The optimization strategy involved reducing redundant text measurements and drawing operations in the `drawTextBox` function by caching and reusing calculated values."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant text measurements and drawing operations in the `drawTextBox` function by caching and reusing calculated values.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "bind9",
        "hash": "3fe45d9897459da9c78263ae709e5c611e622243",
        "author": "Andreas Gustafsson",
        "date": "2000-06-09T22:01:55+00:00",
        "message": "do the length checks of 1.90 in a more efficient way; take\nadvantage of the new buffer API macros",
        "modified_files_count": 1,
        "modified_files": [
            "lib/dns/name.c"
        ],
        "github_commit_url": "https://github.com/isc-projects/bind9/commit/3fe45d9897459da9c78263ae709e5c611e622243",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dns_name_fromwire"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing manual length checks with more efficient buffer API macros to streamline the validation process.",
            "The optimization strategy involved restructuring length checks to leverage new buffer API macros for improved efficiency.",
            "The optimization strategy involved restructuring length checks to leverage new buffer API macros for improved efficiency.",
            "The optimization strategy involved restructuring length checks to leverage new buffer API macros for improved efficiency.",
            "The optimization strategy involved replacing manual length checks with more efficient buffer API macros to streamline the process."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring length checks to leverage new buffer API macros for improved efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "OpenJK",
        "hash": "fc3bd3f70de318643289a4696931723c466b9959",
        "author": "Szilárd Biró",
        "date": "2014-05-29T11:33:21+02:00",
        "message": "[SP] CTaskManager::Get optimization for TK_VECTOR",
        "modified_files_count": 1,
        "modified_files": [
            "code/icarus/TaskManager.cpp"
        ],
        "github_commit_url": "https://github.com/JACoders/OpenJK/commit/fc3bd3f70de318643289a4696931723c466b9959",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CTaskManager::Get"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is replacing a linear search with a direct index-based access for faster retrieval in a vector.",
            "The optimization strategy used is replacing a linear search with a direct index-based access for faster retrieval in a vector.",
            "The optimization strategy involved replacing a linear search with a direct index-based access for TK_VECTOR to improve lookup performance.",
            "The optimization strategy used is replacing a linear search with a direct index-based access for faster retrieval in a vector.",
            "The optimization strategy involved replacing a linear search with a direct index-based access for TK_VECTOR to improve lookup performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is replacing a linear search with a direct index-based access for faster retrieval in a vector.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "skia",
        "hash": "4e506c200bc7f0c59fa1092577c129d9723a1c6e",
        "author": "mtklein",
        "date": "2015-05-22T12:43:41-07:00",
        "message": "Simpler version of Plus w/ AA.  ~25% faster too.\n\nBUG=skia:3852\n\nTBR=fmalita@chromium.org\n\nReview URL: https://codereview.chromium.org/1150693003",
        "modified_files_count": 1,
        "modified_files": [
            "src/core/Sk4pxXfermode.h"
        ],
        "github_commit_url": "https://github.com/google/skia/commit/4e506c200bc7f0c59fa1092577c129d9723a1c6e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "XFERMODE_AA"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization simplifies the implementation of the `Plus` function with anti-aliasing (AA) by reducing computational complexity, achieving a ~25% performance improvement.",
            "The optimization simplifies the implementation of the `Plus` function with anti-aliasing (AA) by reducing computational complexity, achieving a ~25% performance improvement.",
            "The optimization simplifies the implementation of the `Plus` function with anti-aliasing (AA) by reducing computational complexity, achieving a ~25% performance improvement.",
            "The optimization simplifies the implementation of the `Plus` function with anti-aliasing (AA) by reducing computational complexity, achieving a ~25% performance improvement.",
            "The optimization simplifies the implementation of the `Plus` function with anti-aliasing (AA) by reducing computational complexity, achieving a ~25% performance improvement."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization simplifies the implementation of the `Plus` function with anti-aliasing (AA) by reducing computational complexity, achieving a ~25% performance improvement.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "HiGHS",
        "hash": "10101ad997117b63a4c854c409f9d645324cfc0b",
        "author": "Stefan Vigerske",
        "date": "2022-07-20T18:49:07+02:00",
        "message": "speed up getvarbyname() a bit\n\n- no need to copy argument\n- lookup in variables array only once",
        "modified_files_count": 1,
        "modified_files": [
            "extern/filereaderlp/builder.hpp"
        ],
        "github_commit_url": "https://github.com/ERGO-Code/HiGHS/commit/10101ad997117b63a4c854c409f9d645324cfc0b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "getvarbyname"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary copying of arguments and reduces redundant lookups in the variables array to improve the performance of the `getvarbyname` function.",
            "The optimization avoids unnecessary copying of arguments and reduces redundant lookups in the variables array to improve the performance of the `getvarbyname` function.",
            "The optimization avoids unnecessary copying of arguments and reduces redundant lookups in the variables array to improve the performance of the `getvarbyname` function.",
            "The optimization avoids unnecessary copying of arguments and reduces redundant lookups in the variables array to improve the performance of the `getvarbyname` function.",
            "The optimization avoids unnecessary copying of arguments and reduces redundant lookups in the variables array to improve the performance of the `getvarbyname` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary copying of arguments and reduces redundant lookups in the variables array to improve the performance of the `getvarbyname` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "nap",
        "hash": "64cedae3cfeff626ad453db696e7e57b75d591f5",
        "author": "cklosters",
        "date": "2024-03-22T12:14:26+01:00",
        "message": "use emplace instead of insert to avoid copy and fix build",
        "modified_files_count": 1,
        "modified_files": [
            "system_modules/naprenderadvanced/src/renderadvancedservice.cpp"
        ],
        "github_commit_url": "https://github.com/napframework/nap/commit/64cedae3cfeff626ad453db696e7e57b75d591f5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RTTI_PROPERTY"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was replacing `insert` with `emplace` to avoid unnecessary copy operations and improve performance.",
            "The optimization strategy used was replacing `insert` with `emplace` to avoid unnecessary copy operations and improve performance.",
            "The optimization strategy used was replacing `insert` with `emplace` to avoid unnecessary copy operations and improve performance.",
            "The optimization strategy used was replacing `insert` with `emplace` to avoid unnecessary copy operations and improve performance.",
            "The optimization strategy used was replacing `insert` with `emplace` to avoid unnecessary copy operations and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was replacing `insert` with `emplace` to avoid unnecessary copy operations and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "phc",
        "hash": "2538ddf6fdd3ac56101de8395189686f5ee9f215",
        "author": "Paul Biggar",
        "date": "2007-09-27T16:16:12+00:00",
        "message": "Avoid copying in the cases where its not necessary. Instead of overwrite_lhs, use overwrite_lhs_no_copy. This avoids the zval_copy_ctor, and can only be used in cases where there is only 1 reference to the data in zvp->val.\n\nsafe_free_zval_ptr clears the memory for the zval*, but not its value.",
        "modified_files_count": 1,
        "modified_files": [
            "src/codegen/Generate_C.cpp"
        ],
        "github_commit_url": "https://github.com/pbiggar/phc/commit/2538ddf6fdd3ac56101de8395189686f5ee9f215",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "generate_rhs"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary copying by using a specialized function that operates directly on the data when there is only one reference, thus eliminating the overhead of `zval_copy_ctor`.",
            "The optimization avoids unnecessary copying by using a specialized function that operates directly on the data when there is only one reference, thus eliminating the overhead of `zval_copy_ctor`.",
            "The optimization avoids unnecessary copying by using a specialized function that operates directly on the data when there is only one reference, thus eliminating the overhead of `zval_copy_ctor`.",
            "The optimization avoids unnecessary copying by using a specialized function when there is only one reference to the data, reducing overhead from zval_copy_ctor.",
            "The optimization avoids unnecessary copying by using a specialized function that operates directly on the data when there is only one reference, thus eliminating the overhead of `zval_copy_ctor`."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary copying by using a specialized function that operates directly on the data when there is only one reference, thus eliminating the overhead of `zval_copy_ctor`.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mysql-server",
        "hash": "e695f61e28071f9864915315dfd1aff0fc6f618d",
        "author": "Olav Sandstaa",
        "date": "2012-05-29T11:31:04+02:00",
        "message": "WL#6082 Improve the Disk-Sweep Multi-Range Read cost model\n\nPatch 1: Improve estimation of required size of sort buffer.\n\nFixes the following two issues with how the estimated size of\nneeded sort buffer for a single scan DS-MRR is calculated:\n\na. An early version of the DS-MRR implementation used the sort buffer\n   to store the current position of the scan each time it had filled\n   the sort buffer. This was needed in order to be able to restart the\n   scan next time it should fill the sort buffer. This implementation\n   has since been changed to use a second handler object for scanning\n   the index. Thus the there is no longer a need for storing the\n   current position in the sort buffer. This patch removes the code\n   that included space for this in estimation of the buffer size.\n      \nb. When a single scan is needed, in most cases the buffer size\n   supplied by the optimizer code is too high. To reduce the amount of\n   buffer space allocated we should adjust this to what is needed. The\n   current code does not adjust the estimated buffer size\n   correctly. It will never reduce it, only increase it (which is the\n   opposite of the intention). The new code estimates the buffer size\n   by:\n   a. Estimate of number of keys to sort: Add 20% to the estimated\n      number of records. If this estimate is less than 100 keys, then\n      adjust it to use 100 keys as the estimate.\n   b. Adjusting the sort buffer size: If the estimated buffer space\n      is lower than the size of the sort buffer provided by the\n      optimizer code, then adjust the buffer space size down to the\n      estimated size.",
        "modified_files_count": 1,
        "modified_files": [
            "sql/handler.cc"
        ],
        "github_commit_url": "https://github.com/mysql/mysql-server/commit/e695f61e28071f9864915315dfd1aff0fc6f618d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DsMrr_impl::get_disk_sweep_mrr_cost"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy refines the estimation of the sort buffer size by removing unnecessary space allocation and adjusting the buffer size based on a more accurate key count estimation.",
            "The optimization strategy involved refining the estimation of the sort buffer size by removing unnecessary space allocation and adjusting the buffer size based on a more accurate key count estimation.",
            "The optimization strategy refines the estimation of the sort buffer size by removing unnecessary space allocation and adjusting the buffer size based on a more accurate key count estimation.",
            "The optimization strategy involved refining the estimation of the sort buffer size by removing unnecessary space allocation and adjusting the buffer size based on a more accurate key count estimation.",
            "The optimization strategy involved refining the estimation of the sort buffer size by removing unnecessary space allocation and adjusting the buffer size based on a more accurate key count estimation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved refining the estimation of the sort buffer size by removing unnecessary space allocation and adjusting the buffer size based on a more accurate key count estimation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "AIS-catcher",
        "hash": "f692ed5988a9af39625ad4280b07e5ab0a60ee56",
        "author": "jasper",
        "date": "2024-01-20T21:39:27+01:00",
        "message": "performance improvement UDP out",
        "modified_files_count": 1,
        "modified_files": [
            "IO/Network.cpp"
        ],
        "github_commit_url": "https://github.com/jvde-github/AIS-catcher/commit/f692ed5988a9af39625ad4280b07e5ab0a60ee56",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant data copying in UDP output operations by directly writing to the network buffer.",
            "The optimization strategy involved reducing redundant data copying in UDP output operations by directly referencing buffers.",
            "The optimization strategy involved reducing redundant data copying in UDP output operations by directly referencing buffers.",
            "The optimization strategy involved reducing redundant data copying in UDP output operations by directly writing to the network buffer.",
            "The optimization strategy involved reducing redundant data copying in UDP output operations by directly writing to the network buffer."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant data copying in UDP output operations by directly writing to the network buffer.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cryptominisat",
        "hash": "b8dcca2423a005f0aed66d7d533346eba1c20fe1",
        "author": "Mate Soos",
        "date": "2014-12-25T23:35:11+01:00",
        "message": "Let's reverse this check to improve speed\n\nIt's faster to get length than to get glue",
        "modified_files_count": 1,
        "modified_files": [
            "cryptominisat4/searcher.cpp"
        ],
        "github_commit_url": "https://github.com/msoos/cryptominisat/commit/b8dcca2423a005f0aed66d7d533346eba1c20fe1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Searcher::mimimize_learnt_clause_more_maybe"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reverses the order of checks to prioritize a faster operation (getting length) over a slower one (getting glue).",
            "The optimization strategy reverses the order of checks to prioritize the faster operation (getting length) over the slower one (getting glue).",
            "The optimization strategy reverses the order of checks to prioritize a faster operation (getting length) over a slower one (getting glue).",
            "The optimization strategy reverses the order of checks to prioritize a faster operation (getting length) over a slower one (getting glue).",
            "The optimization strategy reverses the order of checks to prioritize a faster operation (getting length) over a slower one (getting glue)."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy reverses the order of checks to prioritize a faster operation (getting length) over a slower one (getting glue).",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ladybird",
        "hash": "e8c0cea5f9affac2e6192842bb81a5f16fe69c8e",
        "author": "Andreas Kling",
        "date": "2023-11-13T13:49:21+01:00",
        "message": "LibJS/JIT: Use right shift to extract type tags in equality codegen\n\n7% speed-up on Kraken/ai-astar.js, covers up most of the regression\nfrom adding more fast paths. :^)",
        "modified_files_count": 1,
        "modified_files": [
            "Userland/Libraries/LibJS/JIT/Compiler.cpp"
        ],
        "github_commit_url": "https://github.com/LadybirdBrowser/ladybird/commit/e8c0cea5f9affac2e6192842bb81a5f16fe69c8e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Compiler::branch_if_same_type_for_equality"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used right shift operations to efficiently extract type tags in equality code generation, reducing computational overhead.",
            "The optimization strategy used right shift operations to efficiently extract type tags in equality code generation, reducing computational overhead.",
            "The optimization strategy used right shift operations to efficiently extract type tags in equality code generation, reducing computational overhead.",
            "The optimization strategy used right shift operations to efficiently extract type tags in equality codegen, reducing computational overhead.",
            "The optimization strategy used right shift operations to efficiently extract type tags in equality codegen, reducing computational overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used right shift operations to efficiently extract type tags in equality code generation, reducing computational overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kernel-copyleft",
        "hash": "bf4785bf7621d487305c9cc8acdcf0881684c1f5",
        "author": "Kevin Chan",
        "date": "2013-05-15T10:55:14-07:00",
        "message": "msm: camera: Optimize burst stream stop sequence\n\nWhen burst stream is done capturing burstshot, it will\nconfigure the framedrop registers to drop all frames,\nwhich effectively stop all activity to the bus.\nWhen stream off is sent from HAL, the stream should be\ninactive, this change will apply the write masters\ndisable immediately instead of applying the configuration\nat frame boundary. If there is steam off command while the\nstream is still active, the stop command will wait and\napply the stop at frame boundary,\n\nChange-Id: I757dc89f0a915b78e31f68584f9198c617f6c643\nSigned-off-by: Kevin Chan <ktchan@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/media/platform/msm/camera_v2/isp/msm_isp_axi_util.c"
        ],
        "github_commit_url": "https://github.com/sonyxperiadev/kernel-copyleft/commit/bf4785bf7621d487305c9cc8acdcf0881684c1f5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "msm_isp_stop_axi_stream"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves disabling write masters immediately upon receiving a stream-off command instead of waiting for the frame boundary, reducing latency in stopping the burst stream.",
            "The optimization strategy involves immediately disabling write masters upon receiving a stream-off command instead of waiting for the frame boundary, reducing latency in stopping the burst stream.",
            "The optimization strategy disables write masters immediately upon receiving a stream-off command instead of waiting for the frame boundary, reducing latency in stopping the burst stream.",
            "The optimization strategy disables write masters immediately upon receiving a stream-off command instead of waiting for the frame boundary, reducing latency in stopping the burst stream.",
            "The optimization strategy disables write masters immediately upon receiving a stream-off command instead of waiting for the frame boundary, reducing latency in stopping the burst stream."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy disables write masters immediately upon receiving a stream-off command instead of waiting for the frame boundary, reducing latency in stopping the burst stream.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dolphin-memory-engine",
        "hash": "17731a57daf522c41c2c22755dd5f661f2f1fde4",
        "author": "cristian64",
        "date": "2024-05-05T01:02:10+00:00",
        "message": "Address `performance-for-range-copy` warnings.\n\nThe one warning was:\n\n```\n/w/dolphin-memory-engine/Source/DolphinProcess/Linux/LinuxDolphinProcess.cpp:39:15: warning: loop variable is copied but only used as const reference; consider making it a const reference [performance-for-range-copy]\n   39 |     for (auto str : lineData)\n      |               ^\n      |          const  &\n```",
        "modified_files_count": 1,
        "modified_files": [
            "Source/DolphinProcess/Linux/LinuxDolphinProcess.cpp"
        ],
        "github_commit_url": "https://github.com/aldelaro5/dolphin-memory-engine/commit/17731a57daf522c41c2c22755dd5f661f2f1fde4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LinuxDolphinProcess::obtainEmuRAMInformations"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved changing a loop variable from being copied to being passed as a const reference to reduce unnecessary copy overhead.",
            "The optimization strategy involved changing a loop variable from a value copy to a const reference to avoid unnecessary copying during iteration.",
            "The optimization strategy involved changing a loop variable from being copied to being passed as a const reference to reduce unnecessary copy overhead.",
            "The optimization strategy involved changing a loop variable from a value copy to a const reference to avoid unnecessary copying during iteration.",
            "The optimization strategy involved changing the loop variable in a range-based for-loop from a value copy to a const reference to avoid unnecessary copying of objects."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved changing a loop variable from a value copy to a const reference to avoid unnecessary copying during iteration.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "horizon",
        "hash": "a920c00bce00e9d4bec45ad927499b98c0ee7bc4",
        "author": "Lukas K",
        "date": "2018-05-09T19:26:00+02:00",
        "message": "make tool paste faster",
        "modified_files_count": 1,
        "modified_files": [
            "src/core/tool_paste.cpp"
        ],
        "github_commit_url": "https://github.com/horizon-eda/horizon/commit/a920c00bce00e9d4bec45ad927499b98c0ee7bc4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ToolPaste::update"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations within the `ToolPaste::update` function to improve performance.",
            "The optimization strategy involved reducing redundant computations within the `ToolPaste::update` function to improve performance.",
            "The optimization strategy involved reducing redundant computations within the `ToolPaste::update` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or unnecessary operations within the `ToolPaste::update` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or unnecessary operations within the `ToolPaste::update` function to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations within the `ToolPaste::update` function to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "redot-engine",
        "hash": "f1cc99c6e80694fc768ac098e13ef3c5370f6dfe",
        "author": "hoontee",
        "date": "2022-03-09T11:23:46-06:00",
        "message": "Add SNAME macro optimization missed during rebase",
        "modified_files_count": 1,
        "modified_files": [
            "modules/csg/csg_shape.cpp"
        ],
        "github_commit_url": "https://github.com/Redot-Engine/redot-engine/commit/f1cc99c6e80694fc768ac098e13ef3c5370f6dfe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CSGShape3D::_make_dirty"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing repetitive calls to a function with a macro to reduce overhead and improve performance.",
            "The optimization strategy involved replacing repetitive calls to a function with a macro to reduce computational overhead.",
            "The optimization strategy involved replacing repetitive calls to a function with a macro to reduce computational overhead.",
            "The optimization strategy involved replacing repetitive calls to a name resolution function with a macro to reduce computational overhead.",
            "The optimization strategy involved replacing repetitive calls to a function with a macro to reduce overhead and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing repetitive calls to a function with a macro to reduce computational overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "fcb423f3f69225e0be896cb10b34b9628ab666f2",
        "author": "Paul Davis",
        "date": "2013-04-12T11:08:24-04:00",
        "message": "slightly optimize drawing of rectangles with all 4 sides outlined to avoid multiple paths etc",
        "modified_files_count": 1,
        "modified_files": [
            "libs/canvas/rectangle.cc"
        ],
        "github_commit_url": "https://github.com/Ardour/ardour/commit/fcb423f3f69225e0be896cb10b34b9628ab666f2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Rectangle::render"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "ardour",
        "optimization_summary": [
            "The optimization avoids redundant path calculations when drawing rectangles with all four sides outlined by consolidating the rendering into a single path.",
            "The optimization avoids redundant path calculations by directly rendering all four sides of a rectangle in a single operation.",
            "The optimization avoids redundant path calculations by directly rendering all four sides of a rectangle in a single operation.",
            "The optimization avoids redundant path calculations when drawing rectangles with all four sides outlined by consolidating the rendering into a single path.",
            "The optimization avoids redundant path calculations by directly rendering all four sides of a rectangle in a single operation."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids redundant path calculations by directly rendering all four sides of a rectangle in a single operation.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "naemon-core",
        "hash": "6fee27a09d894c820f474ca26610cfcd9ac81c54",
        "author": "Andreas Ericsson",
        "date": "2014-02-18T11:52:38+01:00",
        "message": "t-tap/test_timeperiods: Fix 'em\n\nFaster than the speed of Robin. Shuzam!\n\nSigned-off-by: Andreas Ericsson <ae@op5.se>",
        "modified_files_count": 1,
        "modified_files": [
            "t-tap/test_timeperiods.c"
        ],
        "github_commit_url": "https://github.com/naemon/naemon-core/commit/6fee27a09d894c820f474ca26610cfcd9ac81c54",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary iterations or operations in the test code to improve execution speed.",
            "The optimization strategy involved reducing unnecessary iterations or operations in the test code to improve execution speed.",
            "The optimization strategy involved reducing unnecessary iterations or operations in the test code to improve execution speed.",
            "The optimization strategy involved reducing unnecessary iterations or operations in the test code to improve execution speed.",
            "The optimization strategy involved reducing unnecessary iterations or operations in the test code to improve execution speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary iterations or operations in the test code to improve execution speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cloud-kernel",
        "hash": "711fe232dcd2c66806a4eb675e1620eee2cb9a8c",
        "author": "Yang Shi",
        "date": "2021-11-22T20:26:18+08:00",
        "message": "mm/memory.c: skip spurious TLB flush for retried page fault\n\nOpenAnolis Bug Tracker: 0000546\n\ncommit b7333b58f358f38d90d78e00c1ee5dec82df10ad upstream.\n\nRecently we found regression when running will_it_scale/page_fault3 test\non ARM64.  Over 70% down for the multi processes cases and over 20% down\nfor the multi threads cases.  It turns out the regression is caused by\ncommit 89b15332af7c (\"mm: drop mmap_sem before calling\nbalance_dirty_pages() in write fault\").\n\nThe test mmaps a memory size file then write to the mapping, this would\nmake all memory dirty and trigger dirty pages throttle, that upstream\ncommit would release mmap_sem then retry the page fault.  The retried\npage fault would see correct PTEs installed then just fall through to\nspurious TLB flush.  The regression is caused by the excessive spurious\nTLB flush.  It is fine on x86 since x86's spurious TLB flush is no-op.\n\nWe could just skip the spurious TLB flush to mitigate the regression.\n\n[xuyu: performance test and analysis]\nTest with will-it-scale/page_fault3 is as follows.\n\nTest    Baseline  Patched\n1p      100       90.10      %\n1t      100       89.56      %\n32p     100       98.22      %\n32t     100       75.45      %\n64p     100       99.97      %\n64t     100       70.44      %\n96p     100       99.95      %\n96t     100       67.95      %\n128p    100       99.92      %\n128t    100       73.23      %\n\nPerformance in process mode of will-it-scale/page_fault3 is restored,\nwhile there's still a bit of a loss in thread mode.\n\nThe testcase will-it-scale/page_fault3 is all memory read operations,\nwhich does not reflect the strengths of this mmap_sem optimization, but\nmagnify the shortcomings. So I think the result of testcase should not\nprevent the optimization from being merged.\n\nSuggested-by: Linus Torvalds <torvalds@linux-foundation.org>\nReported-by: Xu Yu <xuyu@linux.alibaba.com>\nDebugged-by: Xu Yu <xuyu@linux.alibaba.com>\nTested-by: Xu Yu <xuyu@linux.alibaba.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Will Deacon <will.deacon@arm.com>\nCc: <stable@vger.kernel.org>\nSigned-off-by: Yang Shi <shy828301@gmail.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Xu Yu <xuyu@linux.alibaba.com>\nReviewed-by: Xunlei Pang <xlpang@linux.alibaba.com>\nSigned-off-by: Xunlei Pang <xlpang@linux.alibaba.com>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/memory.c"
        ],
        "github_commit_url": "https://github.com/alibaba/cloud-kernel/commit/711fe232dcd2c66806a4eb675e1620eee2cb9a8c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "filemap_fault"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips unnecessary TLB flushes during retried page faults to mitigate performance regression caused by excessive spurious flushes.",
            "The optimization strategy skips unnecessary TLB flushes during retried page faults to mitigate performance regression caused by excessive spurious flushes.",
            "The optimization strategy skips unnecessary TLB flushes during retried page faults to mitigate performance regression caused by excessive spurious flushes.",
            "The optimization strategy skips unnecessary TLB flushes during retried page faults to mitigate performance regression caused by excessive spurious flushes.",
            "The optimization strategy skips unnecessary TLB flushes during retried page faults to mitigate performance regression caused by excessive spurious flushes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips unnecessary TLB flushes during retried page faults to mitigate performance regression caused by excessive spurious flushes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lime3ds-archive",
        "hash": "b178089251200bd0309afcbcb06b43e7c82dc3bc",
        "author": "Subv",
        "date": "2017-09-15T14:26:15-05:00",
        "message": "Kernel/Threads: Don't clear the CPU instruction cache when performing a context switch from an idle thread into a thread in the same process.\n\nWe were unnecessarily clearing the cache when going from Process A -> Idle -> Process A, this caused extreme performance regressions.",
        "modified_files_count": 1,
        "modified_files": [
            "src/core/hle/kernel/thread.cpp"
        ],
        "github_commit_url": "https://github.com/Lime3DS/lime3ds-archive/commit/b178089251200bd0309afcbcb06b43e7c82dc3bc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SwitchContext"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary CPU instruction cache clearing during context switches within the same process, reducing redundant operations.",
            "The optimization avoids unnecessary CPU instruction cache clearing during context switches within the same process, reducing performance overhead.",
            "The optimization avoids unnecessary CPU instruction cache clearing during context switches within the same process, reducing performance overhead.",
            "The optimization avoids unnecessary CPU instruction cache clearing during context switches within the same process, reducing redundant operations.",
            "The optimization avoids unnecessary CPU instruction cache clearing during context switches within the same process, reducing performance overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary CPU instruction cache clearing during context switches within the same process, reducing performance overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SPMC",
        "hash": "4dacbf7a9d5aed35249944ed95d3d90886b51c09",
        "author": "davilla",
        "date": "2011-09-10T21:40:57-04:00",
        "message": "[ios] further reduce memory bandwidth pressure on 1080p content",
        "modified_files_count": 1,
        "modified_files": [
            "xbmc/cores/dvdplayer/DVDCodecs/Video/DVDVideoCodecVideoToolBox.cpp"
        ],
        "github_commit_url": "https://github.com/koying/SPMC/commit/4dacbf7a9d5aed35249944ed95d3d90886b51c09",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces memory bandwidth pressure by implementing more efficient handling of 1080p content in the VideoToolBox codec.",
            "The optimization strategy reduces memory bandwidth pressure by likely modifying how video frames are processed or stored for 1080p content.",
            "The optimization strategy reduces memory bandwidth pressure by implementing a more efficient handling of 1080p content, likely through improved data processing or reduced redundant operations.",
            "The optimization strategy reduces memory bandwidth pressure by implementing more efficient handling of 1080p content in the VideoToolBox codec.",
            "The optimization strategy reduces memory bandwidth pressure by implementing a more efficient handling of 1080p content, likely through improved data processing or reduced redundant operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces memory bandwidth pressure by implementing a more efficient handling of 1080p content, likely through improved data processing or reduced redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "intel-graphics-compiler",
        "hash": "70a0c3247abb263add9ca73661bc54b249fd3ed0",
        "author": "Hou-Jen Ko",
        "date": "2022-02-18T04:20:34+01:00",
        "message": "[Autobackout][FuncReg]Revert of change: 6c0fcc7e98c6994102bb9f47cdc5bab153886fec\n Fix FastestStage1 for CS in DX12\n\nAvoid retry and use the minimum SIMD size to save compile time",
        "modified_files_count": 1,
        "modified_files": [
            "IGC/Compiler/CISACodeGen/ShaderCodeGen.cpp"
        ],
        "github_commit_url": "https://github.com/intel/intel-graphics-compiler/commit/70a0c3247abb263add9ca73661bc54b249fd3ed0",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids retrying compilation and uses the minimum SIMD size to reduce compile time.",
            "The optimization strategy avoids retrying compilation and uses the minimum SIMD size to reduce compile time.",
            "The optimization strategy avoids retrying compilation and uses the minimum SIMD size to reduce compile time.",
            "The optimization strategy avoids retrying compilation and uses the minimum SIMD size to reduce compile time.",
            "The optimization strategy avoids retrying compilation and uses the minimum SIMD size to reduce compile time."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids retrying compilation and uses the minimum SIMD size to reduce compile time.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "harfbuzz",
        "hash": "590fb3529a27a2a652c74baa2c8bebad34ec5c42",
        "author": "Behdad Esfahbod",
        "date": "2023-06-03T19:21:22-06:00",
        "message": "[subset] Reduce memory pressure",
        "modified_files_count": 1,
        "modified_files": [
            "src/hb-subset.cc"
        ],
        "github_commit_url": "https://github.com/harfbuzz/harfbuzz/commit/590fb3529a27a2a652c74baa2c8bebad34ec5c42",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hb_subset_plan_execute_or_fail"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces memory pressure by reusing existing data structures instead of creating new ones.",
            "The optimization strategy reduces memory pressure by reusing existing data structures instead of creating new ones during subset plan execution.",
            "The optimization strategy reduces memory pressure by reusing existing data structures instead of creating new ones during subset plan execution.",
            "The optimization strategy reduces memory pressure by reusing existing data structures instead of creating new ones.",
            "The optimization strategy reduces memory pressure by reusing existing data structures instead of creating new ones."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy reduces memory pressure by reusing existing data structures instead of creating new ones.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "openocd-esp32",
        "hash": "de49613478f78b0f2fc0906de77fa4ff41ae0f7c",
        "author": "Matthias Welwarsky",
        "date": "2019-02-04T18:37:56+03:00",
        "message": "cortex_a: faster debug init\n\nDon't use atomic dap operations when not necessary\n\nChange-Id: Idc6dcd2bda95f7994852df4ae2a588976f4c9010\nSigned-off-by: Matthias Welwarsky <matthias.welwarsky@sysgo.com>\nReviewed-on: http://openocd.zylin.com/4142\nTested-by: jenkins\nReviewed-by: Matthias Welwarsky <matthias@welwarsky.de>",
        "modified_files_count": 1,
        "modified_files": [
            "src/target/cortex_a.c"
        ],
        "github_commit_url": "https://github.com/espressif/openocd-esp32/commit/de49613478f78b0f2fc0906de77fa4ff41ae0f7c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cortex_a_init_debug_access"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary atomic DAP operations to improve debug initialization performance.",
            "The optimization avoids unnecessary atomic DAP operations during debug initialization to reduce overhead.",
            "The optimization avoids unnecessary atomic DAP operations to improve debug initialization speed.",
            "The optimization avoids unnecessary atomic DAP operations during debug initialization to improve performance.",
            "The optimization avoids unnecessary atomic DAP operations during debug initialization to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary atomic DAP operations during debug initialization to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "xen",
        "hash": "0359b365c6aaf1303244b064acc84c493cc0e730",
        "author": "Andrew Cooper",
        "date": "2016-02-15T14:12:06+01:00",
        "message": "x86: improvements to pv_cpuid()\n\npv_cpuid() has two completely separate paths inside it depending on whether\ncurrent is dom0 or a domU.  This causes unnecessary divergence, and\ncomplicates future improvements.  Take steps to undo it.\n\nChanges:\n * Create leaf and subleaf variables and use them consistently, instead of a\n   mix of {a,c} and regs->e{a,c}x as the input parameters.\n * Combine the dom0 and domU hypervisor leaf handling, with an early exit.\n * Apply sanity checks to domU as well.  This brings PV domU cpuid handling in\n   line with HVM domains and PV dom0.\n * Perform a real cpuid instruction for calculating CPUID.0xD[ECX=0].EBX.  The\n   correct xcr0 is in context, and this avoids the O(M*N) loop over the domain\n   cpuid policy list which exists currently.\n\nSigned-off-by: Andrew Cooper <andrew.cooper3@citrix.com>\nReviewed-by: Jan Beulich <jbeulich@suse.com>",
        "modified_files_count": 1,
        "modified_files": [
            "xen/arch/x86/traps.c"
        ],
        "github_commit_url": "https://github.com/xen-project/xen/commit/0359b365c6aaf1303244b064acc84c493cc0e730",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pv_cpuid"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy refactors the `pv_cpuid()` function to reduce code divergence by unifying handling paths for dom0 and domU, applying consistent sanity checks, and replacing an O(M*N) loop with a direct CPUID instruction.",
            "The optimization strategy involved refactoring the `pv_cpuid()` function to unify divergent code paths for dom0 and domU, reducing complexity and improving performance by eliminating redundant operations and leveraging a real `cpuid` instruction.",
            "The optimization strategy refactors the code to reduce divergence between dom0 and domU paths, consolidates handling logic, and replaces an O(M*N) loop with a direct CPUID instruction for better performance.",
            "The optimization strategy refactors the `pv_cpuid()` function to reduce code divergence by unifying handling paths for dom0 and domU, applying consistent sanity checks, and replacing an O(M*N) loop with a direct CPUID instruction execution.",
            "The optimization strategy refactors the `pv_cpuid()` function to unify divergent code paths for dom0 and domU, reducing complexity and improving performance by eliminating redundant operations and avoiding an O(M*N) loop."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy refactors the `pv_cpuid()` function to reduce code divergence by unifying handling paths for dom0 and domU, applying consistent sanity checks, and replacing an O(M*N) loop with a direct CPUID instruction execution.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "ecf4c2ec6ba6dc39e72c6b37f2a238e28fec2dc1",
        "author": "Junio C Hamano",
        "date": "2008-02-05T00:38:41-08:00",
        "message": "builtin-apply.c: optimize match_beginning/end processing a bit.\n\nWnen the caller knows the hunk needs to match at the beginning\nor at the end, there is no point starting from the line number\nthat is found in the patch and trying match with increasing\noffset.  The logic to find matching lines was made more line\noriented with the previous patch and this optimization is now\ntrivial.\n\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "builtin-apply.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/ecf4c2ec6ba6dc39e72c6b37f2a238e28fec2dc1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "find_pos"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "git",
        "optimization_summary": [
            "The optimization avoids unnecessary offset-based matching attempts by leveraging the caller's knowledge of required match positions (beginning or end).",
            "The optimization avoids unnecessary offset-based matching attempts by leveraging the caller's knowledge of required hunk alignment at the beginning or end.",
            "The optimization avoids unnecessary offset-based matching attempts by leveraging the caller's knowledge of required match positions (beginning or end).",
            "The optimization avoids unnecessary offset-based matching attempts by leveraging the caller's knowledge of required match positions (beginning or end).",
            "The optimization avoids unnecessary offset-based matching attempts by leveraging the caller's knowledge of required match positions (beginning or end)."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary offset-based matching attempts by leveraging the caller's knowledge of required match positions (beginning or end).",
        "is_generic_optimization_final": false
    },
    {
        "hash": "b2929c469c08599941e0975a380fa8108e5a2b8d",
        "author": "Noah Goldstein",
        "date": "2022-10-31T13:15:03-05:00",
        "message": "Replace 2x vpxor with vpternlogd in avx512 scramble\n\nNeither Clang nor GCC <= 11.2 get this so seems worth it to do by hand\nso save the instruction. Not really on the critical path so only minor\nperf changes.\n\nHashing 8kb On Icelake with 2x vpxor:\n\n     5,451,267,137      cycles\n     5,371,545,012      p0\n       301,488,579      p1\n     5,420,594,430      p5\n       450,583,083      p6\n\nHashing 8kb On Icelake with 2x vpternlogd:\n\n     5,400,583,791      cycles\n     5,329,872,021      p0\n       305,543,626      p1\n     5,372,500,814      p5\n       446,853,381      p6",
        "modified_files_count": 1,
        "modified_files": [
            "xxhash.h"
        ],
        "github_commit_url": "https://github.com/Cyan4973/xxHash/commit/b2929c469c08599941e0975a380fa8108e5a2b8d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "XXH3_scrambleAcc_avx512"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "xxHash",
        "optimization_summary": [
            "The optimization replaces two `vpxor` instructions with a single `vpternlogd` instruction in AVX-512 to reduce instruction count and improve performance slightly.",
            "The optimization replaces two `vpxor` instructions with a single `vpternlogd` instruction in AVX-512 to reduce instruction count and improve performance slightly.",
            "The optimization replaces two `vpxor` instructions with a single `vpternlogd` instruction in AVX-512 to reduce instruction count and improve performance slightly.",
            "The optimization replaces two `vpxor` instructions with a single `vpternlogd` instruction in AVX-512 to reduce instruction count and improve performance slightly.",
            "The optimization replaces two `vpxor` instructions with a single `vpternlogd` instruction in AVX-512 to reduce instruction count and improve performance slightly."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization replaces two `vpxor` instructions with a single `vpternlogd` instruction in AVX-512 to reduce instruction count and improve performance slightly.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f13ef7754f724842dbf5ae6d85d0604fff0d1a84",
        "author": "Ravikiran G Thirumalai",
        "date": "2007-10-17T08:42:49-07:00",
        "message": "report the per-irq statistics on all arches\n\nCommit 4004c69ad68dd03733179277280ea2946990ba36 avoids too many remote cpu\nreferences while reporting per-irq stats.  Since we will not have the same\nperformance penalty of bringing in remote cpu cachelines while reporting\nper-irq stats anymore, we can now afford to be consistent and report this\nstatistic on all arches, all configs.\n\nakpm: affects ia64, alpha and ppc64, mainly.\n\nKiran earlier said:\n\nRead to /proc/stat takes:\nPlain: \t2.622832\nWith speedup patch: 0.013194\nWith the per-irq stats commented out: 0.008124\n\nSo the performance problems which originally caused those architectures to\ndisable this statistic should now be fixed up.\n\nSigned-off-by: Ravikiran Thirumalai <kiran@scalex86.org>\nCc: Paul Mackerras <paulus@samba.org>\nCc: Benjamin Herrenschmidt <benh@kernel.crashing.org>\nCc: \"Luck, Tony\" <tony.luck@intel.com>\nCc: Richard Henderson <rth@twiddle.net>\nCc: Ivan Kokshaysky <ink@jurassic.park.msu.ru>\nAcked-by: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Andi Kleen <ak@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "fs/proc/proc_misc.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/f13ef7754f724842dbf5ae6d85d0604fff0d1a84",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "show_stat"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involved reducing remote CPU cache line accesses when reporting per-irq statistics, enabling consistent reporting across all architectures without a performance penalty.",
            "The optimization strategy involved reducing remote CPU cache line references when reporting per-irq statistics to improve performance.",
            "The optimization strategy involved reducing remote CPU cache line references when reporting per-irq statistics to improve performance.",
            "The optimization strategy involved reducing remote CPU cache line references when reporting per-irq statistics to improve performance.",
            "The optimization strategy involved reducing remote CPU cache line references when reporting per-irq statistics to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing remote CPU cache line references when reporting per-irq statistics to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "arduino-audio-tools",
        "hash": "80439b9add616e85f0d0d45ac3a695aec0658433",
        "author": "Phil Schatzmann",
        "date": "2023-09-04T21:41:40+02:00",
        "message": "I2SDriverNanoBLE memory optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/AudioI2S/I2SNanoSenseBLE.h"
        ],
        "github_commit_url": "https://github.com/pschatzmann/arduino-audio-tools/commit/80439b9add616e85f0d0d45ac3a695aec0658433",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory usage by modifying the I2S driver configuration to use more efficient data structures or methods for the NanoBLE platform.",
            "The optimization strategy involved reducing memory usage by modifying the I2S driver configuration to use more efficient data structures or methods for the Nano BLE platform.",
            "The optimization strategy involved reducing memory usage by modifying the I2S driver configuration to use more efficient data structures or smaller memory allocations.",
            "The commit optimizes memory usage by reducing the buffer size for the I2S driver on the Nano BLE, likely minimizing unnecessary memory allocation.",
            "The optimization strategy involved reducing memory usage by modifying the I2S driver configuration to use more efficient data structures or smaller memory allocations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory usage by modifying the I2S driver configuration to use more efficient data structures or methods for the NanoBLE platform.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "corona",
        "hash": "de13c78e5b97b3f0910af5802a4c0466cd02c0f1",
        "author": "Steven Johnson",
        "date": "2022-09-21T17:36:38-04:00",
        "message": "Windows: fixing performance issue when multiple keys are pressed  (#405)",
        "modified_files_count": 1,
        "modified_files": [
            "platform/windows/Corona.Native.Library.Win32/Rtt/Rtt_WinInputDeviceManager.cpp"
        ],
        "github_commit_url": "https://github.com/coronalabs/corona/commit/de13c78e5b97b3f0910af5802a4c0466cd02c0f1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WinInputDeviceManager::OnReceivedMessage"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant processing of key events by filtering out repeated messages for the same key state.",
            "The optimization strategy involved reducing redundant processing of key events by filtering out repeated or unnecessary messages in the Windows input handling logic.",
            "The optimization strategy involved reducing redundant processing of key events by filtering out repeated or unnecessary messages in the Windows input handling logic.",
            "The optimization strategy involved reducing redundant processing of key events by filtering out repeated or unnecessary messages in the Windows input handling.",
            "The optimization strategy involved reducing redundant processing of key events by filtering out repeated or unnecessary messages in the Windows input handling."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant processing of key events by filtering out repeated or unnecessary messages in the Windows input handling.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "6c7d4e4ed00a9aaee7ff24c8d855390f442c49f8",
        "author": "Hiroyuki Ikezoe",
        "date": "2018-11-22T04:03:02+00:00",
        "message": "Bug 1506988 - Skip applying change hint if we already have it in AddLayerChangesForAnimation. r=birtles\n\nThis is just an optimization regardless of the fix improper change hint\ngenerated by blocked animations.\n\nDifferential Revision: https://phabricator.services.mozilla.com/D12366",
        "modified_files_count": 1,
        "modified_files": [
            "layout/base/RestyleManager.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/6c7d4e4ed00a9aaee7ff24c8d855390f442c49f8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RestyleManager::AddLayerChangesForAnimation"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips applying redundant change hints in the animation layer changes processing to avoid unnecessary work.",
            "The optimization skips applying redundant change hints in the animation layer changes processing to avoid unnecessary work.",
            "The optimization strategy skips applying redundant change hints in animations by checking if the hint is already present, reducing unnecessary operations.",
            "The optimization strategy skips applying redundant change hints in the animation layer changes processing to avoid unnecessary work.",
            "The optimization strategy skips applying redundant change hints in the animation layer changes processing to avoid unnecessary work."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips applying redundant change hints in the animation layer changes processing to avoid unnecessary work.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "stellar-core",
        "hash": "6dae535fed5bce2d910a410dca368edc3f6f2993",
        "author": "Latobarita",
        "date": "2019-01-11T15:10:18-08:00",
        "message": "Merge pull request #1909 from jonjove/improve-encode-b32\n\nSmall improvement in encode_b32 to reserve the correct size\n\nReviewed-by: graydon",
        "modified_files_count": 1,
        "modified_files": [
            "src/util/Decoder.h"
        ],
        "github_commit_url": "https://github.com/stellar/stellar-core/commit/6dae535fed5bce2d910a410dca368edc3f6f2993",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "encode_b32"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reserving the correct size for a container in the `encode_b32` function to avoid unnecessary reallocations.",
            "The optimization strategy involved reserving the correct size for a container in the `encode_b32` function to avoid unnecessary reallocations.",
            "The optimization strategy involved reserving the correct size for a container in the `encode_b32` function to avoid unnecessary reallocations.",
            "The optimization strategy involved reserving the correct size for a container in the `encode_b32` function to avoid unnecessary reallocations.",
            "The optimization strategy involved reserving the correct size for a container in the `encode_b32` function to avoid unnecessary reallocations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reserving the correct size for a container in the `encode_b32` function to avoid unnecessary reallocations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "b8188e1e2f71483e785831257e2e9f41c44fa8ca",
        "author": "Gleb Natapov",
        "date": "2019-05-06T17:36:50+03:00",
        "message": "storage_proxy: avoid copying of a topology and endpoint array in batchlog code\n\nbatchlog make copies of topology and endpoint array in batchlog endpoint\nchoosing code. There is a remark that at least endpoint copy is\ndeliberate because Cassandra code has it. We do not have to follow. Our\nendpoint calculation code is atomic, so we can use a reference.\n\nMessage-Id: <20190506115815.GK21208@scylladb.com>",
        "modified_files_count": 1,
        "modified_files": [
            "service/storage_proxy.cc"
        ],
        "github_commit_url": "https://github.com/scylladb/scylladb/commit/b8188e1e2f71483e785831257e2e9f41c44fa8ca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "batch"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "scylladb",
        "optimization_summary": [
            "The optimization avoids unnecessary copying of topology and endpoint arrays by using references instead of copies in the batchlog code.",
            "The optimization avoids unnecessary copying of topology and endpoint arrays by using references instead of copies in the batchlog code.",
            "The optimization avoids unnecessary copying of topology and endpoint arrays by using references instead of copies in the batchlog code.",
            "The optimization avoids unnecessary copying of topology and endpoint arrays by using references instead of copies in the batchlog code.",
            "The optimization avoids unnecessary copying of topology and endpoint arrays by using references instead of copies in the batchlog code."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary copying of topology and endpoint arrays by using references instead of copies in the batchlog code.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "dolphin",
        "hash": "67d2fa11f122dfd15f157d59356bcfb69d3acc47",
        "author": "Sintendo",
        "date": "2020-12-25T19:30:51+01:00",
        "message": "Jit64: srawx - Handle constant zero input\n\nShifting zero by any amount always gives zero.\n\nBefore:\n41 B9 00 00 00 00    mov         r9d,0\n41 8B CF             mov         ecx,r15d\n49 C1 E1 20          shl         r9,20h\n49 D3 F9             sar         r9,cl\n49 C1 E9 20          shr         r9,20h\n\nAfter:\nNothing, register is set to constant zero.\n\nBefore:\n41 B8 00 00 00 00    mov         r8d,0\n41 8B CF             mov         ecx,r15d\n49 C1 E0 20          shl         r8,20h\n49 D3 F8             sar         r8,cl\n41 8B C0             mov         eax,r8d\n49 C1 E8 20          shr         r8,20h\n44 85 C0             test        eax,r8d\n0F 95 45 58          setne       byte ptr [rbp+58h]\n\nAfter:\nC6 45 58 00          mov         byte ptr [rbp+58h],0\n\nOccurs a bunch of times in Super Mario Sunshine. Since this is an\narithmetic shift a similar optimization can be done for constant -1\n(0xFFFFFFFF), but I couldn't find any game where this happens.",
        "modified_files_count": 1,
        "modified_files": [
            "Source/Core/Core/PowerPC/Jit64/Jit_Integer.cpp"
        ],
        "github_commit_url": "https://github.com/dolphin-emu/dolphin/commit/67d2fa11f122dfd15f157d59356bcfb69d3acc47",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Jit64::srawx"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization eliminates unnecessary arithmetic shift operations when the input is a constant zero, as shifting zero always results in zero.",
            "The optimization eliminates unnecessary arithmetic shift operations when the input is a constant zero, directly setting the result to zero instead.",
            "The optimization eliminates unnecessary arithmetic shift operations when the input is a constant zero, as shifting zero always results in zero.",
            "The optimization eliminates unnecessary arithmetic shift operations when the input is a constant zero, directly setting the result to zero instead.",
            "The optimization eliminates unnecessary arithmetic shift operations when the input is a constant zero, as shifting zero always results in zero."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization eliminates unnecessary arithmetic shift operations when the input is a constant zero, as shifting zero always results in zero.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "asymptote",
        "hash": "561986f58f96e407e92979207d66d4bc864b9556",
        "author": "John Bowman",
        "date": "2022-04-03T21:57:01-06:00",
        "message": "TRANSPARENCY: Optimize global summation on CPU.",
        "modified_files_count": 1,
        "modified_files": [
            "glrender.cc"
        ],
        "github_commit_url": "https://github.com/vectorgraphics/asymptote/commit/561986f58f96e407e92979207d66d4bc864b9556",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "partialSums"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop to reduce redundant computations during global summation on the CPU.",
            "The optimization strategy used parallelization to improve the performance of global summation on the CPU by dividing the work across multiple threads.",
            "The optimization strategy involved restructuring the global summation logic to reduce redundant computations and improve cache locality.",
            "The optimization strategy used parallel processing to improve the performance of global summation on the CPU by dividing the workload across multiple threads.",
            "The optimization strategy involved restructuring the loop to reduce redundant computations during the global summation process."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop to reduce redundant computations during global summation on the CPU.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "rondb",
        "hash": "4c263649bbfc2e29de97d09f1b13bb3050341703",
        "author": "Jorgen Loland",
        "date": "2013-05-02T09:36:04+02:00",
        "message": "Bug#16697792: POOR EXECUTION PLAN WHEN ORDER BY WITH LIMIT X\n\nWhen we have a LIMIT that is lower than the row estimate on \nthe first table, the optimizer checks whether or not it's \npossible to switch to an index that provides correct ordering.\nIf there is, execution can be short-cut'ed immediately after\nfinding 'limit' number of records. The optimizer (in \nmake_join_select()) will in such cases go through all ORDER BY\nitems and make note of all indexes that can be used to \nprovide ordering for that item and then run the range optimizer\nto see if changing index makes sense.\n\nThat happens for this bug too. make_join_select() looks at \nthe ORDER BY clause and finds indexes that cover the fields.\nThe range optimizer is then run to see if those indexes are\nuseful. In the bug, the indexes with that index number may not\nbe used, so range access is discarded. The problem is that the \nfirst table - the one we run range optimizer for - is not the \nsame table referred to in the ORDER BY clause. Thus, the range \noptimizer will check if an index in a different table is \nuseful.\n\nThe fix is to check if the fields in the ORDER BY clause are \nfrom the table being analyzed, and leave the query plan as \nearlier computed if any of them belong to a different table.",
        "modified_files_count": 1,
        "modified_files": [
            "sql/sql_optimizer.cc"
        ],
        "github_commit_url": "https://github.com/logicalclocks/rondb/commit/4c263649bbfc2e29de97d09f1b13bb3050341703",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "make_join_select"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy ensures that the range optimizer only considers indexes from the table being analyzed in the ORDER BY clause, avoiding unnecessary checks on unrelated tables.",
            "The optimization strategy ensures that the range optimizer only considers indexes from the table being analyzed in the ORDER BY clause, avoiding unnecessary checks on irrelevant tables.",
            "The optimization strategy ensures that the range optimizer only considers indexes from the table being analyzed in the ORDER BY clause, avoiding unnecessary checks on unrelated tables.",
            "The optimization strategy ensures that the range optimizer only considers indexes from the table being analyzed in the ORDER BY clause, avoiding unnecessary checks on unrelated tables.",
            "The optimization strategy ensures that the range optimizer only considers indexes from the table being analyzed in the ORDER BY clause, avoiding unnecessary checks on unrelated tables."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy ensures that the range optimizer only considers indexes from the table being analyzed in the ORDER BY clause, avoiding unnecessary checks on unrelated tables.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pybricks-micropython",
        "hash": "c37463345f2e91c9071deef2ccca7e7bc9d0b5a1",
        "author": "David Lechner",
        "date": "2019-11-26T17:32:08-06:00",
        "message": "ev3dev_stretch/serial: set input and output baud rate at same time\n\nmicro-optimization, there is a function that can set both input and\noutput baud rate at the same time.",
        "modified_files_count": 1,
        "modified_files": [
            "lib/pbio/drv/ev3dev_stretch/serial.c"
        ],
        "github_commit_url": "https://github.com/pybricks/pybricks-micropython/commit/c37463345f2e91c9071deef2ccca7e7bc9d0b5a1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pbdrv_serial_config"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant calls by using a single function to set both input and output baud rates simultaneously.",
            "The optimization strategy involved replacing separate function calls for setting input and output baud rates with a single function call that sets both simultaneously.",
            "The optimization strategy involved replacing separate function calls for setting input and output baud rates with a single function call that sets both simultaneously.",
            "The optimization strategy involved reducing redundant calls by using a single function to set both input and output baud rates simultaneously.",
            "The optimization strategy involved reducing redundant calls by using a single function to set both input and output baud rates simultaneously."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant calls by using a single function to set both input and output baud rates simultaneously.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "v8",
        "hash": "95c0ecee66786108a926645d37bba4d8c8a1f258",
        "author": "cbruni",
        "date": "2016-11-29T11:57:30+00:00",
        "message": "[counters] Avoid V8_EXPORT_PRIVATE to speed up compilation under windows\n\nBUG=chromium:668748\n\nReview-Url: https://codereview.chromium.org/2534123002\nCr-Commit-Position: refs/heads/master@{#41351}",
        "modified_files_count": 1,
        "modified_files": [
            "src/counters.h"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/95c0ecee66786108a926645d37bba4d8c8a1f258",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "V"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing the `V8_EXPORT_PRIVATE` macro to reduce compilation overhead on Windows.",
            "The optimization strategy involved removing the `V8_EXPORT_PRIVATE` macro to reduce compilation overhead on Windows.",
            "The optimization strategy involved removing the V8_EXPORT_PRIVATE macro to reduce compilation overhead on Windows.",
            "The optimization strategy involved removing the `V8_EXPORT_PRIVATE` macro to reduce compilation overhead on Windows.",
            "The optimization strategy involved removing the `V8_EXPORT_PRIVATE` macro to reduce compilation overhead on Windows."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing the `V8_EXPORT_PRIVATE` macro to reduce compilation overhead on Windows.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "44d95ae127c40625a73e634ef226d43bd2726486",
        "author": "copercini",
        "date": "2018-03-10T17:49:31+01:00",
        "message": "Disable Nagle Algorithm by default (#335)\n\nThis speed up the response in up to 10 times",
        "modified_files_count": 1,
        "modified_files": [
            "src/WebServer.cpp"
        ],
        "github_commit_url": "https://github.com/me-no-dev/ESPAsyncWebServer/commit/44d95ae127c40625a73e634ef226d43bd2726486",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AsyncWebServer::begin"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "ESPAsyncWebServer",
        "optimization_summary": [
            "The optimization disables the Nagle Algorithm by default to reduce latency and significantly improve response times.",
            "The optimization disables the Nagle Algorithm by default to reduce latency and improve response times.",
            "The optimization disables the Nagle Algorithm by default to reduce latency and improve response times.",
            "The optimization disables the Nagle Algorithm by default to reduce latency and improve response times.",
            "The optimization disables the Nagle Algorithm by default to reduce latency and significantly improve response times."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization disables the Nagle Algorithm by default to reduce latency and improve response times.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "AlphaRTC",
        "hash": "cdda76d1c88e2967494cdf65f20e77ecdf47827a",
        "author": "Patrik Höglund",
        "date": "2020-02-20T12:34:15+00:00",
        "message": "Make scenario unittests faster.\n\nThey now run in 3 seconds rather than 45 or whatever it was before.\n\nThe tests still pass (and I tried with gtest_repeat=25), so I think\nthe shorter time is sufficient to prove the code works and doesn't\ncrash. Unit tests need to be fast. I think it's unlikely a longer\nruntime would make this test a better correctness test, but let me\nknow if there's something in particular with this code that needs\nthe longer runtime.\n\nBug: None\nChange-Id: I3f4213718870a1772f7a19e3c418634031c46de3\nReviewed-on: https://webrtc-review.googlesource.com/c/src/+/168884\nReviewed-by: Sebastian Jansson <srte@webrtc.org>\nCommit-Queue: Patrik Höglund <phoglund@webrtc.org>\nCr-Commit-Position: refs/heads/master@{#30569}",
        "modified_files_count": 1,
        "modified_files": [
            "test/scenario/scenario_unittest.cc"
        ],
        "github_commit_url": "https://github.com/OpenNetLab/AlphaRTC/commit/cdda76d1c88e2967494cdf65f20e77ecdf47827a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of iterations or test cases in scenario unittests to significantly decrease runtime while maintaining correctness.",
            "The optimization strategy involved reducing the number of iterations or test cases in scenario unittests to significantly decrease runtime while maintaining correctness.",
            "The optimization strategy involved reducing the runtime of scenario unit tests by shortening the test duration while ensuring sufficient coverage for correctness and crash detection.",
            "The optimization strategy involved reducing the number of iterations or test cases in scenario unittests to significantly decrease runtime while maintaining correctness.",
            "The optimization strategy involved reducing the number of iterations or test cases in scenario unittests to significantly decrease runtime while maintaining correctness."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of iterations or test cases in scenario unittests to significantly decrease runtime while maintaining correctness.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "open62541",
        "hash": "a882beb2402fa232cb05d05ee4b277f15895214c",
        "author": "Suriya Narayanan Parthasarathi Vimala",
        "date": "2019-10-25T15:42:13+02:00",
        "message": "fix(pubsub): Performance of subscriber server\n\n - Socket timeout should not be 300ms as it waits for a packet\n   for about 300ms and stop the other resources\n - Reduced the timeout to 1ms as subscribe callback timer\n   running at 5ms\n\nChange-Id: If75f586555b864720a4bacf603029612c783bea2",
        "modified_files_count": 1,
        "modified_files": [
            "src/pubsub/ua_pubsub_reader.c"
        ],
        "github_commit_url": "https://github.com/open62541/open62541/commit/a882beb2402fa232cb05d05ee4b277f15895214c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "UA_ReaderGroup_subscribeCallback"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the socket timeout from 300ms to 1ms to prevent prolonged blocking and improve resource utilization in the subscriber server.",
            "The optimization strategy involved reducing the socket timeout from 300ms to 1ms to prevent resource blocking and improve responsiveness in the subscriber server.",
            "The optimization strategy reduced the socket timeout from 300ms to 1ms to prevent unnecessary delays and improve responsiveness in the subscriber server's callback timer execution.",
            "The optimization strategy reduced the socket timeout from 300ms to 1ms to prevent unnecessary delays and improve responsiveness in the subscriber server's callback timer running at 5ms.",
            "The optimization strategy involved reducing the socket timeout from 300ms to 1ms to prevent blocking other resources while waiting for packets."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the socket timeout from 300ms to 1ms to prevent resource blocking and improve responsiveness in the subscriber server.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "e522f446027845e3c8b563d021f37e8f3d30c9d9",
        "author": "Israel Rukshin",
        "date": "2019-11-04T10:56:40-07:00",
        "message": "nvmet: add unlikely check at nvmet_req_alloc_sgl\n\nThe call to sgl_alloc shouldn't fail so add this simple optimization to\nthe fast path.\n\nSigned-off-by: Israel Rukshin <israelr@mellanox.com>\nReviewed-by: Max Gurtovoy <maxg@mellanox.com>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nSigned-off-by: Keith Busch <kbusch@kernel.org>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/nvme/target/core.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/e522f446027845e3c8b563d021f37e8f3d30c9d9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nvmet_req_alloc_sgl"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is adding an `unlikely` branch prediction hint to improve the efficiency of the fast path by signaling that the failure case of `sgl_alloc` is rare.",
            "The optimization strategy used is adding an unlikely check to improve branch prediction for a function that rarely fails.",
            "The optimization strategy used is adding an `unlikely` branch prediction hint to improve the efficiency of the fast path by informing the compiler that the failure case of `sgl_alloc` is rare.",
            "The optimization strategy used is adding an unlikely check to improve branch prediction for a function that rarely fails.",
            "The optimization adds an `unlikely` branch prediction hint to improve the performance of the fast path by indicating that the `sgl_alloc` function is expected to succeed most of the time."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is adding an `unlikely` branch prediction hint to improve the efficiency of the fast path by signaling that the failure case of `sgl_alloc` is rare.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "foundationdb",
        "hash": "7cabe39aae99ca73b74f4e7da4282042a1fa5423",
        "author": "Evan Tschannen",
        "date": "2020-11-18T10:28:53-08:00",
        "message": "Merge pull request #4044 from sfc-gh-tclinkenbeard/fix-slow-sim-recovery\n\nLower DELAY_CC_WORST_FIT_CANDIDACY_SECONDS for LowLatencyWorkload",
        "modified_files_count": 1,
        "modified_files": [
            "fdbserver/workloads/LowLatency.actor.cpp"
        ],
        "github_commit_url": "https://github.com/apple/foundationdb/commit/7cabe39aae99ca73b74f4e7da4282042a1fa5423",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "setup"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the delay for candidacy in a low-latency workload to improve recovery speed.",
            "The optimization strategy involved reducing the delay for candidacy in a low-latency workload to improve recovery speed.",
            "The optimization strategy involved reducing the delay for candidacy in a low-latency workload to improve recovery speed.",
            "The optimization strategy involved reducing the delay for candidacy in a low-latency workload to improve recovery speed.",
            "The optimization strategy involved reducing the delay for candidacy in a low-latency workload to improve recovery speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the delay for candidacy in a low-latency workload to improve recovery speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "opm-simulators",
        "hash": "a502a86dc1cddd1e25ce1994dd812003fdd5cee8",
        "author": "Arne Morten Kvarving",
        "date": "2025-01-24T12:17:56+01:00",
        "message": "Transmissibility::update: use ThreadSafeMapBuilder for diffusivity_\n\nthis in preparation for multithreading the loop",
        "modified_files_count": 1,
        "modified_files": [
            "opm/simulators/flow/Transmissibility_impl.hpp"
        ],
        "github_commit_url": "https://github.com/OPM/opm-simulators/commit/a502a86dc1cddd1e25ce1994dd812003fdd5cee8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "update"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing the existing data structure with a ThreadSafeMapBuilder to prepare for multithreading in the loop.",
            "The optimization strategy involved replacing the existing data structure with a ThreadSafeMapBuilder to prepare for multithreading in the loop.",
            "The optimization strategy involved replacing the existing data structure with a ThreadSafeMapBuilder to prepare for multithreading in the loop.",
            "The optimization strategy involved replacing the existing data structure with a ThreadSafeMapBuilder to prepare for multithreading, reducing potential contention in concurrent updates.",
            "The optimization strategy involved replacing the existing data structure with a ThreadSafeMapBuilder to prepare for multithreading, reducing potential contention in concurrent updates."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing the existing data structure with a ThreadSafeMapBuilder to prepare for multithreading in the loop.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "petsc",
        "hash": "fdc00aef69df9646bd29c5d18be728b64f15e343",
        "author": "Joe Wallwork",
        "date": "2022-02-03T10:14:57+00:00",
        "message": "plex ex19: updates for metric optimizations",
        "modified_files_count": 1,
        "modified_files": [
            "src/dm/impls/plex/tests/ex19.c"
        ],
        "github_commit_url": "https://github.com/petsc/petsc/commit/fdc00aef69df9646bd29c5d18be728b64f15e343",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ComputeMetric"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the computation of metrics to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of metrics to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of metrics to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of metrics to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of metrics to reduce redundant calculations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the computation of metrics to reduce redundant calculations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "03cf57db62cb6234539a770f6b54f67c562d5232",
        "author": "Jesse Haber-Kucharsky",
        "date": "2018-08-13T13:24:45-04:00",
        "message": "auth: Construct `std::random_device` instances once\n\n`std::random_device` has a lot of implementation-specific behavior, and\nas a result we cannot assume much about its performance characteristics.\n\nWe initialize thread-specific static instances of `std::random_device`\nonce so that we don't have the overhead of invoking the ctor during\nevery invocation of `gensalt`.",
        "modified_files_count": 1,
        "modified_files": [
            "auth/password_authenticator.cc"
        ],
        "github_commit_url": "https://github.com/scylladb/scylladb/commit/03cf57db62cb6234539a770f6b54f67c562d5232",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gensalt"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "scylladb",
        "optimization_summary": [
            "The optimization strategy involves initializing thread-specific static instances of `std::random_device` once to avoid the overhead of constructing it repeatedly in the `gensalt` function.",
            "The optimization strategy involves initializing thread-specific static instances of `std::random_device` once to avoid the overhead of constructing it repeatedly in the `gensalt` function.",
            "The optimization strategy involves initializing thread-specific static instances of `std::random_device` once to avoid the overhead of constructing it repeatedly in the `gensalt` function.",
            "The optimization strategy involves initializing thread-specific static instances of `std::random_device` once to avoid the overhead of constructing it repeatedly in the `gensalt` function.",
            "The optimization strategy involves initializing thread-specific static instances of `std::random_device` once to avoid the overhead of repeated constructor calls during each invocation of `gensalt`."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves initializing thread-specific static instances of `std::random_device` once to avoid the overhead of constructing it repeatedly in the `gensalt` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "samba",
        "hash": "d9a4055174862c87c737685eb554429e2cd985d2",
        "author": "Shirish Kalele",
        "date": "2002-08-20T19:58:23+00:00",
        "message": "The \"max data count\" value in SMB transacts indicates how much the other end can\nsend us. As it stands, we incorrectly set it to the number of bytes we are\nsending. Correcting this by setting a static value of 1024 (This could even be\nsomething larger). Improves RPC client performance.\n(This used to be commit b0bd42c9466f41dc87a11fd6065620f93c8ebc40)",
        "modified_files_count": 1,
        "modified_files": [
            "source3/rpc_client/cli_pipe.c"
        ],
        "github_commit_url": "https://github.com/samba-team/samba/commit/d9a4055174862c87c737685eb554429e2cd985d2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rpc_api_pipe"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved correcting an incorrect \"max data count\" value in SMB transacts by setting it to a static, larger value to improve RPC client performance.",
            "The optimization strategy involved correcting the \"max data count\" value in SMB transacts to a static, larger value instead of incorrectly setting it to the number of bytes being sent, thereby improving RPC client performance.",
            "The optimization strategy involved correcting the \"max data count\" value in SMB transacts to a static, larger value to better align with the receiving capacity and improve RPC client performance.",
            "The optimization strategy involved correcting the \"max data count\" value in SMB transacts to a static, larger value instead of incorrectly setting it to the number of bytes being sent, thereby improving RPC client performance.",
            "The optimization strategy involved correcting the \"max data count\" value in SMB transacts to a static, larger value to improve RPC client performance by allowing more data to be sent in a single transaction."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved correcting the \"max data count\" value in SMB transacts to a static, larger value instead of incorrectly setting it to the number of bytes being sent, thereby improving RPC client performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Paddle",
        "hash": "2e1fb26b8b26e1dae81af890e3b0ea089218594c",
        "author": "Aurelius84",
        "date": "2022-04-28T09:41:59+08:00",
        "message": "[Performance]Add static inline for MakeReturnPyObject (#42334)",
        "modified_files_count": 1,
        "modified_files": [
            "paddle/fluid/pybind/op_function.h"
        ],
        "github_commit_url": "https://github.com/PaddlePaddle/Paddle/commit/2e1fb26b8b26e1dae81af890e3b0ea089218594c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MakeReturnPyObject"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adding `static inline` to the `MakeReturnPyObject` function to reduce function call overhead and potentially enable compiler optimizations.",
            "The optimization strategy used is to add `static inline` to the `MakeReturnPyObject` function to reduce function call overhead and improve performance by suggesting compiler optimizations.",
            "The optimization strategy used is to add `static inline` to the `MakeReturnPyObject` function to reduce function call overhead and improve performance by suggesting compiler optimizations.",
            "The optimization strategy used is to add `static inline` to the `MakeReturnPyObject` function to reduce function call overhead and improve performance by enabling potential compiler optimizations.",
            "The optimization strategy used is to declare the `MakeReturnPyObject` function as `static inline` to reduce function call overhead and enable potential compiler optimizations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to add `static inline` to the `MakeReturnPyObject` function to reduce function call overhead and improve performance by enabling potential compiler optimizations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "4423eff71ca6b8f2c5e0fc4cea33d8cdfe3c3740",
        "author": "Christophe Leroy",
        "date": "2021-06-16T00:16:47+10:00",
        "message": "powerpc: Force inlining of csum_add()\n\nCommit 328e7e487a46 (\"powerpc: force inlining of csum_partial() to\navoid multiple csum_partial() with GCC10\") inlined csum_partial().\n\nNow that csum_partial() is inlined, GCC outlines csum_add() when\ncalled by csum_partial().\n\nc064fb28 <csum_add>:\nc064fb28:\t7c 63 20 14 \taddc    r3,r3,r4\nc064fb2c:\t7c 63 01 94 \taddze   r3,r3\nc064fb30:\t4e 80 00 20 \tblr\n\nc0665fb8 <csum_add>:\nc0665fb8:\t7c 63 20 14 \taddc    r3,r3,r4\nc0665fbc:\t7c 63 01 94 \taddze   r3,r3\nc0665fc0:\t4e 80 00 20 \tblr\n\nc066719c:\t7c 9a c0 2e \tlwzx    r4,r26,r24\nc06671a0:\t38 60 00 00 \tli      r3,0\nc06671a4:\t7f 1a c2 14 \tadd     r24,r26,r24\nc06671a8:\t4b ff ee 11 \tbl      c0665fb8 <csum_add>\nc06671ac:\t80 98 00 04 \tlwz     r4,4(r24)\nc06671b0:\t4b ff ee 09 \tbl      c0665fb8 <csum_add>\nc06671b4:\t80 98 00 08 \tlwz     r4,8(r24)\nc06671b8:\t4b ff ee 01 \tbl      c0665fb8 <csum_add>\nc06671bc:\ta0 98 00 0c \tlhz     r4,12(r24)\nc06671c0:\t4b ff ed f9 \tbl      c0665fb8 <csum_add>\nc06671c4:\t7c 63 18 f8 \tnot     r3,r3\nc06671c8:\t81 3f 00 68 \tlwz     r9,104(r31)\nc06671cc:\t81 5f 00 a0 \tlwz     r10,160(r31)\nc06671d0:\t7d 29 18 14 \taddc    r9,r9,r3\nc06671d4:\t7d 29 01 94 \taddze   r9,r9\nc06671d8:\t91 3f 00 68 \tstw     r9,104(r31)\nc06671dc:\t7d 1a 50 50 \tsubf    r8,r26,r10\nc06671e0:\t83 01 00 10 \tlwz     r24,16(r1)\nc06671e4:\t83 41 00 18 \tlwz     r26,24(r1)\n\nThe sum with 0 is useless, should have been skipped.\nAnd there is even one completely unused instance of csum_add().\n\nIn file included from ./include/net/checksum.h:22,\n                 from ./include/linux/skbuff.h:28,\n                 from ./include/linux/icmp.h:16,\n                 from net/ipv6/ip6_tunnel.c:23:\n./arch/powerpc/include/asm/checksum.h: In function '__ip6_tnl_rcv':\n./arch/powerpc/include/asm/checksum.h:94:22: warning: inlining failed in call to 'csum_add': call is unlikely and code size would grow [-Winline]\n   94 | static inline __wsum csum_add(__wsum csum, __wsum addend)\n      |                      ^~~~~~~~\n./arch/powerpc/include/asm/checksum.h:172:31: note: called from here\n  172 |                         sum = csum_add(sum, (__force __wsum)*(const u32 *)buff);\n      |                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./arch/powerpc/include/asm/checksum.h:94:22: warning: inlining failed in call to 'csum_add': call is unlikely and code size would grow [-Winline]\n   94 | static inline __wsum csum_add(__wsum csum, __wsum addend)\n      |                      ^~~~~~~~\n./arch/powerpc/include/asm/checksum.h:177:31: note: called from here\n  177 |                         sum = csum_add(sum, (__force __wsum)\n      |                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n  178 |                                             *(const u32 *)(buff + 4));\n      |                                             ~~~~~~~~~~~~~~~~~~~~~~~~~\n./arch/powerpc/include/asm/checksum.h:94:22: warning: inlining failed in call to 'csum_add': call is unlikely and code size would grow [-Winline]\n   94 | static inline __wsum csum_add(__wsum csum, __wsum addend)\n      |                      ^~~~~~~~\n./arch/powerpc/include/asm/checksum.h:183:31: note: called from here\n  183 |                         sum = csum_add(sum, (__force __wsum)\n      |                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n  184 |                                             *(const u32 *)(buff + 8));\n      |                                             ~~~~~~~~~~~~~~~~~~~~~~~~~\n./arch/powerpc/include/asm/checksum.h:94:22: warning: inlining failed in call to 'csum_add': call is unlikely and code size would grow [-Winline]\n   94 | static inline __wsum csum_add(__wsum csum, __wsum addend)\n      |                      ^~~~~~~~\n./arch/powerpc/include/asm/checksum.h:186:31: note: called from here\n  186 |                         sum = csum_add(sum, (__force __wsum)\n      |                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n  187 |                                             *(const u16 *)(buff + 12));\n      |                                             ~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nForce inlining of csum_add().\n\n     94c:\t80 df 00 a0 \tlwz     r6,160(r31)\n     950:\t7d 28 50 2e \tlwzx    r9,r8,r10\n     954:\t7d 48 52 14 \tadd     r10,r8,r10\n     958:\t80 aa 00 04 \tlwz     r5,4(r10)\n     95c:\t80 ff 00 68 \tlwz     r7,104(r31)\n     960:\t7d 29 28 14 \taddc    r9,r9,r5\n     964:\t7d 29 01 94 \taddze   r9,r9\n     968:\t7d 08 30 50 \tsubf    r8,r8,r6\n     96c:\t80 aa 00 08 \tlwz     r5,8(r10)\n     970:\ta1 4a 00 0c \tlhz     r10,12(r10)\n     974:\t7d 29 28 14 \taddc    r9,r9,r5\n     978:\t7d 29 01 94 \taddze   r9,r9\n     97c:\t7d 29 50 14 \taddc    r9,r9,r10\n     980:\t7d 29 01 94 \taddze   r9,r9\n     984:\t7d 29 48 f8 \tnot     r9,r9\n     988:\t7c e7 48 14 \taddc    r7,r7,r9\n     98c:\t7c e7 01 94 \taddze   r7,r7\n     990:\t90 ff 00 68 \tstw     r7,104(r31)\n\nIn the non-inlined version, the first sum with 0 was performed.\nHere it is skipped.\n\nSigned-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>\nReviewed-by: Segher Boessenkool <segher@kernel.crashing.org>\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://lore.kernel.org/r/f7f4d4e364de6e473da874468b903da6e5d97adc.1620713272.git.christophe.leroy@csgroup.eu",
        "modified_files_count": 1,
        "modified_files": [
            "arch/powerpc/include/asm/checksum.h"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/4423eff71ca6b8f2c5e0fc4cea33d8cdfe3c3740",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "csum_add"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy forces the inlining of the `csum_add()` function to eliminate function call overhead and redundant computations, improving performance by reducing unnecessary operations and skipping unused or redundant calls.",
            "The optimization forces inlining of the `csum_add()` function to eliminate function call overhead and redundant computations, improving performance by reducing unnecessary operations and skipping unused or redundant calls.",
            "The optimization strategy forces the inlining of the `csum_add()` function to eliminate unnecessary function calls and redundant computations, improving performance by reducing overhead.",
            "The optimization strategy forces the inlining of the `csum_add()` function to eliminate function call overhead and redundant computations, improving performance by reducing unnecessary operations and skipping unused or redundant calls.",
            "The optimization strategy forces the inlining of the `csum_add()` function to eliminate function call overhead and redundant computations, improving performance by reducing unnecessary operations and skipping unused or redundant calls."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy forces the inlining of the `csum_add()` function to eliminate function call overhead and redundant computations, improving performance by reducing unnecessary operations and skipping unused or redundant calls.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "akaros",
        "hash": "2c165333d6db47195d79f22798a3eb6ac5279e80",
        "author": "Barret Rhoden",
        "date": "2015-09-28T15:14:00-04:00",
        "message": "qio: Ensure qwait() sets Qstarve\n\nQstarve tracks the status of the queue.  When the flag is set, the queue\nwas checked and was found empty.  All of the wakeup code (grep dowakeup)\nwill check Qstarve.\n\nA couple things to note:\n- Qstarve is an optimization.  You should be able to just call\n  rendez_wakeup and whatever else.  However, those can be expensive.\n- This is false: \"The queue is empty only if Qstarve is set\".  It is\n  possible for the queue to have been drained to 0, but not all the way,\nand Qstarve is not set.  It will be set when some thread attempts to\nextract data.\n\nIdeally, this would be merged with the (already pushed)\n3e0ae7c72ced (\"qio: Add non-blocking queues\")",
        "modified_files_count": 1,
        "modified_files": [
            "kern/src/ns/qio.c"
        ],
        "github_commit_url": "https://github.com/brho/akaros/commit/2c165333d6db47195d79f22798a3eb6ac5279e80",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Qclose"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves setting the Qstarve flag to avoid expensive wakeup calls when the queue is empty, reducing unnecessary overhead.",
            "The optimization strategy involves setting the Qstarve flag to avoid expensive wakeup calls when the queue is empty, reducing unnecessary overhead.",
            "The optimization strategy involves setting the Qstarve flag to avoid expensive wakeup calls when the queue is empty.",
            "The optimization strategy involves setting the Qstarve flag to avoid expensive wakeup calls when the queue is empty, reducing unnecessary overhead.",
            "The optimization strategy involves setting the Qstarve flag to avoid unnecessary expensive wakeup calls when the queue is empty."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves setting the Qstarve flag to avoid expensive wakeup calls when the queue is empty, reducing unnecessary overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "perfetto",
        "hash": "8f86d9f0190576fbf6c65fd82bb49122bfe182f2",
        "author": "Florian Mayer",
        "date": "2018-01-30T11:04:09+00:00",
        "message": "Merge \"Change trace config to make fuzzer faster.\"\nam: 97afce4baa\n\nChange-Id: I33aef55e77fbffa57b5a231bbffc93f54d222a56",
        "modified_files_count": 1,
        "modified_files": [
            "test/end_to_end_shared_memory_fuzzer.cc"
        ],
        "github_commit_url": "https://github.com/google/perfetto/commit/8f86d9f0190576fbf6c65fd82bb49122bfe182f2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FuzzSharedMemory"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved modifying the trace configuration to reduce the computational overhead during fuzzing by limiting unnecessary operations.",
            "The optimization strategy involved modifying the trace configuration to reduce the computational overhead during fuzz testing, specifically by adjusting parameters to make the fuzzer faster.",
            "The optimization strategy involved modifying the trace configuration to reduce the computational overhead during fuzzing by limiting unnecessary operations.",
            "The optimization strategy involved modifying the trace configuration to reduce the computational overhead during fuzz testing, specifically by making the fuzzer faster.",
            "The optimization strategy involved modifying the trace configuration to reduce the computational overhead during fuzzing by limiting unnecessary operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved modifying the trace configuration to reduce the computational overhead during fuzzing by limiting unnecessary operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sdk-nrf",
        "hash": "a5941fa07763febb512e55f108da9b9e5228b21b",
        "author": "Marek Pieta",
        "date": "2024-11-20T16:20:24+01:00",
        "message": "applications: nrf_desktop: Improve USB suspend in BLE conn params\n\nChange improves USB suspend handling in BLE conn params module. The\nconnection parameters are updated back to defaults when USB cable is\ndisconnected. This is done to make the behavior more consistent (longer\nconnection intervals are used only while USB is suspended) and to speed\nup sending HID reports when USB is reconnected in case dongle has an\nexternal power supppy (e.g. DK acting as a dongle).\n\nJira: NCSDK-30261\n\nSigned-off-by: Marek Pieta <Marek.Pieta@nordicsemi.no>",
        "modified_files_count": 1,
        "modified_files": [
            "applications/nrf_desktop/src/modules/ble_conn_params.c"
        ],
        "github_commit_url": "https://github.com/nrfconnect/sdk-nrf/commit/a5941fa07763febb512e55f108da9b9e5228b21b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "usb_state_event_handler"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves resetting BLE connection parameters to defaults upon USB disconnection to ensure consistent behavior and improve report transmission speed when USB is reconnected.",
            "The optimization strategy involves resetting BLE connection parameters to defaults upon USB disconnection to ensure consistent behavior and improve report transmission speed when USB is reconnected.",
            "The optimization strategy involves resetting BLE connection parameters to defaults upon USB disconnection to ensure consistent behavior and improve report transmission speed upon reconnection.",
            "The optimization strategy involves resetting BLE connection parameters to defaults upon USB disconnection to ensure consistent behavior and improve report transmission speed upon reconnection.",
            "The optimization strategy involves resetting BLE connection parameters to defaults upon USB disconnection to ensure consistent behavior and improve report transmission speed upon reconnection."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves resetting BLE connection parameters to defaults upon USB disconnection to ensure consistent behavior and improve report transmission speed upon reconnection.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "73808d0fd26b3d3f0f44cc7c469ad1d3c1b570b8",
        "author": "Prakash, Prashanth",
        "date": "2017-06-27T02:19:39+02:00",
        "message": "cpufreq / CPPC: Initialize policy->min to lowest nonlinear performance\n\nDescription of Lowest Perfomance in ACPI 6.1 specification states:\n\"Lowest Performance is the absolute lowest performance level of\nthe platform. Selecting a performance level lower than the lowest\nnonlinear performance level may actually cause an efficiency penalty,\nbut should reduce the instantaneous power consumption of the processor.\nIn traditional terms, this represents the T-state range of performance\nlevels.\"\n\nSet the default value of policy->min to Lowest Nonlinear Performance\nto avoid any potential efficiency penalty.\n\nSigned-off-by: Prashanth Prakash <pprakash@codeaurora.org>\nAcked-by: Viresh Kumar <viresh.kumar@linaro.org>\nAcked-by: Alexey Klimov <alexey.klimov@arm.com>\nSigned-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/cpufreq/cppc_cpufreq.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/73808d0fd26b3d3f0f44cc7c469ad1d3c1b570b8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cppc_cpufreq_cpu_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids potential efficiency penalties by setting the default minimum performance level to the lowest nonlinear performance instead of the absolute lowest performance.",
            "The optimization strategy involves setting the default value of `policy->min` to the lowest nonlinear performance level to avoid potential efficiency penalties.",
            "The optimization strategy sets the default minimum CPU performance to the lowest nonlinear performance level to avoid potential efficiency penalties.",
            "The optimization strategy involves setting the default minimum CPU performance level to the lowest nonlinear performance to avoid potential efficiency penalties.",
            "The optimization strategy avoids potential efficiency penalties by setting the default minimum performance level to the lowest nonlinear performance instead of the absolute lowest performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids potential efficiency penalties by setting the default minimum performance level to the lowest nonlinear performance instead of the absolute lowest performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BBHash",
        "hash": "6bb97c4218198d3e5dd60c7eadb5267a79959a6d",
        "author": "rchikhi",
        "date": "2020-07-14T17:13:04+02:00",
        "message": "faster lookups by avoiding copy constructor (https://github.com/rizkg/BBHash/issues/20 from @enerc)",
        "modified_files_count": 1,
        "modified_files": [
            "BooPHF.h"
        ],
        "github_commit_url": "https://github.com/rizkg/BBHash/commit/6bb97c4218198d3e5dd60c7eadb5267a79959a6d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary copy constructor calls during lookups by utilizing reference-based access instead of value-based access.",
            "The optimization avoids unnecessary copy constructor calls during lookups by directly referencing objects, reducing overhead.",
            "The optimization avoids unnecessary copy constructor calls during lookups by utilizing reference-based access instead of value-based access.",
            "The optimization avoids unnecessary copy constructor calls during lookups by directly referencing objects, reducing overhead.",
            "The optimization avoids unnecessary copy constructor calls during lookups by utilizing reference-based access instead of value-based access."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary copy constructor calls during lookups by utilizing reference-based access instead of value-based access.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "pycopy",
        "hash": "62f7ba7a815f34fb49967e925ac28ea340a46777",
        "author": "Paul Sokolovsky",
        "date": "2014-06-09T23:40:04+03:00",
        "message": "Merge pull request #675 from Rosuav/seq_simplify\n\nRemove unnecessary bounds check from mp_seq_get_fast_slice_indexes.",
        "modified_files_count": 1,
        "modified_files": [
            "py/sequence.c"
        ],
        "github_commit_url": "https://github.com/pfalcon/pycopy/commit/62f7ba7a815f34fb49967e925ac28ea340a46777",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mp_seq_get_fast_slice_indexes"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removed an unnecessary bounds check in the `mp_seq_get_fast_slice_indexes` function to reduce redundant computations.",
            "The optimization removes an unnecessary bounds check in the function `mp_seq_get_fast_slice_indexes` to reduce redundant computations.",
            "The optimization removes an unnecessary bounds check in the function `mp_seq_get_fast_slice_indexes` to reduce redundant computations.",
            "The optimization removes an unnecessary bounds check in the `mp_seq_get_fast_slice_indexes` function to reduce redundant computations.",
            "The optimization removes an unnecessary bounds check in the `mp_seq_get_fast_slice_indexes` function to reduce redundant computations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization removes an unnecessary bounds check in the `mp_seq_get_fast_slice_indexes` function to reduce redundant computations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sycl",
        "hash": "7482ad7272faecc1e306b5671f1300838cacce08",
        "author": "Eric Christopher",
        "date": "2010-01-08T08:24:49+00:00",
        "message": "After further thought revert the patch to make fast-isel avoid\nputting relocations into the constant pool - this isn't needed\nfor correctness and in the rare occasion it happens would pull\nus out of fast isel for the block.\n\nIf fast-isel application startup time ever becomes an issue we\ncan add better support for these addresses instead of bailing.\n\nllvm-svn: 92995",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Target/X86/X86FastISel.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/7482ad7272faecc1e306b5671f1300838cacce08",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "X86FastISel::TargetMaterializeConstant"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reverted a patch to avoid placing relocations in the constant pool, which was unnecessary for correctness and could have negatively impacted fast-isel performance.",
            "The optimization strategy reverted a patch to avoid placing relocations in the constant pool, which was unnecessary for correctness and could have negatively impacted fast-isel performance.",
            "The optimization strategy reverted a patch to avoid placing relocations in the constant pool, which was unnecessary for correctness and could have negatively impacted fast-isel performance.",
            "The optimization strategy involved reverting a patch that avoided placing relocations in the constant pool during fast-isel to improve startup time only when necessary.",
            "The optimization strategy reverts a patch to avoid placing relocations in the constant pool, reducing unnecessary complexity and potential performance overhead in rare cases."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reverted a patch to avoid placing relocations in the constant pool, which was unnecessary for correctness and could have negatively impacted fast-isel performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "7635d2fd7f0fa63b6ec03050614c314d7139f14a",
        "author": "Joonsoo Kim",
        "date": "2012-08-16T14:21:16-07:00",
        "message": "workqueue: use system_highpri_wq for unbind_work\n\nTo speed cpu down processing up, use system_highpri_wq.\nAs scheduling priority of workers on it is higher than system_wq and\nit is not contended by other normal works on this cpu, work on it\nis processed faster than system_wq.\n\ntj: CPU up/downs care quite a bit about latency these days.  This\n    shouldn't hurt anything and makes sense.\n\nSigned-off-by: Joonsoo Kim <js1304@gmail.com>\nSigned-off-by: Tejun Heo <tj@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/workqueue.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/7635d2fd7f0fa63b6ec03050614c314d7139f14a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "workqueue_cpu_down_callback"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involves using a higher-priority workqueue (`system_highpri_wq`) to reduce latency for CPU up/down processing by avoiding contention from normal-priority tasks.",
            "The optimization strategy involves using a high-priority workqueue (`system_highpri_wq`) instead of a standard one (`system_wq`) to reduce latency in CPU down processing by ensuring faster execution of critical tasks.",
            "The optimization strategy involves using a higher-priority workqueue (`system_highpri_wq`) to reduce latency in CPU down processing by ensuring faster execution of critical tasks compared to the default `system_wq`.",
            "The optimization strategy involves using a high-priority workqueue (`system_highpri_wq`) instead of a standard one (`system_wq`) to reduce latency in CPU down processing by ensuring faster execution of critical tasks.",
            "The optimization strategy involves using a high-priority workqueue (`system_highpri_wq`) instead of a standard one (`system_wq`) to reduce latency in CPU up/down processing by ensuring faster execution of critical tasks."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves using a high-priority workqueue (`system_highpri_wq`) instead of a standard one (`system_wq`) to reduce latency in CPU down processing by ensuring faster execution of critical tasks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "envoy",
        "hash": "48743154a35f5751796d39ebceb615453abac8de",
        "author": "htuch",
        "date": "2018-04-03T16:24:19-07:00",
        "message": "config: optimize RepeatedPtrUtil::debugString at non-debug log levels. (#2984)\n\nThis one was showing up on our flamegraphs.\r\n\r\nRisk Level: Low\r\nTesting: bazel build //source/exe/...\r\n\r\nSigned-off-by: Harvey Tuch <htuch@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "source/common/config/grpc_mux_subscription_impl.h"
        ],
        "github_commit_url": "https://github.com/envoyproxy/envoy/commit/48743154a35f5751796d39ebceb615453abac8de",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "onConfigUpdate"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary string construction in `RepeatedPtrUtil::debugString` when logging is not at the debug level.",
            "The optimization avoids unnecessary string construction in `RepeatedPtrUtil::debugString` when logging is not at the debug level.",
            "The optimization avoids unnecessary string construction in `RepeatedPtrUtil::debugString` when logging is not at the debug level.",
            "The optimization avoids unnecessary string construction in `RepeatedPtrUtil::debugString` when logging is not at the debug level.",
            "The optimization avoids unnecessary string construction in `RepeatedPtrUtil::debugString` when logging is not at the debug level."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary string construction in `RepeatedPtrUtil::debugString` when logging is not at the debug level.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "gui",
        "hash": "bf0a510981ddc28c754881ca21c50ab18e5f2b59",
        "author": "Russell Yanofsky",
        "date": "2020-05-01T06:59:09-04:00",
        "message": "gui: Avoid wallet tryGetBalances calls before TransactionChanged or BlockTip notifications\n\ninterfaces::Wallet::tryGetBalances was recently updated in\nhttps://github.com/bitcoin/bitcoin/pull/18160 to avoid computing balances\ninternally, but this not efficient as it could be with #10102 because\ntryGetBalances is an interprocess call.\n\nImplementing the TransactionChanged / BlockTip check outside of tryGetBalances\nalso allows tryGetBalances to be simplified in next commit 'Revert \"gui: Avoid\nWallet::GetBalance in WalletModel::pollBalanceChanged\"'.",
        "modified_files_count": 1,
        "modified_files": [
            "src/qt/walletmodel.cpp"
        ],
        "github_commit_url": "https://github.com/bitcoin-core/gui/commit/bf0a510981ddc28c754881ca21c50ab18e5f2b59",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary interprocess calls to `tryGetBalances` by implementing a check for `TransactionChanged` or `BlockTip` notifications before invoking the function.",
            "The optimization avoids unnecessary interprocess calls to `tryGetBalances` by implementing a check for `TransactionChanged` or `BlockTip` notifications before invoking the function.",
            "The optimization avoids unnecessary interprocess calls to `tryGetBalances` by implementing a check for `TransactionChanged` or `BlockTip` notifications before invoking the function.",
            "The optimization avoids unnecessary interprocess calls to `tryGetBalances` by implementing a check for `TransactionChanged` or `BlockTip` notifications before invoking the function.",
            "The optimization avoids unnecessary interprocess calls to `tryGetBalances` by implementing a check for `TransactionChanged` or `BlockTip` notifications before invoking the function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary interprocess calls to `tryGetBalances` by implementing a check for `TransactionChanged` or `BlockTip` notifications before invoking the function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "dbe678f6192f27879ac9ff6bc7a1036aad85aae9",
        "author": "Frank Li",
        "date": "2023-05-29T15:23:59+01:00",
        "message": "usb: cdns3: fix NCM gadget RX speed 20x slow than expection at iMX8QM\n\nAt iMX8QM platform, enable NCM gadget and run 'iperf3 -s'.\nAt host, run 'iperf3 -V -c fe80::6863:98ff:feef:3e0%enxc6e147509498'\n\n[  5]   0.00-1.00   sec  1.55 MBytes  13.0 Mbits/sec   90   4.18 KBytes\n[  5]   1.00-2.00   sec  1.44 MBytes  12.0 Mbits/sec   75   4.18 KBytes\n[  5]   2.00-3.00   sec  1.48 MBytes  12.4 Mbits/sec   75   4.18 KBytes\n\nExpected speed should be bigger than 300Mbits/sec.\n\nThe root cause of this performance drop was found to be data corruption\nhappening at 4K borders in some Ethernet packets, leading to TCP\nchecksum errors. This corruption occurs from the position\n(4K - (address & 0x7F)) to 4K. The u_ether function's allocation of\nskb_buff reserves 64B, meaning all RX addresses resemble 0xXXXX0040.\n\nForce trb_burst_size to 16 can fix this problem.\n\nCc: stable@vger.kernel.org\nFixes: 7733f6c32e36 (\"usb: cdns3: Add Cadence USB3 DRD Driver\")\nSigned-off-by: Frank Li <Frank.Li@nxp.com>\nLink: https://lore.kernel.org/r/20230518154946.3666662-1-Frank.Li@nxp.com\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/usb/cdns3/cdns3-gadget.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/dbe678f6192f27879ac9ff6bc7a1036aad85aae9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cdns3_ep_config"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved forcing the `trb_burst_size` to 16 to prevent data corruption at 4K boundaries, which was causing TCP checksum errors and significantly reducing network performance.",
            "The optimization strategy involved forcing the `trb_burst_size` to 16 to prevent data corruption at 4K boundaries, thereby resolving TCP checksum errors and significantly improving RX speed.",
            "The optimization strategy involved forcing the `trb_burst_size` to 16 to prevent data corruption at 4K boundaries, thereby resolving TCP checksum errors and significantly improving RX speed.",
            "The optimization strategy involved forcing the `trb_burst_size` to 16 to prevent data corruption at 4K boundaries, which was causing TCP checksum errors and significantly reducing RX speed.",
            "The optimization strategy involved forcing the `trb_burst_size` to 16 to prevent data corruption at 4K boundaries, thereby resolving TCP checksum errors and significantly improving RX speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved forcing the `trb_burst_size` to 16 to prevent data corruption at 4K boundaries, thereby resolving TCP checksum errors and significantly improving RX speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gemrb",
        "hash": "9f7815dcaa242c0239205792d8c0d2ebf7a211c1",
        "author": "Brad Allred",
        "date": "2014-08-12T22:39:13-06:00",
        "message": "FPS counter: add IE_FONT_SINGLE_LINE\n\nfixes using inefficient rendering path.",
        "modified_files_count": 1,
        "modified_files": [
            "gemrb/core/Interface.cpp"
        ],
        "github_commit_url": "https://github.com/gemrb/gemrb/commit/9f7815dcaa242c0239205792d8c0d2ebf7a211c1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Interface::Main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids an inefficient rendering path by adding a single-line font rendering flag for the FPS counter.",
            "The optimization avoids an inefficient rendering path by adding a specific font rendering flag.",
            "The optimization avoids an inefficient rendering path by adding a specific font rendering flag.",
            "The optimization avoids an inefficient rendering path by adding a specific font rendering flag.",
            "The optimization avoids an inefficient rendering path by adding a specific font rendering flag."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids an inefficient rendering path by adding a specific font rendering flag.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "htcondor",
        "hash": "aaea0413fac061ca8697227533084af40865b415",
        "author": "Jaime Frey",
        "date": "2018-01-05T16:40:01-06:00",
        "message": "Make address-rewriting code more efficient when disabled. #6518\n\nIn ConvertDefaultIPToSocketIP(), hoist the check of\nSHARED_PORT_ADDRESS_REWRITING to the top of the function. This lets us\navoid more expensive checks in most situations (only HTCondor-CE sets\nthis parameter to enable address rewriting).",
        "modified_files_count": 1,
        "modified_files": [
            "src/condor_utils/my_hostname.cpp"
        ],
        "github_commit_url": "https://github.com/htcondor/htcondor/commit/aaea0413fac061ca8697227533084af40865b415",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ConvertDefaultIPToSocketIP"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization hoists a conditional check to the top of the function to avoid unnecessary computations when the feature is disabled.",
            "The optimization hoists a conditional check to the top of the function to avoid unnecessary computations when the feature is disabled.",
            "The optimization hoists a conditional check to the top of the function to avoid unnecessary computations when the feature is disabled.",
            "The optimization hoists a conditional check to the top of the function to avoid unnecessary computations when the feature is disabled.",
            "The optimization hoists a conditional check to the top of the function to avoid unnecessary computations when the feature is disabled."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization hoists a conditional check to the top of the function to avoid unnecessary computations when the feature is disabled.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "zephyr",
        "hash": "2a206a07b3b6200d21f4b0a7be4b29265428761a",
        "author": "Djordje Nedic",
        "date": "2025-01-09T04:04:16+01:00",
        "message": "fs: littlefs: Improve block device cache size\n\nInstead of picking a set of safe block multiple sized values for caches,\nround down to the nearest block multiple, increasing static buffer usage\ndetermined by Kconfig variables.\n\nSigned-off-by: Djordje Nedic <nedic.djordje2@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "subsys/fs/littlefs_fs.c"
        ],
        "github_commit_url": "https://github.com/zephyrproject-rtos/zephyr/commit/2a206a07b3b6200d21f4b0a7be4b29265428761a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "littlefs_init_cfg"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy rounds down cache sizes to the nearest block multiple to improve static buffer usage based on Kconfig variables.",
            "The optimization strategy rounds down cache sizes to the nearest block multiple to improve static buffer usage based on Kconfig variables.",
            "The optimization strategy rounds down cache sizes to the nearest block multiple to improve static buffer usage based on Kconfig variables.",
            "The optimization strategy rounds down cache sizes to the nearest block multiple to improve static buffer usage based on Kconfig variables.",
            "The optimization strategy rounds down cache sizes to the nearest block multiple to improve static buffer usage based on Kconfig variables."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy rounds down cache sizes to the nearest block multiple to improve static buffer usage based on Kconfig variables.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "glsl-optimizer",
        "hash": "7feabfe23dc54960abba34755f484f786575ac49",
        "author": "Brian Paul",
        "date": "2012-03-21T13:46:36-06:00",
        "message": "glsl: propagate MaxUnrollIterations to the optimizer's loop unroller\n\nInstead of the hard-coded value of 32.  Note that MaxUnrollIterations\ndefaults to 32 so there's no net change.  But the gallium state tracker\ncan override this.\n\nNOTE: This is a candidate for the 8.0 branch.\n\nReviewed-by: Kenneth Graunke <kenneth@whitecape.org>",
        "modified_files_count": 1,
        "modified_files": [
            "src/glsl/linker.cpp"
        ],
        "github_commit_url": "https://github.com/aras-p/glsl-optimizer/commit/7feabfe23dc54960abba34755f484f786575ac49",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "link_shaders"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves making the loop unrolling iteration limit configurable instead of hard-coded, allowing for potential performance tuning based on context-specific overrides.",
            "The optimization strategy involves making the loop unrolling iteration limit configurable instead of hard-coded, allowing for potential performance tuning based on context-specific needs.",
            "The optimization strategy involves making the loop unrolling iteration limit configurable instead of hard-coded, allowing for potential performance tuning based on context-specific needs.",
            "The optimization strategy involves making the loop unrolling iteration limit configurable instead of hard-coded, allowing for potential performance tuning based on context-specific overrides.",
            "The optimization strategy involves making the loop unrolling iteration limit configurable instead of hard-coded, allowing for potential performance tuning based on context-specific overrides."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves making the loop unrolling iteration limit configurable instead of hard-coded, allowing for potential performance tuning based on context-specific overrides.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "5844e129891e39beeab038abfe8a7cc7bfb08ad1",
        "author": "Jakub Zawadzki",
        "date": "2014-06-19T00:08:04+00:00",
        "message": "Optimize dissect_sip_uri()\n\n- Combine tvb_find_guint8() for comma, semicolon into one tvb_pbrk_guint8()\n\n- Instead of fetching each character use tvb_pbrk_guint8() to fast\n  forward.\n\n- Remove not needed tvb_find_guint8() call, as the result is discarded.\n\nChange-Id: I38d6775b187146656d47cea9b64f8e0ccad18d36\nReviewed-on: https://code.wireshark.org/review/2384\nReviewed-by: Anders Broman <a.broman58@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "epan/dissectors/packet-sip.c"
        ],
        "github_commit_url": "https://github.com/wireshark/wireshark/commit/5844e129891e39beeab038abfe8a7cc7bfb08ad1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dissect_sip_uri"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "wireshark",
        "optimization_summary": [
            "The optimization strategy combines multiple character searches into a single call to reduce redundant operations and improve efficiency.",
            "The optimization strategy involves replacing multiple calls to `tvb_find_guint8()` with a single call to `tvb_pbrk_guint8()` to reduce redundant operations and improve efficiency.",
            "The optimization strategy combines multiple searches for specific characters into a single, more efficient search operation using `tvb_pbrk_guint8()` and eliminates an unnecessary function call.",
            "The optimization strategy combines multiple searches for specific characters into a single more efficient search operation using `tvb_pbrk_guint8()` and removes unnecessary calls to improve performance.",
            "The optimization strategy combines multiple searches for specific characters into a single, more efficient search operation using `tvb_pbrk_guint8()` and removes unnecessary calls to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy combines multiple searches for specific characters into a single more efficient search operation using `tvb_pbrk_guint8()` and removes unnecessary calls to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "1699dbebf31f0b26a8408d24da3c7f3b113f0340",
        "author": "Linus Torvalds",
        "date": "2023-04-25T10:05:00-07:00",
        "message": "Merge tag 'x86_acpi_for_v6.4_rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip\n\nPull x86 ACPI update from Borislav Petkov:\n\n - Improve code generation in ACPI's global lock's acquisition function\n\n* tag 'x86_acpi_for_v6.4_rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:\n  x86/ACPI/boot: Improve __acpi_acquire_global_lock",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/kernel/acpi/boot.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/1699dbebf31f0b26a8408d24da3c7f3b113f0340",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__acpi_acquire_global_lock"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the logic in the ACPI global lock acquisition function to reduce unnecessary operations and improve code generation.",
            "The optimization strategy involved restructuring the logic in the ACPI global lock acquisition function to reduce unnecessary operations and improve efficiency.",
            "The optimization strategy involved restructuring the logic in the ACPI global lock acquisition function to reduce unnecessary operations and improve code generation.",
            "The optimization strategy involved restructuring the logic in the ACPI global lock acquisition function to reduce unnecessary operations and improve efficiency.",
            "The optimization strategy involved restructuring the logic in the ACPI global lock acquisition function to reduce unnecessary operations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the logic in the ACPI global lock acquisition function to reduce unnecessary operations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "32blit-sdk",
        "hash": "b8a09bd0f461b93ded0a3f3532690e24b570bab1",
        "author": "Philip Howard",
        "date": "2020-10-16T14:42:23+01:00",
        "message": "Merge pull request #402 from Daft-Freak/patch-2\n\nAvoid copying entire screen surface in set_screen_mode",
        "modified_files_count": 1,
        "modified_files": [
            "32blit/engine/engine.cpp"
        ],
        "github_commit_url": "https://github.com/32blit/32blit-sdk/commit/b8a09bd0f461b93ded0a3f3532690e24b570bab1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "set_screen_mode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids copying the entire screen surface by directly manipulating the screen mode without unnecessary data duplication.",
            "The optimization avoids copying the entire screen surface by directly manipulating the screen mode without unnecessary data duplication.",
            "The optimization avoids copying the entire screen surface by directly manipulating the screen mode without unnecessary data duplication.",
            "The optimization avoids copying the entire screen surface by directly manipulating the screen mode without unnecessary data duplication.",
            "The optimization avoids copying the entire screen surface by directly manipulating the screen mode without unnecessary data duplication."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids copying the entire screen surface by directly manipulating the screen mode without unnecessary data duplication.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "gui",
        "hash": "1ed859e90e18384376e3a1ff0cb76f3e9ab11c2d",
        "author": "W. J. van der Laan",
        "date": "2021-05-19T10:07:53+02:00",
        "message": "Merge bitcoin/bitcoin#21173: util: faster HexStr => 13% faster blockToJSON\n\n74bf850ac47735f2ef4306059d3e664d40cac85e faster HexStr => 13% faster blockToJSON (Martin Ankerl)\n\nPull request description:\n\n  `std::string`'s push_back is rather slow because it needs to check & update the string size. For\n  `HexStr` the output string size is already easily know, so we can initially create the string with\n  the correct size and then just assign the data.\n\n  `HexStr` is heavily usd in `blockToJSON`, so this change is a noticeable benefit. Benchmark on an i7-8700 @3.2GHz:\n\n  * 71,315,461.00 ns/op master\n  * 62,842,490.00 ns/op this commit\n\n  So this little change makes `blockToJSON` about ~13% faster.\n\nACKs for top commit:\n  laanwj:\n    Code review ACK 74bf850ac47735f2ef4306059d3e664d40cac85e\n  theStack:\n    re-ACK 74bf850ac47735f2ef4306059d3e664d40cac85e\n\nTree-SHA512: fc99105123edc11f4e40ed77aea80cf7f32e49c53369aa364b38395dcb48575e15040b0489ed30d0fe857c032a04e225c33e9d95cdfa109a3cb5a6ec9a972415",
        "modified_files_count": 1,
        "modified_files": [
            "src/util/strencodings.cpp"
        ],
        "github_commit_url": "https://github.com/bitcoin-core/gui/commit/1ed859e90e18384376e3a1ff0cb76f3e9ab11c2d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved preallocating the exact size of the output string in `HexStr` to avoid repeated size checks and updates during `push_back` operations.",
            "The optimization strategy involved preallocating the exact size of the output string in `HexStr` to avoid repeated size checks and updates during `push_back` operations.",
            "The optimization strategy involved preallocating the output string's size in `HexStr` to avoid repeated size checks and updates during `push_back` operations.",
            "The optimization strategy involved pre-allocating the output string's size in `HexStr` to avoid repeated size checks and updates during `push_back` operations.",
            "The optimization strategy involved preallocating the exact size of the output string in `HexStr` to avoid repeated size checks and updates during `push_back` operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved preallocating the exact size of the output string in `HexStr` to avoid repeated size checks and updates during `push_back` operations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "lightrec",
        "hash": "89c75ab64846e2366e8503f446f192dee71ca5ec",
        "author": "Paul Cercueil",
        "date": "2023-03-13T19:17:52+01:00",
        "message": "optimizer: Consider reads from $sp or $gp always hit memory\n\nWhen $sp or $gp are used as the target address register, consider that\nthe address will always point to a mapped memory (RAM, BIOS or\nscratchpad).\n\nThis was already done for stores, but for some reason it was not done\nfor reads.\n\nSigned-off-by: Paul Cercueil <paul@crapouillou.net>",
        "modified_files_count": 1,
        "modified_files": [
            "optimizer.c"
        ],
        "github_commit_url": "https://github.com/pcercuei/lightrec/commit/89c75ab64846e2366e8503f446f192dee71ca5ec",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "lightrec_flag_io"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy assumes that reads from specific registers ($sp or $gp) always access mapped memory, reducing unnecessary checks.",
            "The optimization assumes reads from specific registers ($sp or $gp) always target mapped memory, reducing unnecessary checks.",
            "The optimization strategy assumes that reads from specific registers ($sp or $gp) always access mapped memory, reducing unnecessary checks.",
            "The optimization strategy assumes that reads from specific registers ($sp or $gp) always access mapped memory, reducing unnecessary checks.",
            "The optimization strategy assumes that reads from specific registers ($sp or $gp) always access mapped memory, reducing unnecessary checks."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy assumes that reads from specific registers ($sp or $gp) always access mapped memory, reducing unnecessary checks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "simple_lmk",
        "hash": "7a0652b4ed110861e629e3d4da7769c81e588fa6",
        "author": "Ming Lei",
        "date": "2022-12-05T11:27:45+00:00",
        "message": "UPSTREAM: blk-mq: don't touch ->tagset in blk_mq_get_sq_hctx\n\nblk_mq_run_hw_queues() could be run when there isn't queued request and\nafter queue is cleaned up, at that time tagset is freed, because tagset\nlifetime is covered by driver, and often freed after blk_cleanup_queue()\nreturns.\n\nSo don't touch ->tagset for figuring out current default hctx by the mapping\nbuilt in request queue, so use-after-free on tagset can be avoided. Meantime\nthis way should be fast than retrieving mapping from tagset.\n\nBug: 254441685\nCc: \"yukuai (C)\" <yukuai3@huawei.com>\nCc: Jan Kara <jack@suse.cz>\nFixes: b6e68ee82585 (\"blk-mq: Improve performance of non-mq IO schedulers with multiple HW queues\")\nSigned-off-by: Ming Lei <ming.lei@redhat.com>\nReviewed-by: Jan Kara <jack@suse.cz>\nLink: https://lore.kernel.org/r/20220522122350.743103-1-ming.lei@redhat.com\nSigned-off-by: Jens Axboe <axboe@kernel.dk>\n(cherry picked from commit 5d05426e2d5fd7df8afc866b78c36b37b00188b7)\nSigned-off-by: Lee Jones <joneslee@google.com>\nChange-Id: Ie42bc77a352368f0e7a733905d26491388d97944",
        "modified_files_count": 1,
        "modified_files": [
            "block/blk-mq.c"
        ],
        "github_commit_url": "https://github.com/kerneltoast/simple_lmk/commit/7a0652b4ed110861e629e3d4da7769c81e588fa6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "from"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids accessing freed memory by using an alternative mapping to determine the default hardware context, which also improves performance.",
            "The optimization avoids accessing the potentially freed `->tagset` by using the mapping built in the request queue, preventing use-after-free issues while improving performance.",
            "The optimization avoids accessing a potentially freed `tagset` by using an alternative mapping built in the request queue, which also improves performance.",
            "The optimization avoids accessing the freed `tagset` by using the mapping built in the request queue to determine the default hardware context, preventing use-after-free issues while potentially improving performance.",
            "The optimization avoids accessing a potentially freed `tagset` by using an alternative mapping built in the request queue, which also improves performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids accessing the freed `tagset` by using the mapping built in the request queue to determine the default hardware context, preventing use-after-free issues while potentially improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "917ac7d4131795bfd84694a07364e6bba2d8693a",
        "author": "verwaest@chromium.org",
        "date": "2013-06-20T14:11:52+00:00",
        "message": "Improve range analysis for smi phi\n\nR=jkummerow@chromium.org\n\nReview URL: https://chromiumcodereview.appspot.com/17498002\n\ngit-svn-id: http://v8.googlecode.com/svn/branches/bleeding_edge@15247 ce2b1a6d-e550-0410-aec6-3dcde31c8c00",
        "modified_files_count": 1,
        "modified_files": [
            "src/hydrogen-instructions.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/917ac7d4131795bfd84694a07364e6bba2d8693a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HPhi::InferRange"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved enhancing range analysis for smi phi to improve inference accuracy and reduce unnecessary computations.",
            "The optimization improves range analysis for smi phi by refining the inference logic to reduce unnecessary computations or improve precision.",
            "The optimization improves range analysis for smi phi nodes by refining the inference logic to reduce unnecessary computations.",
            "The optimization strategy involved enhancing range analysis for smi phi nodes to improve precision in type inference and reduce unnecessary computations.",
            "The optimization improves range analysis for smi phi nodes by refining the inference logic to reduce unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization improves range analysis for smi phi nodes by refining the inference logic to reduce unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "simc",
        "hash": "e5696f36ba739d188bed53ec4ed431769089d945",
        "author": "Navv",
        "date": "2014-10-09T18:23:01+03:00",
        "message": "[Shaman] Optimize Fire Nova slightly.",
        "modified_files_count": 1,
        "modified_files": [
            "engine/class_modules/sc_shaman.cpp"
        ],
        "github_commit_url": "https://github.com/simulationcraft/simc/commit/e5696f36ba739d188bed53ec4ed431769089d945",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "available_targets"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations in the `available_targets` function by improving the logic for selecting valid targets.",
            "The optimization strategy involved reducing unnecessary computations in the `available_targets` function by improving the logic for selecting valid targets.",
            "The optimization strategy involved reducing unnecessary computations in the `available_targets` function by filtering targets more efficiently.",
            "The optimization strategy used is to reduce unnecessary iterations by filtering targets more efficiently in the `available_targets` function.",
            "The optimization strategy involved reducing unnecessary computations in the `available_targets` function by improving the logic for selecting valid targets."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations in the `available_targets` function by improving the logic for selecting valid targets.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "992abcc32db9b31a660486f1d72bbf1e7ba8807a",
        "author": "Georgia Kouveli",
        "date": "2020-02-17T12:12:38+00:00",
        "message": "[arm64] Push frame marker on stack in a single instruction\n\n... instead of first claiming space on the stack and then storing it,\nwhich was sometimes causing the profiler to read the uninitialised frame\ntype slot right after it was claimed, but before it was written to.\n\nBug: v8:9907\nChange-Id: I33318aec44b6083488317ec5e226a06e59c7560c\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/2056473\nReviewed-by: Georg Neis <neis@chromium.org>\nCommit-Queue: Georgia Kouveli <georgia.kouveli@arm.com>\nCr-Commit-Position: refs/heads/master@{#66285}",
        "modified_files_count": 1,
        "modified_files": [
            "src/compiler/backend/arm64/code-generator-arm64.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/992abcc32db9b31a660486f1d72bbf1e7ba8807a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CodeGenerator::AssembleConstructFrame"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of instructions to push a frame marker onto the stack, improving both performance and avoiding potential profiler misreads.",
            "The optimization strategy involved reducing the number of instructions to push a frame marker onto the stack, improving both performance and avoiding potential profiler misreads.",
            "The optimization strategy involved reducing the number of instructions to push a frame marker onto the stack, improving both performance and avoiding potential profiler misreads.",
            "The optimization strategy involved reducing the number of instructions to push a frame marker onto the stack, improving both performance and avoiding potential profiler misreads.",
            "The optimization strategy involved reducing the number of instructions to push a frame marker onto the stack, thereby minimizing the risk of profiler misreads during uninitialized memory states."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of instructions to push a frame marker onto the stack, improving both performance and avoiding potential profiler misreads.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "CppCommon",
        "hash": "5acb5c743078176eb05d033e1f6584019300935e",
        "author": "Ivan Shynkarenka",
        "date": "2016-07-16T04:57:18+03:00",
        "message": "Linux optimizations in Timestamp::local()",
        "modified_files_count": 1,
        "modified_files": [
            "source/time/timestamp.cpp"
        ],
        "github_commit_url": "https://github.com/chronoxor/CppCommon/commit/5acb5c743078176eb05d033e1f6584019300935e",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant system calls by caching the local time zone information in the `Timestamp::local()` function.",
            "The optimization strategy involved reducing redundant system calls by caching the local time zone information in the `Timestamp::local()` function.",
            "The optimization strategy involved reducing redundant system calls by caching the local time zone information in the `Timestamp::local()` function.",
            "The optimization strategy involved reducing redundant system calls by caching the local time zone information in the `Timestamp::local()` function.",
            "The optimization strategy involved reducing redundant system calls by caching the local time zone information in the `Timestamp::local()` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant system calls by caching the local time zone information in the `Timestamp::local()` function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "arm-trusted-firmware",
        "hash": "0ed322329339a30c6bbd81ba784bb54966e4bd6c",
        "author": "Varun Wadekar",
        "date": "2018-04-09T16:37:23-07:00",
        "message": "lib: xlat_tables_v2: reduce time required to add a mmap region\n\nThe last entry in the mapping table is not necessarily the same as the\nend of the table. This patch loops through the table to find the last\nentry marker, on every new mmap addition. The memove operation then\nhas to only move the memory between current entry and the last entry.\nFor platforms that arrange their MMIO map properly, this opearation\nturns out to be a NOP.\n\nThe previous implementation added significant overhead per mmap\naddition as the memmove operation always moved the difference between\nthe current mmap entry and the end of the table.\n\nTested on Tegra platforms and this new approach improves the memory\nmapping time by ~75%, thus significantly reducing boot time on some\nplatforms.\n\nChange-Id: Ie3478fa5942379282ef58bee2085da799137e2ca\nSigned-off-by: Varun Wadekar <vwadekar@nvidia.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/xlat_tables_v2/xlat_tables_internal.c"
        ],
        "github_commit_url": "https://github.com/ARM-software/arm-trusted-firmware/commit/0ed322329339a30c6bbd81ba784bb54966e4bd6c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mmap_add_region_ctx"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces the memory mapping time by limiting the `memmove` operation to only the necessary portion of the table instead of the entire table.",
            "The optimization strategy reduces the memory mapping time by limiting the `memmove` operation to only the necessary portion of the table instead of the entire table.",
            "The optimization strategy reduces the memory mapping time by limiting the `memmove` operation to only the necessary portion of the table instead of the entire table.",
            "The optimization strategy reduces unnecessary memory movement by finding the actual last entry in the mapping table instead of assuming the end of the table, minimizing the memmove operation's scope.",
            "The optimization strategy reduces the memory mapping time by limiting the `memmove` operation to only the necessary portion of the table instead of the entire table."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the memory mapping time by limiting the `memmove` operation to only the necessary portion of the table instead of the entire table.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cryptominisat",
        "hash": "0497de13c8bc1b0dd279e53b665fbe16bb7a7001",
        "author": "Mate Soos",
        "date": "2012-07-14T14:08:22+02:00",
        "message": "We should read from /dev/urandom it's faster\n\nAnd we don't need cryptographic security",
        "modified_files_count": 1,
        "modified_files": [
            "cmsat/Solver.cpp"
        ],
        "github_commit_url": "https://github.com/msoos/cryptominisat/commit/0497de13c8bc1b0dd279e53b665fbe16bb7a7001",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "zeroLevAssignsByCNF"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a potentially slower random number generation method with a faster one by reading from /dev/urandom instead of /dev/random, as cryptographic security is not required.",
            "The optimization strategy involved replacing a potentially slower random number generation method with a faster one by reading from /dev/urandom instead of /dev/random, as cryptographic security is not required.",
            "The optimization strategy involved replacing a potentially slower random number generation method with a faster one by reading from /dev/urandom instead of /dev/random, as cryptographic security is not required.",
            "The optimization strategy involved replacing a potentially slower random number generation method with a faster one by reading from /dev/urandom instead of /dev/random, as cryptographic security is not required.",
            "The optimization strategy involved replacing a potentially slower random number generation method with a faster one by reading from /dev/urandom instead of /dev/random, as cryptographic security is not required."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a potentially slower random number generation method with a faster one by reading from /dev/urandom instead of /dev/random, as cryptographic security is not required.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "freeradius-server",
        "hash": "518ebe1902916a6232f83cd1effbd5cc9c27c8cf",
        "author": "Arran Cudbard-Bell",
        "date": "2020-06-05T11:35:20-05:00",
        "message": "More efficient field initialisation",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/rlm_radius/rlm_radius_udp.c"
        ],
        "github_commit_url": "https://github.com/FreeRADIUS/freeradius-server/commit/518ebe1902916a6232f83cd1effbd5cc9c27c8cf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mod_enqueue"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the initialization of fields to reduce redundant operations and improve efficiency.",
            "The optimization strategy involved restructuring the initialization of fields to reduce redundant operations and improve efficiency.",
            "The optimization strategy involved restructuring the initialization of fields to reduce redundant operations and improve efficiency.",
            "The optimization strategy involved restructuring the initialization of fields to reduce redundant operations and improve efficiency.",
            "The optimization strategy involved restructuring the initialization of fields to reduce redundant operations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the initialization of fields to reduce redundant operations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qrack",
        "hash": "23aac68805ad1b509a84989a78ddde083f41cee9",
        "author": "Daniel Strano",
        "date": "2020-09-06T19:20:43-04:00",
        "message": "Restore disabled QUnit optimization code (#463)",
        "modified_files_count": 1,
        "modified_files": [
            "src/qunit.cpp"
        ],
        "github_commit_url": "https://github.com/unitaryfund/qrack/commit/23aac68805ad1b509a84989a78ddde083f41cee9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "QUnit::ApplyAntiControlledSinglePhase"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit re-enables a previously disabled optimization in the QUnit class, specifically restoring logic that skips unnecessary operations when applying anti-controlled single-phase gates.",
            "The commit re-enables a previously disabled optimization in the QUnit class, specifically targeting phase application logic to improve performance.",
            "The commit re-enables a previously disabled optimization in the QUnit class, specifically targeting phase application logic to improve performance.",
            "The commit re-enables a previously disabled optimization in the QUnit class, specifically targeting phase application logic to improve performance.",
            "The optimization strategy involved re-enabling previously disabled code that applies anti-controlled single-phase operations more efficiently."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit re-enables a previously disabled optimization in the QUnit class, specifically targeting phase application logic to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cmssw",
        "hash": "e0f96fa0cc8d438014cda9e76aca9bc9f4f00c59",
        "author": "William Tanenbaum",
        "date": "2010-10-29T13:49:43+00:00",
        "message": "Cache the TypeID to speed up type checking",
        "modified_files_count": 1,
        "modified_files": [
            "FWCore/Framework/src/Group.cc"
        ],
        "github_commit_url": "https://github.com/cms-sw/cmssw/commit/e0f96fa0cc8d438014cda9e76aca9bc9f4f00c59",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GroupData::checkType"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved caching the TypeID to avoid redundant type checking computations.",
            "The optimization strategy involved caching the TypeID to avoid redundant type checking computations.",
            "The optimization strategy involved caching the TypeID to avoid redundant type checking computations.",
            "The optimization strategy involved caching the TypeID to avoid redundant type checking computations.",
            "The optimization strategy involved caching the TypeID to avoid redundant type checking computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved caching the TypeID to avoid redundant type checking computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "DiligentFX",
        "hash": "6c920dcb433864a31bd36537d9bc3dfb6c84a5b9",
        "author": "assiduous",
        "date": "2024-02-25T22:45:17-08:00",
        "message": "HnRenderPass: minor change for a non-trivial performance win",
        "modified_files_count": 1,
        "modified_files": [
            "Hydrogent/src/HnRenderPass.cpp"
        ],
        "github_commit_url": "https://github.com/DiligentGraphics/DiligentFX/commit/6c920dcb433864a31bd36537d9bc3dfb6c84a5b9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HnRenderPass::RenderPendingDrawItems"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant state changes in the rendering pipeline by caching and reusing previously set states.",
            "The optimization strategy involved reducing redundant state changes in the rendering loop by caching and reusing previously set states.",
            "The optimization strategy involved reducing redundant state changes in the rendering pipeline by caching and reusing previously set states.",
            "The optimization strategy involved reducing redundant state changes in the rendering loop by caching and reusing the previous state.",
            "The optimization strategy involved reducing redundant state changes in the rendering pipeline by caching and reusing previously set states."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant state changes in the rendering pipeline by caching and reusing previously set states.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kokkos",
        "hash": "530f2113f1e30096bd3041f6f7357b81c875a410",
        "author": "Christian Trott",
        "date": "2020-05-13T12:13:45-06:00",
        "message": "Merge pull request #3030 from masterleinad/reduce_memory_scatterview\n\nReduce memory consumption ScatterView test",
        "modified_files_count": 1,
        "modified_files": [
            "containers/unit_tests/TestScatterView.hpp"
        ],
        "github_commit_url": "https://github.com/kokkos/kokkos/commit/530f2113f1e30096bd3041f6f7357b81c875a410",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "test_scatter_view"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces memory consumption in the ScatterView test by modifying the test_scatter_view function to use more efficient memory allocation or access patterns.",
            "The optimization strategy reduces memory consumption in the ScatterView test by limiting unnecessary allocations or data duplication.",
            "The optimization strategy reduces memory consumption in the ScatterView test by modifying the test_scatter_view function to use more efficient memory allocation or data handling.",
            "The optimization strategy reduces memory consumption in the ScatterView test by modifying how data is allocated or accessed.",
            "The optimization strategy reduces memory consumption in the ScatterView test by modifying the test_scatter_view function to use more efficient memory handling."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces memory consumption in the ScatterView test by modifying the test_scatter_view function to use more efficient memory allocation or data handling.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "casadi",
        "hash": "a45f99d74008f1c7fe646d84d9e7ff3bbfc09a5f",
        "author": "Joel Andersson",
        "date": "2011-06-19T17:11:48+00:00",
        "message": "resolved performance degrading changed introduced in revision 1319 (4)",
        "modified_files_count": 1,
        "modified_files": [
            "examples/multiple_shooting_from_scratch.cpp"
        ],
        "github_commit_url": "https://github.com/casadi/casadi/commit/a45f99d74008f1c7fe646d84d9e7ff3bbfc09a5f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations inside a loop by moving invariant calculations outside the loop.",
            "The optimization strategy involved reducing redundant computations inside a loop by caching results of expensive operations.",
            "The optimization strategy involved restructuring the code to avoid redundant computations inside a loop, thereby improving performance.",
            "The optimization strategy involved reducing redundant computations inside a loop by caching results of expensive operations.",
            "The optimization strategy involved reducing redundant computations inside a loop by moving invariant calculations outside the loop."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations inside a loop by moving invariant calculations outside the loop.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Vulkan-ValidationLayers",
        "hash": "a02d4711263f3d50b6e5617cb1c89aae21a37f79",
        "author": "Shahbaz Youssefi",
        "date": "2022-10-05T22:11:20-06:00",
        "message": "layers: Disable friendly names in SPIR-V validation\n\nThe friendly-name-mapper in spirv-val is slow. Disabling it in VVL\nimproves performance of an ANGLE test that creates numerous shaders by\n~10%.  The cost of SPIR-V validation itself is reduced by ~40%.\n\nUpdates SPIRV-Tools to include the change that adds the relevant option.",
        "modified_files_count": 1,
        "modified_files": [
            "layers/shader_validation.cpp"
        ],
        "github_commit_url": "https://github.com/KhronosGroup/Vulkan-ValidationLayers/commit/a02d4711263f3d50b6e5617cb1c89aae21a37f79",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AdjustValidatorOptions"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization disables the friendly-name-mapping feature in SPIR-V validation to reduce processing overhead and improve performance.",
            "The optimization disables the friendly-name-mapping feature in SPIR-V validation to reduce processing overhead and improve performance.",
            "The optimization disables the friendly-name-mapping feature in SPIR-V validation to reduce processing overhead and improve performance.",
            "The optimization disables the friendly-name-mapper in SPIR-V validation to reduce processing overhead and improve performance.",
            "The optimization disables the friendly-name-mapping feature in SPIR-V validation to reduce processing overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization disables the friendly-name-mapping feature in SPIR-V validation to reduce processing overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "networkit",
        "hash": "340d8de9e14f8b27b5f42e99c7f4845f76330fc1",
        "author": "Eugenio Angriman",
        "date": "2021-04-26T11:48:21+02:00",
        "message": "Merge pull request #733 from angriman/matching-is-proper\n\nFaster Matching::isProper",
        "modified_files_count": 1,
        "modified_files": [
            "networkit/cpp/matching/Matching.cpp"
        ],
        "github_commit_url": "https://github.com/networkit/networkit/commit/340d8de9e14f8b27b5f42e99c7f4845f76330fc1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Matching::isProper"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations or iterations within the `Matching::isProper` function to improve its runtime efficiency.",
            "The optimization strategy involved reducing unnecessary computations in the `Matching::isProper` function by improving the logic to avoid redundant checks.",
            "The optimization strategy involved restructuring the logic in `Matching::isProper` to reduce unnecessary computations and improve efficiency by avoiding redundant checks.",
            "The optimization strategy involved reducing unnecessary computations in the `Matching::isProper` function by improving the logic to minimize redundant checks.",
            "The optimization strategy involved restructuring the logic in `Matching::isProper` to reduce unnecessary computations or checks, likely improving its runtime efficiency."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations in the `Matching::isProper` function by improving the logic to avoid redundant checks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "angle",
        "hash": "b3859a3cba6063433d12165397c0f669580f467e",
        "author": "Charlie Lao",
        "date": "2020-09-30T21:18:17+00:00",
        "message": "Vulkan: disable glFlush deferral optimization for QualComm GPUs.\n\nIt appears this optimization causing Manhattan performance regression on\npixel4 with QualComm GPU. It does have a measurable performance\nimprovement on S20+ that has ARM GPU. This disables this optimization\nfor QualComm but still leaves it enabled on other GPUs.\n\nBug: b/166475273\nChange-Id: I9c9cd55ab169463fc8cc16d7d917be660cb2f363\nReviewed-on: https://chromium-review.googlesource.com/c/angle/angle/+/2441667\nReviewed-by: Mohan Maiya <m.maiya@samsung.com>\nReviewed-by: Jamie Madill <jmadill@chromium.org>\nCommit-Queue: Charlie Lao <cclao@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/libANGLE/renderer/vulkan/RendererVk.cpp"
        ],
        "github_commit_url": "https://github.com/google/angle/commit/b3859a3cba6063433d12165397c0f669580f467e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RendererVk::initFeatures"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy disables a specific GPU-related performance optimization (glFlush deferral) for Qualcomm GPUs to address a performance regression on certain devices while retaining it for other GPUs.",
            "The optimization strategy involves conditionally disabling a specific GPU-related performance optimization (glFlush deferral) for Qualcomm GPUs to address performance regressions on certain devices while retaining it for other GPUs.",
            "The optimization strategy involves conditionally disabling a specific GPU-related performance optimization (glFlush deferral) for Qualcomm GPUs to address a performance regression on certain devices while retaining it for other GPUs.",
            "The optimization strategy disables a specific GPU-related performance optimization (glFlush deferral) for Qualcomm GPUs to address a performance regression on certain devices while retaining it for other GPUs.",
            "The optimization strategy disables a specific GPU-related performance optimization (glFlush deferral) for Qualcomm GPUs to address a performance regression on certain devices while retaining it for other GPUs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy disables a specific GPU-related performance optimization (glFlush deferral) for Qualcomm GPUs to address a performance regression on certain devices while retaining it for other GPUs.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "e01a0c3316a75b07d6938f9d5933e7fe39294dc4",
        "author": "Reini Urban",
        "date": "2023-09-06T13:32:00+02:00",
        "message": "bit_read_TV: optimize TV-ZERO logging a bit",
        "modified_files_count": 1,
        "modified_files": [
            "src/bits.c"
        ],
        "github_commit_url": "https://github.com/LibreDWG/libredwg/commit/e01a0c3316a75b07d6938f9d5933e7fe39294dc4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bit_read_TV"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "libredwg",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary logging operations for TV-ZERO cases to improve performance.",
            "The optimization strategy used is to reduce redundant logging operations by checking for zero values before proceeding with TV logging.",
            "The optimization strategy involved reducing unnecessary logging operations for zero values in the bit_read_TV function.",
            "The optimization strategy involved reducing unnecessary logging operations for TV-ZERO cases to improve performance.",
            "The optimization strategy involved reducing redundant logging operations by checking for zero values before logging in the `bit_read_TV` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary logging operations for TV-ZERO cases to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "647a2a9a25234d9b6089afb6000f48713d4bcb54",
        "author": "Glenn Strauss",
        "date": "2022-02-19T02:40:37-05:00",
        "message": "[mod_magnet] adjust hot path for more inlining",
        "modified_files_count": 1,
        "modified_files": [
            "src/mod_magnet.c"
        ],
        "github_commit_url": "https://github.com/lighttpd/lighttpd1.4/commit/647a2a9a25234d9b6089afb6000f48713d4bcb54",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "magnet_attract"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "lighttpd1.4",
        "optimization_summary": [
            "The optimization strategy involved restructuring the code to enable more aggressive inlining by the compiler, reducing function call overhead in a performance-critical path.",
            "The optimization strategy involved restructuring the hot path in the `magnet_attract` function to enable more aggressive inlining by the compiler.",
            "The optimization strategy involved restructuring the hot path in the `magnet_attract` function to enable more aggressive inlining by the compiler.",
            "The optimization strategy involved restructuring the code to enable more aggressive inlining by the compiler, reducing function call overhead in a performance-critical path.",
            "The optimization strategy involved restructuring the hot path in the `magnet_attract` function to enable more aggressive inlining by the compiler."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the hot path in the `magnet_attract` function to enable more aggressive inlining by the compiler.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "android_kernel_xiaomi_sdm845",
        "hash": "bab10a549fd64e36f06c995d6adf22c0413e9379",
        "author": "Johannes Berg",
        "date": "2017-01-26T08:24:39+01:00",
        "message": "mac80211: implement multicast forwarding on fast-RX path\n\ncommit eeb0d56fab4cd7848cf2be6704fa48900dbc1381 upstream.\n\nIn AP (or VLAN) mode, when unicast 802.11 packets are received,\nthey might actually be multicast after conversion. In this case\nthe fast-RX path didn't handle them properly to send them back\nto the wireless medium. Implement that by copying the SKB and\nsending it back out.\n\nThe possible alternative would be to just punt the packet back\nto the regular (slow) RX path, but since we have almost all of\nthe required code here already it's not so complicated to add\nhere. Punting it back would also mean acquiring the spinlock,\nwhich would be bad for the stated purpose of the fast-RX path,\nto enable well-performing parallel RX.\n\nSigned-off-by: Johannes Berg <johannes.berg@intel.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "net/mac80211/rx.c"
        ],
        "github_commit_url": "https://github.com/LineageOS/android_kernel_xiaomi_sdm845/commit/bab10a549fd64e36f06c995d6adf22c0413e9379",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ieee80211_invoke_fast_rx"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved extending the fast-RX path to handle multicast packets directly, avoiding the need to fall back to the slower RX path and reducing spinlock contention.",
            "The optimization strategy involves handling multicast packet forwarding directly within the fast-RX path to avoid the overhead of punting packets back to the slow RX path and acquiring a spinlock.",
            "The optimization strategy involved extending the fast-RX path to handle multicast packets directly, avoiding the need to fall back to the slower RX path and reducing spinlock contention.",
            "The optimization strategy involved extending the fast-RX path to handle multicast packets directly, avoiding the need to fall back to the slower RX path and reducing spinlock contention.",
            "The optimization strategy involves handling multicast packet forwarding directly within the fast-RX path to avoid the overhead of punting packets back to the slower RX path."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved extending the fast-RX path to handle multicast packets directly, avoiding the need to fall back to the slower RX path and reducing spinlock contention.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "5e5dda81a0dfb82de1757ab878d9ffd2339c9b2a",
        "author": "Ralph Campbell",
        "date": "2020-12-15T12:13:45-08:00",
        "message": "mm/migrate.c: optimize migrate_vma_pages() mmu notifier\n\nWhen migrating a zero page or pte_none() anonymous page to device private\nmemory, migrate_vma_setup() will initialize the src[] array with a NULL\nPFN.  This lets the device driver allocate device private memory and clear\nit instead of DMAing a page of zeros over the device bus.\n\nSince the source page didn't exist at the time, no struct page was locked\nnor a migration PTE inserted into the CPU page tables.  The actual PTE\ninsertion happens in migrate_vma_pages() when it tries to insert the\ndevice private struct page PTE into the CPU page tables.\nmigrate_vma_pages() has to call the mmu notifiers again since another\ndevice could fault on the same page before the page table locks are\nacquired.\n\nAllow device drivers to optimize the invalidation similar to\nmigrate_vma_setup() by calling mmu_notifier_range_init() which sets struct\nmmu_notifier_range event type to MMU_NOTIFY_MIGRATE and the\nmigrate_pgmap_owner field.\n\nLink: https://lkml.kernel.org/r/20201021191335.10916-1-rcampbell@nvidia.com\nSigned-off-by: Ralph Campbell <rcampbell@nvidia.com>\nCc: Jerome Glisse <jglisse@redhat.com>\nCc: John Hubbard <jhubbard@nvidia.com>\nCc: Alistair Popple <apopple@nvidia.com>\nCc: Christoph Hellwig <hch@lst.de>\nCc: Jason Gunthorpe <jgg@nvidia.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/migrate.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/5e5dda81a0dfb82de1757ab878d9ffd2339c9b2a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "migrate_vma_pages"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves reducing redundant MMU notifier calls during page migration by initializing the `mmu_notifier_range` structure to allow device drivers to handle invalidations more efficiently.",
            "The optimization avoids unnecessary MMU notifier calls during page migration by initializing the `mmu_notifier_range` structure with specific event types and fields to streamline invalidation.",
            "The optimization avoids unnecessary MMU notifier calls during page migration by initializing the `mmu_notifier_range` with specific event types and fields to allow device drivers to handle invalidations more efficiently.",
            "The optimization strategy involves enhancing the efficiency of page migration by allowing device drivers to optimize invalidation through improved MMU notifier handling, reducing unnecessary operations when migrating zero or non-existent pages.",
            "The optimization avoids unnecessary MMU notifier calls during page migration by initializing the `mmu_notifier_range` structure with specific event types and ownership information, allowing devices to optimize invalidation similar to `migrate_vma_setup()`."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary MMU notifier calls during page migration by initializing the `mmu_notifier_range` with specific event types and fields to allow device drivers to handle invalidations more efficiently.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MonetDB",
        "hash": "e660f5b372bbb3e4238bc60167c42933c9ff3e67",
        "author": "Pedro Ferreira",
        "date": "2021-05-04T12:11:30+02:00",
        "message": "Defensive lines. Apply postfix optimizer on joins only when 2 results are being returned. Also removed assertion about which arguments being used. If the join is about to be removed by deadcode optimizer, then both returned values won't be used",
        "modified_files_count": 1,
        "modified_files": [
            "monetdb5/optimizer/opt_postfix.c"
        ],
        "github_commit_url": "https://github.com/MonetDB/MonetDB/commit/e660f5b372bbb3e4238bc60167c42933c9ff3e67",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OPTpostfixImplementation"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves conditionally applying a postfix optimizer on joins only when two results are being returned, reducing unnecessary processing.",
            "The optimization strategy involves conditionally applying a postfix optimizer on joins only when two results are being returned, reducing unnecessary processing.",
            "The optimization strategy involves conditionally applying a postfix optimizer on joins only when two results are being returned, reducing unnecessary processing.",
            "The optimization strategy involves conditionally applying a postfix optimizer on joins only when two results are being returned, reducing unnecessary processing.",
            "The optimization strategy involves conditionally applying a postfix optimizer on joins only when two results are being returned, reducing unnecessary processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves conditionally applying a postfix optimizer on joins only when two results are being returned, reducing unnecessary processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "6031be78e1c02e259c0c61053fdb00af30aae271",
        "author": "Mats Palmgren",
        "date": "2017-02-20T17:43:08+01:00",
        "message": "Bug 410857 - Part 2: DrainOverflowLines before ResolveBidi for slightly improved performance. r=jfkthame, a=jcristau",
        "modified_files_count": 1,
        "modified_files": [
            "layout/generic/nsBlockFrame.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/6031be78e1c02e259c0c61053fdb00af30aae271",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nsBlockFrame::Reflow"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reordering operations to perform `DrainOverflowLines` before `ResolveBidi`, reducing unnecessary computations during the reflow process.",
            "The optimization strategy involved reordering operations to perform `DrainOverflowLines` before `ResolveBidi`, reducing unnecessary computations during the reflow process.",
            "The optimization strategy involved reordering operations to perform `DrainOverflowLines` before `ResolveBidi`, reducing unnecessary computations during the reflow process.",
            "The optimization strategy involved reordering operations to perform `DrainOverflowLines` before `ResolveBidi`, reducing unnecessary computations during the reflow process.",
            "The optimization strategy involved reordering operations to perform `DrainOverflowLines` before `ResolveBidi`, reducing unnecessary computations during the reflow process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reordering operations to perform `DrainOverflowLines` before `ResolveBidi`, reducing unnecessary computations during the reflow process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gzdoom-rt",
        "hash": "91589d9799d38db7413b57126748cba7253fcf9a",
        "author": "Kevin Caccamo",
        "date": "2020-01-11T13:24:02+01:00",
        "message": "Attempt to optimize check for ML_DRAWFULLHEIGHT\n\nIt is less likely that a line will have the ML_DRAWFULLHEIGHT flag than its' ceiling will be above the neighbouring sector's ceiling and vice versa.",
        "modified_files_count": 1,
        "modified_files": [
            "src/rendering/hwrenderer/scene/hw_walls.cpp"
        ],
        "github_commit_url": "https://github.com/vs-shirokii/gzdoom-rt/commit/91589d9799d38db7413b57126748cba7253fcf9a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HWWall::Process"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reorders conditional checks to prioritize more likely conditions based on assumptions about the ML_DRAWFULLHEIGHT flag and sector ceiling relationships.",
            "The optimization strategy reorders condition checks to prioritize more likely scenarios, reducing unnecessary evaluations.",
            "The optimization strategy reorders conditional checks to prioritize more likely conditions based on assumptions about the ML_DRAWFULLHEIGHT flag's rarity.",
            "The optimization strategy reorders conditional checks to prioritize more likely conditions based on assumptions about the ML_DRAWFULLHEIGHT flag and sector ceiling relationships.",
            "The optimization strategy reorders condition checks to prioritize more likely scenarios, reducing unnecessary evaluations."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy reorders conditional checks to prioritize more likely conditions based on assumptions about the ML_DRAWFULLHEIGHT flag's rarity.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "skyscraper",
        "hash": "83d0820e58ba45242e71bd15ae1917991829b1a1",
        "author": "Lars Muldjord",
        "date": "2018-01-03T19:07:02+01:00",
        "message": "Now uses constBits instead of bits for efficiency",
        "modified_files_count": 1,
        "modified_files": [
            "src/compositor.cpp"
        ],
        "github_commit_url": "https://github.com/muldjord/skyscraper/commit/83d0820e58ba45242e71bd15ae1917991829b1a1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Compositor::applyShadow"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing the use of `bits` with `constBits` to avoid unnecessary data copying and improve efficiency.",
            "The optimization strategy involved replacing the use of `bits` with `constBits` to avoid unnecessary data copying and improve efficiency.",
            "The optimization strategy involved replacing the use of `bits()` with `constBits()` to avoid unnecessary deep copying of data, thereby improving efficiency.",
            "The optimization strategy involved replacing the use of `bits` with `constBits` to avoid unnecessary data copying and improve efficiency.",
            "The optimization strategy involved replacing the use of `bits` with `constBits` to avoid unnecessary data copying and improve efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing the use of `bits` with `constBits` to avoid unnecessary data copying and improve efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Server",
        "hash": "0534a2c6be2b00b5f564ffb001ed0e858ff9c237",
        "author": "Michael Cook (mackal)",
        "date": "2021-04-07T01:17:30-05:00",
        "message": "Switch scheduled hot zone check to search instead of split (#1313)\n\nUsing search_deliminated_string here is significantly faster than\r\nsplitting, most likely because of dynamic memory management\r\n\r\nSome tests on my system:\r\n\r\n----------------------------------------------------\r\nBenchmark             Time           CPU Iterations\r\n----------------------------------------------------\r\nbench_split         864 ns        864 ns     807922\r\nbench_search         35 ns         35 ns   20265205\r\n\r\nThis test was a case where the string was present somewhere in the\r\nmiddle which gave a ~96% speed up\r\n\r\n----------------------------------------------------\r\nBenchmark             Time           CPU Iterations\r\n----------------------------------------------------\r\nbench_split         936 ns        936 ns     725518\r\nbench_search         61 ns         61 ns   11156359\r\n\r\nThis test was when the string was not present, which will be the vast\r\nmajority of times this is actually checked, was ~93% speed up",
        "modified_files_count": 1,
        "modified_files": [
            "zone/zone_event_scheduler.cpp"
        ],
        "github_commit_url": "https://github.com/EQEmu/Server/commit/0534a2c6be2b00b5f564ffb001ed0e858ff9c237",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ZoneEventScheduler::Process"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a string-splitting operation with a search operation to reduce dynamic memory management overhead and improve performance.",
            "The optimization strategy replaced a string-splitting operation with a search-based approach to reduce dynamic memory management overhead and improve performance.",
            "The optimization strategy replaced a string-splitting operation with a search operation to reduce dynamic memory management overhead and improve performance.",
            "The optimization strategy replaced a string-splitting operation with a search-based approach to reduce dynamic memory management overhead and improve performance.",
            "The optimization strategy replaced a string-splitting operation with a search-based approach to reduce dynamic memory management overhead and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaced a string-splitting operation with a search-based approach to reduce dynamic memory management overhead and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "blender",
        "hash": "f09606cc68bd28abb8229d1e5c1ad6fe351cf4f7",
        "author": "Germano Cavalcante",
        "date": "2021-05-17T09:09:12-03:00",
        "message": "File List: micro optimization in the icon preview\n\nNo real functional changes.\n\nWhen `i` is zero, `filelist_cache_previews_push` was called twice with\nthe same icon.\n\nThis caused the preview to be computed twice when only once is needed.",
        "modified_files_count": 1,
        "modified_files": [
            "source/blender/editors/space_file/filelist.c"
        ],
        "github_commit_url": "https://github.com/blender/blender/commit/f09606cc68bd28abb8229d1e5c1ad6fe351cf4f7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "filelist_file_cache_block"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant calls to `filelist_cache_previews_push` by ensuring it is only invoked once when `i` is zero.",
            "The optimization avoids redundant calls to `filelist_cache_previews_push` by ensuring it is only invoked once when `i` is zero.",
            "The optimization avoids redundant calls to `filelist_cache_previews_push` by ensuring it is only invoked once when `i` is zero.",
            "The optimization avoids redundant calls to `filelist_cache_previews_push` by ensuring it is only invoked once when `i` is zero.",
            "The optimization avoids redundant calls to `filelist_cache_previews_push` by ensuring it is only called once when `i` is zero."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization avoids redundant calls to `filelist_cache_previews_push` by ensuring it is only invoked once when `i` is zero.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Marlin",
        "hash": "d7b6acc03d03796e34ab0d293cc8be88b4657fda",
        "author": "Mihai",
        "date": "2024-06-15T17:55:45-05:00",
        "message": "⚡️ Optimize LPC176x set_pwm_duty (#27178)",
        "modified_files_count": 1,
        "modified_files": [
            "Marlin/src/HAL/LPC1768/fast_pwm.cpp"
        ],
        "github_commit_url": "https://github.com/MarlinFirmware/Marlin/commit/d7b6acc03d03796e34ab0d293cc8be88b4657fda",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MarlinHAL::set_pwm_duty"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary register writes by checking the current state before updating PWM duty cycles.",
            "The optimization strategy involved reducing redundant calculations and improving the efficiency of setting PWM duty cycles by directly manipulating hardware registers.",
            "The optimization strategy involved replacing a division operation with a bitwise shift to improve the performance of setting PWM duty on LPC176x.",
            "The optimization strategy involved replacing a division operation with a bitwise shift to improve the performance of setting PWM duty on LPC176x.",
            "The optimization strategy involved replacing a division operation with a bitwise shift to improve the performance of setting PWM duty on LPC176x."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a division operation with a bitwise shift to improve the performance of setting PWM duty on LPC176x.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Pikafish",
        "hash": "3a2cd370802db61dc3060b81d613444363cf0371",
        "author": "Marco Costalba",
        "date": "2010-08-06T11:15:41+01:00",
        "message": "Faster perft\n\nSkip moves scoring and sorting: this more then\ndoubles the speed !\n\nVerified is correct.\n\nSigned-off-by: Marco Costalba <mcostalba@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/search.cpp"
        ],
        "github_commit_url": "https://github.com/official-pikafish/Pikafish/commit/3a2cd370802db61dc3060b81d613444363cf0371",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "perft"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips move scoring and sorting in the perft function to reduce computational overhead and significantly improve performance.",
            "The optimization strategy skips move scoring and sorting in the perft function to reduce computational overhead and significantly improve performance.",
            "The optimization strategy skips move scoring and sorting in the perft function to reduce computational overhead and significantly improve performance.",
            "The optimization strategy skips move scoring and sorting in the perft function to reduce computational overhead and significantly improve performance.",
            "The optimization strategy skips move scoring and sorting in the perft function to reduce computational overhead and significantly improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips move scoring and sorting in the perft function to reduce computational overhead and significantly improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "selinux-kernel",
        "hash": "98b7beba1ee6fb4ee755812e6c06cfc9084e7430",
        "author": "Hua Su",
        "date": "2024-10-28T12:16:06+02:00",
        "message": "memblock: uniformly initialize all reserved pages to MIGRATE_MOVABLE\n\nCurrently when CONFIG_DEFERRED_STRUCT_PAGE_INIT is not set, the reserved\npages are initialized to MIGRATE_MOVABLE by default in memmap_init.\n\nReserved memory mainly store the metadata of struct page. When\nHUGETLB_PAGE_OPTIMIZE_VMEMMAP_DEFAULT_ON=Y and hugepages are allocated,\nthe HVO will remap the vmemmap virtual address range to the page which\nvmemmap_reuse is mapped to. The pages previously mapping the range will\nbe freed to the buddy system.\n\nBefore this patch:\nwhen CONFIG_DEFERRED_STRUCT_PAGE_INIT is not set, the freed memory was\nplaced on the Movable list;\nWhen CONFIG_DEFERRED_STRUCT_PAGE_INIT=Y, the freed memory was placed on\nthe Unmovable list.\n\nAfter this patch, the freed memory is placed on the Movable list\nregardless of whether CONFIG_DEFERRED_STRUCT_PAGE_INIT is set.\n\nEg:\nTested on a virtual machine(1000GB):\nIntel(R) Xeon(R) Platinum 8358P CPU\n\nAfter vm start:\necho 500000 > /proc/sys/vm/nr_hugepages\ncat /proc/meminfo | grep -i huge\nHugePages_Total:   500000\nHugePages_Free:    500000\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       2048 kB\nHugetlb:        1024000000 kB\n\ncat /proc/pagetypeinfo\nbefore：\nFree pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10\n…\nNode    0, zone   Normal, type    Unmovable     51      2      1     28     53     35     35     43     40     69   3852\nNode    0, zone   Normal, type      Movable   6485   4610    666    202    200    185    208     87     54      2    240\nNode    0, zone   Normal, type  Reclaimable      2      2      1     23     13      1      2      1      0      1      0\nNode    0, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\nUnmovable ≈ 15GB\n\nafter：\nFree pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10\n…\nNode    0, zone   Normal, type    Unmovable      0      1      1      0      0      0      0      1      1      1      0\nNode    0, zone   Normal, type      Movable   1563   4107   1119    189    256    368    286    132    109      4   3841\nNode    0, zone   Normal, type  Reclaimable      2      2      1     23     13      1      2      1      0      1      0\nNode    0, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\n\nSigned-off-by: Hua Su <suhua.tanke@gmail.com>\nReviewed-by: Wei Yang <richard.weiyang@gmail.com>\nLink: https://lore.kernel.org/r/20241021051151.4664-1-suhua.tanke@gmail.com\nSigned-off-by: Mike Rapoport (Microsoft) <rppt@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/mm_init.c"
        ],
        "github_commit_url": "https://github.com/SELinuxProject/selinux-kernel/commit/98b7beba1ee6fb4ee755812e6c06cfc9084e7430",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "init_reserved_page"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization ensures that all reserved pages are consistently initialized to MIGRATE_MOVABLE, improving memory management efficiency by reducing fragmentation and ensuring uniform behavior regardless of configuration settings.",
            "The optimization ensures that all reserved pages are consistently initialized to MIGRATE_MOVABLE, improving memory management by reducing fragmentation and enhancing the efficiency of page allocation and deallocation.",
            "The optimization ensures that all reserved pages are consistently initialized to MIGRATE_MOVABLE, improving memory management by reducing fragmentation and enhancing the efficiency of page allocation and deallocation.",
            "The optimization ensures that all reserved pages are consistently initialized to MIGRATE_MOVABLE, improving memory management by reducing fragmentation and ensuring uniform behavior regardless of configuration settings.",
            "The optimization ensures that all reserved pages are consistently initialized to MIGRATE_MOVABLE, improving memory management by reducing fragmentation and enhancing the efficiency of freeing memory back to the buddy system."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures that all reserved pages are consistently initialized to MIGRATE_MOVABLE, improving memory management efficiency by reducing fragmentation and ensuring uniform behavior regardless of configuration settings.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "icu",
        "hash": "7130aeef991f52166a2102dc70016e67e6047765",
        "author": "Markus Scherer",
        "date": "2000-07-19T21:24:04+00:00",
        "message": "ICU-103 more performance in fromU() by goto _into_ the loop\n\nX-SVN-Rev: 1954",
        "modified_files_count": 1,
        "modified_files": [
            "icu4c/source/common/ucnvmbcs.c"
        ],
        "github_commit_url": "https://github.com/unicode-org/icu/commit/7130aeef991f52166a2102dc70016e67e6047765",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_MBCSFromUnicodeWithOffsets"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop logic in `_MBCSFromUnicodeWithOffsets` to use a `goto` statement to jump directly into the loop, reducing redundant computations and improving performance.",
            "The optimization strategy involved restructuring the loop logic in `_MBCSFromUnicodeWithOffsets` to use a `goto` statement to jump directly into the loop, reducing redundant computations and improving performance.",
            "The optimization strategy involves restructuring the loop logic to use a `goto` statement to jump directly into the loop, reducing redundant computations and improving performance in the `fromU()` function.",
            "The optimization strategy involves restructuring the loop logic to use a `goto` statement to jump directly into the loop, reducing redundant computations and improving performance.",
            "The optimization strategy involved restructuring the loop logic in `_MBCSFromUnicodeWithOffsets` to use a `goto` statement to jump directly into the loop, reducing redundant computations and improving performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop logic in `_MBCSFromUnicodeWithOffsets` to use a `goto` statement to jump directly into the loop, reducing redundant computations and improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenHD",
        "hash": "b675804f67c21feb9bdfa5c82546fb264c36f3ca",
        "author": "consti10",
        "date": "2022-12-11T07:19:35+01:00",
        "message": "optimization - do not send messages with target sys id == ground unit to the air unit or FC",
        "modified_files_count": 1,
        "modified_files": [
            "OpenHD/ohd_telemetry/src/mav_helper.h"
        ],
        "github_commit_url": "https://github.com/OpenHD/OpenHD/commit/b675804f67c21feb9bdfa5c82546fb264c36f3ca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "split_into_local_only_and_generic"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary message processing by filtering out messages with a specific target system ID before sending them to the air unit or flight controller.",
            "The optimization strategy avoids unnecessary message sending by filtering out messages with a specific target system ID before transmission.",
            "The optimization strategy avoids sending unnecessary messages to the air unit or flight controller by filtering out those with a target system ID matching the ground unit.",
            "The optimization strategy avoids unnecessary message processing by filtering out messages intended for the ground unit before they are sent to the air unit or flight controller.",
            "The optimization strategy avoids unnecessary message processing by filtering out messages with a specific target system ID before sending them to the air unit or flight controller."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary message processing by filtering out messages with a specific target system ID before sending them to the air unit or flight controller.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ensmallen",
        "hash": "5ab02a96b1f998440666e04c568ef66c21bec2e4",
        "author": "Ryan Curtin",
        "date": "2017-08-09T00:11:34-04:00",
        "message": "Significantly improve speed by tweaking optimization parameters.",
        "modified_files_count": 1,
        "modified_files": [
            "src/mlpack/tests/sa_test.cpp"
        ],
        "github_commit_url": "https://github.com/mlpack/ensmallen/commit/5ab02a96b1f998440666e04c568ef66c21bec2e4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BOOST_AUTO_TEST_CASE"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adjusting specific test parameters to reduce runtime without altering the core logic.",
            "The optimization strategy involved adjusting specific test parameters to reduce runtime without altering the core functionality of the test cases.",
            "The optimization strategy involved adjusting specific test parameters to reduce runtime without altering the core functionality of the test.",
            "The optimization strategy involved adjusting specific test parameters to reduce runtime without altering the core functionality of the test cases.",
            "The optimization strategy involved adjusting specific test parameters to reduce runtime without altering the core functionality of the test cases."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting specific test parameters to reduce runtime without altering the core functionality of the test cases.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gimp",
        "hash": "919ddce77389c1c4d69d26832bcbc9a6b2fa285e",
        "author": "Ell",
        "date": "2020-03-14T13:54:58+02:00",
        "message": "app: speed up layer-group preview rendering\n\nIn gimp_drawable_get_sub_preview_async(), when the drawable buffer\nhas a validate handler (i.e., when the drawable is a group layer),\nvalidate the requested area before calling gegl_buffer_get(), so\nthat the buffer is validated in a single step, instead of tile-by-\ntile.",
        "modified_files_count": 1,
        "modified_files": [
            "app/core/gimpdrawable-preview.c"
        ],
        "github_commit_url": "https://github.com/GNOME/gimp/commit/919ddce77389c1c4d69d26832bcbc9a6b2fa285e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gimp_drawable_get_sub_preview_async_func"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves validating the entire requested area of a drawable buffer in a single step instead of tile-by-tile to reduce overhead during layer-group preview rendering.",
            "The optimization strategy involves validating the entire requested area of a drawable buffer in a single step instead of tile-by-tile to reduce overhead during layer-group preview rendering.",
            "The optimization strategy involves validating the entire requested area of a drawable buffer in a single step instead of tile-by-tile to reduce overhead during layer-group preview rendering.",
            "The optimization strategy involves validating the entire requested area of a drawable buffer in a single step instead of tile-by-tile to reduce overhead during layer-group preview rendering.",
            "The optimization strategy involves validating the entire requested area of a drawable buffer in a single step instead of tile-by-tile to reduce overhead during layer-group preview rendering."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves validating the entire requested area of a drawable buffer in a single step instead of tile-by-tile to reduce overhead during layer-group preview rendering.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Monocypher",
        "hash": "c08d3c300b11adc9ac02d90e59c7306ea6c0bcd3",
        "author": "Loup Vaillant",
        "date": "2018-02-24T15:47:53+01:00",
        "message": "Strength reduction for Chacha20\n\nThe performance gain is tiny, but measurable.",
        "modified_files_count": 1,
        "modified_files": [
            "src/monocypher.c"
        ],
        "github_commit_url": "https://github.com/LoupVaillant/Monocypher/commit/c08d3c300b11adc9ac02d90e59c7306ea6c0bcd3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "crypto_chacha20_encrypt"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used strength reduction by replacing multiplication with bit shifts and additions in the Chacha20 encryption loop to reduce computational overhead.",
            "The optimization strategy used strength reduction by replacing multiplication with bit shifts and additions in the Chacha20 encryption function to improve performance.",
            "The optimization strategy used strength reduction by replacing multiplications with additions in the Chacha20 loop to reduce computational overhead.",
            "The optimization strategy used strength reduction by replacing multiplication with bit shifts and additions in the Chacha20 encryption loop to reduce computational overhead.",
            "The optimization strategy used strength reduction by replacing multiplication with bit shifts and additions in the Chacha20 encryption loop to reduce computational overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used strength reduction by replacing multiplication with bit shifts and additions in the Chacha20 encryption loop to reduce computational overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "tensorflow",
        "hash": "51a4843aff53901e1ee08b7623b59cf0dcf2a43a",
        "author": "A. Unique TensorFlower",
        "date": "2024-04-24T09:07:42-07:00",
        "message": "Allow for short-circuiting optimization in ShapeUtil::EqualStructure.\n\nNote that operator& doesn't do short-circuiting, unlike operator&&.\n\nPiperOrigin-RevId: 627745915",
        "modified_files_count": 1,
        "modified_files": [
            "third_party/xla/xla/shape_util.cc"
        ],
        "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/51a4843aff53901e1ee08b7623b59cf0dcf2a43a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ForEachSubshape"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces the non-short-circuiting operator& with the short-circuiting operator&& to improve performance by avoiding unnecessary evaluations.",
            "The optimization strategy replaces the non-short-circuiting operator& with the short-circuiting operator&& to improve performance by avoiding unnecessary evaluations.",
            "The optimization strategy replaces the non-short-circuiting operator& with the short-circuiting operator&& to improve performance by avoiding unnecessary evaluations.",
            "The optimization strategy involved replacing the non-short-circuiting operator& with the short-circuiting operator&& to improve efficiency in conditional evaluations.",
            "The optimization strategy replaces the non-short-circuiting operator& with the short-circuiting operator&& to improve performance by avoiding unnecessary evaluations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces the non-short-circuiting operator& with the short-circuiting operator&& to improve performance by avoiding unnecessary evaluations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cmssw",
        "hash": "3be47f265be2c269c3e2459bd6d806a19401783b",
        "author": "Nicola Minafra",
        "date": "2021-02-19T13:56:34+01:00",
        "message": "slightly more efficient",
        "modified_files_count": 1,
        "modified_files": [
            "RecoLocalCalo/EcalRecAlgos/src/EcalUncalibRecHitTimingCCAlgo.cc"
        ],
        "github_commit_url": "https://github.com/cms-sw/cmssw/commit/3be47f265be2c269c3e2459bd6d806a19401783b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "EcalUncalibRecHitTimingCCAlgo::interpolatePulse"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a linear interpolation calculation with a more efficient formula that reduces unnecessary computations.",
            "The optimization strategy involved replacing a linear interpolation calculation with a more efficient formula that reduces unnecessary computations.",
            "The optimization strategy involved replacing a linear search with a binary search to improve the efficiency of finding elements in a sorted collection.",
            "The optimization strategy involved replacing a linear interpolation calculation with a more efficient formula to reduce computational overhead.",
            "The optimization strategy involved replacing a linear search with a binary search to improve the efficiency of finding elements in a sorted collection."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a linear interpolation calculation with a more efficient formula that reduces unnecessary computations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "glsl-optimizer",
        "hash": "9a5d19d680323dfb9705c6c5ac10ac30d9ccc842",
        "author": "Eric Anholt",
        "date": "2014-04-11T13:38:52-07:00",
        "message": "i965: Skip a bunch of IB BO refcount twiddling.\n\nImproves cairo performance on glamor by 1.64828% +/- 1.04742% (n=65).\n\nReviewed-by: Ian Romanick <ian.d.romanick@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/mesa/drivers/dri/i965/brw_draw_upload.c"
        ],
        "github_commit_url": "https://github.com/aras-p/glsl-optimizer/commit/9a5d19d680323dfb9705c6c5ac10ac30d9ccc842",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "brw_upload_indices"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips unnecessary reference count adjustments for index buffer objects to reduce overhead.",
            "The optimization strategy skips unnecessary reference count adjustments for index buffer objects to reduce overhead.",
            "The optimization strategy skips unnecessary reference count adjustments for index buffer objects to reduce overhead.",
            "The optimization strategy skips unnecessary reference count adjustments for index buffer objects to reduce overhead.",
            "The optimization strategy skips unnecessary reference count adjustments for index buffer objects to reduce overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips unnecessary reference count adjustments for index buffer objects to reduce overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "5f59f407f59f69c248be2452e5923e6735e7019a",
        "author": "Wenlei He",
        "date": "2021-03-25T21:15:36-07:00",
        "message": "[CSSPGO] Minor tweak for inline candidate priority tie breaker\n\nWhen prioritize call site to consider for inlining in sample loader, use number of samples as a first tier breaker before using name/guid comparison. This would favor smaller functions when hotness is the same (from the same block). We could try to retrieve accurate function size if this turns out to be more important.\n\nDifferential Revision: https://reviews.llvm.org/D99370",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Transforms/IPO/SampleProfile.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/5f59f407f59f69c248be2452e5923e6735e7019a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "operator"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy prioritizes inlining decisions by using the number of samples as a tiebreaker before resorting to name/GUID comparison, favoring smaller functions when hotness is equal.",
            "The optimization strategy prioritizes inlining decisions by using the number of samples as a tiebreaker before resorting to name/guid comparison, favoring smaller functions when hotness is equal.",
            "The optimization strategy prioritizes inlining decisions by using the number of samples as a tiebreaker before falling back to name/GUID comparison, favoring smaller functions when hotness is equal.",
            "The optimization strategy prioritizes inlining decisions by using the number of samples as a tiebreaker before falling back to name/guid comparison, favoring smaller functions when hotness is equal.",
            "The optimization strategy prioritizes inlining decisions by using the number of samples as a tiebreaker before falling back to name/guid comparison, favoring smaller functions when hotness is equal."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy prioritizes inlining decisions by using the number of samples as a tiebreaker before falling back to name/GUID comparison, favoring smaller functions when hotness is equal.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mintty",
        "hash": "8c7cac42838bb4f0e9a4ab8345933445db36a7aa",
        "author": "mintty",
        "date": "2017-07-24T18:21:31+02:00",
        "message": "limit width checking to symbol ranges to avoid performance penalty (~#615)",
        "modified_files_count": 1,
        "modified_files": [
            "src/wintext.c"
        ],
        "github_commit_url": "https://github.com/mintty/mintty/commit/8c7cac42838bb4f0e9a4ab8345933445db36a7aa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "win_char_width"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy limits width checking to specific symbol ranges to reduce unnecessary computations and improve performance.",
            "The optimization strategy limits width checking to specific symbol ranges to reduce unnecessary computations.",
            "The optimization strategy limits width checking to specific symbol ranges to reduce unnecessary computations.",
            "The optimization strategy limits width checking to specific symbol ranges to reduce unnecessary computations.",
            "The optimization strategy limits width checking to specific symbol ranges to reduce unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy limits width checking to specific symbol ranges to reduce unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "857f50649cad125398774dca0f7a73ed3ffaf738",
        "author": "Matthias Clasen",
        "date": "2023-08-05T15:15:55+00:00",
        "message": "Merge branch 'microoptimize-label-wfh' into 'main'\n\nMicrooptimize GtkLabel width-for-height computation\n\nSee merge request GNOME/gtk!6219",
        "modified_files_count": 1,
        "modified_files": [
            "gtk/gtklabel.c"
        ],
        "github_commit_url": "https://github.com/GNOME/gtk/commit/857f50649cad125398774dca0f7a73ed3ffaf738",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "my_pango_layout_get_width_for_height"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "gtk",
        "optimization_summary": [
            "The optimization strategy involved refining the width-for-height computation in GtkLabel by improving the efficiency of layout calculations.",
            "The optimization strategy involved refining the width-for-height computation in GtkLabel by improving the efficiency of layout calculations.",
            "The optimization strategy involved refining the width-for-height computation in GtkLabel by improving the efficiency of layout calculations.",
            "The optimization strategy involved refining the width-for-height computation in GtkLabel by improving the efficiency of layout calculations.",
            "The optimization strategy involved refining the width-for-height computation in GtkLabel by improving the efficiency of Pango layout calculations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved refining the width-for-height computation in GtkLabel by improving the efficiency of layout calculations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "epsilon",
        "hash": "4f2daa7a4f9c7209476f9b51e66db4fb1ebc4ce7",
        "author": "Émilie Feral",
        "date": "2017-06-02T14:07:55+02:00",
        "message": "[apps/shared] Improve perf of values controller\n\nChange-Id: I22b0f81c59d06bb8fa58de7f8958a20e0bcf53b0",
        "modified_files_count": 1,
        "modified_files": [
            "apps/shared/values_controller.cpp"
        ],
        "github_commit_url": "https://github.com/numworks/epsilon/commit/4f2daa7a4f9c7209476f9b51e66db4fb1ebc4ce7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ValuesController::indexFromCumulatedWidth"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations in the `indexFromCumulatedWidth` function by caching or precomputing values to avoid redundant calculations.",
            "The optimization strategy involved reducing unnecessary computations in the `indexFromCumulatedWidth` function by caching or simplifying repeated calculations.",
            "The optimization strategy involved reducing unnecessary computations in the `indexFromCumulatedWidth` function by caching or precomputing values to avoid redundant calculations.",
            "The optimization strategy involved improving the performance of the `indexFromCumulatedWidth` function by reducing unnecessary computations or iterations within the loop.",
            "The optimization strategy involved reducing unnecessary computations in the `indexFromCumulatedWidth` function by caching or precomputing values to avoid redundant calculations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations in the `indexFromCumulatedWidth` function by caching or precomputing values to avoid redundant calculations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "468c648335b1724fcaa0c4f2a0247f77fe4f2977",
        "author": "Zhoujie Wu",
        "date": "2017-08-30T14:01:39+02:00",
        "message": "mmc: sdhci-xenon: ignore timing DDR52 in tuning\n\nEmmc DDR52 mode uses fixed delay, return earlier if\ntiming is MMC_TIMING_MMC_DDR52 in execute tuning function.\n\nSigned-off-by: Zhoujie Wu <zjwu@marvell.com>\nAcked-by: Adrian Hunter <adrian.hunter@intel.com>\nSigned-off-by: Ulf Hansson <ulf.hansson@linaro.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/mmc/host/sdhci-xenon.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/468c648335b1724fcaa0c4f2a0247f77fe4f2977",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "xenon_execute_tuning"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves early return in the tuning function to skip unnecessary processing for a specific timing mode (DDR52).",
            "The optimization strategy involves early return in the tuning function to skip unnecessary processing for a specific timing mode (DDR52).",
            "The optimization strategy involves early return in the tuning function to skip unnecessary processing for a specific timing mode (DDR52).",
            "The optimization strategy involves early return in the tuning function to skip unnecessary processing for a specific timing mode (DDR52).",
            "The optimization strategy involves early return in the tuning function to skip unnecessary processing for a specific timing mode (DDR52)."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves early return in the tuning function to skip unnecessary processing for a specific timing mode (DDR52).",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cheribsd",
        "hash": "befafed5757fe80dd2a2e3cc3739e14a0cd11e29",
        "author": "alc",
        "date": "2018-06-09T03:38:34+01:00",
        "message": "Micro-optimize the handling of fictitious pages in vm_page_free_prep().\nA fictitious page is always wired, so there is no point in trying to\nremove one from the page queues.\n\nCompletely remove one inaccurate comment from vm_page_free_prep() and\ncorrect another.\n\nReviewed by:\tkib, markj\nMFC after:\t1 week",
        "modified_files_count": 1,
        "modified_files": [
            "sys/vm/vm_page.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/befafed5757fe80dd2a2e3cc3739e14a0cd11e29",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vm_page_free_prep"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes unnecessary operations on fictitious pages by leveraging their always-wired property, avoiding redundant queue manipulations.",
            "The optimization removes unnecessary operations on fictitious pages by leveraging their always-wired property, avoiding redundant queue manipulations.",
            "The optimization removes unnecessary operations on fictitious pages by leveraging their always-wired property, avoiding redundant queue manipulations.",
            "The optimization removes unnecessary operations on fictitious pages by leveraging their always-wired property, avoiding redundant queue manipulations.",
            "The optimization removes unnecessary operations on fictitious pages by leveraging their always-wired property, avoiding redundant queue manipulations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes unnecessary operations on fictitious pages by leveraging their always-wired property, avoiding redundant queue manipulations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "76f631cb401fbfb5993c6958a8032db4f87881cb",
        "author": "Ching-Te Ku",
        "date": "2020-12-02T21:23:54+02:00",
        "message": "rtw88: coex: update the mechanism for A2DP + PAN\n\nUpdate A2DP+PAN+WL mechanism for CPT(Coexistence Performance Test) to\nenhance WL/BT performance at the environment that some specific AP are\nexisting.\n\nSigned-off-by: Ching-Te Ku <ku920601@realtek.com>\nSigned-off-by: Ping-Ke Shih <pkshih@realtek.com>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>\nLink: https://lore.kernel.org/r/20201126021059.11981-4-pkshih@realtek.com",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/wireless/realtek/rtw88/coex.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/76f631cb401fbfb5993c6958a8032db4f87881cb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rtw_coex_action_bt_a2dp_pan"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit optimizes the coexistence mechanism for A2DP and PAN to improve wireless and Bluetooth performance in specific environments with certain access points.",
            "The optimization strategy updated the coexistence mechanism for A2DP+PAN+WL to improve wireless and Bluetooth performance in specific environments with certain access points.",
            "The commit optimizes the coexistence mechanism for A2DP and PAN to improve wireless and Bluetooth performance in specific environments.",
            "The commit optimizes the coexistence mechanism for A2DP and PAN to improve wireless and Bluetooth performance in specific environments.",
            "The commit optimizes the coexistence mechanism for A2DP and PAN to improve wireless and Bluetooth performance in specific environments."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit optimizes the coexistence mechanism for A2DP and PAN to improve wireless and Bluetooth performance in specific environments.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "petsc",
        "hash": "4e12e03c5b4272c875e968fdebc36a6b875e439b",
        "author": "Hong Zhang",
        "date": "2019-05-15T14:18:51+00:00",
        "message": "Merged in hzhang/opt-mattranspose_seqbaij (pull request #1667)\n\noptimize MatTranspose_SeqBAIJ()\n\nApproved-by: BarryFSmith <bsmith@mcs.anl.gov>",
        "modified_files_count": 1,
        "modified_files": [
            "src/mat/impls/baij/seq/baij.c"
        ],
        "github_commit_url": "https://github.com/petsc/petsc/commit/4e12e03c5b4272c875e968fdebc36a6b875e439b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MatTranspose_SeqBAIJ"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the matrix transposition logic to reduce redundant computations and improve cache locality.",
            "The optimization strategy involved restructuring the matrix transposition logic to reduce redundant computations and improve cache locality.",
            "The optimization strategy involved restructuring the matrix transposition logic to reduce redundant computations and improve cache locality.",
            "The optimization strategy involved restructuring the matrix transposition logic to reduce redundant computations and improve cache locality.",
            "The optimization strategy involved restructuring the matrix transposition logic to reduce redundant computations and improve cache locality."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the matrix transposition logic to reduce redundant computations and improve cache locality.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "openmm",
        "hash": "54c9ceb902a202d919cb19005813218f3f4e9bf1",
        "author": "Peter Eastman",
        "date": "2021-10-08T08:54:27-07:00",
        "message": "Further optimization to updating long range correction (#3275)\n\n* Further optimization to updating long range correction\r\n\r\n* Bug fix",
        "modified_files_count": 1,
        "modified_files": [
            "platforms/common/src/CommonKernels.cpp"
        ],
        "github_commit_url": "https://github.com/openmm/openmm/commit/54c9ceb902a202d919cb19005813218f3f4e9bf1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CommonCalcCustomNonbondedForceKernel::execute"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the computation of long-range corrections to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of long-range corrections to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of long-range corrections to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of long-range corrections to reduce redundant calculations and improve efficiency.",
            "The optimization strategy involved restructuring the computation of long-range corrections to reduce redundant calculations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the computation of long-range corrections to reduce redundant calculations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ispc",
        "hash": "b9d6ba2aa042286f87ab02efae944a54e9ef95c3",
        "author": "Matt Pharr",
        "date": "2012-04-17T15:10:30-07:00",
        "message": "Always set target info, even when compiling to generic targets.\n\nThis allows the SROA pass eliminate a lot of allocas and loads and\nstores, which helps a lot for performance.",
        "modified_files_count": 1,
        "modified_files": [
            "opt.cpp"
        ],
        "github_commit_url": "https://github.com/ispc/ispc/commit/b9d6ba2aa042286f87ab02efae944a54e9ef95c3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Optimize"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves setting target info consistently to enable the SROA pass to eliminate unnecessary allocas, loads, and stores, improving performance.",
            "The optimization strategy involves ensuring target information is always set to enable the SROA pass to eliminate unnecessary allocas, loads, and stores, improving performance.",
            "The optimization strategy involves setting target info consistently to enable the SROA pass to eliminate unnecessary allocas, loads, and stores, improving performance.",
            "The optimization strategy involves setting target info consistently to enable the SROA pass to eliminate unnecessary allocas, loads, and stores, improving performance.",
            "The optimization strategy involves ensuring target information is always set to enable the SROA pass to eliminate unnecessary allocas, loads, and stores, improving performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves setting target info consistently to enable the SROA pass to eliminate unnecessary allocas, loads, and stores, improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "redot-engine",
        "hash": "d5daaa72fa94a6d7e122b6e1618dad90fe1d1065",
        "author": "Rémi Verschelde",
        "date": "2018-02-19T21:53:59+01:00",
        "message": "Merge pull request #15306 from poke1024/item-list-draw-speed\n\nBoost drawing speed of ItemLists with many items",
        "modified_files_count": 1,
        "modified_files": [
            "scene/gui/item_list.cpp"
        ],
        "github_commit_url": "https://github.com/Redot-Engine/redot-engine/commit/d5daaa72fa94a6d7e122b6e1618dad90fe1d1065",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ItemList::_notification"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant drawing operations in the ItemList by skipping unnecessary updates when items are not visible.",
            "The optimization strategy involved reducing redundant drawing operations in the `_notification` function to improve rendering performance for ItemLists with many items.",
            "The optimization strategy involved reducing redundant drawing operations in the ItemList by skipping unnecessary iterations and minimizing per-item processing.",
            "The optimization strategy involved reducing redundant drawing operations in the ItemList by skipping unnecessary iterations and minimizing overhead in the rendering loop.",
            "The optimization strategy involved reducing redundant drawing operations in the ItemList by skipping unnecessary render calls for items that are not visible or do not require updates."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant drawing operations in the ItemList by skipping unnecessary render calls for items that are not visible or do not require updates.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "librdkafka",
        "hash": "25f8c7889211d193325e7df688bff3f8c54d9000",
        "author": "Magnus Edenhill",
        "date": "2017-11-24T08:41:34+01:00",
        "message": "test 0050: decrease msg count, increase msg size, to speed up test.",
        "modified_files_count": 1,
        "modified_files": [
            "tests/0050-subscribe_adds.c"
        ],
        "github_commit_url": "https://github.com/confluentinc/librdkafka/commit/25f8c7889211d193325e7df688bff3f8c54d9000",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main_0050_subscribe_adds"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of messages and increasing their size to decrease processing overhead and speed up the test execution.",
            "The optimization strategy involved reducing the number of messages and increasing their size to decrease processing overhead and speed up the test execution.",
            "The optimization strategy involved reducing the number of messages and increasing their size to decrease processing overhead and speed up the test execution.",
            "The optimization strategy involved reducing the number of messages and increasing their size to decrease processing overhead and speed up the test execution.",
            "The optimization strategy involved reducing the number of messages and increasing their size to decrease processing overhead and speed up the test execution."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of messages and increasing their size to decrease processing overhead and speed up the test execution.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "theseus-ship",
        "hash": "f7d7c246b8b76cbd4440b9c1665f0ccaa57e9880",
        "author": "Martin Gräßlin",
        "date": "2015-01-16T12:28:44+01:00",
        "message": "Slightly optimize Workspace::xStackingOrder\n\nCallgrind analysis showed that this method has room for improvement.\nThe bottle neck is mapping the Unmanaged against the list of windows\nretreived from xcb_query_tree. The number of windows in that list is\nrather large (>1000), which turns the loop into an expensive path.\nWorkspace::findUnmanaged seems to be too expensive for that due to the\noverhead of using a functor and multiple method calls. The Inl. cost\nbefore the optimization for checking ~55,000 windows is 2.46.\n\nThe change uses a good old const-iterator based loop over the unmanaged\nlist to check for the window. This reduces the Incl. cost for checking\n~55,000 windows to 0.28.\n\nREVIEW: 122067",
        "modified_files_count": 1,
        "modified_files": [
            "layers.cpp"
        ],
        "github_commit_url": "https://github.com/winft/theseus-ship/commit/f7d7c246b8b76cbd4440b9c1665f0ccaa57e9880",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Workspace::xStackingOrder"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a functor-based search with a const-iterator loop to reduce overhead and improve performance in checking a large list of windows.",
            "The optimization strategy replaced a functor-based search with a const-iterator loop to reduce overhead and improve performance in checking a large list of windows.",
            "The optimization strategy replaced a functor-based search with a const-iterator loop to reduce overhead when checking for windows in a large list.",
            "The optimization strategy replaced a functor-based search with a const-iterator loop to reduce overhead and improve performance in checking a large list of windows.",
            "The optimization strategy replaced a functor-based search with a const-iterator loop to reduce overhead and improve performance in checking a large list of windows."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaced a functor-based search with a const-iterator loop to reduce overhead and improve performance in checking a large list of windows.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sycl",
        "hash": "c459b5178c2a6c189713c686aba3068f79eea0d8",
        "author": "Douglas Gregor",
        "date": "2012-08-17T22:17:36+00:00",
        "message": "When code completion is enabled, don't do any work in\nSema::ActOnEndOfTranslationUnit(). This is a (minor) optimization.\n\nllvm-svn: 162144",
        "modified_files_count": 1,
        "modified_files": [
            "clang/lib/Sema/Sema.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/c459b5178c2a6c189713c686aba3068f79eea0d8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Sema::ActOnEndOfTranslationUnit"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary work in Sema::ActOnEndOfTranslationUnit() when code completion is enabled by skipping the function's execution.",
            "The optimization avoids unnecessary work in the `Sema::ActOnEndOfTranslationUnit` function when code completion is enabled by skipping its execution.",
            "The optimization avoids unnecessary work in the `Sema::ActOnEndOfTranslationUnit` function when code completion is enabled by skipping its execution.",
            "The optimization avoids unnecessary work in Sema::ActOnEndOfTranslationUnit() when code completion is enabled by skipping the function's execution.",
            "The optimization avoids unnecessary work in Sema::ActOnEndOfTranslationUnit() when code completion is enabled by skipping the function's execution."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary work in Sema::ActOnEndOfTranslationUnit() when code completion is enabled by skipping the function's execution.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MonetDB",
        "hash": "b9067e90b22f978df1fde6d3aacbe9773f66ab48",
        "author": "Martin Kersten",
        "date": "2015-09-15T21:01:07+02:00",
        "message": "Improve using pre-scan\nThis optimizer is hardly ever needed to rewrite the plan.\nA simple pre-test avoids lots of costs.",
        "modified_files_count": 1,
        "modified_files": [
            "monetdb5/optimizer/opt_generator.c"
        ],
        "github_commit_url": "https://github.com/MonetDB/MonetDB/commit/b9067e90b22f978df1fde6d3aacbe9773f66ab48",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OPTgeneratorImplementation"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding a pre-scan test to avoid unnecessary plan rewrites, thereby reducing computational costs.",
            "The optimization strategy involves adding a pre-scan test to avoid unnecessary plan rewrites, thereby reducing computational costs.",
            "The optimization strategy involves adding a pre-scan test to avoid unnecessary plan rewrites, thereby reducing computational costs.",
            "The optimization strategy involves adding a pre-test to avoid unnecessary plan rewrites, reducing computational costs.",
            "The optimization strategy involves adding a pre-test to avoid unnecessary plan rewrites, thereby reducing computational costs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding a pre-scan test to avoid unnecessary plan rewrites, thereby reducing computational costs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "WLED",
        "hash": "934176818f32ffa0ffe359192dbf7d769c3e740f",
        "author": "Damian Schneider",
        "date": "2024-09-12T06:43:20+02:00",
        "message": "more improvements to color_scale() now even faster.\n\ntested and working, also tested video",
        "modified_files_count": 1,
        "modified_files": [
            "wled00/colors.cpp"
        ],
        "github_commit_url": "https://github.com/Aircoookie/WLED/commit/934176818f32ffa0ffe359192dbf7d769c3e740f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "color_fade"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of the `color_scale()` function by likely reducing computational overhead or improving algorithmic complexity.",
            "The optimization strategy involved improving the efficiency of the `color_scale()` function by likely reducing computational overhead or improving algorithmic complexity.",
            "The optimization strategy involved improving the efficiency of the `color_scale()` function by likely reducing computational overhead or improving algorithmic complexity.",
            "The optimization strategy involved improving the efficiency of the `color_scale()` function by likely reducing computational overhead or improving algorithmic complexity.",
            "The optimization strategy involved improving the efficiency of the `color_scale()` function by likely reducing unnecessary computations or iterations within the color manipulation logic."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of the `color_scale()` function by likely reducing computational overhead or improving algorithmic complexity.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MyScaleDB",
        "hash": "5d19150906430531963f5e95346db3795eb499fd",
        "author": "avogar",
        "date": "2022-05-20T10:47:28+00:00",
        "message": "Try to improve short circuit functions processing",
        "modified_files_count": 1,
        "modified_files": [
            "src/Interpreters/ExpressionActions.cpp"
        ],
        "github_commit_url": "https://github.com/myscale/MyScaleDB/commit/5d19150906430531963f5e95346db3795eb499fd",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the evaluation of short-circuit functions to minimize unnecessary computations by avoiding redundant processing.",
            "The optimization strategy involved restructuring the evaluation of short-circuit functions to minimize unnecessary computations by exiting early when a condition is met.",
            "The optimization strategy involved restructuring the evaluation of short-circuit functions to minimize unnecessary computations by exiting early when a result is determined.",
            "The optimization strategy involved restructuring the evaluation of short-circuit functions to minimize unnecessary computations by avoiding redundant processing.",
            "The optimization strategy involved restructuring the evaluation of short-circuit functions to minimize unnecessary computations by leveraging early exits."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the evaluation of short-circuit functions to minimize unnecessary computations by exiting early when a result is determined.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "orx",
        "hash": "fa2c15128485f4d7207b9b8827d147573061738a",
        "author": "iarwain",
        "date": "2020-02-23T00:16:23-05:00",
        "message": "- Minor optimization in orxConfig_IsInheritedValue()",
        "modified_files_count": 1,
        "modified_files": [
            "code/src/core/orxConfig.c"
        ],
        "github_commit_url": "https://github.com/orx/orx/commit/fa2c15128485f4d7207b9b8827d147573061738a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "orxConfig_IsInheritedValue"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the logic in orxConfig_IsInheritedValue() by reducing unnecessary checks and improving early exit conditions to minimize redundant computations.",
            "The optimization strategy involved simplifying the logic in orxConfig_IsInheritedValue() to reduce unnecessary computations and improve performance by directly returning results based on conditional checks.",
            "The optimization strategy involved simplifying the logic in orxConfig_IsInheritedValue() to reduce unnecessary computations by directly returning results based on conditional checks.",
            "The optimization strategy involved simplifying the logic in orxConfig_IsInheritedValue() to reduce unnecessary computations and improve performance by directly returning results based on conditional checks.",
            "The optimization strategy involved simplifying the logic in orxConfig_IsInheritedValue() by reducing unnecessary checks and improving early exit conditions to enhance performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the logic in orxConfig_IsInheritedValue() to reduce unnecessary computations and improve performance by directly returning results based on conditional checks.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "bind9",
        "hash": "ddad2050928e29e8175d1a79431ec15b476da727",
        "author": "Ondřej Surý",
        "date": "2022-07-11T12:26:15+02:00",
        "message": "Don't compress in the rrset if compression was disabled\n\nCurrently, when rrset is being compressed, the optimization has been put\nin place to reuse offset to the previous name in the same rrset.  This\nskips the check for non-improving compression and thus compresses the\nroot zone making the wireformat worse by one byte.\n\nAdditionally, when the compression has been disabled for the name, it\nwould be repeatedly added to the compression table because we act as if\nthe name was not found and the dns_compress_add() doesn't check for the\nexisting entry.\n\nChange the dns_name_towire2() to always lookup the name in the\ncompression table to prevent adding duplicates, but don't use it neither\nin the wireformat nor in the rrset cache.",
        "modified_files_count": 1,
        "modified_files": [
            "lib/dns/name.c"
        ],
        "github_commit_url": "https://github.com/isc-projects/bind9/commit/ddad2050928e29e8175d1a79431ec15b476da727",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dns_name_towire2"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant additions to the compression table and prevents unnecessary compression by always looking up names in the compression table while respecting disabled compression settings.",
            "The optimization avoids redundant additions to the compression table and prevents unnecessary compression in the wireformat when compression is disabled.",
            "The optimization avoids redundant additions to the compression table and prevents unnecessary compression by always looking up names in the compression table while respecting disabled compression settings.",
            "The optimization avoids redundant additions to the compression table and prevents unnecessary compression when disabled by always looking up names in the compression table but not using them in the wireformat or rrset cache.",
            "The optimization avoids redundant additions to the compression table and prevents unnecessary compression by always looking up names in the compression table while respecting disabled compression settings."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids redundant additions to the compression table and prevents unnecessary compression by always looking up names in the compression table while respecting disabled compression settings.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SoundPusher",
        "hash": "2004612332a571936d2a469a4297aaa28cdaf531",
        "author": "Daniel Vollmer",
        "date": "2015-12-30T16:49:27+01:00",
        "message": "Reduce buffer (cycle) size for forwarding\n\nThe default buffer size that CoreAudio chooses (barring other\nconsiderations such as device restrictions etc.) is 512 frames.\n\nThis means that in the worst case, the delay before an input signal\narrives at the output IOProc is that many frames (and about half as\nmuch on average). By explicitly requesting a smaller size (128), we\nreduce the average latency for that part of processing from ~256\nto ~64 frames (about 0.004s at 48kHz).",
        "modified_files_count": 1,
        "modified_files": [
            "SoundPusher/ForwardingInputTap.cpp"
        ],
        "github_commit_url": "https://github.com/q-p/SoundPusher/commit/2004612332a571936d2a469a4297aaa28cdaf531",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces latency by explicitly requesting a smaller buffer size for audio processing.",
            "The optimization strategy reduces latency by explicitly setting a smaller buffer size for audio processing.",
            "The optimization strategy reduces latency by explicitly requesting a smaller buffer size for audio processing.",
            "The optimization reduces latency by explicitly setting a smaller buffer size for audio processing.",
            "The optimization reduces latency by explicitly requesting a smaller buffer size for audio processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces latency by explicitly requesting a smaller buffer size for audio processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "scarab-osd",
        "hash": "3061a2776e3265e10d87c0416bd1c9da1f3bc16a",
        "author": "jflyper",
        "date": "2016-09-04T03:23:13+09:00",
        "message": "ISR switch-case re-order for faster case selection\n\nRe-ordered the cases in the ISR so that important cases are\nselected/executed faster.\n\nStill taking 9usec to respond to read addressing, and another 12.53usec\nfor RXLVL read.\n\nThis has lots to do with gcc’s code generation. Should compare with\n“forced-table-jump” approach.",
        "modified_files_count": 1,
        "modified_files": [
            "MW_OSD/twislave.c"
        ],
        "github_commit_url": "https://github.com/ShikOfTheRa/scarab-osd/commit/3061a2776e3265e10d87c0416bd1c9da1f3bc16a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ISR"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reorders switch-case statements in an ISR to prioritize frequently or critically executed cases for faster access.",
            "The optimization strategy reorders switch-case statements in an ISR to prioritize faster execution of important cases based on their likelihood of occurrence.",
            "The optimization strategy reorders switch-case statements in an ISR to prioritize faster execution of important cases based on their likelihood of occurrence.",
            "The optimization strategy reorders switch-case statements in an ISR to prioritize faster execution of important cases based on their likelihood of occurrence.",
            "The optimization strategy reorders switch-case statements in an ISR to prioritize faster execution of important cases based on their likelihood of occurrence."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reorders switch-case statements in an ISR to prioritize faster execution of important cases based on their likelihood of occurrence.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libmtev",
        "hash": "9596a29d0bdcce6fc1c6e1a710679035c957e9b0",
        "author": "Theo Schlossnagle",
        "date": "2014-06-09T00:10:09+00:00",
        "message": "Optimize: avoid PCRE compiles when hash tables are present.\n\nSince a rule hash table can override a pcre, don't bother compiling\npcres if a hash is present.",
        "modified_files_count": 1,
        "modified_files": [
            "src/noit_filters.c"
        ],
        "github_commit_url": "https://github.com/circonus-labs/libmtev/commit/9596a29d0bdcce6fc1c6e1a710679035c957e9b0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "noit_filter_compile_add"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary PCRE compilations by checking for the presence of a hash table that can override the PCRE.",
            "The optimization avoids unnecessary PCRE compilations by checking for the presence of a hash table that can override the PCRE.",
            "The optimization avoids unnecessary PCRE compilations by checking for the presence of a hash table that can override the PCRE.",
            "The optimization avoids unnecessary PCRE compilations by checking for the presence of a hash table that can override the PCRE.",
            "The optimization avoids unnecessary PCRE compilations by checking for the presence of a hash table that can override the PCRE."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary PCRE compilations by checking for the presence of a hash table that can override the PCRE.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "d921b9cf91e1f84a39f4beab5c824b9c8ad87c0c",
        "author": "Filipe Manana",
        "date": "2023-02-13T17:50:35+01:00",
        "message": "btrfs: send: avoid duplicated orphan dir allocation and initialization\n\nAt can_rmdir() we are allocating and initializing an orphan dir object\ntwice. This can be deduplicated outside of the loop that iterates over\nthe dir index keys. So deduplicate that code, even because other patch\nin the series will need to add more initialization code and another one\nwill add one more condition.\n\nThis patch is part of a larger patchset and the changelog of the last\npatch in the series contains a sample performance test and results.\nThe patches that comprise the patchset are the following:\n\n  btrfs: send: directly return from did_overwrite_ref() and simplify it\n  btrfs: send: avoid unnecessary generation search at did_overwrite_ref()\n  btrfs: send: directly return from will_overwrite_ref() and simplify it\n  btrfs: send: avoid extra b+tree searches when checking reference overrides\n  btrfs: send: remove send_progress argument from can_rmdir()\n  btrfs: send: avoid duplicated orphan dir allocation and initialization\n  btrfs: send: avoid unnecessary orphan dir rbtree search at can_rmdir()\n  btrfs: send: reduce searches on parent root when checking if dir can be removed\n  btrfs: send: iterate waiting dir move rbtree only once when processing refs\n  btrfs: send: initialize all the red black trees earlier\n  btrfs: send: genericize the backref cache to allow it to be reused\n  btrfs: adapt lru cache to allow for 64 bits keys on 32 bits systems\n  btrfs: send: cache information about created directories\n  btrfs: allow a generation number to be associated with lru cache entries\n  btrfs: add an api to delete a specific entry from the lru cache\n  btrfs: send: use the lru cache to implement the name cache\n  btrfs: send: update size of roots array for backref cache entries\n  btrfs: send: cache utimes operations for directories if possible\n\nSigned-off-by: Filipe Manana <fdmanana@suse.com>\nReviewed-by: David Sterba <dsterba@suse.com>\nSigned-off-by: David Sterba <dsterba@suse.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fs/btrfs/send.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/d921b9cf91e1f84a39f4beab5c824b9c8ad87c0c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "can_rmdir"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization deduplicates the allocation and initialization of an orphan directory object to avoid redundant operations within a loop.",
            "The optimization strategy deduplicates the allocation and initialization of an orphan directory object to avoid redundant operations within a loop.",
            "The optimization strategy deduplicates the allocation and initialization of an orphan directory object to avoid redundant operations within a loop.",
            "The optimization deduplicates the allocation and initialization of an orphan directory object outside of a loop to avoid redundant operations.",
            "The optimization deduplicates the allocation and initialization of an orphan directory object to avoid redundant operations within a loop."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization deduplicates the allocation and initialization of an orphan directory object to avoid redundant operations within a loop.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "x0",
        "hash": "311bbb48fa0bd5a189c7698910ebcc3874b81017",
        "author": "Christian Parpart",
        "date": "2014-03-04T23:26:48+01:00",
        "message": "x0d: honor optimization level var",
        "modified_files_count": 1,
        "modified_files": [
            "x0d/src/XzeroDaemon.cpp"
        ],
        "github_commit_url": "https://github.com/christianparpart/x0/commit/311bbb48fa0bd5a189c7698910ebcc3874b81017",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "XzeroDaemon::setup"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit optimizes performance by respecting the optimization level variable to enable compiler-driven optimizations.",
            "The optimization strategy involved honoring an optimization level variable to potentially enable compiler-level optimizations.",
            "The commit optimizes performance by ensuring the optimization level variable is respected during setup, potentially enabling compiler-level optimizations.",
            "The optimization strategy involved honoring an optimization level variable to potentially enable compiler-level optimizations.",
            "The optimization strategy involved honoring an optimization level variable to potentially enable compiler-level optimizations during the setup phase."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved honoring an optimization level variable to potentially enable compiler-level optimizations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "blender",
        "hash": "b168c255aae848f730a12b9cb16e88681a0c6809",
        "author": "Clément Foucault",
        "date": "2020-06-04T21:28:19+02:00",
        "message": "GPUTexture: Make GPU_texture_unbind_all faster on newer opengl version",
        "modified_files_count": 1,
        "modified_files": [
            "source/blender/gpu/intern/gpu_texture.c"
        ],
        "github_commit_url": "https://github.com/blender/blender/commit/b168c255aae848f730a12b9cb16e88681a0c6809",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GPU_texture_unbind_all"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is leveraging newer OpenGL versions to reduce the overhead of unbinding all textures by minimizing redundant calls or operations.",
            "The optimization strategy used is leveraging newer OpenGL versions to reduce the overhead of unbinding all textures by minimizing redundant operations.",
            "The optimization strategy involved reducing the number of texture unbind operations by leveraging newer OpenGL versions' capabilities to unbind multiple textures at once.",
            "The optimization strategy used is leveraging newer OpenGL versions to reduce the overhead of unbinding all textures by minimizing redundant state changes.",
            "The optimization strategy used conditional compilation to leverage newer OpenGL features, reducing the number of unbind operations for better performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is leveraging newer OpenGL versions to reduce the overhead of unbinding all textures by minimizing redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "odp",
        "hash": "5ed89eb5eefd985087051e044c5c16980fdd8e5f",
        "author": "Petri Savolainen",
        "date": "2016-08-16T16:05:38+03:00",
        "message": "linux-gen: sched: keep scheduling over empty queues\n\nEmpty queues are kept in scheduler priority queues for\nperformance reasons. The scheduler moved to the next priority\nqueue after seeing an empty queue, which resulted sometimes\nscheduler to return zero events, although there were events\navailable deeper in the priority queue.\n\nThis patch keeps scheduler scheduling a priority queue until an\nevent is found or the queue is empty (over empty or destroyed\nqueues).\n\nThis fixes bug https://bugs.linaro.org/show_bug.cgi?id=2457\n\nSigned-off-by: Petri Savolainen <petri.savolainen@nokia.com>\nTested-by: Brian Brooks <brian.brooks@linaro.org>\nSigned-off-by: Maxim Uvarov <maxim.uvarov@linaro.org>",
        "modified_files_count": 1,
        "modified_files": [
            "platform/linux-generic/odp_schedule.c"
        ],
        "github_commit_url": "https://github.com/OpenDataPlane/odp/commit/5ed89eb5eefd985087051e044c5c16980fdd8e5f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "do_schedule"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids prematurely moving to the next priority queue by continuing to schedule over empty or destroyed queues until an event is found or the queue is confirmed empty.",
            "The optimization strategy avoids prematurely moving to the next priority queue by continuing to schedule over empty or destroyed queues until an event is found or the queue is confirmed empty.",
            "The optimization strategy avoids prematurely moving to the next priority queue by continuing to schedule over empty or destroyed queues until an event is found or the queue is confirmed empty.",
            "The optimization strategy avoids prematurely moving to the next priority queue by continuing to schedule over empty or destroyed queues until an event is found or the queue is confirmed empty.",
            "The optimization strategy avoids prematurely moving to the next priority queue by continuing to schedule over empty or destroyed queues until an event is found or the queue is confirmed empty."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids prematurely moving to the next priority queue by continuing to schedule over empty or destroyed queues until an event is found or the queue is confirmed empty.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mace",
        "hash": "ae7766cdace8174aac5741e13a8b2cdaf208575d",
        "author": "虞连飞",
        "date": "2018-11-27T11:47:41+08:00",
        "message": "optimize eltwise computing order",
        "modified_files_count": 1,
        "modified_files": [
            "mace/ops/eltwise.cc"
        ],
        "github_commit_url": "https://github.com/XiaoMi/mace/commit/ae7766cdace8174aac5741e13a8b2cdaf208575d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DoEltwise"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reordering the computation sequence in the element-wise operations to improve cache locality and reduce redundant calculations.",
            "The optimization strategy involved reordering the computation sequence in the element-wise operations to improve cache locality and reduce memory access overhead.",
            "The optimization strategy involved reordering the computation sequence in the element-wise operations to improve cache locality and reduce memory access overhead.",
            "The optimization strategy involved reordering the computation sequence in the element-wise operations to improve cache locality and reduce redundant calculations.",
            "The optimization strategy involved reordering the computation sequence in the element-wise operations to improve cache locality and reduce memory access overhead."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reordering the computation sequence in the element-wise operations to improve cache locality and reduce memory access overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qulacs",
        "hash": "97a86940cc81c458094214f21ee9949291a0e25c",
        "author": "KowerKoint",
        "date": "2023-06-21T12:42:43+09:00",
        "message": "Merge pull request #565 from qulacs/fastalize-parametriccircuit-copy\n\nremove std::find(), precalc where parametric gates exist",
        "modified_files_count": 1,
        "modified_files": [
            "src/vqcsim/parametric_circuit.cpp"
        ],
        "github_commit_url": "https://github.com/qulacs/qulacs/commit/97a86940cc81c458094214f21ee9949291a0e25c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ParametricQuantumCircuit::copy"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing `std::find()` with precomputed indices to reduce the overhead of repeated searches for parametric gates.",
            "The optimization strategy involved replacing `std::find()` with a precomputed lookup to reduce the computational overhead of repeatedly searching for parametric gates.",
            "The optimization strategy involved replacing `std::find()` with precomputed indices to reduce the overhead of repeated searches for parametric gates.",
            "The optimization strategy involved replacing `std::find()` with precomputed indices to reduce the overhead of repeated searches for parametric gates.",
            "The optimization strategy involved replacing `std::find()` with precomputed indices to reduce the computational overhead of repeatedly searching for parametric gates."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing `std::find()` with precomputed indices to reduce the overhead of repeated searches for parametric gates.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "mantid",
        "hash": "620b3fa197e899e8ccc8c8dfd3993ad0518a7841",
        "author": "Chen Zhang",
        "date": "2021-11-22T11:03:22-05:00",
        "message": "optimize for speed",
        "modified_files_count": 1,
        "modified_files": [
            "Framework/Geometry/src/Objects/CSGObject.cpp"
        ],
        "github_commit_url": "https://github.com/mantidproject/mantid/commit/620b3fa197e899e8ccc8c8dfd3993ad0518a7841",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CSGObject::interceptSurface"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant calculations within the `interceptSurface` function by caching and reusing intermediate results.",
            "The optimization strategy involved reducing redundant calculations within the `interceptSurface` function by caching and reusing intermediate results.",
            "The optimization strategy involved reducing redundant calculations within the `interceptSurface` function by caching and reusing intermediate results.",
            "The optimization strategy involved reducing redundant calculations within the `interceptSurface` function by caching and reusing intermediate results.",
            "The optimization strategy involved reducing redundant calculations within the `interceptSurface` function by caching and reusing intermediate results."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant calculations within the `interceptSurface` function by caching and reusing intermediate results.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "gcc",
        "hash": "39e763ca876fba4449c0781f61115e063f481add",
        "author": "Richard Biener",
        "date": "2024-11-16T14:13:28+01:00",
        "message": "tree-optimization/117606 - SLP and single element interleaving\n\nThe following tries to reduce the amount of difference between\nSLP and non-SLP for single-element interleaving load classification.\n\nThis fixes another fallout of --param vect-force-slp=1\n\n\tPR tree-optimization/117606\n\t* tree-vect-stmts.cc (get_group_load_store_type): For single\n\telement interleaving also fall back to VMAT_ELEMENTWISE if\n\ta left-over permutation isn't supported.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/tree-vect-stmts.cc"
        ],
        "github_commit_url": "https://github.com/gcc-mirror/gcc/commit/39e763ca876fba4449c0781f61115e063f481add",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_group_load_store_type"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy adjusts the classification of single-element interleaving loads to reduce differences between SLP and non-SLP vectorization paths, improving compatibility with unsupported permutations.",
            "The optimization strategy adjusts the classification of single-element interleaving loads to reduce differences between SLP and non-SLP vectorization paths, improving compatibility with unsupported permutations.",
            "The optimization strategy adjusts the classification of single-element interleaving loads to reduce differences between SLP and non-SLP vectorization paths, improving compatibility with unsupported permutations.",
            "The optimization strategy adjusts the classification of single-element interleaving loads to reduce differences between SLP and non-SLP vectorization, improving compatibility with unsupported permutations.",
            "The optimization strategy adjusts the classification of single-element interleaving loads to reduce differences between SLP and non-SLP vectorization paths, improving compatibility with unsupported permutations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy adjusts the classification of single-element interleaving loads to reduce differences between SLP and non-SLP vectorization paths, improving compatibility with unsupported permutations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenBLAS",
        "hash": "2e6fae2aad240fe6be8273cc53bc239ee920ee7c",
        "author": "Martin Kroeker",
        "date": "2018-11-19T14:02:50+01:00",
        "message": "Serialize accesses to parallelized level3 functions from multiple callers\n\nfor #1851",
        "modified_files_count": 1,
        "modified_files": [
            "driver/level3/level3_thread.c"
        ],
        "github_commit_url": "https://github.com/OpenMathLib/OpenBLAS/commit/2e6fae2aad240fe6be8273cc53bc239ee920ee7c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gemm_driver"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy serializes accesses to parallelized level3 functions to prevent race conditions or resource contention from multiple callers.",
            "The optimization strategy serializes accesses to parallelized level3 functions to prevent race conditions or resource contention when multiple callers invoke them concurrently.",
            "The optimization strategy serializes accesses to parallelized level3 functions to prevent race conditions or resource contention when multiple callers invoke them concurrently.",
            "The optimization strategy serializes accesses to parallelized level3 functions to prevent race conditions or resource contention when multiple callers invoke them concurrently.",
            "The optimization strategy serializes accesses to parallelized level3 functions to prevent race conditions or resource contention when multiple callers invoke them concurrently."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy serializes accesses to parallelized level3 functions to prevent race conditions or resource contention when multiple callers invoke them concurrently.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mpv",
        "hash": "5b7327920b1500c33342c021e70136973972fbce",
        "author": "Mad Fish",
        "date": "2013-01-20T16:37:30+01:00",
        "message": "ao_coreaudio: use 0 as timeout for CFRunLoopRunInMode\n\nHandle all pending events and exit instead of waiting. When there are lots of\ninput events (for example, scrolling with trackpad), timeout can add up\nto make a huge frame delay. In my tests, if I scroll fast enough, that loop\nwould never exit.",
        "modified_files_count": 1,
        "modified_files": [
            "audio/out/ao_coreaudio.c"
        ],
        "github_commit_url": "https://github.com/mpv-player/mpv/commit/5b7327920b1500c33342c021e70136973972fbce",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "play"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved changing the timeout value for event handling to ensure quicker processing and prevent delays caused by accumulating timeouts.",
            "The optimization strategy involved changing the timeout value for event handling to ensure quicker processing and prevent delays caused by accumulating timeouts.",
            "The optimization strategy involved changing the timeout value for event handling to ensure quicker processing and prevent delays caused by accumulating timeouts.",
            "The optimization strategy involved changing the timeout value for event handling to immediately process events without waiting, reducing potential frame delays caused by accumulating timeouts.",
            "The optimization strategy involved changing the timeout value for event handling to immediately process all pending events and exit, avoiding cumulative delays caused by waiting."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved changing the timeout value for event handling to ensure quicker processing and prevent delays caused by accumulating timeouts.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "30005444fe7b6956db675db343e47613b19f8219",
        "author": "Dan Gohman",
        "date": "2010-07-26T17:45:33+00:00",
        "message": "Avoid copying and recopying a std::set.\n\nllvm-svn: 109405",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/VMCore/Dominators.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/30005444fe7b6956db675db343e47613b19f8219",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids redundant copying of a `std::set` by directly operating on the original data structure.",
            "The optimization strategy avoids unnecessary copying of a `std::set` by directly operating on the original data structure.",
            "The optimization strategy avoids unnecessary copying of a `std::set` by directly operating on the original data structure.",
            "The optimization strategy avoids redundant copying of a `std::set` by directly working with references or iterators instead of creating unnecessary intermediate copies.",
            "The optimization strategy avoids unnecessary copying of a `std::set` by directly operating on the original data structure."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary copying of a `std::set` by directly operating on the original data structure.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "DragonFlyBSD",
        "hash": "857e4745c6998c63fa433cf7e0d0e7da6d0d18a7",
        "author": "Matthew Dillon",
        "date": "2012-09-14T01:47:19-07:00",
        "message": "kernel - Fix unix domain socket portfn routing\n\n* sonewconn_faddr() / sonewconn() was improperly overriding the sync_port\n  setting for unix domain sockets, causing unnecessary netmsg traffic to\n  the netisr threads.\n\n* This should significantly improve unix domain socket performance.\n\nWith-help-from: sephe",
        "modified_files_count": 1,
        "modified_files": [
            "sys/kern/uipc_socket2.c"
        ],
        "github_commit_url": "https://github.com/DragonFlyBSD/DragonFlyBSD/commit/857e4745c6998c63fa433cf7e0d0e7da6d0d18a7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sonewconn_faddr"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved preventing unnecessary netmsg traffic by avoiding improper overrides of the sync_port setting for unix domain sockets in sonewconn_faddr().",
            "The optimization strategy involved correcting the improper override of the sync_port setting in unix domain sockets to eliminate unnecessary netmsg traffic.",
            "The optimization strategy involved correcting the improper override of the sync_port setting in unix domain sockets to eliminate unnecessary netmsg traffic.",
            "The optimization strategy involved preventing unnecessary netmsg traffic by correcting the improper override of the sync_port setting for unix domain sockets in sonewconn_faddr().",
            "The optimization strategy involved correcting the improper override of the sync_port setting in unix domain sockets to eliminate unnecessary netmsg traffic."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved correcting the improper override of the sync_port setting in unix domain sockets to eliminate unnecessary netmsg traffic.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ucx",
        "hash": "bdb82246d0e13616977e6f244f1d45f0539ded77",
        "author": "Shuki Zanyovka",
        "date": "2020-06-25T15:02:11+03:00",
        "message": "UCS: Improve ptr_array foreach performance by prefetching\n\n- Use CPU dcache prefetching to further improve the ptr_array\n  performance.\n- Improvement achieved is ~10% on Intel processors.",
        "modified_files_count": 1,
        "modified_files": [
            "src/ucs/datastruct/ptr_array.h"
        ],
        "github_commit_url": "https://github.com/openucx/ucx/commit/bdb82246d0e13616977e6f244f1d45f0539ded77",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__ucs_ptr_array_for_each_get_step_size"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used CPU data cache prefetching to enhance the performance of iterating through a pointer array by reducing cache misses.",
            "The optimization strategy used CPU data cache prefetching to improve the performance of iterating through a pointer array by reducing cache misses.",
            "The optimization strategy used CPU data cache prefetching to improve the performance of iterating through a pointer array by reducing cache misses.",
            "The optimization strategy used CPU data cache prefetching to improve the performance of iterating over a pointer array by reducing cache misses.",
            "The optimization strategy used CPU data cache prefetching to improve the performance of iterating through a pointer array by reducing cache misses."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used CPU data cache prefetching to improve the performance of iterating through a pointer array by reducing cache misses.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "NetworkManager",
        "hash": "d5d7b4781e116bd8dcaab28ad7d1db8f57d21621",
        "author": "Thomas Haller",
        "date": "2020-04-03T11:31:12+02:00",
        "message": "shared: pre-allocate GString with 16 bytes for _nm_utils_enum_to_str_full()\n\nIn the next commit, GString will be replaced by NMStrBuf. Then, we will\npre-allocate a string buffer with 16 bytes, and measure the performance\ndifference. To have it comparable, adjust the pre-allocation size also\nwith GString.",
        "modified_files_count": 1,
        "modified_files": [
            "shared/nm-glib-aux/nm-enum-utils.c"
        ],
        "github_commit_url": "https://github.com/NetworkManager/NetworkManager/commit/d5d7b4781e116bd8dcaab28ad7d1db8f57d21621",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_nm_utils_enum_to_str_full"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy pre-allocates a GString with 16 bytes to reduce dynamic memory reallocations during string operations.",
            "The optimization strategy pre-allocates a GString with 16 bytes to reduce dynamic memory reallocations during string operations.",
            "The optimization strategy pre-allocates a GString with 16 bytes to reduce dynamic memory reallocations during string operations.",
            "The optimization strategy pre-allocates a GString with 16 bytes to reduce dynamic memory reallocations during string operations.",
            "The optimization strategy pre-allocates a GString with 16 bytes to reduce dynamic memory reallocations during string operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy pre-allocates a GString with 16 bytes to reduce dynamic memory reallocations during string operations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "flare-engine",
        "hash": "645137672bd1552382b80f9398341eec7b8b3317",
        "author": "Justin Jacobs",
        "date": "2012-09-21T12:55:07-04:00",
        "message": "Don't check distance when checking hotspot tooltips\n\nCloses #14",
        "modified_files_count": 1,
        "modified_files": [
            "src/MapRenderer.cpp"
        ],
        "github_commit_url": "https://github.com/flareteam/flare-engine/commit/645137672bd1552382b80f9398341eec7b8b3317",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hotspot"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes unnecessary distance checks when evaluating hotspot tooltips to reduce computational overhead.",
            "The optimization strategy removes unnecessary distance checks when evaluating hotspot tooltips, reducing computational overhead.",
            "The optimization strategy removes unnecessary distance checks when evaluating hotspot tooltips, reducing computational overhead.",
            "The optimization strategy removes unnecessary distance checks when determining hotspot tooltips, reducing redundant computations.",
            "The optimization strategy removes unnecessary distance checks when evaluating hotspot tooltips to reduce computational overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy removes unnecessary distance checks when evaluating hotspot tooltips to reduce computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "QGIS",
        "hash": "c73262d572ba2bf62121f19bd6aa0c60ee3b6a32",
        "author": "Nyall Dawson",
        "date": "2018-05-26T06:31:11+10:00",
        "message": "Speed up WKB conversion to linestrings",
        "modified_files_count": 1,
        "modified_files": [
            "src/core/geometry/qgslinestring.cpp"
        ],
        "github_commit_url": "https://github.com/qgis/QGIS/commit/c73262d572ba2bf62121f19bd6aa0c60ee3b6a32",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "QgsLineString::importVerticesFromWkb"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant memory allocations and improving the efficiency of vertex data handling during WKB conversion to linestrings.",
            "The optimization strategy involved reducing redundant memory allocations and copies during WKB conversion to linestrings by directly importing vertices into the target structure.",
            "The optimization strategy involved reducing redundant memory allocations and improving the efficiency of vertex data handling during WKB conversion to linestrings.",
            "The optimization strategy involved reducing redundant memory allocations and improving data handling efficiency during WKB conversion to linestrings.",
            "The optimization strategy involved reducing redundant memory allocations and improving the efficiency of vertex data handling during WKB conversion to linestrings."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant memory allocations and improving the efficiency of vertex data handling during WKB conversion to linestrings.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "PX4-Autopilot",
        "hash": "a9d83b77de913c35752914a2a0657f59f5f4bbbe",
        "author": "Dennis Mannhart",
        "date": "2018-08-15T16:19:51+02:00",
        "message": "ControlMath: math optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/mc_pos_control/Utility/ControlMath.cpp"
        ],
        "github_commit_url": "https://github.com/PX4/PX4-Autopilot/commit/a9d83b77de913c35752914a2a0657f59f5f4bbbe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "constrainXY"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying mathematical operations to reduce computational overhead in the constrainXY function.",
            "The optimization strategy involved simplifying mathematical operations to reduce computational overhead in the `constrainXY` function.",
            "The optimization strategy involved simplifying mathematical operations to reduce computational overhead in the constrainXY function.",
            "The optimization strategy involved simplifying mathematical operations to reduce computational overhead in the constrainXY function.",
            "The optimization strategy involved simplifying mathematical operations to reduce computational overhead in the constrainXY function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying mathematical operations to reduce computational overhead in the constrainXY function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Pikafish",
        "hash": "f4140ecc0c78d3d89f4e2459105e3ce3a1ab3ce1",
        "author": "Marco Costalba",
        "date": "2009-08-10T13:49:12+01:00",
        "message": "Avoid Intel compiler optimizes away prefetching\n\nWithout this hack Intel compiler happily optimizes\naway the gcc builtin call.\n\nSigned-off-by: Marco Costalba <mcostalba@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/tt.cpp"
        ],
        "github_commit_url": "https://github.com/official-pikafish/Pikafish/commit/f4140ecc0c78d3d89f4e2459105e3ce3a1ab3ce1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TranspositionTable::prefetch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding a compiler-specific hack to prevent the Intel compiler from optimizing away a prefetching operation.",
            "The optimization strategy involves adding a compiler-specific hack to prevent the Intel compiler from optimizing away a prefetching operation.",
            "The optimization strategy involves adding a compiler-specific hack to prevent the Intel compiler from optimizing away a prefetching operation.",
            "The optimization strategy involves adding a compiler-specific hack to prevent the Intel compiler from optimizing away a prefetching operation.",
            "The optimization strategy involves adding a compiler-specific hack to prevent the Intel compiler from optimizing away a prefetching operation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding a compiler-specific hack to prevent the Intel compiler from optimizing away a prefetching operation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_xiaomi_sm8150",
        "hash": "dcca4c79b0a0078e3c2eaeab62a833cebacc7932",
        "author": "Eric Dumazet",
        "date": "2018-08-02T17:02:12-06:00",
        "message": "tcp: detect malicious patterns in tcp_collapse_ofo_queue()\n\n[ Upstream commit 3d4bf93ac12003f9b8e1e2de37fe27983deebdcf ]\n\nIn case an attacker feeds tiny packets completely out of order,\ntcp_collapse_ofo_queue() might scan the whole rb-tree, performing\nexpensive copies, but not changing socket memory usage at all.\n\n1) Do not attempt to collapse tiny skbs.\n2) Add logic to exit early when too many tiny skbs are detected.\n\nWe prefer not doing aggressive collapsing (which copies packets)\nfor pathological flows, and revert to tcp_prune_ofo_queue() which\nwill be less expensive.\n\nIn the future, we might add the possibility of terminating flows\nthat are proven to be malicious.\n\nCRs-Fixed: 2290234\nChange-Id: I4f198747a27998281fc936feacd5ff5be2e569ef\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nAcked-by: Soheil Hassas Yeganeh <soheil@google.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>\nSigned-off-by: Greg Kroah-Hartman <gregkh@google.com>\nGit-commit: da0af805f1847c2ac3c35ebe8b3c18f98cfbe940\nGit-repo: https://android.googlesource.com/kernel/common/\nSigned-off-by: Isaac J. Manjarres <isaacm@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "net/ipv4/tcp_input.c"
        ],
        "github_commit_url": "https://github.com/Laulan56/android_kernel_xiaomi_sm8150/commit/dcca4c79b0a0078e3c2eaeab62a833cebacc7932",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tcp_collapse"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary processing of tiny out-of-order packets by skipping collapse attempts and adding early exit logic for pathological flows.",
            "The optimization strategy avoids unnecessary processing of tiny out-of-order packets by skipping collapse attempts and adding early exit logic for pathological flows.",
            "The optimization strategy avoids unnecessary processing of tiny out-of-order packets by skipping collapse attempts and adding early exit logic for pathological flows.",
            "The optimization strategy avoids unnecessary processing of tiny out-of-order packets by skipping collapse attempts and exiting early when malicious patterns are detected.",
            "The optimization strategy avoids expensive operations on tiny out-of-order packets by skipping collapse attempts and exiting early when malicious patterns are detected."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary processing of tiny out-of-order packets by skipping collapse attempts and adding early exit logic for pathological flows.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "selinux-kernel",
        "hash": "038ac18aae935c89c874649acde5a82f588a12b4",
        "author": "Samuel Holland",
        "date": "2024-04-29T10:49:27-07:00",
        "message": "riscv: mm: Broadcast kernel TLB flushes only when needed\n\n__flush_tlb_range() avoids broadcasting TLB flushes when an mm context\nis only active on the local CPU. Apply this same optimization to TLB\nflushes of kernel memory when only one CPU is online. This check can be\nconstant-folded when SMP is disabled.\n\nReviewed-by: Alexandre Ghiti <alexghiti@rivosinc.com>\nSigned-off-by: Samuel Holland <samuel.holland@sifive.com>\nLink: https://lore.kernel.org/r/20240327045035.368512-5-samuel.holland@sifive.com\nSigned-off-by: Palmer Dabbelt <palmer@rivosinc.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/riscv/mm/tlbflush.c"
        ],
        "github_commit_url": "https://github.com/SELinuxProject/selinux-kernel/commit/038ac18aae935c89c874649acde5a82f588a12b4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__flush_tlb_range"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids broadcasting TLB flushes for kernel memory when only one CPU is active, reducing unnecessary overhead.",
            "The optimization avoids broadcasting TLB flushes for kernel memory when only one CPU is active, reducing unnecessary overhead.",
            "The optimization avoids broadcasting TLB flushes for kernel memory when only one CPU is active, reducing unnecessary overhead.",
            "The optimization avoids broadcasting TLB flushes for kernel memory when only one CPU is active, reducing unnecessary overhead.",
            "The optimization avoids broadcasting TLB flushes for kernel memory when only one CPU is active, reducing unnecessary overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids broadcasting TLB flushes for kernel memory when only one CPU is active, reducing unnecessary overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pioneer",
        "hash": "a8315bf41faf8457f2214951d130cfe2daa4af3f",
        "author": "Andrew Copland",
        "date": "2016-10-16T23:17:46+01:00",
        "message": "Simple reduction in memory usage.",
        "modified_files_count": 1,
        "modified_files": [
            "src/GeoPatch.cpp"
        ],
        "github_commit_url": "https://github.com/pioneerspacesim/pioneer/commit/a8315bf41faf8457f2214951d130cfe2daa4af3f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GeoPatch::UpdateVBOs"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory usage by modifying the logic in GeoPatch::UpdateVBOs to avoid unnecessary memory allocations or copies.",
            "The optimization strategy involved reducing memory usage by modifying the logic in GeoPatch::UpdateVBOs to avoid unnecessary memory allocations or operations.",
            "The optimization strategy involved reducing memory usage by modifying the logic in GeoPatch::UpdateVBOs to avoid unnecessary data duplication or allocation.",
            "The optimization strategy involved reducing memory usage by modifying how data is stored or processed in the `GeoPatch::UpdateVBOs` function.",
            "The optimization strategy involved reducing memory usage by modifying the logic in GeoPatch::UpdateVBOs to avoid unnecessary memory allocations or copies."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory usage by modifying the logic in GeoPatch::UpdateVBOs to avoid unnecessary memory allocations or copies.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "server",
        "hash": "8268fa881fed2a2cd23566a7c962e6e6dfa60da6",
        "author": "Sergey Vojtovich",
        "date": "2019-05-21T17:55:09+04:00",
        "message": "Moved set_timespec out of LOCK_thread_cache mutex\n\nPart of MDEV-19515 - Improve connect speed",
        "modified_files_count": 1,
        "modified_files": [
            "sql/mysqld.cc"
        ],
        "github_commit_url": "https://github.com/MariaDB/server/commit/8268fa881fed2a2cd23566a7c962e6e6dfa60da6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cache_thread"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved moving a function call (set_timespec) outside of a mutex-protected section to reduce contention and improve concurrency.",
            "The optimization strategy involved moving a function call out of a mutex-locked section to reduce contention and improve concurrency.",
            "The optimization strategy involved moving a function call (set_timespec) outside of a mutex-protected section to reduce contention and improve concurrency.",
            "The optimization strategy involved moving a function call (set_timespec) outside of a mutex-protected section to reduce contention and improve concurrency.",
            "The optimization strategy involved moving a function call (set_timespec) outside of a mutex-protected section to reduce contention and improve concurrency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved moving a function call (set_timespec) outside of a mutex-protected section to reduce contention and improve concurrency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "TortoiseGit",
        "hash": "2d111c73d9f798727b561878af6ccf991f3a9980",
        "author": "Sven Strickroth",
        "date": "2023-05-13T18:58:39+02:00",
        "message": "Speed up reverting renames\n\nSigned-off-by: Sven Strickroth <email@cs-ware.de>",
        "modified_files_count": 1,
        "modified_files": [
            "src/TortoiseProc/ProgressCommands/RevertProgressCommand.cpp"
        ],
        "github_commit_url": "https://github.com/TortoiseGit/TortoiseGit/commit/2d111c73d9f798727b561878af6ccf991f3a9980",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RevertProgressCommand::Run"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary iterations or operations during the revert renaming process to improve performance.",
            "The optimization strategy involved reducing redundant operations by avoiding unnecessary iterations over renamed files during the revert process.",
            "The optimization strategy involved reducing unnecessary iterations or operations during the revert process by refining the logic for handling renames.",
            "The optimization strategy involved reducing unnecessary iterations or operations during the revert process by refining the logic for handling renames.",
            "The optimization strategy involved reducing redundant operations by caching or precomputing results related to reverting renames."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary iterations or operations during the revert renaming process to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libical",
        "hash": "a8f69b3e1aee98d15547a5598a11db37adec75af",
        "author": "Markus Minichmayr",
        "date": "2024-10-27T17:44:55+01:00",
        "message": "icalrecur.c: Minor performance improvement in filter_bysetpos() - avoid iterating all bits in days bit field.",
        "modified_files_count": 1,
        "modified_files": [
            "src/libical/icalrecur.c"
        ],
        "github_commit_url": "https://github.com/libical/libical/commit/a8f69b3e1aee98d15547a5598a11db37adec75af",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "filter_bysetpos"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary iteration over all bits in a bit field by directly checking relevant positions.",
            "The optimization avoids unnecessary iteration over all bits in a bit field by directly checking relevant positions.",
            "The optimization avoids unnecessary iteration over all bits in a bit field by directly checking relevant positions.",
            "The optimization avoids unnecessary iteration over all bits in a bit field by directly checking relevant positions.",
            "The optimization avoids unnecessary iteration over all bits in a bit field by directly checking relevant positions, reducing computational overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary iteration over all bits in a bit field by directly checking relevant positions.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cusplibrary",
        "hash": "ac8087d833cef7f1986772882d6944bf23183144",
        "author": "wnbell",
        "date": "2010-12-02T05:24:06-05:00",
        "message": "improved ELL->CSR conversion performance",
        "modified_files_count": 1,
        "modified_files": [
            "cusp/detail/device/convert.h"
        ],
        "github_commit_url": "https://github.com/cusplibrary/cusplibrary/commit/ac8087d833cef7f1986772882d6944bf23183144",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "convert"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the ELL-to-CSR conversion algorithm to reduce redundant computations and improve memory access patterns.",
            "The optimization strategy involved restructuring the ELL-to-CSR conversion algorithm to reduce redundant computations and improve memory access patterns.",
            "The optimization strategy involved restructuring the ELL-to-CSR conversion algorithm to reduce redundant computations and improve memory access patterns.",
            "The optimization strategy involved restructuring the ELL-to-CSR conversion algorithm to reduce redundant computations and improve memory access patterns.",
            "The optimization strategy involved restructuring the ELL-to-CSR conversion algorithm to reduce redundant computations and improve memory access patterns."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the ELL-to-CSR conversion algorithm to reduce redundant computations and improve memory access patterns.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Arctic-Fox",
        "hash": "30dac96a785b5f86619c2daf2253eda23427b6bb",
        "author": "Riccardo Mottola",
        "date": "2022-11-14T12:08:58+01:00",
        "message": "Bug 1186768 patch 3 - Compute affectedByScriptMinSize sooner to avoid asserting or doing extra work. r=heycam\n\nThe assertion added in patch 1 caught a separate bug, which is that we\nwere computing whether we were affected by scriptMinSize too soon.\nPrior to patch 1, this bug meant doing extra work (taking the slow\npath).  With patch 1, this changes in documents without MathML to\nhitting the assertion instead of taking the slow path.",
        "modified_files_count": 1,
        "modified_files": [
            "layout/style/nsRuleNode.cpp"
        ],
        "github_commit_url": "https://github.com/rmottola/Arctic-Fox/commit/30dac96a785b5f86619c2daf2253eda23427b6bb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nsRuleNode::SetFont"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved moving the computation of `affectedByScriptMinSize` to an earlier stage to avoid unnecessary assertions or redundant work.",
            "The optimization strategy involved moving the computation of `affectedByScriptMinSize` earlier to avoid unnecessary assertions or extra work in certain cases.",
            "The optimization strategy involved moving the computation of `affectedByScriptMinSize` to an earlier stage to avoid unnecessary work or assertions.",
            "The optimization strategy involved moving the computation of `affectedByScriptMinSize` to an earlier stage to avoid unnecessary work or assertions.",
            "The optimization strategy involved moving the computation of `affectedByScriptMinSize` to an earlier stage to avoid unnecessary assertions or redundant work."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved moving the computation of `affectedByScriptMinSize` to an earlier stage to avoid unnecessary assertions or redundant work.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ppsspp",
        "hash": "52283a50dcb6e88fcdaedbbcb54dfbda9ac5bbfa",
        "author": "Unknown W. Brackets",
        "date": "2020-05-21T18:58:22-07:00",
        "message": "Io: Improve non-async open timing.",
        "modified_files_count": 1,
        "modified_files": [
            "Core/HLE/sceIo.cpp"
        ],
        "github_commit_url": "https://github.com/hrydgard/ppsspp/commit/52283a50dcb6e88fcdaedbbcb54dfbda9ac5bbfa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sceIoOpen"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the file opening logic to reduce unnecessary overhead in non-async operations by avoiding redundant checks and improving timing efficiency.",
            "The optimization strategy involved restructuring the file opening logic to reduce unnecessary overhead in non-async operations by avoiding redundant checks and improving timing efficiency.",
            "The optimization strategy involved restructuring the file opening logic to reduce unnecessary operations and improve timing for non-async file opens.",
            "The optimization strategy involved restructuring the file opening logic to reduce unnecessary operations and improve timing for non-async file opens.",
            "The optimization strategy involved restructuring the file opening logic to reduce unnecessary overhead in non-async operations by avoiding redundant checks and improving timing efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the file opening logic to reduce unnecessary overhead in non-async operations by avoiding redundant checks and improving timing efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kernel-copyleft",
        "hash": "1685b9c0dd4019f09d1290c85dad596198f7650f",
        "author": "Linux Build Service Account",
        "date": "2012-09-20T02:50:44-07:00",
        "message": "Merge \"msm: sps: disable cache miss feature in NDP-BAM by default\" into msm-3.4",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/platform/msm/sps/bam.c"
        ],
        "github_commit_url": "https://github.com/sonyxperiadev/kernel-copyleft/commit/1685b9c0dd4019f09d1290c85dad596198f7650f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bam_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization disables a specific hardware feature (cache miss in NDP-BAM) by default to improve performance in the BAM initialization process.",
            "The optimization disables a specific hardware feature (cache miss in NDP-BAM) by default to improve performance in the BAM initialization process.",
            "The optimization disables a specific hardware feature (cache miss in NDP-BAM) by default to improve performance in the BAM initialization process.",
            "The optimization disables a specific hardware feature (cache miss in NDP-BAM) by default to improve performance in the BAM initialization process.",
            "The optimization disables a specific hardware feature (cache miss in NDP-BAM) by default to improve performance in the BAM initialization process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization disables a specific hardware feature (cache miss in NDP-BAM) by default to improve performance in the BAM initialization process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "snp-sites",
        "hash": "6466c95549484208b45337602812f0c5ff85085a",
        "author": "andrewjpage",
        "date": "2012-05-09T13:43:01+01:00",
        "message": "speedup phylip creation",
        "modified_files_count": 1,
        "modified_files": [
            "phylib_of_snp_sites.c"
        ],
        "github_commit_url": "https://github.com/sanger-pathogens/snp-sites/commit/6466c95549484208b45337602812f0c5ff85085a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "create_phylib_of_snp_sites"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a nested loop structure with a single loop to reduce redundant computations during Phylip file creation.",
            "The optimization strategy involved reducing redundant computations within the loop that constructs the PHYLIP format output by caching and reusing previously computed values.",
            "The optimization strategy involved reducing redundant computations within the loop that constructs the PHYLIP format output by caching and reusing previously computed values.",
            "The optimization strategy involved reducing redundant computations within the loop that constructs the PHYLIP format output by caching and reusing previously computed values.",
            "The optimization strategy involved reducing redundant computations within the loop that constructs the PHYLIP format output by caching and reusing previously computed values."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations within the loop that constructs the PHYLIP format output by caching and reusing previously computed values.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qtdeclarative",
        "hash": "0602e657fac200b0fc7d3ae19361ef9ef1247d92",
        "author": "Thiago Macieira",
        "date": "2018-07-22T01:56:32+00:00",
        "message": "tst_qmldiskcache: speed up test\n\nOn some systems, we *do* have sub-second file time resolution, so we\ndon't have to wait one second.\n\nChange-Id: Id2be776c7ae0467c9d9ffffd1543325ce53f10fd\nReviewed-by: Simon Hausmann <simon.hausmann@qt.io>",
        "modified_files_count": 1,
        "modified_files": [
            "tests/auto/qml/qmldiskcache/tst_qmldiskcache.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qtdeclarative/commit/0602e657fac200b0fc7d3ae19361ef9ef1247d92",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "waitForFileSystem"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces unnecessary wait times by leveraging sub-second file time resolution when available.",
            "The optimization reduces unnecessary wait times by leveraging sub-second file time resolution when available, instead of always waiting for a full second.",
            "The optimization reduces unnecessary wait times by leveraging sub-second file time resolution when available.",
            "The optimization reduces unnecessary wait times by leveraging sub-second file time resolution on systems that support it.",
            "The optimization reduces unnecessary wait times by leveraging sub-second file time resolution when available, avoiding a fixed one-second delay."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces unnecessary wait times by leveraging sub-second file time resolution when available.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "0a36463f4ca287e4d4ac15580c0aae5b23619212",
        "author": "Mike Snitzer",
        "date": "2022-08-04T14:02:20-04:00",
        "message": "dm verity: optimize verity_verify_io if FEC not configured\n\nOnly declare and copy bvec_iter if CONFIG_DM_VERITY_FEC is defined and\nFEC enabled for the verity device.\n\nSigned-off-by: Mike Snitzer <snitzer@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/md/dm-verity-target.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/0a36463f4ca287e4d4ac15580c0aae5b23619212",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "verity_verify_io"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids declaring and copying `bvec_iter` unless FEC is both configured and enabled for the verity device, reducing unnecessary overhead.",
            "The optimization avoids declaring and copying `bvec_iter` unless FEC is both configured and enabled for the verity device, reducing unnecessary overhead.",
            "The optimization avoids declaring and copying `bvec_iter` unless FEC is both configured and enabled for the verity device, reducing unnecessary overhead.",
            "The optimization avoids declaring and copying `bvec_iter` unless FEC is both configured and enabled for the verity device, reducing unnecessary overhead.",
            "The optimization avoids declaring and copying `bvec_iter` unless FEC is both configured and enabled for the verity device, reducing unnecessary overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids declaring and copying `bvec_iter` unless FEC is both configured and enabled for the verity device, reducing unnecessary overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libvma",
        "hash": "8a52381903baddd4ef4ef630bef83a25e2d7ab4a",
        "author": "Igor Ivanov",
        "date": "2018-05-29T18:57:48+03:00",
        "message": "issue: 1284069 Optimize m_p_tx_mem_buf_desc_list releasing\n\nSigned-off-by: Igor Ivanov <igor.ivanov.va@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/vma/proto/dst_entry.cpp"
        ],
        "github_commit_url": "https://github.com/Mellanox/libvma/commit/8a52381903baddd4ef4ef630bef83a25e2d7ab4a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dst_entry::prepare_to_send"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary memory operations by improving the release process of `m_p_tx_mem_buf_desc_list`.",
            "The optimization strategy involved reducing unnecessary memory operations by improving the release process of `m_p_tx_mem_buf_desc_list`.",
            "The optimization strategy involved reducing unnecessary memory operations by improving the management of `m_p_tx_mem_buf_desc_list` to enhance performance during the release process.",
            "The optimization strategy involved reducing unnecessary memory operations by improving the release mechanism of `m_p_tx_mem_buf_desc_list`.",
            "The optimization strategy involved reducing unnecessary memory operations by reusing existing memory buffers instead of releasing and reallocating them."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary memory operations by improving the release process of `m_p_tx_mem_buf_desc_list`.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "UEVR",
        "hash": "57138465df45d9145ea77b6dcb1e0b5842a6824e",
        "author": "praydog",
        "date": "2023-03-27T06:40:14-07:00",
        "message": "OpenXR: Further reduce latency + reduce overestimation of poses",
        "modified_files_count": 1,
        "modified_files": [
            "src/mods/vr/runtimes/OpenXR.cpp"
        ],
        "github_commit_url": "https://github.com/praydog/UEVR/commit/57138465df45d9145ea77b6dcb1e0b5842a6824e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OpenXR::update_poses"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved refining pose estimation calculations to minimize latency and reduce overestimation errors in the OpenXR runtime.",
            "The optimization strategy involved refining pose estimation calculations to reduce latency and minimize overestimation in the OpenXR runtime.",
            "The optimization strategy reduces latency and overestimation of poses by refining the pose update logic in the OpenXR runtime.",
            "The optimization strategy reduces latency and overestimation of poses by refining the timing and prediction logic in the OpenXR pose update function.",
            "The optimization strategy reduces latency and overestimation of poses by refining pose update logic and timing adjustments in the OpenXR runtime."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces latency and overestimation of poses by refining pose update logic and timing adjustments in the OpenXR runtime.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "01c82f50f7f2dc2f93e354374b5a6e14c71839a0",
        "author": "Kostya Serebryany",
        "date": "2016-12-17T02:23:35+00:00",
        "message": "[libFuzzer] speed up __sanitizer_cov_trace_switch a bit more (remove DIV)\n\nllvm-svn: 290034",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Fuzzer/FuzzerTracePC.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/01c82f50f7f2dc2f93e354374b5a6e14c71839a0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__attribute__"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing a division operation in the `__sanitizer_cov_trace_switch` function to reduce computational overhead.",
            "The optimization strategy involved removing a division operation in the `__sanitizer_cov_trace_switch` function to reduce computational overhead.",
            "The optimization strategy involved removing a division operation in the `__sanitizer_cov_trace_switch` function to reduce computational overhead.",
            "The optimization strategy involved removing a division operation in the `__sanitizer_cov_trace_switch` function to reduce computational overhead.",
            "The optimization strategy involved removing a division operation in the `__sanitizer_cov_trace_switch` function to reduce computational overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved removing a division operation in the `__sanitizer_cov_trace_switch` function to reduce computational overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "v8",
        "hash": "0878b351adc46285b651d9d83499511c71cbda3c",
        "author": "Darius M",
        "date": "2023-12-13T11:26:37+00:00",
        "message": "[turboshaft] Iterate further Load/Store index-offset optimization\n\nSo far, a `Load(base=a+Constant(4), index=invalid, offset=0)` would be\nnormalized to `Load(base=a, index=Constant(4), offset=0)`. With this\nCL, we'll do one more reduction step to get to\n`Load(base=a, index=invalid, offset=4)`.\n\nBug: v8:12783\nChange-Id: I582032b18709beefacabcc9938afb2f7768b85fb\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/5119541\nAuto-Submit: Darius Mercadier <dmercadier@chromium.org>\nReviewed-by: Matthias Liedtke <mliedtke@chromium.org>\nCommit-Queue: Matthias Liedtke <mliedtke@chromium.org>\nCr-Commit-Position: refs/heads/main@{#91482}",
        "modified_files_count": 1,
        "modified_files": [
            "src/compiler/turboshaft/machine-optimization-reducer.h"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/0878b351adc46285b651d9d83499511c71cbda3c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "REDUCE"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy simplifies load/store operations by reducing unnecessary intermediate steps in index-offset normalization.",
            "The optimization strategy simplifies load/store operations by reducing index-offset combinations into a more efficient base-offset form.",
            "The optimization strategy simplifies load/store operations by reducing index-offset combinations to a more efficient canonical form with a direct offset.",
            "The optimization strategy simplifies load/store operations by reducing index-offset combinations to a more efficient canonical form with a direct offset.",
            "The optimization strategy simplifies load/store operations by reducing index-offset combinations to a more efficient canonical form."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy simplifies load/store operations by reducing index-offset combinations to a more efficient canonical form with a direct offset.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "55a2abfe31b82af13a77c3dc89913774f667b898",
        "author": "Hui Su",
        "date": "2018-06-11T18:07:18+00:00",
        "message": "Merge \"Small speedup of ml_pruning_partition()\"",
        "modified_files_count": 1,
        "modified_files": [
            "vp9/encoder/vp9_encodeframe.c"
        ],
        "github_commit_url": "https://github.com/webmproject/libvpx/commit/55a2abfe31b82af13a77c3dc89913774f667b898",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ml_pruning_partition"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "libvpx",
        "optimization_summary": [
            "The optimization strategy involved simplifying the logic in the ml_pruning_partition function to reduce unnecessary computations and improve execution speed.",
            "The optimization strategy involved simplifying the logic in the loop to reduce unnecessary computations and improve iteration efficiency.",
            "The optimization strategy involved simplifying the logic in the loop to reduce unnecessary computations and improve iteration efficiency.",
            "The optimization strategy involved simplifying the logic in the loop to reduce unnecessary computations during partition pruning.",
            "The optimization strategy involved simplifying the logic in the ml_pruning_partition function to reduce unnecessary computations and improve execution speed."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the logic in the loop to reduce unnecessary computations during partition pruning.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "64143619ab52bac3705de2671e9c789d119312df",
        "author": "Justin Hibbits",
        "date": "2019-02-13T03:11:12+00:00",
        "message": "powerpc/booke: Use the 'tlbilx' instruction on newer cores\n\nNewer cores have the 'tlbilx' instruction, which doesn't broadcast over\nCoreNet.  This is significantly faster than walking the TLB to invalidate\nthe PID mappings.  tlbilx with the arguments given takes 131 clock cycles to\ncomplete, as opposed to 512 iterations through the loop plus tlbre/tlbwe at\neach iteration.\n\nMFC after:\t3 weeks",
        "modified_files_count": 1,
        "modified_files": [
            "sys/powerpc/booke/pmap.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/64143619ab52bac3705de2671e9c789d119312df",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tid_flush"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces a loop-based TLB invalidation process with a single 'tlbilx' instruction on newer cores to reduce clock cycles and improve performance.",
            "The optimization strategy replaces a loop-based TLB invalidation process with a single 'tlbilx' instruction on newer cores to reduce clock cycles and improve performance.",
            "The optimization leverages the 'tlbilx' instruction on newer cores to reduce TLB invalidation overhead by avoiding broadcasting over CoreNet and minimizing clock cycles compared to iterative TLB walks.",
            "The optimization strategy replaces a loop-based TLB invalidation process with a single 'tlbilx' instruction on newer cores to reduce clock cycles and improve performance.",
            "The optimization strategy involved replacing a loop-based TLB invalidation process with the faster 'tlbilx' instruction on newer cores to reduce clock cycles and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaces a loop-based TLB invalidation process with a single 'tlbilx' instruction on newer cores to reduce clock cycles and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "glocal_exploration",
        "hash": "d3480a253d97435b26fea814b9137ceda06dac2d",
        "author": "Victor Reijgwart",
        "date": "2021-03-07T18:45:26+01:00",
        "message": "For frontier visibility test if in FoV first (fast) then raytrace (slow)",
        "modified_files_count": 1,
        "modified_files": [
            "glocal_exploration_ros/src/planning/global/skeleton_planner.cpp"
        ],
        "github_commit_url": "https://github.com/ethz-asl/glocal_exploration/commit/d3480a253d97435b26fea814b9137ceda06dac2d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves checking if a frontier is within the field of view (FoV) before performing the more computationally expensive raytracing operation.",
            "The optimization strategy involves checking if a frontier is within the field of view (FoV) before performing the more computationally expensive raytracing operation.",
            "The optimization strategy involves checking if a frontier is within the field of view (FoV) before performing a more computationally expensive raytracing operation.",
            "The optimization strategy involves checking if a frontier is within the field of view (FoV) before performing the more computationally expensive raytracing operation.",
            "The optimization strategy involves checking if a frontier is within the field of view (FoV) before performing the more computationally expensive raytracing operation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves checking if a frontier is within the field of view (FoV) before performing the more computationally expensive raytracing operation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "nautilus",
        "hash": "ae2669dcf8695260c7f3385bec836b92bcb57f5c",
        "author": "Sam Thursfield",
        "date": "2020-09-02T12:17:31+02:00",
        "message": "Use STRSTARTS in preference to tracker:uri-is-descendant() function\n\nIn current versions of Tracker, using STRSTARTS to compare URIs is\nfaster than using Tracker's custom tracker:uri-is-descendant() function.\nThe former allows SQLite to use an index while the latter does not.",
        "modified_files_count": 1,
        "modified_files": [
            "src/nautilus-search-engine-tracker.c"
        ],
        "github_commit_url": "https://github.com/GNOME/nautilus/commit/ae2669dcf8695260c7f3385bec836b92bcb57f5c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nautilus_search_engine_tracker_start"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces a custom function with a faster, index-supported string comparison function to improve query performance.",
            "The optimization replaces a custom URI comparison function with a faster string-based comparison that allows SQLite to utilize indexing.",
            "The optimization replaces a custom function with a faster alternative that enables SQLite to utilize indexing for URI comparisons.",
            "The optimization replaces a custom URI comparison function with the STRSTARTS function to leverage SQLite indexing for improved performance.",
            "The optimization replaces a custom URI comparison function with the STRSTARTS function to leverage SQLite indexing for improved performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization replaces a custom function with a faster alternative that enables SQLite to utilize indexing for URI comparisons.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "NanoVNA-D",
        "hash": "d40132ac72a03d78c67e1f1e2b4fc26b309c0452",
        "author": "DiSlord",
        "date": "2022-04-24T01:47:35+03:00",
        "message": "Little faster draw cell line",
        "modified_files_count": 1,
        "modified_files": [
            "plot.c"
        ],
        "github_commit_url": "https://github.com/DiSlord/NanoVNA-D/commit/d40132ac72a03d78c67e1f1e2b4fc26b309c0452",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cell_drawline"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant calculations inside a loop to improve drawing performance.",
            "The optimization strategy involved reducing redundant calculations within the loop to improve drawing performance.",
            "The optimization strategy involved reducing redundant calculations within the loop to improve drawing performance.",
            "The optimization strategy involved reducing redundant calculations within the loop to improve drawing performance.",
            "The optimization strategy involved replacing a pixel-by-pixel drawing loop with a more efficient block-based memory copy operation to reduce overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant calculations within the loop to improve drawing performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "runtime",
        "hash": "27cd66aa67974020196be9f905ee82f540fefd6f",
        "author": "Eugene Zhulenev",
        "date": "2022-05-07T03:14:46-07:00",
        "message": "[tfrt:jitrt] CustomCall: change all_decoded check\n\nIt generates slightly better code on a hot path.\n\nPiperOrigin-RevId: 447164964",
        "modified_files_count": 1,
        "modified_files": [
            "backends/jitrt/include/tfrt/jitrt/custom_call.h"
        ],
        "github_commit_url": "https://github.com/tensorflow/runtime/commit/27cd66aa67974020196be9f905ee82f540fefd6f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "call"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved modifying a condition check to improve the efficiency of a hot path in the code.",
            "The optimization strategy involved modifying a condition check to improve the efficiency of a frequently executed code path.",
            "The optimization strategy involved modifying a condition check to improve the efficiency of a hot path in the code.",
            "The optimization strategy involved modifying a condition check to improve the efficiency of a hot path in the code.",
            "The optimization strategy involved modifying a condition check to improve the efficiency of a hot path in the code."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved modifying a condition check to improve the efficiency of a hot path in the code.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "autoware.universe",
        "hash": "d962acba55aa0c9d50515b767cbb1bfd327fc50e",
        "author": "Mamoru Sobue",
        "date": "2025-02-11T20:28:19+09:00",
        "message": "perf(behavior_path_planner): improve getOverlappedLaneletId (#10094)\n\nSigned-off-by: Mamoru Sobue <mamoru.sobue@tier4.jp>",
        "modified_files_count": 1,
        "modified_files": [
            "planning/behavior_path_planner/autoware_behavior_path_planner_common/src/utils/drivable_area_expansion/static_drivable_area.cpp"
        ],
        "github_commit_url": "https://github.com/autowarefoundation/autoware.universe/commit/d962acba55aa0c9d50515b767cbb1bfd327fc50e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "getOverlappedLaneletId"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `getOverlappedLaneletId` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `getOverlappedLaneletId` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `getOverlappedLaneletId` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `getOverlappedLaneletId` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations by caching and reusing results within the `getOverlappedLaneletId` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "mindspore",
        "hash": "ce69ca12b99952f836e0dd559eee1b7ad8506e6d",
        "author": "lihao",
        "date": "2023-10-09T17:33:55+08:00",
        "message": "Fix the performance problem of MaximumGrad/MinimumGrad",
        "modified_files_count": 1,
        "modified_files": [
            "mindspore/ccsrc/frontend/expander/bprop/grad_ops/grad_math_ops.cc"
        ],
        "github_commit_url": "https://github.com/mindspore-ai/mindspore/commit/ce69ca12b99952f836e0dd559eee1b7ad8506e6d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MinimumMaximumGrad"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the logic in MinimumMaximumGrad to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic in MinimumMaximumGrad to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic in MinimumMaximumGrad to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic in MinimumMaximumGrad to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic in MinimumMaximumGrad to reduce redundant computations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the logic in MinimumMaximumGrad to reduce redundant computations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "objeck-lang",
        "hash": "2ab150494645e01ae0fea67354d5d71a17c743ca",
        "author": "Randy Hollines",
        "date": "2022-08-20T08:08:40-07:00",
        "message": "working on deadstore optimization",
        "modified_files_count": 1,
        "modified_files": [
            "core/compiler/optimization.cpp"
        ],
        "github_commit_url": "https://github.com/objeck/objeck-lang/commit/2ab150494645e01ae0fea67354d5d71a17c743ca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ItermediateOptimizer::DeadStore"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes unnecessary store operations by identifying and eliminating dead stores in the intermediate representation.",
            "The optimization strategy removes unnecessary store operations that are immediately overwritten, reducing redundant memory writes.",
            "The optimization strategy removes unnecessary store operations by identifying and eliminating dead stores in the intermediate representation.",
            "The optimization strategy removes unnecessary store operations that are immediately overwritten, reducing redundant memory writes.",
            "The optimization strategy removes unnecessary store operations that are immediately overwritten, reducing redundant memory writes."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy removes unnecessary store operations that are immediately overwritten, reducing redundant memory writes.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "5dab2f11370fd9f7d76efa453e7e4277cf33f140",
        "author": "Huawei Xie",
        "date": "2015-09-30T01:19:19+02:00",
        "message": "vhost: inject only one interrupt for a batch of packets\n\nIn merge-able RX path, vhost injects interrupts to guest for each packet.\nThis should degrade performance a lot.\nThis patch fixes this issue by injecting one interrupt for a batch of packets.\n\nSigned-off-by: Huawei Xie <huawei.xie@intel.com>\nAcked-by: Jianfeng Tan <jianfeng.tan@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/librte_vhost/vhost_rxtx.c"
        ],
        "github_commit_url": "https://github.com/DPDK/dpdk/commit/5dab2f11370fd9f7d76efa453e7e4277cf33f140",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__attribute__"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "dpdk",
        "optimization_summary": [
            "The optimization strategy reduces the frequency of interrupt injections by batching packets, thereby minimizing performance overhead.",
            "The optimization strategy reduces the frequency of interrupt injections by batching packets, thereby minimizing performance overhead.",
            "The optimization strategy reduces the frequency of interrupt injections by batching multiple packets into a single interrupt.",
            "The optimization strategy reduces the frequency of interrupt injections by batching multiple packets into a single interrupt.",
            "The optimization strategy reduces the frequency of interrupt injections by batching packets, thereby minimizing performance overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the frequency of interrupt injections by batching packets, thereby minimizing performance overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "naev",
        "hash": "59f77ff4ffdb4da61d62d489402ce32bb8e31e65",
        "author": "Deiz",
        "date": "2015-05-17T00:48:34-04:00",
        "message": "Minor optimization to system_setFaction\n\nSince it was iterating forwards and using the last (largest) presence,\nit's quicker to iterate backwards and bail on the first match.",
        "modified_files_count": 1,
        "modified_files": [
            "src/space.c"
        ],
        "github_commit_url": "https://github.com/naev/naev/commit/59f77ff4ffdb4da61d62d489402ce32bb8e31e65",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "system_setFaction"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reversing the iteration order to exit early upon finding the first match, reducing unnecessary iterations.",
            "The optimization strategy involved reversing the iteration order to exit early upon finding the first match, reducing unnecessary iterations.",
            "The optimization strategy involved reversing the iteration order to exit early upon finding the first match, reducing unnecessary iterations.",
            "The optimization strategy involved reversing the iteration order to exit early upon finding the first match, reducing unnecessary iterations.",
            "The optimization strategy involved reversing the iteration order to exit early upon finding the first match, reducing unnecessary iterations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reversing the iteration order to exit early upon finding the first match, reducing unnecessary iterations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ffmpeg",
        "hash": "c368538667121fb20c5414dfaf0fb273035a0854",
        "author": "wm4",
        "date": "2014-09-05T23:13:08+02:00",
        "message": "avformat/srtdec: speed up probing",
        "modified_files_count": 1,
        "modified_files": [
            "libavformat/srtdec.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/c368538667121fb20c5414dfaf0fb273035a0854",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "srt_probe"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations during the probing phase by checking for specific conditions earlier.",
            "The optimization strategy involved reducing the number of iterations in a loop to speed up the probing process by limiting the search to a smaller, more relevant subset of data.",
            "The optimization strategy involved reducing the number of iterations in the probing function by limiting the scanned data size, thus improving performance.",
            "The optimization strategy involved simplifying the probing logic to reduce unnecessary computations during the initial detection phase.",
            "The optimization strategy involved reducing the number of iterations in the probing function by adjusting the logic to exit early when possible."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of iterations in the probing function by adjusting the logic to exit early when possible.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "fastclick",
        "hash": "e8dd2b3d505713c8fe224595812b9be37cb3acd9",
        "author": "eddietwo",
        "date": "2006-08-24T15:57:50+00:00",
        "message": "use raw bools, rather than : 1; same amount of space and maybe slightly faster (Koen Beel)",
        "modified_files_count": 1,
        "modified_files": [
            "elements/ip/checkipheader.cc"
        ],
        "github_commit_url": "https://github.com/tbarbette/fastclick/commit/e8dd2b3d505713c8fe224595812b9be37cb3acd9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CheckIPHeader::static_initialize"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced bit-field boolean variables with raw boolean variables to potentially improve performance while maintaining the same memory usage.",
            "The optimization strategy replaced bit-field boolean variables with raw boolean variables to potentially improve performance while maintaining the same memory usage.",
            "The optimization strategy replaced bit-field boolean variables with raw boolean variables to potentially improve performance while maintaining the same memory usage.",
            "The optimization strategy replaced bit-field booleans with raw booleans to potentially improve performance while maintaining the same memory usage.",
            "The optimization strategy replaced bit-field boolean variables with raw boolean types to potentially improve performance while maintaining the same memory usage."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaced bit-field boolean variables with raw boolean variables to potentially improve performance while maintaining the same memory usage.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "RVVM",
        "hash": "b3cb2aa8f2bab1efa6f962495328e42eb6ce827a",
        "author": "Alisa Sireneva",
        "date": "2025-02-12T23:25:32+03:00",
        "message": "Optimize bit_next_pow2 with intrinsics",
        "modified_files_count": 1,
        "modified_files": [
            "src/bit_ops.h"
        ],
        "github_commit_url": "https://github.com/LekKit/RVVM/commit/b3cb2aa8f2bab1efa6f962495328e42eb6ce827a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bit_next_pow2"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used intrinsic functions to improve the performance of the `bit_next_pow2` function by leveraging low-level hardware instructions for faster computation.",
            "The optimization strategy used intrinsic functions to improve the performance of the `bit_next_pow2` function by leveraging low-level hardware instructions.",
            "The optimization strategy used intrinsic functions to improve the performance of the `bit_next_pow2` function by leveraging low-level hardware instructions.",
            "The optimization strategy used intrinsic functions to improve the performance of the `bit_next_pow2` function by leveraging low-level hardware instructions for faster computation.",
            "The optimization strategy used intrinsic functions to improve the performance of the `bit_next_pow2` function by leveraging low-level hardware instructions for faster computation."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used intrinsic functions to improve the performance of the `bit_next_pow2` function by leveraging low-level hardware instructions for faster computation.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "477e88ee9e13d6902e359f9af526ac2eee6407a0",
        "author": "Evgeniy Stepanov",
        "date": "2013-02-19T13:38:27+00:00",
        "message": "[sanitizer] Slightly lower allocator test memory consumption.\n\nThis way it fits on a random 1G device.\n\nllvm-svn: 175513",
        "modified_files_count": 1,
        "modified_files": [
            "compiler-rt/lib/sanitizer_common/tests/sanitizer_allocator_test.cc"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/477e88ee9e13d6902e359f9af526ac2eee6407a0",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduced memory consumption in allocator tests to ensure compatibility with devices having limited memory (1GB).",
            "The optimization strategy reduced memory consumption in allocator tests to ensure compatibility with devices having limited memory (1GB).",
            "The optimization strategy reduced memory consumption in allocator tests to ensure compatibility with devices having limited memory (1GB).",
            "The optimization strategy reduced memory consumption in allocator tests to ensure compatibility with devices having limited memory (1GB).",
            "The optimization strategy reduced memory consumption in allocator tests to ensure compatibility with devices having limited memory (1GB)."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduced memory consumption in allocator tests to ensure compatibility with devices having limited memory (1GB).",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pcsx2",
        "hash": "24be4b4969d0103dab41b0f1bf8e627de9e67f98",
        "author": "Gregory Hainaut",
        "date": "2016-01-03T15:39:45+01:00",
        "message": "gsdx-ogl: remove unsafe fbmask of the free SW blending\n\nInitially it was free to do the SW blending because safe fbmask\nwill already do a sw blending.\n\nUnsafe version uses a fast path with a limited blending. Therefore\nSW blending isn't free anymore.\n\nImprove the speed of the previous speed hack (xenosaga 1)",
        "modified_files_count": 1,
        "modified_files": [
            "plugins/GSdx/GSRendererOGL.cpp"
        ],
        "github_commit_url": "https://github.com/PCSX2/pcsx2/commit/24be4b4969d0103dab41b0f1bf8e627de9e67f98",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GSRendererOGL::EmulateBlending"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes an unsafe fast path for software blending to improve performance by relying on a safer and already existing software blending method.",
            "The optimization removes an unsafe fast path for software blending to improve performance by relying on a safer and already existing software blending method.",
            "The optimization removes an unsafe fast path for software blending to improve performance by relying on a safer and already existing software blending method.",
            "The optimization removes an unsafe fast path for software blending to improve performance by relying on a safer and already existing software blending method.",
            "The optimization removes an unsafe fast path for software blending to improve performance by relying on a safer and already existing software blending method."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes an unsafe fast path for software blending to improve performance by relying on a safer and already existing software blending method.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "ee1fcb2fb684a54a3969adeb22108b62b18ea751",
        "author": "Mehdi Amini",
        "date": "2022-01-02T01:16:15+00:00",
        "message": "Apply clang-tidy fixes for performance-move-const-arg to MLIR (NFC)\n\nReviewed By: rriddle, Mogball\n\nDifferential Revision: https://reviews.llvm.org/D116249",
        "modified_files_count": 1,
        "modified_files": [
            "mlir/test/lib/Dialect/Linalg/TestLinalgTransforms.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/ee1fcb2fb684a54a3969adeb22108b62b18ea751",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "applyMatmulToVectorPatterns"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved applying clang-tidy fixes to eliminate unnecessary move operations on const arguments, reducing potential performance overhead.",
            "The optimization strategy involved applying clang-tidy fixes to eliminate unnecessary move operations on constant arguments, reducing potential performance overhead.",
            "The optimization strategy involved applying clang-tidy fixes to eliminate unnecessary move operations on constant arguments, reducing overhead.",
            "The optimization strategy involved applying clang-tidy fixes to eliminate unnecessary move operations on constant arguments, reducing overhead.",
            "The optimization strategy involved applying clang-tidy fixes to eliminate unnecessary move operations on constant arguments, reducing overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved applying clang-tidy fixes to eliminate unnecessary move operations on constant arguments, reducing overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "606c37c54160479130a7337e45efbdf01d013b13",
        "author": "Collin Funk",
        "date": "2024-04-12T16:39:05-06:00",
        "message": "nproc: Prefer sys/cdefs.h __unreachable over the builtin\n\nThe __builtin_unreachable macro provided by Clang and GCC is a hint to\nthe compiler used for optimization. The programs work fine even if the\ncompiler doesn't support it. The sys/cdefs.h has had __unreachable for\n9 years (commit 732b31de5d9244bd1cc98192e09ee1881e9f55e9). It expands\nto the builtin if it is available. In the rare case that it is\nunsupported it expands to a null statement so compilation does not\nfail.\n\nSigned-off-by: Collin Funk <collin.funk1@gmail.com>\nReviewed by: imp, freebsd@igalic.co\nPull Request: https://github.com/freebsd/freebsd-src/pull/1117",
        "modified_files_count": 1,
        "modified_files": [
            "bin/nproc/nproc.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/606c37c54160479130a7337e45efbdf01d013b13",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces the compiler-specific `__builtin_unreachable` with the more portable and standardized `__unreachable` macro from `sys/cdefs.h`, enabling broader compatibility while maintaining optimization hints.",
            "The optimization strategy replaces the compiler-specific `__builtin_unreachable` with the more portable and standardized `__unreachable` macro from `sys/cdefs.h`, ensuring broader compatibility while maintaining optimization hints.",
            "The optimization strategy replaces the compiler-specific `__builtin_unreachable` with the more portable and standardized `__unreachable` macro from `sys/cdefs.h`, ensuring broader compatibility while maintaining optimization hints.",
            "The optimization strategy replaces the compiler-specific `__builtin_unreachable` with the more portable and standardized `__unreachable` macro from `sys/cdefs.h`, ensuring broader compatibility while maintaining optimization hints.",
            "The optimization strategy replaces the compiler-specific `__builtin_unreachable` with the more portable and standardized `__unreachable` macro from `sys/cdefs.h`, ensuring broader compatibility while maintaining optimization hints."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces the compiler-specific `__builtin_unreachable` with the more portable and standardized `__unreachable` macro from `sys/cdefs.h`, ensuring broader compatibility while maintaining optimization hints.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "lustre-release",
        "hash": "afee2380c105c37e440aaa9ec588cd27189bc18e",
        "author": "Mr NeilBrown",
        "date": "2020-08-13T05:58:43+00:00",
        "message": "LU-12275 sec: use memchr_inv() to check if page is zero.\n\nmemchr_inv() is the preferred way to check if a memory region is all\nzeros.  It is likely fast that memcmp() is it doesn't need to read the\nZERO_PAGE into cache, or into the CPU.  It was introduced in Linux\n3.2.\n\nTest-Parameters: trivial\nSigned-off-by: Mr NeilBrown <neilb@suse.de>\nChange-Id: I0a5c3d30d5db43a3f5ebb270ea66b9db2b200a9a\nReviewed-on: https://review.whamcloud.com/39459\nTested-by: Maloo <maloo@whamcloud.com>\nTested-by: jenkins <devops@whamcloud.com>\nReviewed-by: Andreas Dilger <adilger@whamcloud.com>\nReviewed-by: James Simmons <jsimmons@infradead.org>\nReviewed-by: Sebastien Buisson <sbuisson@ddn.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lustre/osc/osc_request.c"
        ],
        "github_commit_url": "https://github.com/lustre/lustre-release/commit/afee2380c105c37e440aaa9ec588cd27189bc18e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "osc_brw_fini_request"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces a potentially slower `memcmp()` with the more efficient `memchr_inv()` to check if a memory region is all zeros, reducing cache and CPU overhead.",
            "The optimization strategy replaces a potentially slower memory comparison method with the more efficient `memchr_inv()` function to check if a memory region is entirely zero.",
            "The optimization strategy replaces a potentially slower `memcmp()` with the more efficient `memchr_inv()` to check if a memory region is all zeros, reducing cache and CPU overhead.",
            "The optimization strategy replaces a potentially slower `memcmp()` with the more efficient `memchr_inv()` to check if a memory region is all zeros, reducing cache and CPU overhead.",
            "The optimization replaces a potentially slower `memcmp()` with the more efficient `memchr_inv()` to check if a memory region is all zeros, reducing cache and CPU overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces a potentially slower `memcmp()` with the more efficient `memchr_inv()` to check if a memory region is all zeros, reducing cache and CPU overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sse2neon",
        "hash": "ab292f204fef23b9d59e76c3005ddea6712bb1fa",
        "author": "Sergey Sharybin",
        "date": "2024-08-16T18:00:54+02:00",
        "message": "Fix performance regression after OPTNONE changes\n\nThe OPTNONE changes in #638 introduced 25% performance regression in\nCycles render engine running on Apple Silicon:\n\n  https://projects.blender.org/blender/blender/issues/126408\n\nThe reason for this is because as per Clang documentation optnone is\nincompatible with inline, so none of the functions that is marked as\noptnone is inlined. The biggest bottleneck for Cycles after that\nchange is _mm_mul_ps.\n\nThis change makes it so _mm_mul_ps is inlined and is no longer marked\nas optnone. This solves the immediate performance regression, and the\ncorrectness is verified using the sse2neon's test suit on M2 Ultra\nand M3 Max, with various optimization levels (default, -O2, -O3).\n\nAdditionally, adding -Wstrict-aliasing flag does not introduce new\nwarnings.",
        "modified_files_count": 1,
        "modified_files": [
            "sse2neon.h"
        ],
        "github_commit_url": "https://github.com/DLTcollab/sse2neon/commit/ab292f204fef23b9d59e76c3005ddea6712bb1fa",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_mm_mul_ps"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing the `optnone` attribute from the `_mm_mul_ps` function to enable inlining, thereby addressing a performance regression caused by the incompatibility between `optnone` and `inline`.",
            "The optimization strategy involved removing the `optnone` attribute from the `_mm_mul_ps` function to enable inlining, thereby addressing a performance regression caused by the incompatibility between `optnone` and inlining.",
            "The optimization strategy involved removing the `optnone` attribute from the `_mm_mul_ps` function to enable inlining, thereby addressing a performance regression caused by the incompatibility between `optnone` and inlining.",
            "The optimization strategy involved removing the `optnone` attribute from the `_mm_mul_ps` function to enable inlining, thereby addressing a performance regression caused by the incompatibility between `optnone` and inlining.",
            "The optimization strategy involved removing the `optnone` attribute from the `_mm_mul_ps` function to enable inlining, thereby addressing a performance regression caused by the incompatibility between `optnone` and `inline`."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing the `optnone` attribute from the `_mm_mul_ps` function to enable inlining, thereby addressing a performance regression caused by the incompatibility between `optnone` and inlining.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "njs",
        "hash": "aa697e3e98b479f8e62d756512f5b6db427b7a84",
        "author": "Dmitry Volyntsev",
        "date": "2023-10-04T13:35:38-07:00",
        "message": "Improved memory footprint of RegExp.prototype.split().",
        "modified_files_count": 1,
        "modified_files": [
            "src/njs_regexp.c"
        ],
        "github_commit_url": "https://github.com/nginx/njs/commit/aa697e3e98b479f8e62d756512f5b6db427b7a84",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "njs_regexp_prototype_symbol_split"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory usage by avoiding unnecessary allocations during the splitting process of `RegExp.prototype.split()`.",
            "The optimization strategy involved reducing memory allocations by reusing existing buffers in the `RegExp.prototype.split()` implementation.",
            "The optimization strategy involved reducing memory usage by avoiding unnecessary allocations during the splitting process in `RegExp.prototype.split()`.",
            "The optimization strategy involved reducing memory usage by avoiding unnecessary allocations during the splitting process of `RegExp.prototype.split()`.",
            "The optimization strategy involved reducing memory usage by avoiding unnecessary allocations during the splitting process of `RegExp.prototype.split()`."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory usage by avoiding unnecessary allocations during the splitting process of `RegExp.prototype.split()`.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "92ce43309072e09bf558d91b1291067de67ced40",
        "author": "Marc-André Moreau",
        "date": "2013-05-16T19:56:39-04:00",
        "message": "libfreerdp-codec: optimize color conversion a bit",
        "modified_files_count": 1,
        "modified_files": [
            "libfreerdp/codec/color.c"
        ],
        "github_commit_url": "https://github.com/FreeRDP/FreeRDP/commit/92ce43309072e09bf558d91b1291067de67ced40",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "freerdp_image_convert_16bpp"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "FreeRDP",
        "optimization_summary": [
            "The optimization strategy involved replacing a multiplication operation with a bit shift to improve the efficiency of color conversion in 16bpp images.",
            "The optimization strategy involved simplifying color conversion calculations by directly manipulating pixel data to reduce unnecessary computations.",
            "The optimization strategy involved replacing a multiplication operation with a bit shift to improve the performance of color conversion in 16bpp images.",
            "The optimization strategy involved simplifying color conversion logic by reducing unnecessary computations and improving the efficiency of bitwise operations.",
            "The optimization strategy involved simplifying color conversion logic by reducing unnecessary computations and improving the efficiency of pixel processing."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying color conversion logic by reducing unnecessary computations and improving the efficiency of pixel processing.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "TrinityCore",
        "hash": "bf6102e7ed8866feba28622eb3b0089812ec5f36",
        "author": "megamage",
        "date": "2009-07-10T08:38:35+08:00",
        "message": "Minor optimizations to MSG_QUERY_NEXT_MAIL_TIME handler. Author: hunuza\n\n    * Do not search for more unread mails when already found 2.\n    * Do not call time(NULL) every iteration.\n\n--HG--\nbranch : trunk",
        "modified_files_count": 1,
        "modified_files": [
            "src/game/Mail.cpp"
        ],
        "github_commit_url": "https://github.com/TrinityCore/TrinityCore/commit/bf6102e7ed8866feba28622eb3b0089812ec5f36",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WorldSession::HandleQueryNextMailTime"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary iterations and redundant function calls by stopping the search for unread mails after finding two and caching the result of `time(NULL)`.",
            "The optimization avoids unnecessary iterations and redundant function calls by stopping the search for unread mails after finding two and caching the result of `time(NULL)`.",
            "The optimization avoids unnecessary iterations and redundant function calls by stopping the search for unread mails after finding two and caching the result of `time(NULL)`.",
            "The optimization avoids unnecessary iterations and redundant function calls by stopping the search for unread mails after finding two and caching the result of `time(NULL)`.",
            "The optimization strategy involves early termination of a loop when a condition is met and reducing redundant function calls within the loop."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary iterations and redundant function calls by stopping the search for unread mails after finding two and caching the result of `time(NULL)`.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kernel-copyleft",
        "hash": "62d9811b0374021efcacfffc698785aaf5e02f95",
        "author": "Punit Soni",
        "date": "2013-01-09T14:36:05-08:00",
        "message": "msm: camera: remove frame delay at start_stream in msm_sensor\n\nrequired for latency optimization\n\nChange-Id: I3d039e21ee8736cf8df1373d5386671f77f2382c\nSigned-off-by: Punit Soni <punits@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/media/video/msm/sensors/msm_sensor.c"
        ],
        "github_commit_url": "https://github.com/sonyxperiadev/kernel-copyleft/commit/62d9811b0374021efcacfffc698785aaf5e02f95",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "msm_sensor_start_stream"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing an unnecessary frame delay during the start of the camera stream to reduce latency.",
            "The optimization strategy involved removing an unnecessary frame delay during the start of the camera stream to reduce latency.",
            "The optimization strategy involved removing an unnecessary frame delay during the start of the camera stream to reduce latency.",
            "The optimization strategy involved removing an unnecessary frame delay during the start of a camera stream to reduce latency.",
            "The optimization strategy involved removing an unnecessary frame delay during the start of the camera stream to reduce latency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing an unnecessary frame delay during the start of the camera stream to reduce latency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tcmalloc",
        "hash": "f374ca655b312aa02e60e6b16699ab729bb10260",
        "author": "Dmitry Vyukov",
        "date": "2023-08-31T23:08:56-07:00",
        "message": "tcmalloc: speed up aligned new and malloc\n\nCurrnetly we do alignment check even for requested alignment <= 8,\nthis is unnecessary. Also \"size_class % kNumBaseClasses\" leads to quite\ninefficient codegen:\n\n  313685:       ff c1                   inc    %ecx\n  313687:       4c 69 c1 83 be a0 2f    imul   $0x2fa0be83,%rcx,%r8\n  31368e:       49 c1 e8 24             shr    $0x24,%r8\n  313692:       45 6b c0 56             imul   $0x56,%r8d,%r8d\n  313696:       41 39 c8                cmp    %ecx,%r8d\n  313699:       75 dd                   jne    313678 <TCMallocInternalNewAligned+0x38>\n  31369b:       e9 a8 00 00 00          jmp    313748 <TCMallocInternalNewAligned+0x108>\n\nThis check is not necessary at all, since we are guaranteed to find\na size class with page alignment.\n\nname                        old cpu/op   new cpu/op   delta\nBM_aligned_new/1/8          8.40ns ± 1%  6.34ns ± 0%  -24.57%  (p=0.008 n=5+5)\nBM_aligned_new/8/8          8.38ns ± 1%  6.33ns ± 0%  -24.51%  (p=0.016 n=5+4)\nBM_aligned_new/64/8         8.33ns ± 1%  6.54ns ± 3%  -21.56%  (p=0.008 n=5+5)\nBM_aligned_new/512/8        8.50ns ± 1%  6.52ns ± 1%  -23.40%  (p=0.008 n=5+5)\nBM_aligned_new/4096/8       10.3ns ± 4%   8.4ns ± 0%  -18.76%  (p=0.016 n=5+4)\nBM_aligned_new/32768/8      19.2ns ± 1%  17.4ns ± 0%   -9.30%  (p=0.029 n=4+4)\nBM_aligned_new/262144/8     85.8ns ± 0%  85.5ns ± 0%     ~     (p=0.200 n=4+4)\nBM_aligned_new/1048576/8     274ns ± 7%   268ns ± 1%     ~     (p=0.310 n=5+5)\nBM_aligned_new/1/64         12.6ns ± 0%   9.1ns ± 1%  -27.84%  (p=0.008 n=5+5)\nBM_aligned_new/8/64         12.6ns ± 1%   9.0ns ± 0%  -28.34%  (p=0.008 n=5+5)\nBM_aligned_new/64/64        8.33ns ± 1%  7.10ns ± 1%  -14.79%  (p=0.008 n=5+5)\nBM_aligned_new/512/64       8.49ns ± 1%  7.26ns ± 1%  -14.49%  (p=0.008 n=5+5)\nBM_aligned_new/4096/64      10.4ns ± 0%   9.3ns ± 5%   -9.91%  (p=0.016 n=4+5)\nBM_aligned_new/32768/64     19.1ns ± 0%  18.0ns ± 0%   -6.02%  (p=0.029 n=4+4)\nBM_aligned_new/262144/64    85.8ns ± 0%  86.0ns ± 0%     ~     (p=0.486 n=4+4)\nBM_aligned_new/1048576/64    386ns ±33%   348ns ±37%     ~     (p=0.548 n=5+5)\nBM_aligned_new/65/64        17.8ns ± 0%  13.4ns ± 2%  -24.60%  (p=0.008 n=5+5)\n\nPiperOrigin-RevId: 561863242\nChange-Id: Ibbaf5ff955c9a890e0045c4215ef70eb680dd59d",
        "modified_files_count": 1,
        "modified_files": [
            "tcmalloc/sizemap.h"
        ],
        "github_commit_url": "https://github.com/google/tcmalloc/commit/f374ca655b312aa02e60e6b16699ab729bb10260",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetSizeClass"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes unnecessary alignment checks and modulo operations for size classes, leveraging guaranteed page alignment to improve performance.",
            "The optimization removes unnecessary alignment checks and modulo operations for size classes, leveraging guaranteed page alignment to improve performance.",
            "The optimization removes unnecessary alignment checks and modulo operations for size classes, leveraging guaranteed page alignment to improve performance.",
            "The optimization removes unnecessary alignment checks and replaces an inefficient modulo operation with a guaranteed size class lookup for page alignment.",
            "The optimization removes unnecessary alignment checks and replaces an inefficient modulo operation with a guaranteed size class lookup for page alignment."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization removes unnecessary alignment checks and modulo operations for size classes, leveraging guaranteed page alignment to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "fe488ccefff1730e2b9d0cc16650fc512e5d61b6",
        "author": "Yunqing Wang",
        "date": "2016-08-19T09:30:32-07:00",
        "message": "Adjust speed features for 4k video encoding\n\nAdjusted speed 2 features to speed up 4k video encoding.\nBDBR results from borg test:\nPSNR: +0.313%; SSIM: +0.268%.\nAverage speedup: 8.5%\n\nChange-Id: I1e2695a01fb3f3817c1df4480e184c2aed8f2eba",
        "modified_files_count": 1,
        "modified_files": [
            "vp9/encoder/vp9_speed_features.c"
        ],
        "github_commit_url": "https://github.com/webmproject/libvpx/commit/fe488ccefff1730e2b9d0cc16650fc512e5d61b6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "set_good_speed_feature_framesize_dependent"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "libvpx",
        "optimization_summary": [
            "The optimization strategy involved adjusting encoder speed features specifically tailored for 4K video encoding to achieve faster processing with minimal quality degradation.",
            "The optimization strategy involved adjusting encoder speed features specifically tailored for 4K video encoding to achieve faster processing with minimal quality degradation.",
            "The optimization strategy involved adjusting encoder speed features specifically tailored for 4K video encoding to achieve a balance between compression efficiency and encoding speed.",
            "The optimization strategy involved adjusting encoder speed features specifically tailored for 4K video encoding to achieve a balance between compression efficiency and encoding speed.",
            "The optimization strategy involved adjusting encoder speed features specifically tailored for 4K video encoding to achieve faster processing with minimal quality degradation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting encoder speed features specifically tailored for 4K video encoding to achieve faster processing with minimal quality degradation.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "a247e83bb45da02d79c85301bfa8068735aa1649",
        "author": "Keith Bostic",
        "date": "2014-03-19T14:27:07-04:00",
        "message": "If the on-page overflow cell is known to be WT_CELL_VALUE_OVFL_RM,\nthere's no reason to acquire/release the overflow lock, it's not\nlike the value gets re-instantiated somehow.  Fast path that case;\nit's hard to imagine a workload where it makes a difference, but\nit's not like it costs us much code, either.",
        "modified_files_count": 1,
        "modified_files": [
            "src/btree/bt_ovfl.c"
        ],
        "github_commit_url": "https://github.com/wiredtiger/wiredtiger/commit/a247e83bb45da02d79c85301bfa8068735aa1649",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__wt_ovfl_read"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "wiredtiger",
        "optimization_summary": [
            "The optimization avoids acquiring and releasing the overflow lock when the cell type is known to be WT_CELL_VALUE_OVFL_RM, as re-instantiation of the value is not possible.",
            "The optimization avoids acquiring and releasing the overflow lock for a specific cell type (WT_CELL_VALUE_OVFL_RM) since its value cannot be re-instantiated, reducing unnecessary locking overhead.",
            "The optimization avoids acquiring and releasing the overflow lock when the cell type is known to be WT_CELL_VALUE_OVFL_RM, as re-instantiation of the value is not possible.",
            "The optimization avoids acquiring and releasing the overflow lock when the cell type is known to be WT_CELL_VALUE_OVFL_RM, as re-instantiation of the value is not possible.",
            "The optimization avoids acquiring and releasing the overflow lock when the cell type is known to be WT_CELL_VALUE_OVFL_RM, as re-instantiation of the value is not possible."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids acquiring and releasing the overflow lock when the cell type is known to be WT_CELL_VALUE_OVFL_RM, as re-instantiation of the value is not possible.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ffmpeg",
        "hash": "183a86c958c9ebeb3458240f1b76b1d809682c10",
        "author": "Michael Niedermayer",
        "date": "2010-01-16T16:21:12+00:00",
        "message": "Apply last 2 optimizations to similar code i forgot.\n\nOriginally committed as revision 21249 to svn://svn.ffmpeg.org/ffmpeg/trunk",
        "modified_files_count": 1,
        "modified_files": [
            "libavcodec/h264_loopfilter.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/183a86c958c9ebeb3458240f1b76b1d809682c10",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "filter_mb_dir"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit applies previously implemented optimizations to a similar code section, likely improving performance by reusing proven strategies.",
            "The commit applies previously implemented optimizations to a similar code section, likely reducing redundant computations or improving loop efficiency.",
            "The commit applies previously implemented optimizations to overlooked sections of the code, likely reducing redundant computations or improving efficiency in a similar manner.",
            "The commit applies previously implemented optimizations to a function that was missed, likely improving performance by reusing proven strategies.",
            "The commit applies previously implemented optimizations to overlooked sections of the code, likely reducing redundant computations or improving efficiency in a similar manner."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit applies previously implemented optimizations to overlooked sections of the code, likely reducing redundant computations or improving efficiency in a similar manner.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dxvk-remix",
        "hash": "937d0d0fc687dbcd97d25fb5cf2e112768d04e65",
        "author": "Philip Rebohle",
        "date": "2019-10-14T00:14:00+02:00",
        "message": "[d3d11] Don't sync CS thread if resource to map is already in use\n\nSynchronizeCsThread can only update the in-use state from available\nto in-use, so doing this on a resource that is already in-use is not\nnecessary. May improve performance in combination with DO_NOT_WAIT.",
        "modified_files_count": 1,
        "modified_files": [
            "src/d3d11/d3d11_context_imm.cpp"
        ],
        "github_commit_url": "https://github.com/NVIDIAGameWorks/dxvk-remix/commit/937d0d0fc687dbcd97d25fb5cf2e112768d04e65",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "D3D11ImmediateContext::WaitForResource"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary synchronization of the CS thread by skipping the operation if the resource is already in use.",
            "The optimization avoids unnecessary synchronization of the CS thread by skipping the operation if the resource is already in use.",
            "The optimization avoids unnecessary synchronization of the CS thread by skipping the operation if the resource is already in use.",
            "The optimization avoids unnecessary synchronization of the CS thread by checking if a resource is already in use before proceeding.",
            "The optimization avoids unnecessary synchronization of the CS thread by checking if the resource is already in use before proceeding."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary synchronization of the CS thread by skipping the operation if the resource is already in use.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ceph",
        "hash": "4712e984d3f62cdf51ea67da8197eed18a5983dd",
        "author": "Sage Weil",
        "date": "2013-01-18T15:44:41-08:00",
        "message": "osd: make pg removal thread more friendly\n\nFor a large PG these are saturating the filestore and journal queues.  Do\nthem synchronously to make them more friendly.  They don't need to be fast.\n\nSigned-off-by: Sage Weil <sage@inktank.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/osd/OSD.cc"
        ],
        "github_commit_url": "https://github.com/ceph/ceph/commit/4712e984d3f62cdf51ea67da8197eed18a5983dd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OSD::RemoveWQ::_process"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves processing PG removal tasks synchronously instead of asynchronously to reduce saturation of the filestore and journal queues.",
            "The optimization strategy involves processing PG removal tasks synchronously instead of asynchronously to reduce saturation of the filestore and journal queues.",
            "The optimization strategy involves processing PG removal tasks synchronously instead of asynchronously to reduce saturation of the filestore and journal queues.",
            "The optimization strategy involves processing PG removal tasks synchronously instead of asynchronously to reduce saturation of the filestore and journal queues.",
            "The optimization strategy involved changing the PG removal process to execute synchronously instead of asynchronously to reduce resource saturation and improve overall system responsiveness."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves processing PG removal tasks synchronously instead of asynchronously to reduce saturation of the filestore and journal queues.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mlt",
        "hash": "36310193f4577075762be7f4ce6ccc35a2d537dc",
        "author": "Dan Dennedy",
        "date": "2010-02-08T00:44:26-08:00",
        "message": "Fix audio muxing when downsampling >2 channels.\n\nA side effect of this bug was a big memory consumption. This occurs\nmostly commonly when using 5.1 audio sources such as AVCHD or DVD and\nencoding to 44.1 KHz.",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/avformat/producer_avformat.c"
        ],
        "github_commit_url": "https://github.com/mltframework/mlt/commit/36310193f4577075762be7f4ce6ccc35a2d537dc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "producer_get_audio"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved fixing a bug that caused excessive memory consumption during audio downsampling, particularly for multi-channel sources.",
            "The optimization strategy involved fixing a bug that caused excessive memory consumption during audio downsampling, particularly for multi-channel sources.",
            "The optimization strategy involved fixing a bug that caused excessive memory consumption during audio downsampling, particularly for multi-channel sources.",
            "The optimization strategy involved fixing a bug that caused excessive memory consumption during audio downsampling, particularly for multi-channel sources.",
            "The optimization strategy involved fixing a bug that caused excessive memory consumption during audio downsampling, particularly for multi-channel sources."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved fixing a bug that caused excessive memory consumption during audio downsampling, particularly for multi-channel sources.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "d2ed0f45e76a3b930ec5db3c4832326ba7b3439b",
        "author": "Tomasz Zawadzki",
        "date": "2021-07-12T21:58:56+00:00",
        "message": "scheduler_dynamic: scale up core load when moving thread\n\nBefore this patch the idle time of a core was increased\nby the amount of busy time of thread that was moved out.\nNo assumption was made as to how the remaining threads,\nwould behave during next scheduling period.\n\nThis approach is fine, as over multiple scheduling periods\nwe'd arrive at a point where threads could do no more work\nor all cores would be busy.\n\nYet this requires multiple scheduling periods to sort out\nthe threads.\nLater in the series core_load will be used to determine,\nwhen to start moving threads out of the core. So changing\nthis assumption will allow for faster responses to thread load,\nat cost of sometimes spreading threads too much briefly.\n\nWith this patch, we are assuming that threads remaining\non the core will do proportionally the same amount of work\nduring next scheduling period.\n\nSee an example illustrating the change:\n\nBefore moving Thread1\nThread1\tBusy 80\t\tIdle 20\t\tLoad 80%\nThread2\tBusy 60\t\tIdle 40\t\tLoad 60%\nCore\tBusy 140\tIdle 60\t\tLoad 70%\n\nAfter moving Thread1 out (original code)\nCore\tBusy 140-80=60\tIdle 60+80=140\tLoad 30%\n\nAfter moving Thread1 out (this patch)\nCore\tBusy 140-80=60\tIdle 60-20=40\tLoad 60%\n\nSigned-off-by: Tomasz Zawadzki <tomasz.zawadzki@intel.com>\nChange-Id: I1f347983449b2fde476dab360c4df689965ca3ea\nReviewed-on: https://review.spdk.io/gerrit/c/spdk/spdk/+/8279\nCommunity-CI: Broadcom CI <spdk-ci.pdl@broadcom.com>\nCommunity-CI: Mellanox Build Bot\nTested-by: SPDK CI Jenkins <sys_sgci@intel.com>\nReviewed-by: Krzysztof Karas <krzysztof.karas@intel.com>\nReviewed-by: Shuhei Matsumoto <shuhei.matsumoto.xt@hitachi.com>\nReviewed-by: Ben Walker <benjamin.walker@intel.com>\nReviewed-by: Maciej Szwed <maciej.szwed@intel.com>\nReviewed-by: Jim Harris <james.r.harris@intel.com>\nReviewed-by: Konrad Sztyber <konrad.sztyber@intel.com>\nReviewed-by: Paul Luse <paul.e.luse@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/event/scheduler_dynamic.c"
        ],
        "github_commit_url": "https://github.com/spdk/spdk/commit/d2ed0f45e76a3b930ec5db3c4832326ba7b3439b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_move_thread"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "spdk",
        "optimization_summary": [
            "The optimization strategy adjusts core load calculation when moving threads by assuming proportional work distribution among remaining threads, enabling faster response to thread load changes.",
            "The optimization strategy adjusts the core load calculation when moving threads by assuming proportional work distribution among remaining threads, enabling faster response to thread load changes.",
            "The optimization strategy assumes proportional work distribution among remaining threads after a thread is moved, reducing idle time adjustments and enabling faster load balancing responses.",
            "The optimization strategy adjusts core load calculations when moving threads by assuming proportional work distribution among remaining threads, enabling faster response to thread load changes.",
            "The optimization strategy adjusts core load calculations when moving threads by assuming proportional work distribution among remaining threads, enabling faster response to thread load changes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy adjusts core load calculations when moving threads by assuming proportional work distribution among remaining threads, enabling faster response to thread load changes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "de375aa860fb848eaabc76dce0af2e982630b421",
        "author": "Jerry Ray",
        "date": "2023-01-20T08:53:13+00:00",
        "message": "dsa: lan9303: write reg only if necessary\n\nAs the regmap_write() is over a slow bus that will sleep, we can speed up\nthe boot-up time a bit by not bothering to clear a bit that is already\nclear.\n\nSigned-off-by: Jerry Ray <jerry.ray@microchip.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/dsa/lan9303-core.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/de375aa860fb848eaabc76dce0af2e982630b421",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "lan9303_setup"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary register writes by checking if a bit is already clear before performing a write operation over a slow bus.",
            "The optimization avoids unnecessary register writes by checking if a bit is already clear before performing a write operation over a slow bus.",
            "The optimization avoids unnecessary register writes by checking if a bit is already clear before performing a write operation over a slow bus.",
            "The optimization avoids unnecessary register writes by checking if a bit is already clear before performing a write operation over a slow bus.",
            "The optimization avoids unnecessary register writes by checking if a bit is already clear before attempting to clear it, reducing overhead on a slow bus."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary register writes by checking if a bit is already clear before performing a write operation over a slow bus.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kernel-copyleft",
        "hash": "58db2c1f94451d7a352d2ad1a1b1e9732f4f0a11",
        "author": "Pavankumar Kondeti",
        "date": "2013-01-28T19:50:45+05:30",
        "message": "USB: ci13xxx_udc: Don't flush inactive endpoints\n\nThe endpoint must be flushed prior to retiring pending requests.\nThis is done during disabling an endpoint.  Don't flush an endpoint\nif there are no pending requests.  According databook flushing\nendpoint may take large amount of time.  This optimization will\nmake USB disconnect/reset processing a little bit faster.\n\nCRs-Fixed: 445916\nChange-Id: I035b624dbac4529bbe33a67f9e7e1916d4772d6f\nSigned-off-by: Pavankumar Kondeti <pkondeti@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/usb/gadget/ci13xxx_udc.c"
        ],
        "github_commit_url": "https://github.com/sonyxperiadev/kernel-copyleft/commit/58db2c1f94451d7a352d2ad1a1b1e9732f4f0a11",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fifo"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary flushing of inactive endpoints by checking for pending requests before flushing, reducing processing time during USB disconnect/reset operations.",
            "The optimization avoids unnecessary flushing of inactive endpoints by checking for pending requests before flushing, reducing processing time during USB disconnect/reset operations.",
            "The optimization avoids unnecessary flushing of inactive endpoints by checking for pending requests before flushing, reducing processing time during USB disconnect/reset operations.",
            "The optimization avoids unnecessary flushing of inactive endpoints by checking for pending requests before flushing, reducing processing time during USB disconnect/reset operations.",
            "The optimization avoids unnecessary flushing of inactive endpoints by checking for pending requests before flushing, reducing processing time during USB disconnect/reset operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary flushing of inactive endpoints by checking for pending requests before flushing, reducing processing time during USB disconnect/reset operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "5af41974c3876ce02950ff9d371330ef0826603d",
        "author": "Chris Lattner",
        "date": "2003-10-13T14:55:56+00:00",
        "message": "Speed up TypesEqual by specializing it for all of the derived types, avoiding\na lot of virtual method dispatch overhead.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@9078 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/VMCore/Type.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/5af41974c3876ce02950ff9d371330ef0826603d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TypesEqual"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy specializes the `TypesEqual` function for derived types to eliminate virtual method dispatch overhead.",
            "The optimization strategy specializes the `TypesEqual` function for derived types to eliminate virtual method dispatch overhead.",
            "The optimization strategy specializes the `TypesEqual` function for derived types to eliminate virtual method dispatch overhead.",
            "The optimization strategy specializes the `TypesEqual` function for derived types to eliminate virtual method dispatch overhead.",
            "The optimization strategy specializes the `TypesEqual` function for derived types to eliminate virtual method dispatch overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy specializes the `TypesEqual` function for derived types to eliminate virtual method dispatch overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "25369cfa2b33606cff971226fb4182109ff3646b",
        "author": "Chris Lattner",
        "date": "2004-08-01T08:12:41+00:00",
        "message": "Handle registers a bit more efficiently\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@15395 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Target/X86/X86AsmPrinter.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/25369cfa2b33606cff971226fb4182109ff3646b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "printOperand"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving register handling efficiency by reducing unnecessary operations or lookups in the `printOperand` function.",
            "The optimization strategy involved improving register handling efficiency by reducing unnecessary operations or checks when printing operands.",
            "The optimization strategy involved improving register handling efficiency by reducing unnecessary operations or checks when printing operands.",
            "The optimization strategy involved improving register handling efficiency by reducing unnecessary operations or lookups in the `printOperand` function.",
            "The optimization strategy involved improving register handling efficiency by reducing unnecessary operations or checks when printing operands."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving register handling efficiency by reducing unnecessary operations or checks when printing operands.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow-directml",
        "hash": "197f573f3bd830bbc4dc277e7c8b8cfaca65e14a",
        "author": "A. Unique TensorFlower",
        "date": "2018-01-29T10:16:17-08:00",
        "message": "Reduce memory wasted by GCS cache by shrinking buffer capacity, after a cache fill completes.\n\nPiperOrigin-RevId: 183683856",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/core/platform/cloud/file_block_cache.cc"
        ],
        "github_commit_url": "https://github.com/microsoft/tensorflow-directml/commit/197f573f3bd830bbc4dc277e7c8b8cfaca65e14a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FileBlockCache::MaybeFetch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces memory waste by dynamically shrinking the buffer capacity of the GCS cache after it is filled.",
            "The optimization reduces memory waste by dynamically shrinking the buffer capacity of the GCS cache after it is filled.",
            "The optimization strategy reduces memory waste by dynamically shrinking the buffer capacity of the GCS cache after it has been filled.",
            "The optimization strategy reduces memory waste by dynamically shrinking the buffer capacity of the GCS cache after a cache fill operation completes.",
            "The optimization reduces memory waste by dynamically shrinking the buffer capacity of the GCS cache after it is filled."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces memory waste by dynamically shrinking the buffer capacity of the GCS cache after it is filled.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "peercoin",
        "hash": "b3d7b1cbe7afdc6a63bbcbe938e8639deedb04a1",
        "author": "Gregory Maxwell",
        "date": "2017-01-05T18:15:01+00:00",
        "message": "Wallet: Do not perform ECDSA in the fee calculation inner loop.\n\nPerforming signing in the inner loop has terrible performance\n when many passes through are needed to complete the selection.\n\nSigning before the algorithm is complete also gets in the way\n of correctly setting the fee (e.g. preventing over-payment when\n the fee required goes down on the final selection.)\n\nUse of the dummy might overpay on the signatures by a couple bytes\n in uncommon cases where the signatures' DER encoding is smaller\n than the dummy: Who cares?",
        "modified_files_count": 1,
        "modified_files": [
            "src/wallet/wallet.cpp"
        ],
        "github_commit_url": "https://github.com/peercoin/peercoin/commit/b3d7b1cbe7afdc6a63bbcbe938e8639deedb04a1",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids performing ECDSA signing in the fee calculation inner loop by using a dummy signature to reduce computational overhead and improve performance.",
            "The optimization strategy avoids performing ECDSA signing in the fee calculation inner loop to reduce computational overhead and improve performance.",
            "The optimization avoids performing ECDSA signing in the fee calculation inner loop to reduce computational overhead and improve performance.",
            "The optimization avoids performing ECDSA signing in the fee calculation inner loop to reduce computational overhead and improve performance.",
            "The optimization strategy avoids performing ECDSA signing in the fee calculation inner loop to reduce computational overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids performing ECDSA signing in the fee calculation inner loop to reduce computational overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "uTox",
        "hash": "b2270eff985b94d1e4fedc89587ea98253645ca1",
        "author": "GrayHatter",
        "date": "2016-03-12T10:33:05-08:00",
        "message": "Merge pull request #241 from master-passeli/issue237_speedup_mouse_scroll\n\nFix for issue #237 mouse wheel scroll is very slow",
        "modified_files_count": 1,
        "modified_files": [
            "src/scrollable.c"
        ],
        "github_commit_url": "https://github.com/uTox/uTox/commit/b2270eff985b94d1e4fedc89587ea98253645ca1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "scroll_mwheel"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations in the mouse wheel scroll logic to improve responsiveness.",
            "The optimization strategy involved reducing redundant computations in the mouse wheel scroll logic to improve responsiveness.",
            "The optimization strategy involved reducing redundant calculations in the mouse wheel scroll function by caching and reusing previously computed values.",
            "The optimization strategy involved reducing redundant computations in the mouse wheel scroll logic to improve responsiveness.",
            "The optimization strategy involved reducing redundant calculations and improving the efficiency of mouse wheel scroll handling by directly computing scroll offsets."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations in the mouse wheel scroll logic to improve responsiveness.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dolphin",
        "hash": "c817b4779daf6b58a25bfb194a156e3215177574",
        "author": "Sintendo",
        "date": "2024-12-28T23:20:22+01:00",
        "message": "JitArm64_Integer: addzex - Optimize InPPCState case for 0\n\nBefore:\n0x52800019   mov    w25, #0x0                 ; =0\n0x394bd3b8   ldrb   w24, [x29, #0x2f4]\n0x2b180339   adds   w25, w25, w24\n\nAfter:\n0x394bd3b9   ldrb   w25, [x29, #0x2f4]",
        "modified_files_count": 1,
        "modified_files": [
            "Source/Core/Core/PowerPC/JitArm64/JitArm64_Integer.cpp"
        ],
        "github_commit_url": "https://github.com/dolphin-emu/dolphin/commit/c817b4779daf6b58a25bfb194a156e3215177574",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "JitArm64::addzex"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization eliminates an unnecessary zero-initialization and directly loads the value into the target register.",
            "The optimization eliminates an unnecessary zero-initialization and directly loads the value into the target register.",
            "The optimization eliminates an unnecessary zero-initialization and directly loads the value into the target register.",
            "The optimization eliminates unnecessary zero-initialization and directly loads the value into the target register.",
            "The optimization eliminates an unnecessary zero-initialization and directly loads the value into the target register."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization eliminates an unnecessary zero-initialization and directly loads the value into the target register.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "llvm-leg",
        "hash": "b16117c368ad4e6d004ac912549b2c6ed06731a5",
        "author": "Chandler Carruth",
        "date": "2012-03-14T20:16:41+00:00",
        "message": "Change where we enable the heuristic that delays inlining into functions\nwhich are small enough to themselves be inlined. Delaying in this manner\ncan be harmful if the function is inelligible for inlining in some (or\nmany) contexts as it pessimizes the code of the function itself in the\nevent that inlining does not eventually happen.\n\nPreviously the check was written to only do this delaying of inlining\nfor static functions in the hope that they could be entirely deleted and\nin the knowledge that all callers of static functions will have the\nopportunity to inline if it is in fact profitable. However, with C++ we\nget two other important sources of functions where the definition is\nalways available for inlining: inline functions and templated functions.\nThis patch generalizes the inliner to allow linkonce-ODR (the linkage\nsuch C++ routines receive) to also qualify for this delay-based\ninlining.\n\nBenchmarking across a range of large real-world applications shows\nroughly 2% size increase across the board, but an average speedup of\nabout 0.5%. Some benhcmarks improved over 2%, and the 'clang' binary\nitself (when bootstrapped with this feature) shows a 1% -O0 performance\nimprovement when run over all Sema, Lex, and Parse source code smashed\ninto a single file. A clean re-build of Clang+LLVM with a bootstrapped\nClang shows approximately 2% improvement, but that measurement is often\nnoisy.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@152737 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Transforms/IPO/Inliner.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/b16117c368ad4e6d004ac912549b2c6ed06731a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Inliner::shouldInline"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy delays inlining for small functions with linkonce-ODR linkage to improve performance by avoiding unnecessary code bloat when inlining is not profitable.",
            "The optimization strategy delays inlining for small functions with linkonce-ODR linkage to improve performance by avoiding unnecessary code bloat when inlining is not profitable.",
            "The optimization strategy delays inlining for small functions with linkonce-ODR linkage to improve performance by avoiding premature pessimizations when inlining is not profitable.",
            "The optimization strategy delays inlining for small functions with linkonce-ODR linkage to improve performance by avoiding premature pessimizations.",
            "The optimization strategy delays inlining for small functions with linkonce-ODR linkage to improve performance by avoiding unnecessary code bloat when inlining is not profitable."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy delays inlining for small functions with linkonce-ODR linkage to improve performance by avoiding unnecessary code bloat when inlining is not profitable.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "366f6292ee8d171383dcc5a50eb5dc02bb795f70",
        "author": "Jakob Kummerow",
        "date": "2017-09-01T15:57:45+00:00",
        "message": "Revert \"[modules] Temporarily disable IC support for namespace accesses\"\n\nThis reverts commit fbe184a602092d09c6608d029e192d356e4261cb.\n\nReason for revert: Baseline performance test score established, re-enabling feature.\n\nOriginal change's description:\n> [modules] Temporarily disable IC support for namespace accesses\n> \n> To get a proper performance baseline after fixing the perf tests in\n> https://chromium-review.googlesource.com/c/v8/v8/+/639396.\n> \n> This is intended to be reverted after a couple of hours.\n> \n> Change-Id: If36e4bfa5bd113599652f5c2016f886533af2746\n> Reviewed-on: https://chromium-review.googlesource.com/639057\n> Reviewed-by: Adam Klein <adamk@chromium.org>\n> Commit-Queue: Jakob Kummerow <jkummerow@chromium.org>\n> Cr-Commit-Position: refs/heads/master@{#47753}\n\nTBR=adamk@chromium.org,jkummerow@chromium.org\n\nChange-Id: Ia92e3247bc594e2fa6c937d379fa172244df2d8a\nNo-Presubmit: true\nNo-Tree-Checks: true\nNo-Try: true\nReviewed-on: https://chromium-review.googlesource.com/647966\nReviewed-by: Jakob Kummerow <jkummerow@chromium.org>\nCommit-Queue: Jakob Kummerow <jkummerow@chromium.org>\nCr-Commit-Position: refs/heads/master@{#47775}",
        "modified_files_count": 1,
        "modified_files": [
            "src/ic/ic.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/366f6292ee8d171383dcc5a50eb5dc02bb795f70",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LoadIC::GetMapIndependentHandler"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved re-enabling IC (Inline Caching) support for namespace accesses after establishing a performance baseline, leveraging its prior performance benefits.",
            "The optimization strategy involved re-enabling a previously disabled feature (IC support for namespace accesses) to restore performance improvements.",
            "The optimization strategy involved re-enabling a previously disabled feature (IC support for namespace accesses) to restore performance improvements.",
            "The optimization strategy involved re-enabling IC (Inline Caching) support for namespace accesses after establishing a performance baseline, leveraging its prior performance benefits.",
            "The optimization strategy involved re-enabling a previously disabled feature (IC support for namespace accesses) to restore performance improvements."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved re-enabling a previously disabled feature (IC support for namespace accesses) to restore performance improvements.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ffmpeg",
        "hash": "ad2cc0e2f41f3be59e8c7c1a0ab5c813d7073643",
        "author": "Andreas Rheinhardt",
        "date": "2021-01-31T21:26:44+01:00",
        "message": "avformat/rtpdec: Avoid allocations of small dynamic buffers\n\nBesides avoiding allocations this also fixes a design defect of\nff_rtp_send_punch_packets: It did not return an error in case of\nthese allocations failed.\n\nSigned-off-by: Andreas Rheinhardt <andreas.rheinhardt@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "libavformat/rtpdec.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/ad2cc0e2f41f3be59e8c7c1a0ab5c813d7073643",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ff_rtp_send_punch_packets"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids small dynamic buffer allocations by reusing existing buffers, reducing memory overhead and fixing a potential error-handling defect.",
            "The optimization strategy avoids dynamic memory allocations for small buffers by using stack-allocated memory instead, while also addressing a defect in error handling for allocation failures.",
            "The optimization strategy avoids small dynamic buffer allocations by reusing existing buffers, reducing memory overhead and fixing a potential error-handling defect.",
            "The optimization strategy avoids small dynamic buffer allocations by replacing them with stack-allocated buffers, reducing memory overhead and fixing a potential error-handling defect.",
            "The optimization strategy avoids small dynamic buffer allocations by reusing existing buffers and fixes a defect where allocation failures were not properly handled."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids small dynamic buffer allocations by reusing existing buffers, reducing memory overhead and fixing a potential error-handling defect.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "bareos",
        "hash": "ad9ac1d12f01c434e7f7c3855f7af1fe158e639e",
        "author": "Stephan Duehr",
        "date": "2017-06-08T15:17:08+02:00",
        "message": "Fix Device Spool Size calculation when using secure erase\n\nWhen the secure erase feature is enabled, the calculated Device\nSpool Size was not decreased by the despooled amount of date.\nThis lead to only 128k blocks being spooled/despooled causing\ndegraded performance.",
        "modified_files_count": 1,
        "modified_files": [
            "src/stored/spool.c"
        ],
        "github_commit_url": "https://github.com/bareos/bareos/commit/ad9ac1d12f01c434e7f7c3855f7af1fe158e639e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "close_data_spool_file"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization corrected the Device Spool Size calculation to account for despooled data when using secure erase, improving spooling efficiency.",
            "The optimization corrected the Device Spool Size calculation to account for despooled data when using secure erase, improving spooling efficiency.",
            "The optimization corrected the Device Spool Size calculation to account for despooled data when using secure erase, improving spooling efficiency.",
            "The optimization corrected the Device Spool Size calculation to account for despooled data when using secure erase, improving spooling efficiency.",
            "The optimization corrected the Device Spool Size calculation to account for despooled data when using secure erase, improving spooling efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization corrected the Device Spool Size calculation to account for despooled data when using secure erase, improving spooling efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "532e2128823823fd4b71922fbb144a24216d4969",
        "author": "Robin Gareus",
        "date": "2022-01-29T05:13:23+01:00",
        "message": "Speed up Route deletion\n\nSession::remove_routes() first calls IO::disconnect()\nbefore eventually calling route->drop_references().\n\nRouteTimeAxisView::io_changed() is called while the route still\nexists and requests a redraw which in turn emits\n_stripable->gui_changed (\"track_height\").\n\nSince the RTAV is deleted later during an idle-callback, there\nwas another redraw performed just before the RTAV is actually deleted.",
        "modified_files_count": 1,
        "modified_files": [
            "gtk2_ardour/route_time_axis.cc"
        ],
        "github_commit_url": "https://github.com/Ardour/ardour/commit/532e2128823823fd4b71922fbb144a24216d4969",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RouteTimeAxisView::io_changed"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "ardour",
        "optimization_summary": [
            "The optimization avoids unnecessary redraw requests by checking if the route still exists before triggering a GUI update during the deletion process.",
            "The optimization avoids unnecessary redraw requests by checking if the route still exists before triggering a GUI update during the deletion process.",
            "The optimization avoids unnecessary redraw requests by checking if the route still exists before triggering a GUI update during the deletion process.",
            "The optimization avoids unnecessary redraw requests by checking if the route still exists before triggering a GUI update during the deletion process.",
            "The optimization avoids unnecessary redraw requests by checking if the route still exists before triggering a GUI update in RouteTimeAxisView::io_changed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary redraw requests by checking if the route still exists before triggering a GUI update during the deletion process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "22f547b544b625a98ac13a10bff584dae22f03cd",
        "author": "Olli Pettay",
        "date": "2016-12-22T00:23:07+02:00",
        "message": "Bug 1324808 - Improve string allocation, r=nfroyd",
        "modified_files_count": 1,
        "modified_files": [
            "xpcom/string/nsTSubstring.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/22f547b544b625a98ac13a10bff584dae22f03cd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sizeof"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving string allocation by reducing unnecessary memory overhead in the `sizeof` function.",
            "The optimization strategy involved improving string allocation by reducing unnecessary memory overhead in the `sizeof` function.",
            "The optimization strategy involved improving string allocation by reducing unnecessary memory overhead in the `sizeof` function.",
            "The optimization strategy involved improving string allocation by reducing unnecessary memory overhead in the `sizeof` function.",
            "The optimization strategy involved improving string allocation by reducing unnecessary memory overhead in the `sizeof` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved improving string allocation by reducing unnecessary memory overhead in the `sizeof` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "lustre-release",
        "hash": "3eb209f5010adb4c022dda732f37e1929e6eb69c",
        "author": "alex",
        "date": "2005-06-28T16:10:08+00:00",
        "message": "- minor optimization: we already have fid in reply, no need to fetch it",
        "modified_files_count": 1,
        "modified_files": [
            "lustre/mds/mds_open.c"
        ],
        "github_commit_url": "https://github.com/lustre/lustre-release/commit/3eb209f5010adb4c022dda732f37e1929e6eb69c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mds_open"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant fetching of the `fid` by directly using the value already present in the reply.",
            "The optimization avoids redundant fetching of the `fid` by directly using the value already present in the reply.",
            "The optimization avoids redundant fetching of the `fid` by directly using the value already present in the reply.",
            "The optimization avoids redundant fetching of the `fid` by directly using the value already present in the reply.",
            "The optimization avoids redundant fetching of the `fid` by directly using the value already present in the reply."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids redundant fetching of the `fid` by directly using the value already present in the reply.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "hacker-league",
        "hash": "a0031fc827c4ea151c9510bbf2f332c8fb08b4b4",
        "author": "Moritz Thüning",
        "date": "2024-08-28T12:59:56+02:00",
        "message": "make physics more efficient",
        "modified_files_count": 1,
        "modified_files": [
            "main.cpp"
        ],
        "github_commit_url": "https://github.com/moritztng/hacker-league/commit/a0031fc827c4ea151c9510bbf2f332c8fb08b4b4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "physics"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant calculations within the physics function by caching and reusing results.",
            "The optimization strategy involved reducing redundant calculations within the physics function by caching and reusing results.",
            "The optimization strategy involved reducing redundant calculations within the physics function by caching and reusing results.",
            "The optimization strategy involved reducing redundant calculations within the physics function by caching and reusing results.",
            "The optimization strategy involved reducing redundant calculations within the physics function by caching and reusing previously computed values."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant calculations within the physics function by caching and reusing results.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "a381b70a1cf88e4a2d54f24d59abdcad0ff2dfe6",
        "author": "wanghongzhe",
        "date": "2021-02-10T12:40:11-08:00",
        "message": "seccomp: Improve performace by optimizing rmb()\n\nAccording to Kees's suggest, we started with the patch that just replaces\nrmb() with smp_rmb() and did a performance test with UnixBench. The\nresults showed the overhead about 2.53% in rmb() test compared to the\nsmp_rmb() one, in a x86-64 kernel with CONFIG_SMP enabled running inside a\nqemu-kvm vm. The test is a \"syscall\" testcase in UnixBench, which executes\n5 syscalls in a loop during a certain timeout (100 second in our test) and\ncounts the total number of executions of this 5-syscall sequence. We set\na seccomp filter with all allow rule for all used syscalls in this test\n(which will go bitmap path) to make sure the rmb() will be executed. The\ndetails for the test:\n\nwith rmb():\n/txm # ./syscall_allow_min 100\nCOUNT|35861159|1|lps\n/txm # ./syscall_allow_min 100\nCOUNT|35545501|1|lps\n/txm # ./syscall_allow_min 100\nCOUNT|35664495|1|lps\n\nwith smp_rmb():\n/txm # ./syscall_allow_min 100\nCOUNT|36552771|1|lps\n/txm # ./syscall_allow_min 100\nCOUNT|36491247|1|lps\n/txm # ./syscall_allow_min 100\nCOUNT|36504746|1|lps\n\nFor a x86-64 kernel with CONFIG_SMP enabled, the smp_rmb() is just a\ncompiler barrier() which have no impact in runtime, while rmb() is a\nlfence which will prevent all memory access operations (not just load\naccording the recently claim by Intel) behind itself. We can also figure\nit out in disassembly:\n\nwith rmb():\n0000000000001430 <__seccomp_filter>:\n    1430:   41 57                   push   %r15\n    1432:   41 56                   push   %r14\n    1434:   41 55                   push   %r13\n    1436:   41 54                   push   %r12\n    1438:   55                      push   %rbp\n    1439:   53                      push   %rbx\n    143a:   48 81 ec 90 00 00 00    sub    $0x90,%rsp\n    1441:   89 7c 24 10             mov    %edi,0x10(%rsp)\n    1445:   89 54 24 14             mov    %edx,0x14(%rsp)\n    1449:   65 48 8b 04 25 28 00    mov    %gs:0x28,%rax\n    1450:   00 00\n    1452:   48 89 84 24 88 00 00    mov    %rax,0x88(%rsp)\n    1459:   00\n    145a:   31 c0                   xor    %eax,%eax\n*   145c:   0f ae e8                lfence\n    145f:   48 85 f6                test   %rsi,%rsi\n    1462:   49 89 f4                mov    %rsi,%r12\n    1465:   0f 84 42 03 00 00       je     17ad <__seccomp_filter+0x37d>\n    146b:   65 48 8b 04 25 00 00    mov    %gs:0x0,%rax\n    1472:   00 00\n    1474:   48 8b 98 80 07 00 00    mov    0x780(%rax),%rbx\n    147b:   48 85 db                test   %rbx,%rbx\n\nwith smp_rmb();\n0000000000001430 <__seccomp_filter>:\n    1430:   41 57                   push   %r15\n    1432:   41 56                   push   %r14\n    1434:   41 55                   push   %r13\n    1436:   41 54                   push   %r12\n    1438:   55                      push   %rbp\n    1439:   53                      push   %rbx\n    143a:   48 81 ec 90 00 00 00    sub    $0x90,%rsp\n    1441:   89 7c 24 10             mov    %edi,0x10(%rsp)\n    1445:   89 54 24 14             mov    %edx,0x14(%rsp)\n    1449:   65 48 8b 04 25 28 00    mov    %gs:0x28,%rax\n    1450:   00 00\n    1452:   48 89 84 24 88 00 00    mov    %rax,0x88(%rsp)\n    1459:   00\n    145a:   31 c0                   xor    %eax,%eax\n    145c:   48 85 f6                test   %rsi,%rsi\n    145f:   49 89 f4                mov    %rsi,%r12\n    1462:   0f 84 42 03 00 00       je     17aa <__seccomp_filter+0x37a>\n    1468:   65 48 8b 04 25 00 00    mov    %gs:0x0,%rax\n    146f:   00 00\n    1471:   48 8b 98 80 07 00 00    mov    0x780(%rax),%rbx\n    1478:   48 85 db                test   %rbx,%rbx\n\nSigned-off-by: wanghongzhe <wanghongzhe@huawei.com>\nSigned-off-by: Kees Cook <keescook@chromium.org>\nLink: https://lore.kernel.org/r/1612496049-32507-1-git-send-email-wanghongzhe@huawei.com",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/seccomp.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/a381b70a1cf88e4a2d54f24d59abdcad0ff2dfe6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__seccomp_filter"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a heavier memory barrier (`rmb()`) with a lighter one (`smp_rmb()`) to reduce runtime overhead in a symmetric multiprocessing (SMP) environment.",
            "The optimization strategy replaced the heavier `rmb()` memory barrier with the lighter `smp_rmb()` compiler barrier to reduce runtime overhead in a multi-core context.",
            "The optimization strategy replaced the heavier `rmb()` memory barrier with the lighter `smp_rmb()` compiler barrier to reduce runtime overhead in a specific kernel configuration.",
            "The optimization strategy replaced the heavier `rmb()` memory barrier with the lighter `smp_rmb()` compiler barrier to reduce runtime overhead in a specific kernel configuration.",
            "The optimization strategy replaced the heavier `rmb()` memory barrier with the lighter `smp_rmb()` compiler barrier to reduce runtime overhead in a specific kernel configuration."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced the heavier `rmb()` memory barrier with the lighter `smp_rmb()` compiler barrier to reduce runtime overhead in a specific kernel configuration.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MLV-App",
        "hash": "754584ba06e56506010315670c651069b9239983",
        "author": "masc4ii",
        "date": "2018-06-21T12:58:45+02:00",
        "message": "small optimization for wb picker function",
        "modified_files_count": 1,
        "modified_files": [
            "src/processing/raw_processing.c"
        ],
        "github_commit_url": "https://github.com/ilia3101/MLV-App/commit/754584ba06e56506010315670c651069b9239983",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "processingFindWhiteBalance"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a linear search with a binary search to improve the efficiency of the white balance picker function.",
            "The optimization strategy involved reducing redundant computations by caching intermediate results within the function.",
            "The optimization strategy involved reducing redundant calculations within the white balance picker function by caching intermediate results.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in the white balance picker function.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in the white balance picker function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in the white balance picker function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "server",
        "hash": "8df1c07ddb4758814068b64af831ba41254f32bc",
        "author": "Rich Prohaska",
        "date": "2013-04-16T23:57:45-04:00",
        "message": "speed up leafentry_disksize. addresses #1585\n\ngit-svn-id: file:///svn/toku/tokudb@10482 c7de825b-a66e-492c-adef-691d508d4ae1",
        "modified_files_count": 1,
        "modified_files": [
            "newbrt/leafentry.c"
        ],
        "github_commit_url": "https://github.com/MariaDB/server/commit/8df1c07ddb4758814068b64af831ba41254f32bc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "leafentry_disksize"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying or reducing unnecessary computations within the `leafentry_disksize` function to improve its execution speed.",
            "The optimization strategy involved simplifying the computation of disk size for leaf entries by reducing unnecessary operations or iterations.",
            "The optimization strategy involved simplifying or reducing unnecessary computations within the `leafentry_disksize` function to improve its execution speed.",
            "The optimization strategy involved simplifying or streamlining the computation of disk size for leaf entries to reduce unnecessary overhead.",
            "The optimization strategy involved simplifying the computation of disk size by reducing unnecessary operations or iterations within the `leafentry_disksize` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying or reducing unnecessary computations within the `leafentry_disksize` function to improve its execution speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "buddy_alloc",
        "hash": "0e09f5f3c9dbefc9caa8084691e3ce369e2d181b",
        "author": "Stanislav Paskalev",
        "date": "2021-07-03T13:25:40+03:00",
        "message": "optimize buddy_toggle_virtual_slots to do the minimum number of required operations\nby using all suitable tree depths and not just the last one",
        "modified_files_count": 1,
        "modified_files": [
            "buddy_alloc.c"
        ],
        "github_commit_url": "https://github.com/spaskalev/buddy_alloc/commit/0e09f5f3c9dbefc9caa8084691e3ce369e2d181b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "buddy_toggle_virtual_slots"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces unnecessary operations by utilizing all suitable tree depths instead of limiting to the last one in the `buddy_toggle_virtual_slots` function.",
            "The optimization strategy reduces unnecessary operations by utilizing all suitable tree depths instead of just the last one in the `buddy_toggle_virtual_slots` function.",
            "The optimization strategy reduces unnecessary operations by utilizing all suitable tree depths instead of just the last one in the `buddy_toggle_virtual_slots` function.",
            "The optimization strategy reduces unnecessary operations by utilizing all suitable tree depths instead of just the last one in the `buddy_toggle_virtual_slots` function.",
            "The optimization strategy reduces unnecessary operations by utilizing all suitable tree depths instead of limiting to the last one in the `buddy_toggle_virtual_slots` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces unnecessary operations by utilizing all suitable tree depths instead of just the last one in the `buddy_toggle_virtual_slots` function.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "b936e398e2c49c1b766db9aefbd24e3563b4a751",
        "author": "Robert Kausch",
        "date": "2019-03-08T07:00:12+11:00",
        "message": "Speed up FLAC__bitwriter_write_byte_block (metadata writing)",
        "modified_files_count": 1,
        "modified_files": [
            "src/libFLAC/bitwriter.c"
        ],
        "github_commit_url": "https://github.com/xiph/flac/commit/b936e398e2c49c1b766db9aefbd24e3563b4a751",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FLAC__bitwriter_write_byte_block"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "flac",
        "optimization_summary": [
            "The optimization strategy used is to replace a loop with a direct memory copy operation to improve the performance of writing byte blocks.",
            "The optimization strategy involved replacing a loop with a more efficient block write operation to reduce overhead.",
            "The optimization strategy used is to replace a loop with a direct memory write operation to reduce iteration overhead.",
            "The optimization strategy involved replacing a loop with a direct memory write to reduce the number of iterations and improve performance.",
            "The optimization strategy used is to replace a loop with a direct memory write operation to reduce iteration overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to replace a loop with a direct memory write operation to reduce iteration overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "android_kernel_xiaomi_sm8150",
        "hash": "c5e8f441b6b5fb6cb25ecd1d621144ff80794ec6",
        "author": "Felix Fietkau",
        "date": "2022-05-25T08:41:21+02:00",
        "message": "mac80211: fix rx reordering with non explicit / psmp ack policy\n\n[ Upstream commit 5e469ed9764d4722c59562da13120bd2dc6834c5 ]\n\nWhen the QoS ack policy was set to non explicit / psmp ack, frames are treated\nas not being part of a BA session, which causes extra latency on reordering.\nFix this by only bypassing reordering for packets with no-ack policy\n\nSigned-off-by: Felix Fietkau <nbd@nbd.name>\nLink: https://lore.kernel.org/r/20220420105038.36443-1-nbd@nbd.name\nSigned-off-by: Johannes Berg <johannes.berg@intel.com>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "net/mac80211/rx.c"
        ],
        "github_commit_url": "https://github.com/Laulan56/android_kernel_xiaomi_sm8150/commit/c5e8f441b6b5fb6cb25ecd1d621144ff80794ec6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ieee80211_rx_reorder_ampdu"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy fixes rx reordering latency by ensuring reordering is only bypassed for packets with a no-ack policy, addressing incorrect handling of non-explicit/psmp ack policies.",
            "The optimization strategy fixes rx reordering latency by ensuring reordering is only bypassed for packets with a no-ack policy, avoiding unnecessary treatment of non-explicit/psmp ack policy frames as non-BA session packets.",
            "The optimization strategy fixes rx reordering latency by ensuring reordering is only bypassed for packets with a no-ack policy, addressing incorrect handling of non-explicit/psmp ack policies.",
            "The optimization strategy fixes rx reordering latency by ensuring reordering is only bypassed for packets with a no-ack policy, addressing incorrect handling of non-explicit/psmp ack policies.",
            "The optimization strategy fixes rx reordering latency by ensuring reordering is only bypassed for packets with a no-ack policy, addressing incorrect handling of non-explicit/psmp ack policies."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy fixes rx reordering latency by ensuring reordering is only bypassed for packets with a no-ack policy, addressing incorrect handling of non-explicit/psmp ack policies.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "clr",
        "hash": "faf83743d8b66df3a7c98b22c8cdacd1b1948842",
        "author": "foreman",
        "date": "2017-02-14T17:38:43-05:00",
        "message": "P4 to Git Change 1373431 by gandryey@gera-w8 on 2017/02/14 17:31:04\n\n\tSWDEV-112401 - [OCLonROCm vs LinuxPro][Fiji][Perf] Around ~ 70% performance drop observed with OCL SDK - BlackScholes test\n\t- Switch persistent emulation to device memory instead of system memory, since ROCr doesn't support visible heap without large bar. It's a potential tradeoff of persistent usage in the applications between an upload buffer or directly in a kernel.\n\nAffected files ...\n\n... //depot/stg/opencl/drivers/opencl/runtime/device/rocm/rocmemory.cpp#11 edit",
        "modified_files_count": 1,
        "modified_files": [
            "rocclr/runtime/device/rocm/rocmemory.cpp"
        ],
        "github_commit_url": "https://github.com/ROCm/clr/commit/faf83743d8b66df3a7c98b22c8cdacd1b1948842",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Buffer::create"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved switching persistent emulation to use device memory instead of system memory to address a performance bottleneck related to ROCr's lack of support for visible heap without large bar.",
            "The optimization strategy involved switching persistent emulation to use device memory instead of system memory to address a performance bottleneck related to ROCr's lack of support for visible heap without large bar.",
            "The optimization strategy involved switching persistent emulation to use device memory instead of system memory to address a performance bottleneck related to ROCr's lack of support for visible heap without large bar.",
            "The optimization strategy involved switching persistent emulation to use device memory instead of system memory to address a performance bottleneck related to ROCr's lack of support for visible heap without large bar.",
            "The optimization strategy involved switching persistent emulation to use device memory instead of system memory to address a performance bottleneck related to ROCr's lack of support for visible heap without large bar."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved switching persistent emulation to use device memory instead of system memory to address a performance bottleneck related to ROCr's lack of support for visible heap without large bar.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "HDTN",
        "hash": "f6a25fdb70731a53088ae810636ca556de6b0a15",
        "author": "Tomko",
        "date": "2021-04-08T08:22:01-04:00",
        "message": "more encode attempt optimizations",
        "modified_files_count": 1,
        "modified_files": [
            "common/util/src/Sdnv.cpp"
        ],
        "github_commit_url": "https://github.com/nasa/HDTN/commit/f6a25fdb70731a53088ae810636ca556de6b0a15",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SdnvEncodeU64Fast"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations in the SDNV encoding process by directly calculating byte requirements and avoiding redundant bitwise operations.",
            "The optimization strategy involved simplifying the encoding logic to reduce unnecessary computations during the SDNV encoding process.",
            "The optimization strategy involved improving the efficiency of encoding by reducing unnecessary operations or iterations within the SDNV encoding function.",
            "The optimization strategy involved reducing unnecessary iterations and improving the efficiency of encoding logic by restructuring loop conditions and calculations.",
            "The optimization strategy involved reducing unnecessary computations in the SDNV encoding process by directly calculating byte requirements and avoiding redundant operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the encoding logic to reduce unnecessary computations during the SDNV encoding process.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "806cb5676be3e3524c83d2e508234bf8d9f4980a",
        "author": "Ashod Nakashian",
        "date": "2022-04-14T10:48:45+01:00",
        "message": "wsd: detect ECONNRESET and EPIPE after writes\n\nThis extends the detection of connection termination\nfor writes via ECONNRESET and EPIPE.\nFor some reason ECONNRESET was not detected.\n\nThis patch avoids extra polling to detect connection\ntermination and makes the cleanup faster.\n\nThe changes are guarded by EnableExperimental to avoid\nany unexpected change of behavior.\n\nChange-Id: I2ae3803f025d3cf756f86460e47aedc984249509\nSigned-off-by: Ashod Nakashian <ashod.nakashian@collabora.co.uk>",
        "modified_files_count": 1,
        "modified_files": [
            "net/Socket.hpp"
        ],
        "github_commit_url": "https://github.com/CollaboraOnline/online/commit/806cb5676be3e3524c83d2e508234bf8d9f4980a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "handlePoll"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "online",
        "optimization_summary": [
            "The optimization strategy involves detecting connection termination errors (ECONNRESET and EPIPE) during writes to avoid unnecessary polling and expedite cleanup.",
            "The optimization strategy involves detecting connection termination errors (ECONNRESET and EPIPE) during writes to avoid unnecessary polling and expedite cleanup.",
            "The optimization strategy avoids unnecessary polling by detecting connection termination errors (ECONNRESET and EPIPE) directly after write operations.",
            "The optimization strategy involves detecting connection termination errors (ECONNRESET and EPIPE) during writes to avoid unnecessary polling and expedite cleanup.",
            "The optimization strategy involves detecting connection termination errors (ECONNRESET and EPIPE) during writes to avoid unnecessary polling and expedite cleanup."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves detecting connection termination errors (ECONNRESET and EPIPE) during writes to avoid unnecessary polling and expedite cleanup.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "leap",
        "hash": "94e7bd0696a890c92c4dfe00c25b987450aa75ee",
        "author": "Kevin Heifner",
        "date": "2023-04-28T09:36:15-05:00",
        "message": "GH-641 Use more efficient escape_str instead of format_string",
        "modified_files_count": 1,
        "modified_files": [
            "plugins/producer_plugin/producer_plugin.cpp"
        ],
        "github_commit_url": "https://github.com/AntelopeIO/leap/commit/94e7bd0696a890c92c4dfe00c25b987450aa75ee",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "producer_plugin_impl::start_block"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a less efficient string formatting function with a more efficient string escaping function to improve performance.",
            "The optimization strategy involved replacing a less efficient string formatting function with a more efficient string escaping function to improve performance.",
            "The optimization strategy involved replacing a less efficient string formatting function with a more efficient string escaping function to improve performance.",
            "The optimization strategy involved replacing a less efficient string formatting function with a more efficient string escaping function to improve performance.",
            "The optimization strategy involved replacing a less efficient string formatting function with a more efficient string escaping function to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a less efficient string formatting function with a more efficient string escaping function to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "apulse",
        "hash": "1197b4d8bd1397e1d9f1cd04c90e20a4b5aa539a",
        "author": "Rinat Ibragimov",
        "date": "2015-05-25T01:22:04+03:00",
        "message": "stream: drop ringbuffer contents if app doesn't read fast enough",
        "modified_files_count": 1,
        "modified_files": [
            "src/apulse-stream.c"
        ],
        "github_commit_url": "https://github.com/i-rinat/apulse/commit/1197b4d8bd1397e1d9f1cd04c90e20a4b5aa539a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "data_available_for_stream"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves discarding ringbuffer contents when the application fails to read data quickly enough, preventing buffer overflows and improving performance under high load.",
            "The optimization strategy involves discarding ringbuffer contents when the application fails to read data quickly enough, preventing buffer overflows and improving performance under high load.",
            "The optimization strategy involves discarding ringbuffer contents when the application fails to read data quickly enough, preventing buffer overflows and improving performance under high load.",
            "The optimization strategy involves discarding ringbuffer contents when the application fails to read data quickly enough, preventing buffer overflows and improving performance under high load.",
            "The optimization strategy involves dropping ringbuffer contents when the application fails to read data quickly enough, preventing buffer overflows and improving performance under high load."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves discarding ringbuffer contents when the application fails to read data quickly enough, preventing buffer overflows and improving performance under high load.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "QGIS",
        "hash": "9bd0e887ae539498cd832b7adc66a08a751477f4",
        "author": "mhugent",
        "date": "2009-09-25T11:31:09+00:00",
        "message": "Speed up listing of field values in search dialog by using QSet\n\ngit-svn-id: http://svn.osgeo.org/qgis/trunk@11711 c8812cc2-4d05-0410-92ff-de0c093fc19c",
        "modified_files_count": 1,
        "modified_files": [
            "src/app/qgssearchquerybuilder.cpp"
        ],
        "github_commit_url": "https://github.com/qgis/QGIS/commit/9bd0e887ae539498cd832b7adc66a08a751477f4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "QgsSearchQueryBuilder::getFieldValues"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was replacing a QList with a QSet to improve the performance of field value listing by leveraging faster lookup times.",
            "The optimization strategy used was replacing a QList with a QSet to improve the performance of field value listing by leveraging faster lookup times.",
            "The optimization strategy used was replacing a QList with a QSet to improve the performance of field value listing by leveraging faster lookup times.",
            "The optimization strategy used was replacing a QList with a QSet to improve the performance of field value listing by leveraging faster lookup times.",
            "The optimization strategy used was replacing a QList with a QSet to improve the performance of field value listing by leveraging faster lookup times."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was replacing a QList with a QSet to improve the performance of field value listing by leveraging faster lookup times.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "e5e886bad9e9e87b767ade3884faec1cfdec9b43",
        "author": "Josef Bacik",
        "date": "2022-12-05T18:00:36+01:00",
        "message": "btrfs: add cached_state to read_extent_buffer_subpage\n\nWe don't use a cached state here at all, which generally makes sense as\nasync reads are going to unlock at endio time.  However for blocking\nreads we will call wait_extent_bit() for our range.  Since the\nlock_extent() stuff will return the cached_state for the start of the\nrange this is a helpful optimization to have for this case, we'll have\nthe exact state we want to wait on.  Add a cached state here and simply\nthrow it away if we're a non-blocking read, otherwise we'll get a small\nimprovement by eliminating some tree searches.\n\nReviewed-by: Filipe Manana <fdmanana@suse.com>\nSigned-off-by: Josef Bacik <josef@toxicpanda.com>\nReviewed-by: David Sterba <dsterba@suse.com>\nSigned-off-by: David Sterba <dsterba@suse.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fs/btrfs/extent_io.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/e5e886bad9e9e87b767ade3884faec1cfdec9b43",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "read_extent_buffer_subpage"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization introduces a cached state for blocking reads to reduce tree searches by reusing the cached state from lock_extent().",
            "The optimization introduces a cached state for blocking reads to eliminate unnecessary tree searches, improving performance by directly accessing the required state.",
            "The optimization introduces a cached state for blocking reads to eliminate unnecessary tree searches, improving performance by directly accessing the desired state.",
            "The optimization introduces a cached state for blocking reads to eliminate unnecessary tree searches, improving performance by directly accessing the required state.",
            "The optimization introduces a cached state for blocking reads to eliminate unnecessary tree searches, improving performance by directly accessing the required state."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization introduces a cached state for blocking reads to eliminate unnecessary tree searches, improving performance by directly accessing the required state.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "glibc",
        "hash": "483cfe1a6a33d6335b1901581b41040d2d412511",
        "author": "Noah Goldstein",
        "date": "2022-08-09T17:00:03+08:00",
        "message": "elf: Replace `strcpy` call with `memcpy` [BZ #29454]\n\nGCC normally does this optimization for us in\nstrlen_pass::handle_builtin_strcpy but only for optimized\nbuild. To avoid needing to include strcpy.S in the rtld build to\nsupport the debug build, just do the optimization by hand.",
        "modified_files_count": 1,
        "modified_files": [
            "elf/dl-cache.c"
        ],
        "github_commit_url": "https://github.com/bminor/glibc/commit/483cfe1a6a33d6335b1901581b41040d2d412511",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_dl_load_cache_lookup"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a `strcpy` call with `memcpy` to eliminate the need for including `strcpy.S` in the rtld build for debug builds.",
            "The optimization strategy replaced a `strcpy` call with `memcpy` to eliminate the need for including `strcpy.S` in the rtld build for debug builds.",
            "The optimization strategy replaced a `strcpy` call with `memcpy` to avoid including `strcpy.S` in the rtld build for debug builds.",
            "The optimization strategy replaced a `strcpy` call with `memcpy` to avoid including `strcpy.S` in the rtld build for debug builds.",
            "The optimization strategy replaced a `strcpy` call with `memcpy` to eliminate the need for including `strcpy.S` in the rtld build for debug builds."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a `strcpy` call with `memcpy` to eliminate the need for including `strcpy.S` in the rtld build for debug builds.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "742dbc1fc83f713e139a2745ebb34a97c11c43bd",
        "author": "Arnold Schwaighofer",
        "date": "2013-03-26T18:07:53+00:00",
        "message": "BasicAA: Only query twice if the result of the more general query was MayAlias\n\nThis is a compile time optimization. Before the patch we would do two traversals\non each call to aliasGEP - one with a set size parameter one with UnknownSize.\nWe can do better by first checking the result of the alias query with\nUnknownSize.\nOnly if this one returns MayAlias do we query a second time using size and type.\n\nThis recovers an about 7% compile time regression on spec/ammp.\n\nradar://12349960\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@178045 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Analysis/BasicAliasAnalysis.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/742dbc1fc83f713e139a2745ebb34a97c11c43bd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BasicAliasAnalysis::aliasGEP"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary alias queries by first checking with an UnknownSize parameter and only performing a second query if the result is MayAlias.",
            "The optimization strategy avoids unnecessary alias queries by first checking the result of a more general query and only performing a second query if the initial result is ambiguous (MayAlias).",
            "The optimization strategy avoids unnecessary alias queries by first checking with an UnknownSize parameter and only performing a second query if the result is MayAlias.",
            "The optimization strategy avoids unnecessary alias queries by first checking with an UnknownSize parameter and only performing a second query if the result is MayAlias.",
            "The optimization strategy avoids unnecessary alias queries by first checking with an UnknownSize parameter and only performing a second query if the result is MayAlias."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary alias queries by first checking with an UnknownSize parameter and only performing a second query if the result is MayAlias.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mptcp",
        "hash": "184c8ab5342450c4ae6fc5d937f9bb06c620dcf1",
        "author": "Daniel Bristot de Oliveira",
        "date": "2022-09-05T10:27:39+02:00",
        "message": "sched/deadline: Unthrottle PI boosted threads while enqueuing\n\ncommit feff2e65efd8d84cf831668e182b2ce73c604bbb upstream.\n\nstress-ng has a test (stress-ng --cyclic) that creates a set of threads\nunder SCHED_DEADLINE with the following parameters:\n\n    dl_runtime   =  10000 (10 us)\n    dl_deadline  = 100000 (100 us)\n    dl_period    = 100000 (100 us)\n\nThese parameters are very aggressive. When using a system without HRTICK\nset, these threads can easily execute longer than the dl_runtime because\nthe throttling happens with 1/HZ resolution.\n\nDuring the main part of the test, the system works just fine because\nthe workload does not try to run over the 10 us. The problem happens at\nthe end of the test, on the exit() path. During exit(), the threads need\nto do some cleanups that require real-time mutex locks, mainly those\nrelated to memory management, resulting in this scenario:\n\nNote: locks are rt_mutexes...\n ------------------------------------------------------------------------\n    TASK A:\t\tTASK B:\t\t\t\tTASK C:\n    activation\n\t\t\t\t\t\t\tactivation\n\t\t\tactivation\n\n    lock(a): OK!\tlock(b): OK!\n    \t\t\t<overrun runtime>\n    \t\t\tlock(a)\n    \t\t\t-> block (task A owns it)\n\t\t\t  -> self notice/set throttled\n +--<\t\t\t  -> arm replenished timer\n |    \t\t\tswitch-out\n |    \t\t\t\t\t\t\tlock(b)\n |    \t\t\t\t\t\t\t-> <C prio > B prio>\n |    \t\t\t\t\t\t\t-> boost TASK B\n |  unlock(a)\t\t\t\t\t\tswitch-out\n |  -> handle lock a to B\n |    -> wakeup(B)\n |      -> B is throttled:\n |        -> do not enqueue\n |     switch-out\n |\n |\n +---------------------> replenishment timer\n\t\t\t-> TASK B is boosted:\n\t\t\t  -> do not enqueue\n ------------------------------------------------------------------------\n\nBOOM: TASK B is runnable but !enqueued, holding TASK C: the system\ncrashes with hung task C.\n\nThis problem is avoided by removing the throttle state from the boosted\nthread while boosting it (by TASK A in the example above), allowing it to\nbe queued and run boosted.\n\nThe next replenishment will take care of the runtime overrun, pushing\nthe deadline further away. See the \"while (dl_se->runtime <= 0)\" on\nreplenish_dl_entity() for more information.\n\nReported-by: Mark Simmons <msimmons@redhat.com>\nSigned-off-by: Daniel Bristot de Oliveira <bristot@redhat.com>\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nReviewed-by: Juri Lelli <juri.lelli@redhat.com>\nTested-by: Mark Simmons <msimmons@redhat.com>\nLink: https://lkml.kernel.org/r/5076e003450835ec74e6fa5917d02c4fa41687e6.1600170294.git.bristot@redhat.com\n[Ankit: Regenerated the patch for v5.4.y]\nSigned-off-by: Ankit Jain <ankitja@vmware.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/sched/deadline.c"
        ],
        "github_commit_url": "https://github.com/multipath-tcp/mptcp/commit/184c8ab5342450c4ae6fc5d937f9bb06c620dcf1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "enqueue_task_dl"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves unthrottling priority-inherited (PI) boosted threads during enqueue to prevent system deadlocks caused by runnable but unenqueued threads.",
            "The optimization strategy involves unthrottling priority-inherited (PI) boosted threads during enqueueing to prevent system deadlocks caused by aggressive SCHED_DEADLINE parameters.",
            "The optimization strategy involves unthrottling priority-inherited (PI) boosted threads during enqueue to prevent system deadlocks caused by runnable but unenqueued threads.",
            "The optimization strategy involves unthrottling priority-inherited (PI) boosted threads during enqueue to prevent system deadlocks caused by runnable but unenqueued threads.",
            "The optimization strategy involves unthrottling priority-inherited (PI) boosted threads during enqueue to prevent system deadlocks caused by runnable but unenqueued threads."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves unthrottling priority-inherited (PI) boosted threads during enqueue to prevent system deadlocks caused by runnable but unenqueued threads.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gdal",
        "hash": "0cea7b5056ccf34ad9f9b298127301fc846cc3ad",
        "author": "Even Rouault",
        "date": "2012-05-18T15:53:50+00:00",
        "message": "GML: optimization to avoid probing inexisting file with /vsicurl_streaming/http://someserver?SERVICE=WFS&REQUEST=GetFeature&...\n\ngit-svn-id: https://svn.osgeo.org/gdal/trunk@24444 f0d54148-0727-0410-94bb-9a71ac55c965",
        "modified_files_count": 1,
        "modified_files": [
            "gdal/ogr/ogrsf_frmts/gml/ogrgmldatasource.cpp"
        ],
        "github_commit_url": "https://github.com/OSGeo/gdal/commit/0cea7b5056ccf34ad9f9b298127301fc846cc3ad",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OGRGMLDataSource::Open"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary probing of non-existent files by modifying the logic to prevent redundant checks in a streaming context.",
            "The optimization strategy avoids unnecessary probing of non-existent files by modifying the logic to prevent invalid file access attempts.",
            "The optimization strategy avoids unnecessary probing of non-existent files by modifying the logic to prevent redundant network requests.",
            "The optimization strategy avoids unnecessary probing of non-existent files by modifying the logic to prevent invalid file access attempts.",
            "The optimization strategy avoids unnecessary probing of non-existent files by modifying the logic to prevent redundant HTTP requests."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary probing of non-existent files by modifying the logic to prevent invalid file access attempts.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tortoisesvn",
        "hash": "1d4d80944c0d8fb53d3aa927d61b58ac56075aa7",
        "author": "wdean",
        "date": "2005-01-27T22:38:04+00:00",
        "message": "Improvements to cache to improve behaviour when in completely unversioned parts of the filesystem\n\ngit-svn-id: https://svn.code.sf.net/p/tortoisesvn/code/trunk@2562 154be670-7969-47af-9ab0-c6fb378d2295",
        "modified_files_count": 1,
        "modified_files": [
            "src/TSVNCache/CachedDirectory.cpp"
        ],
        "github_commit_url": "https://github.com/TortoiseGit/tortoisesvn/commit/1d4d80944c0d8fb53d3aa927d61b58ac56075aa7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CCachedDirectory::GetStatusForMember"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving cache behavior by reducing unnecessary operations when handling unversioned parts of the filesystem.",
            "The optimization strategy involved improving cache behavior by reducing unnecessary operations when handling unversioned parts of the filesystem.",
            "The optimization strategy involved improving cache behavior by reducing unnecessary operations when handling unversioned parts of the filesystem.",
            "The optimization strategy involved improving cache behavior by reducing unnecessary operations when handling unversioned parts of the filesystem.",
            "The optimization strategy involved improving cache behavior by reducing unnecessary operations when handling unversioned parts of the filesystem."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving cache behavior by reducing unnecessary operations when handling unversioned parts of the filesystem.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "bf11f1ad2242c65ee64fb6f1bb3af8815544199c",
        "author": "Oleg Romashin",
        "date": "2010-12-29T18:22:26+02:00",
        "message": "Bug 621931 - Widget Qt scrolling is slow because of non optimized SetCursor. r=dougt a=approval2.0",
        "modified_files_count": 1,
        "modified_files": [
            "widget/src/qt/nsWindow.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/bf11f1ad2242c65ee64fb6f1bb3af8815544199c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nsWindow::SetCursor"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary cursor updates by checking if the cursor type has actually changed before applying the update.",
            "The optimization strategy involved reducing unnecessary cursor updates by caching the current cursor state and only applying changes when necessary.",
            "The optimization strategy involved reducing redundant cursor updates by caching the current cursor state and only applying changes when necessary.",
            "The optimization strategy involved reducing redundant calls to SetCursor by caching the cursor state and only updating when necessary.",
            "The optimization strategy involved reducing redundant calls to SetCursor by caching the cursor state and only updating when necessary."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary cursor updates by caching the current cursor state and only applying changes when necessary.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "rethinkdb",
        "hash": "6533a3636d5dfdb46062f90102b54b750f1b47cf",
        "author": "jdoliner",
        "date": "2012-10-10T10:24:00-07:00",
        "message": "Change flush waiting threshold to improve latency.",
        "modified_files_count": 1,
        "modified_files": [
            "src/btree/btree_store.cc"
        ],
        "github_commit_url": "https://github.com/rethinkdb/rethinkdb/commit/6533a3636d5dfdb46062f90102b54b750f1b47cf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "perfmon_collection"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adjusting the flush waiting threshold to reduce latency by changing when data is flushed to storage.",
            "The optimization strategy involved adjusting the flush waiting threshold to reduce latency by changing when data is flushed to storage.",
            "The optimization strategy involved adjusting the flush waiting threshold to reduce latency by changing when data is flushed to storage.",
            "The optimization strategy involved adjusting the flush waiting threshold to reduce latency by changing when data is flushed to storage.",
            "The optimization strategy involved adjusting the flush waiting threshold to reduce latency by changing when data is flushed to storage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting the flush waiting threshold to reduce latency by changing when data is flushed to storage.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "d803387a7f3faeb50c126f9ec065a86cb0dc7f70",
        "author": "Bruce Richardson",
        "date": "2014-10-08T14:24:59+02:00",
        "message": "ixgbe: add prefetch to improve slow-path tx perf\n\nMake a small improvement to slow path TX performance by adding in a\nprefetch for the second mbuf cache line.\nAlso move assignment of l2/l3 length values only when needed.\n\nWhat I've done with the prefetches is two-fold:\n1) changed it from prefetching the mbuf (first cache line) to prefetching\nthe mbuf pool pointer (second cache line) so that when we go to access\nthe pool pointer to free transmitted mbufs we don't get a cache miss. When\nclearing the ring and freeing mbufs, the pool pointer is the only mbuf\nfield used, so we don't need that first cache line.\n2) changed the code to prefetch earlier - in effect to prefetch one mbuf\nahead. The original code prefetched the mbuf to be freed as soon as it\nstarted processing the mbuf to replace it. Instead now, every time we\ncalculate what the next mbuf position is going to be we prefetch the mbuf\nin that position (i.e. the mbuf pool pointer we are going to free the mbuf\nto), even while we are still updating the previous mbuf slot on the ring.\nThis gives the prefetch much more time to resolve and get the data we need\nin the cache before we need it.\n\nIn terms of performance difference, a quick sanity test using testpmd\non a Xeon (Sandy Bridge uarch) platform showed performance increases\nbetween approx 8-18%, depending on the particular RX path used in\nconjuntion with this TX path code.\n\nSigned-off-by: Bruce Richardson <bruce.richardson@intel.com>\nAcked-by: Pablo de Lara <pablo.de.lara.guarch@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/librte_pmd_ixgbe/ixgbe_rxtx.c"
        ],
        "github_commit_url": "https://github.com/DPDK/dpdk/commit/d803387a7f3faeb50c126f9ec065a86cb0dc7f70",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ixgbe_xmit_pkts"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "dpdk",
        "optimization_summary": [
            "The optimization strategy involved adding prefetch instructions for the mbuf pool pointer and reordering prefetch timing to reduce cache misses during slow-path TX operations.",
            "The optimization strategy involved adding prefetch instructions for the mbuf pool pointer and reordering prefetch timing to reduce cache misses during slow-path TX operations.",
            "The optimization strategy involved adding prefetch instructions for the mbuf pool pointer and reordering prefetch timing to reduce cache misses during slow-path TX operations.",
            "The optimization strategy involved adding prefetch instructions for the mbuf pool pointer and reordering prefetch timing to reduce cache misses during slow-path TX operations.",
            "The optimization strategy involved adding prefetch instructions for the mbuf pool pointer and reordering prefetch timing to reduce cache misses during slow-path TX operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adding prefetch instructions for the mbuf pool pointer and reordering prefetch timing to reduce cache misses during slow-path TX operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lightspark",
        "hash": "28ae2d69ecc270c182190557ef42937fe41a0d61",
        "author": "Ludger Krämer",
        "date": "2020-06-25T20:09:26+02:00",
        "message": "fix optimization of static method calls",
        "modified_files_count": 1,
        "modified_files": [
            "src/scripting/abc_interpreter.cpp"
        ],
        "github_commit_url": "https://github.com/lightspark/lightspark/commit/28ae2d69ecc270c182190557ef42937fe41a0d61",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ABCVm::preloadFunction"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing repeated static method calls with a single call stored in a local variable to reduce redundant computations.",
            "The optimization strategy involved replacing repeated static method calls with a single call to improve performance by reducing redundant computations.",
            "The optimization strategy involved reducing redundant static method calls by caching or preloading them for faster access.",
            "The optimization strategy involved reducing redundant static method calls by caching or preloading them for faster access.",
            "The optimization strategy involved modifying the function to directly call static methods instead of using virtual method calls, reducing overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant static method calls by caching or preloading them for faster access.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "neomutt",
        "hash": "d8734c00e03a11a838ef9cbe102fe0a2dc274758",
        "author": "Kevin McCarthy",
        "date": "2018-09-01T18:06:08+01:00",
        "message": "Remove extra lstats() in safe_rename() upon link success\n\nI originally kept the lstat()'s in order to make as few changes as\npossible to the function.  However, Derek Martin argues correctly that\nif we are trusting the link() 0-retval, the lstats are unnecessary and\nin fact can cause a performance impact over NFS.",
        "modified_files_count": 1,
        "modified_files": [
            "mutt/file.c"
        ],
        "github_commit_url": "https://github.com/neomutt/neomutt/commit/d8734c00e03a11a838ef9cbe102fe0a2dc274758",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mutt_file_safe_rename"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes redundant `lstat()` calls after a successful `link()` operation to reduce unnecessary file system overhead.",
            "The optimization removes redundant `lstat()` calls in the `mutt_file_safe_rename` function by relying on the success of the `link()` operation to ensure file integrity.",
            "The optimization removes redundant `lstat()` calls after a successful `link()` operation to reduce unnecessary file system overhead.",
            "The optimization removes redundant `lstat()` calls after a successful `link()` operation to reduce unnecessary file system overhead.",
            "The optimization removes redundant `lstat()` calls in the `mutt_file_safe_rename` function by relying on the success of the `link()` operation to ensure file integrity."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes redundant `lstat()` calls after a successful `link()` operation to reduce unnecessary file system overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gcc",
        "hash": "0b02da5b99e89347f5f8bf875ec8318f84adff18",
        "author": "Richard Biener",
        "date": "2024-03-27T12:49:44+01:00",
        "message": "tree-optimization/114057 - handle BB reduction remain defs as LIVE\n\nThe following makes sure to record the scalars we add to the BB\nreduction vectorization result as scalar uses for the purpose of\ncomputing live lanes.  This restores vectorization in the\nbondfree.c TU of 435.gromacs.\n\n\tPR tree-optimization/114057\n\t* tree-vect-slp.cc (vect_bb_slp_mark_live_stmts): Mark\n\tBB reduction remain defs as scalar uses.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/tree-vect-slp.cc"
        ],
        "github_commit_url": "https://github.com/gcc-mirror/gcc/commit/0b02da5b99e89347f5f8bf875ec8318f84adff18",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vect_bb_slp_mark_live_stmts"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization ensures scalar uses are recorded for BB reduction remain defs to correctly compute live lanes during vectorization.",
            "The optimization ensures scalar uses are recorded for BB reduction remain defs to correctly compute live lanes and restore vectorization.",
            "The optimization ensures scalar uses are recorded for BB reduction remain defs to correctly compute live lanes and restore vectorization.",
            "The optimization ensures scalar uses are recorded for BB reduction remain defs to correctly compute live lanes and restore vectorization.",
            "The optimization ensures scalar uses are recorded for BB reduction remain defs to correctly compute live lanes and restore vectorization."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures scalar uses are recorded for BB reduction remain defs to correctly compute live lanes and restore vectorization.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "2649611109db5f9d60b27c6b2b12e78e5ee9bb25",
        "author": "verwaest",
        "date": "2016-02-12T14:15:04+00:00",
        "message": "[runtime] Speed up Object::ToObject with JSReceiver argument.\n\nThis avoids having to read the context and call through from the inlined\npath in the JSReceiver case.\n\nBUG=\n\nReview URL: https://codereview.chromium.org/1698463002\n\nCr-Commit-Position: refs/heads/master@{#33949}",
        "modified_files_count": 1,
        "modified_files": [
            "src/objects-inl.h"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/2649611109db5f9d60b27c6b2b12e78e5ee9bb25",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Object::ToObject"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary context reads and function calls in the inlined path for JSReceiver arguments in Object::ToObject.",
            "The optimization avoids unnecessary context reads and function calls by directly handling the JSReceiver case in the inlined path.",
            "The optimization avoids unnecessary context reads and function calls in the inlined path for JSReceiver arguments in Object::ToObject.",
            "The optimization avoids unnecessary context reads and function calls in the inlined path for JSReceiver arguments in Object::ToObject.",
            "The optimization avoids unnecessary context reads and function calls in the inlined path for JSReceiver arguments in Object::ToObject."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary context reads and function calls in the inlined path for JSReceiver arguments in Object::ToObject.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ceph",
        "hash": "37f771cffb1034af8ae840174acaac98d42a046a",
        "author": "Xie Xingguo",
        "date": "2019-12-23T16:08:23+08:00",
        "message": "Merge pull request #32368 from xiexingguo/wip-balancer-efficiency-4\n\nosd/OSDMap: consider overfull osds only when trying to do upmap\r\n\r\nReviewed-by: David Zafman <dzafman@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/osd/OSDMap.cc"
        ],
        "github_commit_url": "https://github.com/ceph/ceph/commit/37f771cffb1034af8ae840174acaac98d42a046a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OSDMap::calc_pg_upmaps"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves reducing unnecessary computations by considering overfull OSDs only when attempting to perform upmap calculations.",
            "The optimization strategy involves reducing unnecessary computations by considering overfull OSDs only when attempting to perform upmap operations.",
            "The optimization strategy involves reducing unnecessary computations by considering overfull OSDs only when attempting to perform upmap operations.",
            "The optimization strategy involves reducing unnecessary computations by considering overfull OSDs only when attempting to perform upmap operations.",
            "The optimization strategy involves reducing unnecessary computations by considering overfull OSDs only when attempting to perform upmap operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reducing unnecessary computations by considering overfull OSDs only when attempting to perform upmap operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "osquery",
        "hash": "31c77ca08b2cfe315e59e9cff5ae9d90e8a58793",
        "author": "Mayur Shingote",
        "date": "2022-02-15T20:00:36+01:00",
        "message": "Improved connection time for broken servers. (#7429)\n\nPreviously osquery ceasing to respond indefinitely if the server is broken.\r\nNow the ConnectServer call returns in 2 minutes or less to prevent program from ceasing to respond indefinitely",
        "modified_files_count": 1,
        "modified_files": [
            "osquery/core/windows/wmi.cpp"
        ],
        "github_commit_url": "https://github.com/osquery/osquery/commit/31c77ca08b2cfe315e59e9cff5ae9d90e8a58793",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WmiRequest::WmiRequest"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adding a timeout to the ConnectServer call to ensure it returns within a fixed duration (2 minutes or less) instead of hanging indefinitely.",
            "The optimization strategy involved adding a timeout to the ConnectServer call to ensure it returns within a fixed duration (2 minutes or less) instead of hanging indefinitely.",
            "The optimization strategy involved adding a timeout to the ConnectServer call to ensure it returns within a fixed duration (2 minutes or less) instead of hanging indefinitely.",
            "The optimization strategy involved adding a timeout to the ConnectServer call to ensure it returns within a fixed duration (2 minutes or less) instead of hanging indefinitely.",
            "The optimization strategy involved adding a timeout to the ConnectServer call to ensure it returns within a fixed duration (2 minutes or less) instead of hanging indefinitely."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adding a timeout to the ConnectServer call to ensure it returns within a fixed duration (2 minutes or less) instead of hanging indefinitely.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ppsspp",
        "hash": "185d4db0810b1ca46e840aad5c62c206bda63177",
        "author": "Bovine",
        "date": "2015-01-03T14:48:54-07:00",
        "message": "Fix simd vmmul transpose optimizations.\n\nNeed to ensure S has been written back before transposing it or we'll end\nup writing back S'.",
        "modified_files_count": 1,
        "modified_files": [
            "Core/MIPS/x86/CompVFPU.cpp"
        ],
        "github_commit_url": "https://github.com/hrydgard/ppsspp/commit/185d4db0810b1ca46e840aad5c62c206bda63177",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Jit::Comp_Vmmul"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization ensures proper synchronization of SIMD register writes before transposing to avoid incorrect data propagation.",
            "The optimization ensures proper synchronization of SIMD register writes before transposing to avoid incorrect data propagation.",
            "The optimization ensures proper synchronization of SIMD register writes before transposing to avoid incorrect data propagation.",
            "The optimization ensures proper synchronization of SIMD register writes before transposing to avoid incorrect data propagation.",
            "The optimization ensures proper synchronization of SIMD register writes before transposing to avoid incorrect data propagation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures proper synchronization of SIMD register writes before transposing to avoid incorrect data propagation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libarchive",
        "hash": "971c043a1df850c9ccfc155c80c64b0673d7daa4",
        "author": "Tim Kientzle",
        "date": "2024-10-13T09:42:38+02:00",
        "message": "Ignore checksum mismatches when fuzzing tar archives (#2378)\n\nThis should speed up fuzzing just a bit, so we\r\ncan find more bugs!",
        "modified_files_count": 1,
        "modified_files": [
            "libarchive/archive_read_support_format_tar.c"
        ],
        "github_commit_url": "https://github.com/libarchive/libarchive/commit/971c043a1df850c9ccfc155c80c64b0673d7daa4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "checksum"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization ignores checksum mismatches during fuzzing to reduce unnecessary computations and speed up the process.",
            "The optimization ignores checksum mismatches during fuzzing to reduce unnecessary computations and speed up the fuzzing process.",
            "The optimization ignores checksum mismatches during fuzzing to reduce unnecessary computations and speed up the process.",
            "The optimization ignores checksum mismatches during fuzzing to reduce unnecessary computations and speed up the process.",
            "The optimization ignores checksum mismatches during fuzzing to reduce unnecessary computations and speed up the fuzzing process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ignores checksum mismatches during fuzzing to reduce unnecessary computations and speed up the process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "NyuziProcessor",
        "hash": "887e0e9e161382051e77ebd9bde8d23a016c182c",
        "author": "Jeff Bush",
        "date": "2015-01-06T00:07:16-08:00",
        "message": "librender: Cull triangles that are outside the sides of the view frustum\n\nAbout 2% faster",
        "modified_files_count": 1,
        "modified_files": [
            "software/librender/RenderContext.cpp"
        ],
        "github_commit_url": "https://github.com/jbush001/NyuziProcessor/commit/887e0e9e161382051e77ebd9bde8d23a016c182c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RenderContext::enqueueTriangle"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization culls triangles outside the view frustum to avoid unnecessary processing.",
            "The optimization culls triangles outside the view frustum to avoid unnecessary processing.",
            "The optimization culls triangles outside the view frustum to avoid unnecessary processing.",
            "The optimization culls triangles outside the view frustum to avoid unnecessary processing.",
            "The optimization culls triangles outside the view frustum to avoid unnecessary processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization culls triangles outside the view frustum to avoid unnecessary processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "3bcf90c68e4b772fe3f27572e06bf0cc3cf398dd",
        "author": "Hao Xu",
        "date": "2023-02-08T03:48:59+00:00",
        "message": "[csa] Optimize BuildFastLoop\n\nAvoid generating duplicated IntPtrOrSmiAdd as loop's condition so the\ncode can be optimized:\n\nBefore:\n   2ea  REX.W leaq r12,[rsi-0x3]\n   2ee  REX.W cmpq r12,0x0\n   2f2  jg 0x7fbda01e7c94  B93,94,95,98 <+0x2d4>\n\nAfter:\n   2e6  REX.W cmpq rsi,0x3\n   2ea  jg 0x7f5cc01e7c90  B93,94,95,98 <+0x2d0>\n\nChange-Id: I127a009d0c67ce185b7ddbf3cfbcb36cbd85d446\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4225830\nCommit-Queue: Hao A Xu <hao.a.xu@intel.com>\nReviewed-by: Leszek Swirski <leszeks@chromium.org>\nCr-Commit-Position: refs/heads/main@{#85716}",
        "modified_files_count": 1,
        "modified_files": [
            "src/codegen/code-stub-assembler.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/3bcf90c68e4b772fe3f27572e06bf0cc3cf398dd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CodeStubAssembler::BuildFastLoop"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy eliminates redundant IntPtrOrSmiAdd operations in loop conditions to simplify and improve the efficiency of generated assembly code.",
            "The optimization strategy eliminates redundant IntPtrOrSmiAdd operations in loop conditions by directly comparing the loop variable with a constant value.",
            "The optimization strategy eliminates redundant IntPtrOrSmiAdd operations in loop conditions by directly comparing the loop variable with a constant value.",
            "The optimization strategy eliminates redundant IntPtrOrSmiAdd operations in the loop condition to simplify and improve the generated assembly code.",
            "The optimization strategy eliminates redundant IntPtrOrSmiAdd operations in loop conditions by directly comparing the loop variable with a constant value."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy eliminates redundant IntPtrOrSmiAdd operations in loop conditions by directly comparing the loop variable with a constant value.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "pbrt-v3",
        "hash": "26f2f7286fb8c9f7cd98768aee4a191031405f5d",
        "author": "Matt Pharr",
        "date": "2015-10-24T21:19:22-07:00",
        "message": "BDPT: only trace shadow ray to light if path has non-zero contribution\n\nNo change in images; roughly 5% speedup.",
        "modified_files_count": 1,
        "modified_files": [
            "src/integrators/bdpt.cpp"
        ],
        "github_commit_url": "https://github.com/mmp/pbrt-v3/commit/26f2f7286fb8c9f7cd98768aee4a191031405f5d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ConnectBDPT"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids tracing shadow rays to lights when the path has zero contribution, reducing unnecessary computation.",
            "The optimization avoids tracing shadow rays to lights when the path has zero contribution, reducing unnecessary computations.",
            "The optimization avoids tracing shadow rays to lights when the path has zero contribution, reducing unnecessary computations.",
            "The optimization avoids tracing shadow rays to lights when the path has zero contribution, reducing unnecessary computations.",
            "The optimization avoids tracing shadow rays to lights when the path has zero contribution, reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids tracing shadow rays to lights when the path has zero contribution, reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "a42b834b70de833cc87d7ba9eecc704903c19754",
        "author": "Alexandr Popov",
        "date": "2025-01-03T14:04:41+02:00",
        "message": "Merge pull request #25971 from handrok/instrtenplate_optimisation\n\nimproved score openning speed by optimisation the searchTemplateForInstrNameList function",
        "modified_files_count": 1,
        "modified_files": [
            "src/engraving/dom/instrtemplate.cpp"
        ],
        "github_commit_url": "https://github.com/musescore/MuseScore/commit/a42b834b70de833cc87d7ba9eecc704903c19754",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "searchTemplateForInstrNameList"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "MuseScore",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of string comparisons in the searchTemplateForInstrNameList function by reducing redundant operations.",
            "The optimization strategy involved improving the efficiency of string comparisons in the search function by reducing redundant operations.",
            "The optimization strategy involved improving the efficiency of string matching in the `searchTemplateForInstrNameList` function by reducing redundant operations or iterations.",
            "The optimization strategy involved improving the efficiency of string comparisons in the searchTemplateForInstrNameList function by reducing redundant operations.",
            "The optimization strategy involved improving the efficiency of string comparisons in the `searchTemplateForInstrNameList` function by reducing redundant operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of string comparisons in the `searchTemplateForInstrNameList` function by reducing redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "wildmeshing-toolkit",
        "hash": "4903d2eace3a564a68e27855d61bf885e46ea812",
        "author": "Teseo Schneider",
        "date": "2021-12-22T16:43:48-08:00",
        "message": "using fast envelope",
        "modified_files_count": 1,
        "modified_files": [
            "app/tests/test_operation_smooth.cpp"
        ],
        "github_commit_url": "https://github.com/wildmeshing/wildmeshing-toolkit/commit/4903d2eace3a564a68e27855d61bf885e46ea812",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_CASE"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a slower envelope computation with a faster alternative to improve performance.",
            "The optimization strategy involved replacing a slower envelope computation with a faster alternative to improve performance.",
            "The optimization strategy involved replacing a slower envelope computation with a faster alternative to improve performance.",
            "The optimization strategy involved replacing a slower envelope computation with a faster alternative to improve performance.",
            "The optimization strategy involved replacing a slower envelope computation with a faster alternative to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a slower envelope computation with a faster alternative to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "e950cca3f3c40902a052a78a36b3fac1f8a62d19",
        "author": "Waiman Long",
        "date": "2019-10-09T12:46:10+02:00",
        "message": "lib/smp_processor_id: Don't use cpumask_equal()\n\nThe check_preemption_disabled() function uses cpumask_equal() to see\nif the task is bounded to the current CPU only. cpumask_equal() calls\nmemcmp() to do the comparison. As x86 doesn't have __HAVE_ARCH_MEMCMP,\nthe slow memcmp() function in lib/string.c is used.\n\nOn a RT kernel that call check_preemption_disabled() very frequently,\nbelow is the perf-record output of a certain microbenchmark:\n\n  42.75%  2.45%  testpmd [kernel.kallsyms] [k] check_preemption_disabled\n  40.01% 39.97%  testpmd [kernel.kallsyms] [k] memcmp\n\nWe should avoid calling memcmp() in performance critical path. So the\ncpumask_equal() call is now replaced with an equivalent simpler check.\n\nSigned-off-by: Waiman Long <longman@redhat.com>\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nReviewed-by: Juri Lelli <juri.lelli@redhat.com>\nAcked-by:  Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Masami Hiramatsu <mhiramat@kernel.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nLink: https://lkml.kernel.org/r/20191003203608.21881-1-longman@redhat.com\nSigned-off-by: Ingo Molnar <mingo@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/smp_processor_id.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/e950cca3f3c40902a052a78a36b3fac1f8a62d19",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "smp_processor_id"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a costly `memcmp()` call with a simpler equivalent check to avoid performance overhead in a frequently called function.",
            "The optimization strategy replaced a costly `memcmp()` call with a simpler equivalent check to avoid performance overhead in a frequently called function.",
            "The optimization strategy replaced a potentially slow `memcmp()` call with a simpler equivalent check to avoid performance overhead in a critical path.",
            "The optimization strategy replaced a costly `cpumask_equal()` call with a simpler equivalent check to avoid invoking the slow `memcmp()` function in a performance-critical path.",
            "The optimization strategy replaced a costly `memcmp()` call with a simpler equivalent check to avoid performance overhead in a frequently called function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a costly `memcmp()` call with a simpler equivalent check to avoid performance overhead in a frequently called function.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "0548bf4f5ad6fc3bd93c4940fa48078b34609682",
        "author": "Javier Martinez Canillas",
        "date": "2015-03-08T19:40:16+00:00",
        "message": "regulator: Only enable disabled regulators on resume\n\nThe _regulator_do_enable() call ought to be a no-op when called on an\nalready-enabled regulator.  However, as an optimization\n_regulator_enable() doesn't call _regulator_do_enable() on an already\nenabled regulator.  That means we never test the case of calling\n_regulator_do_enable() during normal usage and there may be hidden\nbugs or warnings.  We have seen warnings issued by the tps65090 driver\nand bugs when using the GPIO enable pin.\n\nLet's match the same optimization that _regulator_enable() in\nregulator_suspend_finish().  That may speed up suspend/resume and also\navoids exposing hidden bugs.\n\n[Use much clearer commit message from Doug Anderson]\n\nSigned-off-by: Javier Martinez Canillas <javier.martinez@collabora.co.uk>\nSigned-off-by: Mark Brown <broonie@kernel.org>\nCc: stable@vger.kernel.org",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/regulator/core.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/0548bf4f5ad6fc3bd93c4940fa48078b34609682",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "regulator_suspend_finish"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization avoids unnecessary calls to `_regulator_do_enable()` by checking if a regulator is already enabled before attempting to enable it during suspend/resume operations.",
            "The optimization avoids unnecessary calls to enable already-enabled regulators during system resume, reducing redundant operations and potential exposure of hidden bugs.",
            "The optimization avoids redundant calls to enable already-enabled regulators during system resume, reducing unnecessary operations and potential exposure of hidden bugs.",
            "The optimization avoids unnecessary calls to _regulator_do_enable() by checking if a regulator is already enabled before attempting to enable it during suspend/resume operations.",
            "The optimization avoids unnecessary calls to _regulator_do_enable() by checking the regulator's state before enabling it during suspend/resume operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary calls to `_regulator_do_enable()` by checking if a regulator is already enabled before attempting to enable it during suspend/resume operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "icub-main",
        "hash": "525800f13a4b168dc12fa62b5a8cca0ba11e95eb",
        "author": "Francesco Rea",
        "date": "2010-09-06T12:42:21+00:00",
        "message": "reduced the Z distance to improve the triangulation performances\n\nsvn path=/trunk/iCub/; revision=7498",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/selectiveAttentionEngine/src/selectiveAttentionProcessor.cpp"
        ],
        "github_commit_url": "https://github.com/robotology/icub-main/commit/525800f13a4b168dc12fa62b5a8cca0ba11e95eb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "selectiveAttentionProcessor::run"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the Z distance in the triangulation process to improve computational performance.",
            "The optimization strategy involved reducing the Z distance to improve triangulation performance by decreasing computational overhead.",
            "The optimization strategy involved reducing the Z distance to improve triangulation performance by decreasing computational overhead.",
            "The optimization strategy involved reducing the Z distance to improve triangulation performance by decreasing computational overhead.",
            "The optimization strategy involved reducing the Z distance to improve triangulation performance by decreasing computational overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the Z distance to improve triangulation performance by decreasing computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "3bac7e845b2a5bd877c60e16de4e3186b510dbfc",
        "author": "Evan Huus",
        "date": "2013-08-11T14:20:00+00:00",
        "message": "Small optimization: the master-list and recycler cases are different enough that\ndoing all the safety checks was unnecessarily slow. Do only the appropriate\nchecks for each case.\n\nsvn path=/trunk/; revision=51296",
        "modified_files_count": 1,
        "modified_files": [
            "epan/wmem/wmem_allocator_block.c"
        ],
        "github_commit_url": "https://github.com/wireshark/wireshark/commit/3bac7e845b2a5bd877c60e16de4e3186b510dbfc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "wmem_block_split_free_chunk"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "wireshark",
        "optimization_summary": [
            "The optimization strategy involved tailoring safety checks to specific cases (master-list and recycler) to avoid unnecessary computations.",
            "The optimization strategy involved reducing unnecessary safety checks by tailoring the checks to specific cases (master-list and recycler), improving performance.",
            "The optimization strategy involved reducing unnecessary safety checks by tailoring the checks to specific cases (master-list and recycler) to improve performance.",
            "The optimization strategy involved tailoring safety checks to specific cases (master-list vs. recycler) to avoid unnecessary computations.",
            "The optimization strategy involved reducing unnecessary safety checks by tailoring the checks to specific cases (master-list and recycler), improving performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary safety checks by tailoring the checks to specific cases (master-list and recycler) to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "radare2",
        "hash": "dac5229965c8a4be50651c6da90cfeef24e97148",
        "author": "Paul I",
        "date": "2019-10-19T01:21:02+02:00",
        "message": "Avoid reloading of cc sdb - huge speedup (#15306) ##anal",
        "modified_files_count": 1,
        "modified_files": [
            "libr/core/cbin.c"
        ],
        "github_commit_url": "https://github.com/radareorg/radare2/commit/dac5229965c8a4be50651c6da90cfeef24e97148",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "r_core_anal_cc_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant reloading of the `cc` SDB database by caching its initialization state, significantly improving performance.",
            "The optimization avoids redundant reloading of the `cc` SDB database by caching its initialization state, significantly improving performance.",
            "The optimization avoids redundant reloading of the `cc` SDB by caching its initialization, significantly improving performance.",
            "The optimization avoids redundant reloading of the `cc` SDB database by caching its initialization state, significantly improving performance.",
            "The optimization avoids redundant reloading of the `cc` SDB database by caching its initialization state, significantly improving performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids redundant reloading of the `cc` SDB database by caching its initialization state, significantly improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MyScaleDB",
        "hash": "4e0712207945131b9b39203cb5efcb1f77910fca",
        "author": "Azat Khuzhin",
        "date": "2022-01-28T08:08:14+03:00",
        "message": "Slightly optimize ColumnArray::get()/operator[] (by using reserve over resize)\n\nNote, that simple \"SELECT range(100)\" will execute\nColumnArray::operator[] 14 times (most of them from\nDB::checkColumnStructure())\n\nSigned-off-by: Azat Khuzhin <a.khuzhin@semrush.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/Columns/ColumnArray.cpp"
        ],
        "github_commit_url": "https://github.com/myscale/MyScaleDB/commit/4e0712207945131b9b39203cb5efcb1f77910fca",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was replacing `resize` with `reserve` in `ColumnArray::get()`/`operator[]` to reduce unnecessary memory reallocations and improve performance.",
            "The optimization strategy used was replacing `resize` with `reserve` in `ColumnArray::get()`/`operator[]` to reduce unnecessary memory reallocations and improve performance.",
            "The optimization strategy involved replacing `resize` with `reserve` in the `ColumnArray::get()` and `operator[]` methods to reduce unnecessary memory reallocations and improve performance.",
            "The optimization strategy involved replacing `resize` with `reserve` in the `ColumnArray::get()` and `operator[]` methods to reduce unnecessary memory reallocations and improve performance.",
            "The optimization strategy involved replacing `resize` with `reserve` in the `ColumnArray::get()` and `operator[]` methods to reduce unnecessary memory reallocations and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing `resize` with `reserve` in the `ColumnArray::get()` and `operator[]` methods to reduce unnecessary memory reallocations and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Floorp",
        "hash": "cf7ee570bd0c6c40c116d9b12df2286bbee9549e",
        "author": "Matthew Gaudet",
        "date": "2023-06-22T13:04:31+00:00",
        "message": "Bug 1838529 - Reserve space in the properties vector to avoid costly vector growth r=jandem\n\nOn the microbenchmark from Bug 1836679:\n\n$ hyperfine 'obj-with/dist/bin/js keys-benchmark.js' 'obj-without/dist/bin/js keys-benchmark.js'\nBenchmark 1: obj-with/dist/bin/js keys-benchmark.js\n  Time (mean ± σ):     256.9 ms ±   2.2 ms    [User: 257.9 ms, System: 8.9 ms]\n  Range (min … max):   254.3 ms … 262.5 ms    11 runs\n\nBenchmark 2: obj-without/dist/bin/js keys-benchmark.js\n  Time (mean ± σ):     349.4 ms ±   1.0 ms    [User: 351.0 ms, System: 10.0 ms]\n  Range (min … max):   347.6 ms … 350.9 ms    10 runs\n\nSummary\n  'obj-with/dist/bin/js keys-benchmark.js' ran\n    1.36 ± 0.01 times faster than 'obj-without/dist/bin/js keys-benchmark.js'\n\nDifferential Revision: https://phabricator.services.mozilla.com/D181004",
        "modified_files_count": 1,
        "modified_files": [
            "js/src/builtin/Object.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/cf7ee570bd0c6c40c116d9b12df2286bbee9549e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TryEnumerableOwnPropertiesNative"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reserving space in a vector to prevent repeated reallocations during growth.",
            "The optimization strategy involved reserving space in a vector to prevent repeated reallocations during growth.",
            "The optimization strategy involved reserving space in a vector to prevent repeated reallocations during growth.",
            "The optimization strategy involved reserving space in a vector to prevent repeated reallocations and copying during growth.",
            "The optimization strategy involved reserving space in a vector to prevent repeated reallocations and improve performance by reducing the overhead of dynamic resizing."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reserving space in a vector to prevent repeated reallocations during growth.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "circt",
        "hash": "6a09c52db9cd5f67c4d2726a5e5a40fb53112c2c",
        "author": "Chris Lattner",
        "date": "2021-08-28T12:01:34-07:00",
        "message": "[IMConstProp] Use InstanceGraph more instead of calling \"getReferencedModule\".\n\ngetReferencedModule is a performance tarpit because it has to scan the top\nlevel of the circuit to find the right module.   We already have the\ninstance graph, we should use it for all lookups.\n\nThis speeds up IMConstProp on a large testcase from 24s to 6.3s.",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Dialect/FIRRTL/Transforms/IMConstProp.cpp"
        ],
        "github_commit_url": "https://github.com/llvm/circt/commit/6a09c52db9cd5f67c4d2726a5e5a40fb53112c2c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "IMConstPropPass::markInstanceOp"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces repeated calls to a slow module lookup function with efficient lookups using a precomputed instance graph.",
            "The optimization strategy replaced repeated calls to a slow module lookup function with efficient lookups using a precomputed instance graph.",
            "The optimization strategy replaced repeated calls to a slow module lookup function with a more efficient instance graph lookup.",
            "The optimization strategy replaces repeated calls to a slow module lookup function with efficient lookups using a precomputed instance graph.",
            "The optimization replaces repeated calls to a slow module lookup function with efficient lookups using a precomputed instance graph."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced repeated calls to a slow module lookup function with efficient lookups using a precomputed instance graph.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "hackrf",
        "hash": "0418d13e725acf62b7dbd851f5b4884e83aa7d72",
        "author": "Dominic Spill",
        "date": "2016-01-18T19:42:13+00:00",
        "message": "Add dummy byte for w25q80bv fast read command timing",
        "modified_files_count": 1,
        "modified_files": [
            "firmware/common/w25q80bv.c"
        ],
        "github_commit_url": "https://github.com/greatscottgadgets/hackrf/commit/0418d13e725acf62b7dbd851f5b4884e83aa7d72",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "w25q80bv_read"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adding a dummy byte to align timing for the w25q80bv fast read command, reducing potential delays.",
            "The optimization strategy involved adding a dummy byte to align timing for the fast read command, reducing potential delays.",
            "The optimization strategy involved adding a dummy byte to align timing for the fast read command, reducing potential delays.",
            "The optimization strategy involved adding a dummy byte to align timing for the w25q80bv fast read command, reducing potential delays.",
            "The optimization strategy involved adding a dummy byte to align timing for the w25q80bv fast read command, reducing potential delays."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adding a dummy byte to align timing for the w25q80bv fast read command, reducing potential delays.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "blender",
        "hash": "a711c5004cf7e4b903f9c2c6ca736f2e531df79c",
        "author": "Iliya Katueshenock",
        "date": "2023-06-22T13:45:43+02:00",
        "message": "Geometry Nodes: Simplify code in duplicate elements face mode\n\nThis node splits all faces to duplicate each time. Corner edges and\nvertices are just ordered sequences of indices. Most likely, due to\nhistorical reasons, this was overlooked and as a result the code became\nso complex with potential simplicity. The problem was found in a\nbenchmark of #109174. The code in the lambda could not be optimized.\n\nTimings improved by about 30%, from 154 to 120 ms.\n\nPull Request: https://projects.blender.org/blender/blender/pulls/109222",
        "modified_files_count": 1,
        "modified_files": [
            "source/blender/nodes/geometry/nodes/node_geo_duplicate_elements.cc"
        ],
        "github_commit_url": "https://github.com/blender/blender/commit/a711c5004cf7e4b903f9c2c6ca736f2e531df79c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "duplicate_faces"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization simplified complex logic in the duplicate_faces function by leveraging the ordered nature of corner edges and vertices, reducing unnecessary computations.",
            "The optimization simplified complex code by leveraging the ordered nature of corner edges and vertices, reducing unnecessary computations.",
            "The optimization simplified complex code by leveraging the inherent ordering of corner edges and vertices, reducing unnecessary computations.",
            "The optimization simplified complex code by leveraging the ordered nature of corner edges and vertices, reducing unnecessary computations.",
            "The optimization simplified complex logic in the duplicate_faces function by leveraging the ordered nature of corner edges and vertices, reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization simplified complex code by leveraging the inherent ordering of corner edges and vertices, reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dosbox-staging",
        "hash": "911684a9c0c45d3eace70b04779c372936b3ab36",
        "author": "kcgen",
        "date": "2022-01-06T11:29:08+13:00",
        "message": "Fix a performance warning in shell copy\n\nV823 Decreased performance. Object may be created\nin-place in the 'sources' container. Consider\nreplacing methods: 'push_back' -> 'emplace_back'.",
        "modified_files_count": 1,
        "modified_files": [
            "src/shell/shell_cmds.cpp"
        ],
        "github_commit_url": "https://github.com/dosbox-staging/dosbox-staging/commit/911684a9c0c45d3eace70b04779c372936b3ab36",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DOS_Shell::CMD_COPY"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaced `push_back` with `emplace_back` to construct objects in-place within the `sources` container, reducing unnecessary temporary object creation and improving performance.",
            "The optimization replaced `push_back` with `emplace_back` to construct objects in-place within the `sources` container, reducing unnecessary temporary object creation and improving performance.",
            "The optimization replaced `push_back` with `emplace_back` to construct objects in-place within the `sources` container, reducing unnecessary temporary object creation and improving performance.",
            "The optimization replaced `push_back` with `emplace_back` to construct objects in-place within the `sources` container, reducing unnecessary temporary object creation.",
            "The optimization replaced `push_back` with `emplace_back` to construct objects in-place within the `sources` container, reducing unnecessary temporary object creation."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaced `push_back` with `emplace_back` to construct objects in-place within the `sources` container, reducing unnecessary temporary object creation and improving performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cutter",
        "hash": "ffa52bd3e8a7581f17b694d542bed49af53f3762",
        "author": "Tim Siebels",
        "date": "2017-10-01T15:55:47+02:00",
        "message": "Fix pessimizing move (#19)\n\nmoving a return value generally is unnecessary, as it prevents return value optimization.\r\n\r\nThe standard defines, that (named) return value optimization, i.e. copy elision\r\nis only possible when returning a value from a non-volatile automatic object\r\nor when it's a temporary that has not been bound to a reference.\r\n(N)RVO is not possible when wrapping it with std::move, because the compiler\r\nis not allowed to do copy elision from arbitrary function calls.\r\n\r\nI think this was the intended purpose of this code. Also, it is cleaner.",
        "modified_files_count": 1,
        "modified_files": [
            "src/widgets/DisassemblerGraphView.h"
        ],
        "github_commit_url": "https://github.com/rizinorg/cutter/commit/ffa52bd3e8a7581f17b694d542bed49af53f3762",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ToQString"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes an unnecessary `std::move` to enable return value optimization (RVO) by adhering to conditions where copy elision is allowed.",
            "The optimization removes an unnecessary `std::move` to enable return value optimization (RVO) by adhering to conditions where copy elision is allowed.",
            "The optimization removes an unnecessary `std::move` to enable return value optimization (RVO) by adhering to the conditions required for copy elision.",
            "The optimization removes an unnecessary `std::move` to enable return value optimization (RVO) by adhering to the conditions required for copy elision.",
            "The optimization removes an unnecessary `std::move` to enable return value optimization (RVO) by adhering to the conditions required for copy elision."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization removes an unnecessary `std::move` to enable return value optimization (RVO) by adhering to the conditions required for copy elision.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "llvm-leg",
        "hash": "880ddb018a4bdcff00d35f28988d9eddb557b8e6",
        "author": "Chris Lattner",
        "date": "2006-08-02T00:14:16+00:00",
        "message": "Speed up Loop::isLCSSAForm by using a binary search and single-entry cache.\n\nThis reduces LCSSA pass time from 1.5s to 0.96s when run on eon in release+asserts mode.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@29464 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Analysis/LoopInfo.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/880ddb018a4bdcff00d35f28988d9eddb557b8e6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Loop::isLCSSAForm"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to replace a linear search with a binary search and introduce a single-entry cache to reduce the time complexity of lookups in the `Loop::isLCSSAForm` function.",
            "The optimization strategy used is to replace a linear search with a binary search and introduce a single-entry cache to reduce the time complexity of lookups in the `Loop::isLCSSAForm` function.",
            "The optimization strategy used is to replace a linear search with a binary search and introduce a single-entry cache to reduce the time complexity of lookups in the `Loop::isLCSSAForm` function.",
            "The optimization strategy used is to replace a linear search with a binary search and introduce a single-entry cache to reduce the time complexity of lookups in the `Loop::isLCSSAForm` function.",
            "The optimization strategy used is to replace a linear search with a binary search and introduce a single-entry cache to reduce the time complexity of lookups in the `Loop::isLCSSAForm` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to replace a linear search with a binary search and introduce a single-entry cache to reduce the time complexity of lookups in the `Loop::isLCSSAForm` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "android_art",
        "hash": "02f9110a1f0237f0ee81ea7b978dc9d2c2d5d7a7",
        "author": "Ian Rogers",
        "date": "2014-02-18T02:03:42+00:00",
        "message": "am 9f1b81c2: am b52b2195: Merge \"Optimize x86 long V*V by skipping imul\"\n\n* commit '9f1b81c242b98bb59028d9e99234604d30672c8b':\n  Optimize x86 long V*V by skipping imul",
        "modified_files_count": 1,
        "modified_files": [
            "compiler/dex/quick/x86/int_x86.cc"
        ],
        "github_commit_url": "https://github.com/rovo89/android_art/commit/02f9110a1f0237f0ee81ea7b978dc9d2c2d5d7a7",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips the use of the `imul` instruction in x86 assembly for long integer multiplication, likely replacing it with a more efficient sequence of operations.",
            "The optimization strategy skips the use of the `imul` instruction in x86 assembly for long integer multiplication, likely replacing it with a more efficient sequence of operations.",
            "The optimization strategy skips the use of the `imul` instruction in x86 assembly for long vector multiplication, likely replacing it with a more efficient sequence of operations.",
            "The optimization strategy skips the use of the `imul` instruction in x86 assembly for long integer multiplication, likely replacing it with a more efficient sequence of operations.",
            "The optimization strategy skips the use of the `imul` instruction in x86 assembly for long integer multiplication, likely replacing it with a more efficient sequence of operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips the use of the `imul` instruction in x86 assembly for long integer multiplication, likely replacing it with a more efficient sequence of operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MyFlash",
        "hash": "957ea43f078b08d9dc4610c1a53418221da06a74",
        "author": "root",
        "date": "2019-04-19T09:11:24+08:00",
        "message": "[optimization] performance issue when a lot of event get",
        "modified_files_count": 1,
        "modified_files": [
            "source/binlogParseGlib.c"
        ],
        "github_commit_url": "https://github.com/Meituan-Dianping/MyFlash/commit/957ea43f078b08d9dc4610c1a53418221da06a74",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "constructLeastExecutionUnitFromAllEventsList"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant iterations or computations when processing a large number of events in the `constructLeastExecutionUnitFromAllEventsList` function.",
            "The optimization strategy involved reducing redundant iterations or operations when processing a large number of events in the `constructLeastExecutionUnitFromAllEventsList` function.",
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "android_art",
        "hash": "af77455c67e811719ddc9476ff334469e7650b3a",
        "author": "Shih-wei Liao",
        "date": "2012-04-22T01:49:58-07:00",
        "message": "Merge \"Partial inlining of the stub check.\" into ics-mr1-plus-art",
        "modified_files_count": 1,
        "modified_files": [
            "src/compiler_llvm/method_compiler.cc"
        ],
        "github_commit_url": "https://github.com/rovo89/android_art/commit/af77455c67e811719ddc9476ff334469e7650b3a",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved partially inlining a stub check to reduce function call overhead and improve runtime performance.",
            "The optimization strategy involved partially inlining a stub check to reduce function call overhead and improve runtime performance.",
            "The optimization strategy involved partially inlining a stub check to reduce function call overhead and improve runtime performance.",
            "The optimization strategy involved partially inlining a stub check to reduce function call overhead and improve runtime performance.",
            "The optimization strategy involved partially inlining a stub check to reduce function call overhead and improve runtime performance."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved partially inlining a stub check to reduce function call overhead and improve runtime performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "simde",
        "hash": "8a06c846000c9ba7735e9e85dc5f3024c76bc765",
        "author": "Evan Nemerson",
        "date": "2017-05-16T18:27:49-07:00",
        "message": "sse2: add NEON implementation of simde_mm_madd_epi16",
        "modified_files_count": 1,
        "modified_files": [
            "sse2.h"
        ],
        "github_commit_url": "https://github.com/simd-everywhere/simde/commit/8a06c846000c9ba7735e9e85dc5f3024c76bc765",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "simde_mm_madd_epi16"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adding a NEON implementation for the `simde_mm_madd_epi16` function to leverage ARM-specific SIMD instructions for improved performance.",
            "The commit optimizes performance by adding a NEON implementation for the `simde_mm_madd_epi16` function to leverage ARM-specific SIMD instructions.",
            "The commit optimizes performance by adding a NEON implementation for the `simde_mm_madd_epi16` function to leverage ARM-specific SIMD instructions.",
            "The commit optimizes performance by adding a NEON implementation for the `simde_mm_madd_epi16` function to leverage ARM-specific SIMD instructions.",
            "The optimization strategy involved adding a NEON implementation for the `simde_mm_madd_epi16` function to leverage ARM-specific SIMD instructions for improved performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit optimizes performance by adding a NEON implementation for the `simde_mm_madd_epi16` function to leverage ARM-specific SIMD instructions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gnsstk",
        "hash": "d8afc8c63a4265b83ddd31f7e90fff826c7d45f2",
        "author": "Jon Little",
        "date": "2015-04-24T14:56:12-05:00",
        "message": "Merge branch '141-DiscFix-Slowdown' into 'master'\n\n141 disc fix slowdown\n\nCloses #141 but additional performance would be nice...\n\nSee merge request !5",
        "modified_files_count": 1,
        "modified_files": [
            "core/lib/TimeHandling/TimeString.cpp"
        ],
        "github_commit_url": "https://github.com/SGL-UT/gnsstk/commit/d8afc8c63a4265b83ddd31f7e90fff826c7d45f2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "printTime"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations or iterations within the `printTime` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the `printTime` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the `printTime` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the `printTime` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the `printTime` function to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations or iterations within the `printTime` function to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "8a9b36e2588b85e954f71dc03f165091a6fe0593",
        "author": "Chris Wilson",
        "date": "2019-04-30T16:04:54+01:00",
        "message": "drm/i915: Wait for the struct_mutex on idling\n\nWhen the system is idling, contention for struct_mutex should be low and\nso we will be more efficient to wait for a contended mutex than\nreschedule.\n\nSigned-off-by: Chris Wilson <chris@chris-wilson.co.uk>\nReviewed-by: Tvrtko Ursulin <tvrtko.ursulin@intel.com>\nLink: https://patchwork.freedesktop.org/patch/msgid/20190430094405.6127-1-chris@chris-wilson.co.uk",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/i915/i915_gem_pm.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/8a9b36e2588b85e954f71dc03f165091a6fe0593",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "idle_work_handler"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves waiting for a contended mutex during system idling instead of rescheduling, leveraging low contention to improve efficiency.",
            "The optimization strategy involves waiting for a contended mutex during system idling instead of rescheduling, leveraging low contention to improve efficiency.",
            "The optimization strategy involves waiting for a contended mutex during system idling instead of rescheduling, leveraging low contention to improve efficiency.",
            "The optimization strategy involves waiting for a contended mutex during system idling instead of rescheduling, leveraging low contention periods to improve efficiency.",
            "The optimization strategy involves waiting for a contended mutex during system idling instead of rescheduling, leveraging low contention to improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves waiting for a contended mutex during system idling instead of rescheduling, leveraging low contention to improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_msm-5.4_nothing_sm7325",
        "hash": "163489b64361083144b88d21824d4bb58d741208",
        "author": "Thomas Gleixner",
        "date": "2020-03-25T08:25:58+01:00",
        "message": "futex: Unbreak futex hashing\n\ncommit 8d67743653dce5a0e7aa500fcccb237cde7ad88e upstream.\n\nThe recent futex inode life time fix changed the ordering of the futex key\nunion struct members, but forgot to adjust the hash function accordingly,\n\nAs a result the hashing omits the leading 64bit and even hashes beyond the\nfutex key causing a bad hash distribution which led to a ~100% performance\nregression.\n\nHand in the futex key pointer instead of a random struct member and make\nthe size calculation based of the struct offset.\n\nFixes: 8019ad13ef7f (\"futex: Fix inode life-time issue\")\nReported-by: Rong Chen <rong.a.chen@intel.com>\nDecoded-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nTested-by: Rong Chen <rong.a.chen@intel.com>\nLink: https://lkml.kernel.org/r/87h7yy90ve.fsf@nanos.tec.linutronix.de\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/futex.c"
        ],
        "github_commit_url": "https://github.com/NothingOSS/android_kernel_msm-5.4_nothing_sm7325/commit/163489b64361083144b88d21824d4bb58d741208",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_futex_key"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization fixes a performance regression caused by incorrect hash function usage by ensuring the correct futex key pointer and size are used for hashing.",
            "The optimization fixes a performance regression caused by an incorrect hash function implementation by properly passing the futex key pointer and calculating the size based on the struct offset.",
            "The optimization fixes a hash function to correctly utilize the entire futex key, improving hash distribution and restoring performance.",
            "The optimization fixes a performance regression caused by an incorrect hash function implementation by properly passing the futex key pointer and calculating the size based on the struct offset.",
            "The optimization fixes a performance regression caused by incorrect hash function usage by adjusting the hashing logic to correctly handle the futex key structure."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization fixes a performance regression caused by incorrect hash function usage by ensuring the correct futex key pointer and size are used for hashing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qt",
        "hash": "464ee98eee5ce160b497aec6a1163422980dd797",
        "author": "Andreas Aardal Hanssen",
        "date": "2009-09-03T12:30:06+02:00",
        "message": "Fix test failure & optimize matrix operations in QGraphicsItem.\n\nThis fixes failures in tst_QGraphicsItem::setTransformProperties().\n\nChange 9e8ff32d introduced QMatrix4x4 as an internal matrix for\nQGraphicsItem. Problem is, QMatrix4x4 is float-based whereas QTransform\nis double-based. This change readds the use of QTransform in the case\nwhere there are no QGraphicsTransforms in the list. This by itself also\nmakes this common case a bit faster.\n\nThe workaround is moot if somebody adds any QGraphicsTransform,\nincluding one that doesn't do anything (like rotate by 0 degrees). So\nwe might have to find a better fix.\n\nReviewed-by: Olivier",
        "modified_files_count": 1,
        "modified_files": [
            "src/gui/graphicsview/qgraphicsitem_p.h"
        ],
        "github_commit_url": "https://github.com/qt/qt/commit/464ee98eee5ce160b497aec6a1163422980dd797",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "computedFullTransform"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reverts to using QTransform instead of QMatrix4x4 for cases without QGraphicsTransforms, reducing precision mismatches and improving performance in a common scenario.",
            "The optimization strategy reverts to using QTransform instead of QMatrix4x4 for matrix operations when no QGraphicsTransforms are present, reducing precision mismatches and improving performance in the common case.",
            "The optimization strategy reverts to using QTransform instead of QMatrix4x4 for matrix operations in the common case where no QGraphicsTransforms are present, reducing precision mismatches and improving performance.",
            "The optimization strategy involved reverting to a double-based matrix (QTransform) for common cases without QGraphicsTransforms to improve performance and fix precision-related test failures.",
            "The optimization strategy reverts to using QTransform instead of QMatrix4x4 for matrix operations when no QGraphicsTransforms are present, reducing precision mismatches and improving performance in the common case."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reverts to using QTransform instead of QMatrix4x4 for matrix operations when no QGraphicsTransforms are present, reducing precision mismatches and improving performance in the common case.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Octave",
        "hash": "ee4caeda308c09b3d23a69d5a479498737d5808c",
        "author": "Rik",
        "date": "2017-03-19T13:27:30-07:00",
        "message": "Improve performance of dlmread by pre-allocating larger array (bug #50102).\n\n* dlmread.cc (Fdlmread): Increase rmax, max number of rows, in powers of 2 to\navoid constant re-sizing of output matrix.",
        "modified_files_count": 1,
        "modified_files": [
            "libinterp/corefcn/dlmread.cc"
        ],
        "github_commit_url": "https://github.com/NexMirror/Octave/commit/ee4caeda308c09b3d23a69d5a479498737d5808c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DEFUN"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was to pre-allocate the output matrix in powers of 2 to reduce the overhead of frequent resizing during dynamic growth.",
            "The optimization strategy used is pre-allocating a larger array in powers of 2 to reduce the overhead of constant resizing during matrix growth.",
            "The optimization strategy used was to pre-allocate the output matrix in powers of 2 to reduce the overhead of frequent resizing during dynamic growth.",
            "The optimization strategy used was to pre-allocate the output matrix in powers of 2 to reduce the overhead of frequent resizing during dynamic growth.",
            "The optimization strategy used was to pre-allocate the output matrix in powers of 2 to reduce the overhead of frequent resizing during dynamic growth."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was to pre-allocate the output matrix in powers of 2 to reduce the overhead of frequent resizing during dynamic growth.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "net-snmp",
        "hash": "6c621c010009b92471bd250799aa1e70a22072f9",
        "author": "Bart Van Assche",
        "date": "2022-10-16T16:05:10-07:00",
        "message": "libsnmp: Optimize asn_build_unsigned_int64()\n\nUse a single 64-bit integer instead of two 32-bit integers to store the\nvalue being encoded.",
        "modified_files_count": 1,
        "modified_files": [
            "snmplib/asn1.c"
        ],
        "github_commit_url": "https://github.com/net-snmp/net-snmp/commit/6c621c010009b92471bd250799aa1e70a22072f9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "object"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was to replace two 32-bit integers with a single 64-bit integer to reduce the complexity and improve the efficiency of encoding large values.",
            "The optimization strategy used was to replace two 32-bit integers with a single 64-bit integer to reduce storage and processing overhead during encoding.",
            "The optimization strategy used was to replace two 32-bit integers with a single 64-bit integer to reduce the complexity and improve the efficiency of encoding large values.",
            "The optimization strategy used was to replace two 32-bit integers with a single 64-bit integer to reduce storage and simplify encoding operations.",
            "The optimization strategy used was to replace two 32-bit integers with a single 64-bit integer to reduce the complexity and improve the efficiency of encoding operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was to replace two 32-bit integers with a single 64-bit integer to reduce the complexity and improve the efficiency of encoding operations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "TheiaSfM",
        "hash": "e8e795759bc50c9a62da9f8fdcbecfecf7ac7675",
        "author": "Chris Sweeney",
        "date": "2015-11-05T20:57:54+01:00",
        "message": "Merge \"Improved efficiency for 5pt alg\"",
        "modified_files_count": 1,
        "modified_files": [
            "src/theia/sfm/pose/five_point_relative_pose.cc"
        ],
        "github_commit_url": "https://github.com/sweeneychris/TheiaSfM/commit/e8e795759bc50c9a62da9f8fdcbecfecf7ac7675",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of the 5-point algorithm by reducing unnecessary computations or iterations within the function.",
            "The optimization strategy involved improving the efficiency of the five-point algorithm by reducing unnecessary computations or iterations within the function.",
            "The optimization strategy involved improving the efficiency of the 5-point algorithm by reducing redundant computations or unnecessary operations within the function.",
            "The optimization strategy involved improving the efficiency of the 5-point algorithm by reducing redundant computations or improving numerical stability.",
            "The optimization strategy involved improving the efficiency of the 5-point algorithm by reducing redundant computations or unnecessary operations within the function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of the 5-point algorithm by reducing redundant computations or unnecessary operations within the function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "rondb",
        "hash": "031862bc330ae70de367c240f6da347a25400b04",
        "author": "Steinar H. Gunderson",
        "date": "2021-10-29T12:57:58+02:00",
        "message": "Bug #33517637: Speed up microbenchmarks in debug mode\n\nRunning microbenchmarks in debug mode is pointless, but since we run\nmicrobenchmarks as regular tests (because we don't have the full Google\nmicrobenchmark framework, and haven't made a separate registration\nframework), at least 100+100 iterations of each test (and minimum one\nsecond) are run anyway. This wastes time when running unit tests (both\nfor people and on automated builds), so reduce the number of iterations\nto a minimal number. This way, we can still check that the test doesn't\ncrash, but we don't need to wait for it.\n\nChange-Id: I34e6bd6078ef0ef6384474e0d525bd461f116be8",
        "modified_files_count": 1,
        "modified_files": [
            "unittest/gunit/benchmark.cc"
        ],
        "github_commit_url": "https://github.com/logicalclocks/rondb/commit/031862bc330ae70de367c240f6da347a25400b04",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "internal_do_microbenchmark"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces the number of iterations in microbenchmarks during debug mode to minimize unnecessary execution time while still ensuring basic functionality checks.",
            "Reduced the number of microbenchmark iterations in debug mode to minimize unnecessary execution time while still ensuring basic functionality checks.",
            "The optimization strategy reduces the number of iterations in microbenchmarks during debug mode to minimize execution time while still ensuring basic functionality checks.",
            "The optimization strategy reduces the number of iterations in microbenchmarks during debug mode to minimize unnecessary execution time while still ensuring basic functionality checks.",
            "The optimization strategy reduces the number of iterations in microbenchmarks during debug mode to minimize execution time while still ensuring basic functionality checks."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the number of iterations in microbenchmarks during debug mode to minimize execution time while still ensuring basic functionality checks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ewig",
        "hash": "618671dc7c20941921d7170666a119ed5009e43d",
        "author": "Juan Pedro Bolivar Puente",
        "date": "2017-04-11T10:06:25+02:00",
        "message": "Make code build with new immer changes\n\nAlso use the new `immer::copy` function for improved performance.",
        "modified_files_count": 1,
        "modified_files": [
            "src/ewig/main.cpp"
        ],
        "github_commit_url": "https://github.com/arximboldi/ewig/commit/618671dc7c20941921d7170666a119ed5009e43d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adopting the new `immer::copy` function to enhance performance by leveraging improved copy semantics.",
            "The optimization strategy involved adopting the new `immer::copy` function to enhance performance by leveraging its improved implementation.",
            "The optimization strategy involved adopting the new `immer::copy` function to enhance performance by leveraging its improved implementation.",
            "The optimization strategy involved adopting the new `immer::copy` function to enhance performance by leveraging its improved implementation.",
            "The optimization strategy involved adopting the new `immer::copy` function to enhance performance by leveraging its improved implementation."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved adopting the new `immer::copy` function to enhance performance by leveraging its improved implementation.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sysrepo",
        "hash": "88863fcecaa51c4563434e52b22dc2387d13279d",
        "author": "Michal Vasko",
        "date": "2024-12-17T15:19:08+01:00",
        "message": "edit diff OPTIMIZE do not duplicate origin",
        "modified_files_count": 1,
        "modified_files": [
            "src/edit_diff.c"
        ],
        "github_commit_url": "https://github.com/sysrepo/sysrepo/commit/88863fcecaa51c4563434e52b22dc2387d13279d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sr_edit_diff_set_origin"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids duplicating the origin string by directly assigning it instead of creating a copy.",
            "The optimization avoids duplicating the origin string by directly assigning it instead of creating a copy.",
            "The optimization avoids duplicating the origin string by directly assigning it instead of creating a copy.",
            "The optimization avoids duplicating the origin string by directly assigning it instead of creating a copy.",
            "The optimization avoids duplicating the origin string by directly assigning it instead of creating a copy."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids duplicating the origin string by directly assigning it instead of creating a copy.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "rhodes",
        "hash": "abe1c2d55511823beb9a5d2522f68804d94df7be",
        "author": "dmitrys",
        "date": "2012-11-30T21:09:43+04:00",
        "message": "fix low performance issue after lost Bluetooth connect on WM platform",
        "modified_files_count": 1,
        "modified_files": [
            "platform/wm/rhodes/bluetooth/Bluetooth.cpp"
        ],
        "github_commit_url": "https://github.com/rhomobile/rhodes/commit/abe1c2d55511823beb9a5d2522f68804d94df7be",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RhoBluetoothManager::runThreadReadData"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the frequency of a resource-intensive operation during Bluetooth disconnection handling on the WM platform.",
            "The optimization strategy involved reducing the frequency of a resource-intensive operation during Bluetooth disconnection handling on the WM platform.",
            "The optimization strategy involved reducing the frequency of a resource-intensive operation during Bluetooth reconnection on the WM platform by introducing a conditional check to execute it only when necessary.",
            "The optimization strategy involved reducing the frequency of a resource-intensive operation by introducing a conditional check to execute it only when necessary.",
            "The optimization strategy involved reducing the frequency of a resource-intensive operation during Bluetooth disconnection handling on the WM platform."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the frequency of a resource-intensive operation during Bluetooth disconnection handling on the WM platform.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "orx",
        "hash": "6739e59116c85d05515d3f038302fa1bd74764fc",
        "author": "iarwain",
        "date": "2014-04-18T00:02:33-04:00",
        "message": "- Worked around an optimization bug in some versions of GCC affecting end of FXs",
        "modified_files_count": 1,
        "modified_files": [
            "code/src/object/orxFX.c"
        ],
        "github_commit_url": "https://github.com/orx/orx/commit/6739e59116c85d05515d3f038302fa1bd74764fc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "orxFX_Apply"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit worked around a GCC optimization bug by modifying the code to ensure correct behavior when handling the end of FXs.",
            "The commit worked around a GCC optimization bug by modifying the control flow or data handling in the `orxFX_Apply` function to ensure correct behavior across compiler versions.",
            "The commit worked around a GCC optimization bug by modifying the code to ensure correct behavior when handling the end of FXs.",
            "The commit worked around a GCC optimization bug by modifying the code to avoid incorrect behavior in specific compiler versions.",
            "The optimization worked around a GCC compiler bug by modifying the FX end logic to ensure correct behavior across different compiler versions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit worked around a GCC optimization bug by modifying the code to ensure correct behavior when handling the end of FXs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "PhotoshopAPI",
        "hash": "b493e23067e1243456e807fb95dca621c2c66094",
        "author": "EmilDohne",
        "date": "2024-02-05T15:57:51+01:00",
        "message": "optimize RLE decompression slightly",
        "modified_files_count": 1,
        "modified_files": [
            "PhotoshopAPI/src/Util/Compression/RLE.h"
        ],
        "github_commit_url": "https://github.com/EmilDohne/PhotoshopAPI/commit/b493e23067e1243456e807fb95dca621c2c66094",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DecompressPackBits"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant memory accesses during RLE decompression by reusing previously computed values.",
            "The optimization strategy involved replacing a loop with a more efficient bitwise operation to reduce computational overhead during RLE decompression.",
            "The optimization strategy involved replacing a loop with a more efficient bitwise operation to reduce computational overhead during RLE decompression.",
            "The optimization strategy involved replacing a loop with a more efficient bitwise operation to reduce computational overhead during RLE decompression.",
            "The optimization strategy involved reducing redundant memory accesses during RLE decompression by reusing previously computed values."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a loop with a more efficient bitwise operation to reduce computational overhead during RLE decompression.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "RaZ",
        "hash": "08954743b61c0441119ebed0098880fdafe07543",
        "author": "Razakhel",
        "date": "2024-09-14T09:55:35+02:00",
        "message": "[Data/BoundingVolumeHierarchy] Querying a leaf checks the triangle first\n\n- It allows avoiding doing useless operations further, since we know it can't hit anything\n\n- If the node is a leaf, the triangle is directly tested instead of first testing the AABB\n  - Performance-wise, it presumably is either the same or marginally more efficient, as there's supposedly a high probability of hitting the triangle when reaching a leaf\n  - The ray-AABB check can fill the hit structure with irrelevant data\n\n- These changes allow for a speedup of ~10%",
        "modified_files_count": 1,
        "modified_files": [
            "src/RaZ/Data/BoundingVolumeHierarchy.cpp"
        ],
        "github_commit_url": "https://github.com/Razakhel/RaZ/commit/08954743b61c0441119ebed0098880fdafe07543",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BoundingVolumeHierarchyNode::query"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves directly testing the triangle in a leaf node before performing an AABB check to avoid unnecessary operations and potentially reduce irrelevant data processing.",
            "The optimization strategy involves directly testing the triangle in a leaf node before performing an AABB check to avoid unnecessary operations and potentially reduce irrelevant data processing.",
            "The optimization strategy involves directly testing the triangle in a leaf node before performing an AABB check to avoid unnecessary operations and potentially reduce irrelevant data processing.",
            "The optimization strategy involves directly testing the triangle in a leaf node before performing an AABB check to avoid unnecessary operations and potentially reduce irrelevant data processing.",
            "The optimization strategy involves directly testing the triangle in a leaf node before performing an AABB check to avoid unnecessary operations and potentially reduce irrelevant data processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves directly testing the triangle in a leaf node before performing an AABB check to avoid unnecessary operations and potentially reduce irrelevant data processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cmssw",
        "hash": "3e65652444b6e2df73f5acb813f4b4d1136ae81a",
        "author": "Vincenzo Innocente",
        "date": "2012-09-16T10:49:28+00:00",
        "message": "% faster then lookup",
        "modified_files_count": 1,
        "modified_files": [
            "Geometry/TrackerGeometryBuilder/interface/RectangularPixelTopology.h"
        ],
        "github_commit_url": "https://github.com/cms-sw/cmssw/commit/3e65652444b6e2df73f5acb813f4b4d1136ae81a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "isItBigPixelInY"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a lookup-based check with a direct conditional comparison to improve performance.",
            "The optimization strategy used is replacing a lookup-based check with a direct conditional comparison to improve performance.",
            "The optimization strategy involved replacing a lookup operation with a direct comparison to improve performance.",
            "The optimization strategy used is replacing a lookup operation with a direct comparison to improve performance.",
            "The optimization strategy used is replacing a lookup-based check with a direct conditional comparison to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is replacing a lookup-based check with a direct conditional comparison to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "parallel-n64",
        "hash": "f0accf683ecf8e5056c08ce927af084ba7e218f0",
        "author": "unknown",
        "date": "2015-07-28T14:56:16-04:00",
        "message": "Decode register specifier `rs` only when necessary (faster NOP).",
        "modified_files_count": 1,
        "modified_files": [
            "mupen64plus-rsp-cxd4/execute.h"
        ],
        "github_commit_url": "https://github.com/libretro/parallel-n64/commit/f0accf683ecf8e5056c08ce927af084ba7e218f0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "run_task"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids decoding the register specifier `rs` unless it is necessary, reducing redundant operations for faster execution of NOP instructions.",
            "The optimization strategy involves decoding the register specifier `rs` only when necessary, reducing unnecessary operations for faster NOP execution.",
            "The optimization strategy involves decoding the register specifier `rs` only when necessary, reducing unnecessary operations for faster NOP execution.",
            "The optimization strategy involves decoding the register specifier `rs` only when necessary, reducing unnecessary operations for NOP instructions.",
            "The optimization strategy involves conditionally decoding the register specifier `rs` only when it is necessary, reducing unnecessary operations for NOP instructions."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves decoding the register specifier `rs` only when necessary, reducing unnecessary operations for NOP instructions.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "simdjson",
        "hash": "52406402ed1f8ff246b18ddcfced9d2f4e98ccc9",
        "author": "Daniel Lemire",
        "date": "2024-05-01T14:53:48-04:00",
        "message": "fix: replace vm*vq_u8 by vm*vq_u32 for better performance under some systems.",
        "modified_files_count": 1,
        "modified_files": [
            "include/simdjson/arm64/simd.h"
        ],
        "github_commit_url": "https://github.com/simdjson/simdjson/commit/52406402ed1f8ff246b18ddcfced9d2f4e98ccc9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "any"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a less efficient SIMD instruction (vm*vq_u8) with a more efficient one (vm*vq_u32) to improve performance on certain systems.",
            "The optimization strategy replaced 8-bit vector multiplication with 32-bit vector multiplication to improve performance on certain systems by leveraging more efficient hardware instructions.",
            "The optimization strategy replaced a less efficient SIMD instruction (vm*vq_u8) with a more efficient one (vm*vq_u32) to improve performance on certain systems.",
            "The optimization strategy replaced 8-bit vector multiplication with 32-bit vector multiplication to improve performance on certain systems by leveraging more efficient hardware instructions.",
            "The optimization strategy replaced a less efficient SIMD instruction (`vm*vq_u8`) with a more efficient one (`vm*vq_u32`) to improve performance on certain systems."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a less efficient SIMD instruction (vm*vq_u8) with a more efficient one (vm*vq_u32) to improve performance on certain systems.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "scribus",
        "hash": "551a34ccf2da24852acce3feae808ed1c30550d9",
        "author": "Jean Ghali",
        "date": "2021-12-15T23:23:55+00:00",
        "message": "Small performance optimization\n\ngit-svn-id: svn://scribus.net/trunk/Scribus@24780 11d20701-8431-0410-a711-e3c959e3b870",
        "modified_files_count": 1,
        "modified_files": [
            "scribus/util_text.cpp"
        ],
        "github_commit_url": "https://github.com/scribusproject/scribus/commit/551a34ccf2da24852acce3feae808ed1c30550d9",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit likely involved a generic optimization such as loop restructuring or condition reordering to improve performance without altering functionality.",
            "The commit message and details are unavailable, so the optimization strategy cannot be determined.",
            "The commit likely implemented a generic optimization by reducing unnecessary computations or improving loop efficiency in the `util_text.cpp` file.",
            "The commit likely involved a generic optimization such as replacing expensive operations with cheaper alternatives or reducing redundant computations in a function.",
            "The commit message and details are unavailable, so the optimization strategy cannot be determined."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The commit likely involved a generic optimization such as loop restructuring or condition reordering to improve performance without altering functionality.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "5b2f6d9cd50b1c8909326c7175aef288a9915f33",
        "author": "Denton Liu",
        "date": "2020-04-07T16:57:30-07:00",
        "message": "sequencer: make file exists check more efficient\n\nWe currently check whether a file exists and return early before reading\nthe file. Instead of accessing the file twice, always read the file and\ncheck `errno` to see if the file doesn't exist.\n\nSigned-off-by: Denton Liu <liu.denton@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sequencer.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5b2f6d9cd50b1c8909326c7175aef288a9915f33",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "read_oneliner"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "git",
        "optimization_summary": [
            "The optimization strategy reduces file system calls by reading the file directly and checking `errno` instead of performing a separate existence check.",
            "The optimization strategy reduces file system calls by reading the file directly and checking `errno` instead of performing a separate existence check.",
            "The optimization strategy reduces file system calls by reading the file directly and checking `errno` instead of performing a separate existence check.",
            "The optimization strategy reduces file system calls by reading the file directly and checking `errno` instead of performing a separate existence check.",
            "The optimization strategy reduces file system calls by reading the file directly and checking `errno` instead of performing a separate existence check."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy reduces file system calls by reading the file directly and checking `errno` instead of performing a separate existence check.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "hhvm",
        "hash": "cf359f6a7ef0bc249cc5c7e1cd51b72962b7933b",
        "author": "Michael O'Farrell",
        "date": "2018-09-21T12:28:43-07:00",
        "message": "Make xls actually use a simd reg to break cycles\n\nSummary: The code requires the register be simd.\n\nReviewed By: ricklavoie\n\nDifferential Revision: D9976821\n\nfbshipit-source-id: 8bd786c7b26591ab6ba942d3d1d30449ab364ee7",
        "modified_files_count": 1,
        "modified_files": [
            "hphp/runtime/vm/jit/vasm-xls.cpp"
        ],
        "github_commit_url": "https://github.com/facebook/hhvm/commit/cf359f6a7ef0bc249cc5c7e1cd51b72962b7933b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VxlsContext"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved modifying the code to utilize SIMD registers to break cycles and improve performance.",
            "The optimization strategy involved modifying the code to utilize a SIMD register to break cycles and improve performance.",
            "The optimization leverages SIMD registers to break cycles and improve instruction-level parallelism.",
            "The optimization strategy involved modifying the code to utilize SIMD registers to break cycles and improve performance.",
            "The optimization strategy involved modifying the code to utilize SIMD registers explicitly to break dependency cycles and improve instruction-level parallelism."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved modifying the code to utilize SIMD registers to break cycles and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gcc",
        "hash": "c7fd6c4369ef1a009b40c1787ea9d2dad2cf449f",
        "author": "Andrew MacLeod",
        "date": "2024-12-06T16:41:19-05:00",
        "message": "Only add inferred ranges if they change the value.\n\nDo not add an inferred range if it is already incorprated in the\ncurrent range of an SSA_NAME.\n\n\tPR tree-optimization/117467\n\t* gimple-range-infer.cc (infer_range_manager::add_ranges): Check\n\trange_of_expr to see if the inferred range is needed.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/gimple-range-infer.cc"
        ],
        "github_commit_url": "https://github.com/gcc-mirror/gcc/commit/c7fd6c4369ef1a009b40c1787ea9d2dad2cf449f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "infer_range_manager::add_ranges"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids adding redundant inferred ranges by checking if they are already incorporated in the current range of an SSA_NAME.",
            "The optimization avoids adding redundant inferred ranges by checking if they are already incorporated in the current range of an SSA_NAME.",
            "The optimization avoids adding redundant inferred ranges by checking if they are already incorporated in the current range of an SSA_NAME.",
            "The optimization avoids adding redundant inferred ranges by checking if they are already incorporated in the current range of an SSA_NAME.",
            "The optimization avoids adding redundant inferred ranges by checking if they are already incorporated in the current range of an SSA_NAME."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids adding redundant inferred ranges by checking if they are already incorporated in the current range of an SSA_NAME.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "KeyDB",
        "hash": "61ba83b75b6cf3d9b11069cc78a60aeb355d9785",
        "author": "antirez",
        "date": "2014-05-07T16:12:32+02:00",
        "message": "Scripting: simpler reply buffer creation in luaRedisGenericCommand().\n\nIt if faster to just create the string with a single sdsnewlen() call.\nIf c->bufpos is zero, the call will simply be like sdsemtpy().",
        "modified_files_count": 1,
        "modified_files": [
            "src/scripting.c"
        ],
        "github_commit_url": "https://github.com/Snapchat/KeyDB/commit/61ba83b75b6cf3d9b11069cc78a60aeb355d9785",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "luaRedisGenericCommand"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to replace multiple string creation operations with a single `sdsnewlen()` call to reduce overhead and improve performance.",
            "The optimization strategy used is to replace multiple string creation operations with a single `sdsnewlen()` call to reduce overhead and improve performance.",
            "The optimization strategy simplifies reply buffer creation by using a single `sdsnewlen()` call instead of multiple operations, reducing overhead when `c->bufpos` is zero.",
            "The optimization strategy used is to replace multiple string creation operations with a single `sdsnewlen()` call to reduce overhead and improve performance.",
            "The optimization strategy simplifies reply buffer creation by using a single `sdsnewlen()` call instead of multiple operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to replace multiple string creation operations with a single `sdsnewlen()` call to reduce overhead and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "monero",
        "hash": "cfa45836951d948eb9c4c76c5d5f97bbfbb514e3",
        "author": "luigi1111",
        "date": "2023-07-06T21:32:11-05:00",
        "message": "Merge pull request #8894\n\nc589e15 Speed up perf_timer init on x86 (SChernykh)",
        "modified_files_count": 1,
        "modified_files": [
            "src/common/perf_timer.cpp"
        ],
        "github_commit_url": "https://github.com/monero-project/monero/commit/cfa45836951d948eb9c4c76c5d5f97bbfbb514e3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_ticks_per_ns"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the initialization speed of the `perf_timer` by optimizing the `get_ticks_per_ns` function specifically for x86 architecture.",
            "The optimization strategy involved improving the initialization speed of the `perf_timer` on x86 by likely reducing unnecessary computations or system calls during the retrieval of ticks per nanosecond.",
            "The optimization strategy involved improving the initialization speed of the `perf_timer` on x86 by likely reducing computational overhead or leveraging architecture-specific features.",
            "The optimization strategy involved improving the initialization speed of the `perf_timer` by optimizing the calculation of ticks per nanosecond on x86 architecture.",
            "The optimization strategy involved improving the initialization speed of the `perf_timer` on x86 by likely reducing computational overhead or leveraging architecture-specific features."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the initialization speed of the `perf_timer` by optimizing the `get_ticks_per_ns` function specifically for x86 architecture.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kernel_xiaomi_sm8250",
        "hash": "6b274863bca832165bc35509087604dea0c0c42d",
        "author": "Charan Teja Reddy",
        "date": "2019-11-21T21:31:32-08:00",
        "message": "mm: ignore boosting for min watermark\n\nIgnore boosting for min watermark for __GFP_ATOMIC, ALLOC_HIGH and\nALLOC_HARDER allocation requests. Of the others, this helps in avoiding\nthe atomic allocation failures.\n\nChange-Id: I41dcc71ed37b7a1d2093d13f40e82c7750642e39\nSigned-off-by: Charan Teja Reddy <charante@codeaurora.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/page_alloc.c"
        ],
        "github_commit_url": "https://github.com/EmanuelCN/kernel_xiaomi_sm8250/commit/6b274863bca832165bc35509087604dea0c0c42d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_page_from_freelist"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy ignores boosting for minimum watermark checks in specific memory allocation requests to reduce atomic allocation failures.",
            "The optimization strategy ignores boosting for the minimum watermark in specific allocation requests to reduce atomic allocation failures.",
            "The optimization strategy ignores boosting for minimum watermark checks in specific allocation requests to reduce atomic allocation failures.",
            "The optimization strategy ignores boosting for minimum watermark checks in specific allocation requests to reduce atomic allocation failures.",
            "The optimization strategy ignores boosting for minimum watermark checks during specific memory allocation requests to reduce atomic allocation failures."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy ignores boosting for minimum watermark checks in specific allocation requests to reduce atomic allocation failures.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "stress-ng",
        "hash": "1b7ce6062adbf0ea37140dd1cafd9131ee4d63a9",
        "author": "Colin Ian King",
        "date": "2021-01-24T13:09:45+00:00",
        "message": "Force keep_stressing_flag to always be inlined\n\nperf is showing that the helper function in some cases is not being\ninlined and resulting in a performance impact on call/returns. Force\nit to be inlined.\n\nSigned-off-by: Colin Ian King <colin.king@canonical.com>",
        "modified_files_count": 1,
        "modified_files": [
            "stress-ng.h"
        ],
        "github_commit_url": "https://github.com/ColinIanKing/stress-ng/commit/1b7ce6062adbf0ea37140dd1cafd9131ee4d63a9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "keep_stressing_flag"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization forces the inlining of the `keep_stressing_flag` function to eliminate call/return overhead and improve performance.",
            "The optimization forces the inlining of the `keep_stressing_flag` function to eliminate call/return overhead.",
            "The optimization forces the inlining of the `keep_stressing_flag` function to eliminate call/return overhead.",
            "The optimization strategy forces the inlining of the `keep_stressing_flag` function to eliminate call/return overhead and improve performance.",
            "The optimization forces the inlining of the `keep_stressing_flag` function to eliminate call/return overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization forces the inlining of the `keep_stressing_flag` function to eliminate call/return overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "cce6deeb56aa8aad1d3154d70ea419cf25967f5c",
        "author": "Chuck Lever",
        "date": "2016-05-17T15:47:59-04:00",
        "message": "xprtrdma: Avoid using Write list for small NFS READ requests\n\nAvoid the latency and interrupt overhead of registering a Write\nchunk when handling NFS READ requests of a few hundred bytes or\nless.\n\nThis change does not interoperate with Linux NFS/RDMA servers\nthat do not have commit 9d11b51ce7c1 ('svcrdma: Fix send_reply()\nscatter/gather set-up'). Commit 9d11b51ce7c1 was introduced in v4.3,\nand is included in 4.2.y, 4.1.y, and 3.18.y.\n\nOracle bug 22925946 has been filed to request that the above fix\nbe included in the Oracle Linux UEK4 NFS/RDMA server.\n\nRed Hat bugzillas 1327280 and 1327554 have been filed to request\nthat RHEL NFS/RDMA server backports include the above fix.\n\nWorkaround: Replace the \"proto=rdma,port=20049\" mount options\nwith \"proto=tcp\" until commit 9d11b51ce7c1 is applied to your\nNFS server.\n\nSigned-off-by: Chuck Lever <chuck.lever@oracle.com>\nTested-by: Steve Wise <swise@opengridcomputing.com>\nReviewed-by: Sagi Grimberg <sagi@grimberg.me>\nSigned-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>",
        "modified_files_count": 1,
        "modified_files": [
            "net/sunrpc/xprtrdma/rpc_rdma.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/cce6deeb56aa8aad1d3154d70ea419cf25967f5c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rpcrdma_marshal_req"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids using the Write list for small NFS READ requests to reduce latency and interrupt overhead.",
            "The optimization avoids using the Write list for small NFS READ requests to reduce latency and interrupt overhead.",
            "The optimization avoids using the Write list for small NFS READ requests to reduce latency and interrupt overhead.",
            "The optimization avoids using the Write list for small NFS READ requests to reduce latency and interrupt overhead.",
            "The optimization avoids using the Write list for small NFS READ requests to reduce latency and interrupt overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids using the Write list for small NFS READ requests to reduce latency and interrupt overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "0afabc1fdb98edac2c1ea2bbc0712a495599acec",
        "author": "Andrey Konovalov",
        "date": "2021-02-16T15:33:31+01:00",
        "message": "FROMGIT: kasan: optimize large kmalloc poisoning\n\nSimilarly to kasan_kmalloc(), kasan_kmalloc_large() doesn't need to\nunpoison the object as it as already unpoisoned by alloc_pages() (or by\nksize() for krealloc()).\n\nThis patch changes kasan_kmalloc_large() to only poison the redzone.\n\nLink: https://lkml.kernel.org/r/33dee5aac0e550ad7f8e26f590c9b02c6129b4a3.1612546384.git.andreyknvl@google.com\nSigned-off-by: Andrey Konovalov <andreyknvl@google.com>\nReviewed-by: Marco Elver <elver@google.com>\nCc: Alexander Potapenko <glider@google.com>\nCc: Andrey Ryabinin <aryabinin@virtuozzo.com>\nCc: Branislav Rankov <Branislav.Rankov@arm.com>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Dmitry Vyukov <dvyukov@google.com>\nCc: Evgenii Stepanov <eugenis@google.com>\nCc: Kevin Brodsky <kevin.brodsky@arm.com>\nCc: Peter Collingbourne <pcc@google.com>\nCc: Vincenzo Frascino <vincenzo.frascino@arm.com>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Stephen Rothwell <sfr@canb.auug.org.au>\n(cherry picked from commit f124e80f84413625cbbdfe714654d1864fbafaae\n https://git.kernel.org/pub/scm/linux/kernel/git/next/linux-next.git akpm)\nBug: 172318110\nChange-Id: Iab96fa5f5a2a1a8b033f7dbe3d3d732954ee2d22",
        "modified_files_count": 1,
        "modified_files": [
            "mm/kasan/common.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/0afabc1fdb98edac2c1ea2bbc0712a495599acec",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__kasan_kmalloc_large"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy eliminates redundant unpoisoning of memory objects in `kasan_kmalloc_large()` by leveraging the fact that they are already unpoisoned elsewhere, thus reducing unnecessary operations.",
            "The optimization strategy eliminates redundant unpoisoning of memory objects in `kasan_kmalloc_large()` by leveraging the fact that they are already unpoisoned elsewhere, thus reducing unnecessary operations.",
            "The optimization strategy eliminates redundant unpoisoning of memory objects in `kasan_kmalloc_large()` by leveraging the fact that they are already unpoisoned elsewhere, thus reducing unnecessary operations.",
            "The optimization strategy eliminates redundant unpoisoning of memory objects in `kasan_kmalloc_large()` by leveraging the fact that they are already unpoisoned elsewhere, thus reducing unnecessary operations.",
            "The optimization strategy eliminates redundant unpoisoning of memory objects in `kasan_kmalloc_large()` by leveraging the fact that they are already unpoisoned elsewhere, thus reducing unnecessary operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy eliminates redundant unpoisoning of memory objects in `kasan_kmalloc_large()` by leveraging the fact that they are already unpoisoned elsewhere, thus reducing unnecessary operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "41a4651af6fd6830bff136ac26597d2ff480df52",
        "author": "Benedikt Meurer",
        "date": "2019-03-22T15:06:55+00:00",
        "message": "[tracing] Correct \"V8.OptimizeCode\" scope.\n\nThe \"V8.OptimizeCode\" trace event (in \"disabled-by-default-v8.compile\"\ncategory) didn't include the setup of the OptimizedCompilationJob, which\nis quite expensive already and should be accounted for properly.\n\nBug: v8:8598\nChange-Id: Ieec139c8d555d02edfbc52e904ee214d1007afbd\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/1533871\nReviewed-by: Peter Marshall <petermarshall@chromium.org>\nCommit-Queue: Benedikt Meurer <bmeurer@chromium.org>\nCr-Commit-Position: refs/heads/master@{#60413}",
        "modified_files_count": 1,
        "modified_files": [
            "src/compiler.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/41a4651af6fd6830bff136ac26597d2ff480df52",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetOptimizedCode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved expanding the scope of a trace event to include expensive setup operations for more accurate performance accounting.",
            "The optimization strategy involved expanding the scope of a trace event to include expensive setup operations for more accurate performance accounting.",
            "The optimization strategy involved expanding the scope of a trace event to include expensive setup operations for more accurate performance accounting.",
            "The optimization strategy involved expanding the scope of a trace event to include expensive setup operations for more accurate performance accounting.",
            "The optimization strategy involved expanding the scope of a tracing event to include expensive setup operations for more accurate performance accounting."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved expanding the scope of a trace event to include expensive setup operations for more accurate performance accounting.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dte",
        "hash": "3ad41d654c936bc81e092ffd98ecaedcb643d850",
        "author": "Craig Barnes",
        "date": "2023-02-22T10:25:47+00:00",
        "message": "Implement get_indent_width() without using get_indent_info()\n\nThis makes the generated code considerably more efficient.",
        "modified_files_count": 1,
        "modified_files": [
            "src/indent.c"
        ],
        "github_commit_url": "https://github.com/craigbarnes/dte/commit/3ad41d654c936bc81e092ffd98ecaedcb643d850",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_indent_width"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the function by directly calculating the indent width without relying on an intermediate function call.",
            "The optimization strategy involved simplifying the function by directly calculating the indent width without relying on an intermediate function call.",
            "The optimization strategy involved simplifying the function logic by directly calculating the indentation width without relying on an intermediate function call.",
            "The optimization strategy involved simplifying the function by directly calculating the indentation width without relying on an intermediate function call.",
            "The optimization strategy involved simplifying the function by directly calculating the indentation width without relying on an intermediate function call."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the function by directly calculating the indentation width without relying on an intermediate function call.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FastDoom",
        "hash": "3debe3a8ecea6186375a54ee7a93282fd98fcf17",
        "author": "viti95",
        "date": "2021-03-24T22:19:02+01:00",
        "message": "Small optimization for 16 colors LUT calculation",
        "modified_files_count": 1,
        "modified_files": [
            "i_ibm.c"
        ],
        "github_commit_url": "https://github.com/viti95/FastDoom/commit/3debe3a8ecea6186375a54ee7a93282fd98fcf17",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "I_SetPalette"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the logic for calculating a 16-color lookup table to reduce unnecessary computations.",
            "The optimization strategy involved simplifying the logic for calculating a 16-color lookup table to reduce unnecessary computations.",
            "The optimization strategy involved replacing a multiplication operation with a bit shift to improve the efficiency of calculating lookup table indices for 16-color palettes.",
            "The optimization strategy involved simplifying the logic for calculating a 16-color lookup table (LUT) by reducing redundant operations or iterations.",
            "The optimization strategy involved replacing a multiplication operation with a bit shift to improve the efficiency of calculating lookup table indices for 16-color palettes."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the logic for calculating a 16-color lookup table to reduce unnecessary computations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "mppp",
        "hash": "0dad166a5c9bc7092f99e55baaec235d077db9ab",
        "author": "Francesco Biscani",
        "date": "2017-07-03T22:56:36+02:00",
        "message": "Improve test performance by avoiding string conversions.",
        "modified_files_count": 1,
        "modified_files": [
            "test/integer_arith.cpp"
        ],
        "github_commit_url": "https://github.com/bluescarni/mppp/commit/0dad166a5c9bc7092f99e55baaec235d077db9ab",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary string conversions in tests to improve performance.",
            "The optimization strategy avoids unnecessary string conversions in tests to improve performance.",
            "The optimization strategy involved eliminating unnecessary string conversions in test cases to improve performance.",
            "The optimization strategy avoids unnecessary string conversions in test cases to improve performance.",
            "The optimization strategy avoids unnecessary string conversions in tests to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary string conversions in tests to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "d5699e0b08f9892f19021e453e98ab008cae753c",
        "author": "Tyler Rockwood",
        "date": "2024-02-06T11:50:14-06:00",
        "message": "fragmented_vector: improve memory_size calculation\n\nAccount for chunked_vector\n\nSigned-off-by: Tyler Rockwood <rockwood@redpanda.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/v/container/include/container/fragmented_vector.h"
        ],
        "github_commit_url": "https://github.com/redpanda-data/redpanda/commit/d5699e0b08f9892f19021e453e98ab008cae753c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "memory_size"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "redpanda",
        "optimization_summary": [
            "The optimization strategy involved improving the `memory_size` calculation by accounting for chunked_vector, likely reducing unnecessary computations or iterations.",
            "The optimization strategy involved refining the `memory_size` calculation to account for chunked_vector, improving accuracy and potentially performance by better reflecting memory usage.",
            "The optimization strategy involved refining the `memory_size` calculation to account for chunked_vector, improving accuracy and potentially performance.",
            "The optimization strategy involved refining the `memory_size` calculation to account for chunked_vector, improving accuracy and potentially performance.",
            "The optimization strategy involved refining the `memory_size` calculation to account for chunked_vector, improving accuracy and potentially performance by better reflecting memory usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved refining the `memory_size` calculation to account for chunked_vector, improving accuracy and potentially performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "media-driver",
        "hash": "068a665054d786b83c8af0b791bf4aeddb75dd90",
        "author": "LeyuYao",
        "date": "2023-01-17T19:30:08+08:00",
        "message": "[Encode] Optimize stream in programming\n\nDisable vdenc stream in when segment is disabled",
        "modified_files_count": 1,
        "modified_files": [
            "media_softlet/agnostic/common/codec/hal/enc/av1/features/encode_av1_segmentation.cpp"
        ],
        "github_commit_url": "https://github.com/intel/media-driver/commit/068a665054d786b83c8af0b791bf4aeddb75dd90",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Av1Segmentation::Update"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy disables the vdenc stream when segmentation is disabled to avoid unnecessary processing.",
            "The optimization disables vdenc stream processing when segmentation is disabled to avoid unnecessary operations.",
            "The optimization disables vdenc stream processing when segmentation is disabled to avoid unnecessary operations.",
            "The optimization disables vdenc stream processing when segmentation is disabled to avoid unnecessary operations.",
            "The optimization disables vdenc stream processing when segmentation is disabled to avoid unnecessary operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization disables vdenc stream processing when segmentation is disabled to avoid unnecessary operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "d4346abfe3871e36bac55487d968502db1471545",
        "author": "Jonathan Kew",
        "date": "2017-09-20T10:10:01+01:00",
        "message": "Bug 1377515 - Use GetFontTable rather than CopyFontTable in gfxDWriteFontEntry::IsCJKFont() to try and avoid copying. r=bas",
        "modified_files_count": 1,
        "modified_files": [
            "gfx/thebes/gfxDWriteFontList.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/d4346abfe3871e36bac55487d968502db1471545",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gfxDWriteFontEntry::IsCJKFont"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a function that copies font table data with one that retrieves it directly to avoid unnecessary memory copying.",
            "The optimization strategy involved replacing a function that copies font table data with one that retrieves it directly to avoid unnecessary memory copying.",
            "The optimization strategy involved replacing a function that copies font table data with one that retrieves it directly to reduce memory overhead.",
            "The optimization strategy involved replacing a function that copies font table data with one that retrieves it directly to avoid unnecessary memory copying.",
            "The optimization strategy involved replacing a function that copies font table data with one that retrieves it directly to avoid unnecessary memory copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a function that copies font table data with one that retrieves it directly to avoid unnecessary memory copying.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "rusefi",
        "hash": "0f749322d03b1f13e7d9202d571da46b29ce32b4",
        "author": "Andrey Gusakov",
        "date": "2024-07-29T09:21:47-04:00",
        "message": "drivers: w25q: speedup a bit, timeout exit",
        "modified_files_count": 1,
        "modified_files": [
            "firmware/hw_layer/drivers/flash/w25q/hal_flash_device.c"
        ],
        "github_commit_url": "https://github.com/rusefi/rusefi/commit/0f749322d03b1f13e7d9202d571da46b29ce32b4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "w25q_poll_status"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary polling iterations by introducing an early exit condition based on a timeout.",
            "The optimization strategy involved reducing unnecessary polling iterations by introducing an early exit condition based on a timeout.",
            "The optimization strategy involved reducing unnecessary polling operations by introducing a timeout exit condition in the status check loop.",
            "The optimization strategy involved reducing unnecessary polling iterations by introducing an early exit condition based on a timeout.",
            "The optimization strategy involved reducing unnecessary polling operations by implementing an early exit upon timeout detection."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary polling iterations by introducing an early exit condition based on a timeout.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "eab4b8aa34fc64e3a91358e1612e6d059396193b",
        "author": "Avi Kivity",
        "date": "2009-09-10T08:33:21+03:00",
        "message": "KVM: VMX: Optimize vmx_get_cpl()\n\nInstead of calling vmx_get_segment() (which reads a whole bunch of\nvmcs fields), read only the cs selector which contains the cpl.\n\nSigned-off-by: Avi Kivity <avi@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/kvm/vmx.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/eab4b8aa34fc64e3a91358e1612e6d059396193b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vmx_get_cpl"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy reduces overhead by directly reading the CS selector from the VMCS instead of calling a function that reads multiple fields.",
            "The optimization strategy reduces overhead by directly reading the CS selector from the VMCS instead of calling a function that retrieves multiple segment fields.",
            "The optimization strategy reduces overhead by directly reading the CS selector from the VMCS instead of calling a function that retrieves multiple segment fields.",
            "The optimization strategy reduces overhead by directly reading the CS selector from the VMCS instead of calling a function that reads multiple fields.",
            "The optimization strategy reduces overhead by directly reading the CS selector from the VMCS instead of calling a function that retrieves multiple segment fields."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces overhead by directly reading the CS selector from the VMCS instead of calling a function that retrieves multiple segment fields.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "open_spiel",
        "hash": "be7d512e17f0829e115a2cfbca8edb0f07d8bc36",
        "author": "Finbarr Timbers",
        "date": "2020-07-18T11:55:42-06:00",
        "message": "Adds back special-case optimization for UpdateIncrementalStateDistribution in UniversalPoker. This was accidentally removed previously.\n\nPiperOrigin-RevId: 321604122\nChange-Id: I7ce6b791b87aa3cca6243010a6c49403660d7342",
        "modified_files_count": 1,
        "modified_files": [
            "open_spiel/algorithms/state_distribution.cc"
        ],
        "github_commit_url": "https://github.com/google-deepmind/open_spiel/commit/be7d512e17f0829e115a2cfbca8edb0f07d8bc36",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "UpdateIncrementalStateDistribution"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit reintroduces a special-case optimization for the `UpdateIncrementalStateDistribution` function in UniversalPoker, likely reducing redundant computations or improving efficiency for a specific scenario.",
            "The commit reintroduces a special-case optimization for the `UpdateIncrementalStateDistribution` function in UniversalPoker, likely reducing redundant computations or improving efficiency for a specific scenario.",
            "The commit reintroduces a special-case optimization for the `UpdateIncrementalStateDistribution` function in UniversalPoker, likely reducing redundant computations or improving efficiency for a specific scenario.",
            "The commit reintroduces a special-case optimization for the `UpdateIncrementalStateDistribution` function in UniversalPoker, likely reducing redundant computations or improving efficiency for a specific scenario.",
            "The commit reintroduces a special-case optimization for the `UpdateIncrementalStateDistribution` function in UniversalPoker, likely reducing redundant computations or improving efficiency for a specific scenario."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit reintroduces a special-case optimization for the `UpdateIncrementalStateDistribution` function in UniversalPoker, likely reducing redundant computations or improving efficiency for a specific scenario.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "0e4ca37c2581f6e449c193612e77657c4dd87865",
        "author": "Niclas Schwalbe",
        "date": "2021-11-07T14:50:07+08:00",
        "message": "[misc] Update \"get_largest_pot\" in scalar.h + Bug Fix (#3405)\n\n* Update scalar.h\r\n\r\nFind the largest potence faster.\r\n\r\n* Update scalar.h\r\n\r\n* Update scalar.h\r\n\r\nFixed a bug\r\n\r\n* Update scalar.h\r\n\r\nManually edited formatting errors.\r\n\r\n* Update scalar.h\r\n\r\nretry workflow\r\n\r\n* Create scalar.h\r\n\r\nretry workflow",
        "modified_files_count": 1,
        "modified_files": [
            "taichi/math/scalar.h"
        ],
        "github_commit_url": "https://github.com/taichi-dev/taichi/commit/0e4ca37c2581f6e449c193612e77657c4dd87865",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_largest_pot"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "taichi",
        "optimization_summary": [
            "The optimization strategy used is to improve the efficiency of finding the largest power of two by reducing unnecessary computations.",
            "The optimization strategy used is to improve the efficiency of finding the largest power of two by reducing unnecessary computations.",
            "The optimization strategy used is to improve the efficiency of finding the largest power of two by reducing unnecessary computations.",
            "The optimization strategy used is to improve the efficiency of finding the largest power of two by reducing unnecessary computations.",
            "The optimization strategy used is to improve the efficiency of finding the largest power of two by reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to improve the efficiency of finding the largest power of two by reducing unnecessary computations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "3e9ba6684d5ac9c48a1741566b1c1ce781e77125",
        "author": "Milian Wolff",
        "date": "2013-09-24T18:51:33+02:00",
        "message": "Optimize ConnectionModel::connectionRemoved by two orders of magnitude\n\nQVector in Qt4 does not move objects when erasing, even though\nConnection is marked as movable. To workaround this issue, we swap\nwith the last entry and pop from the back which is cheap.\n\n********* Start testing of GammaRay::BenchSuite *********\nConfig: Using QTest library 4.8.5, Qt 4.8.5\nPASS   : GammaRay::BenchSuite::initTestCase()\nRESULT : GammaRay::BenchSuite::connectionModel_connectionRemoved():\n     95 msecs per iteration (total: 95, iterations: 1)\nPASS   : GammaRay::BenchSuite::connectionModel_connectionRemoved()\nPASS   : GammaRay::BenchSuite::cleanupTestCase()\nTotals: 3 passed, 0 failed, 0 skipped\n********* Finished testing of GammaRay::BenchSuite *********\n\n Performance counter stats for './bin/benchsuite connectionModel_connectionRemoved':\n\n        404.448500 task-clock                #    0.991 CPUs utilized\n               112 context-switches          #    0.277 K/sec\n                 6 cpu-migrations            #    0.015 K/sec\n            12,756 page-faults               #    0.032 M/sec\n     1,138,930,126 cycles                    #    2.816 GHz                     [49.29%]\n   <not supported> stalled-cycles-frontend\n   <not supported> stalled-cycles-backend\n     1,464,750,989 instructions              #    1.29  insns per cycle         [74.73%]\n       367,314,247 branches                  #  908.185 M/sec                   [75.32%]\n         4,651,435 branch-misses             #    1.27% of all branches         [75.41%]\n\n       0.408093680 seconds time elapsed",
        "modified_files_count": 1,
        "modified_files": [
            "core/connectionmodel.cpp"
        ],
        "github_commit_url": "https://github.com/KDAB/GammaRay/commit/3e9ba6684d5ac9c48a1741566b1c1ce781e77125",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ConnectionModel::connectionRemovedMainThread"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "GammaRay",
        "optimization_summary": [
            "The optimization strategy used is replacing the erase operation with a swap-and-pop approach to avoid the overhead of shifting elements in a QVector.",
            "The optimization strategy used is replacing the erase operation with a swap-and-pop approach to avoid expensive element shifting in QVector.",
            "The optimization strategy used is replacing the erase operation with a swap-and-pop approach to avoid expensive element shifting in QVector.",
            "The optimization strategy used is replacing the erase operation with a swap-and-pop approach to avoid expensive object shifting in QVector.",
            "The optimization strategy used is replacing the erase operation with a swap-and-pop approach to avoid expensive element shifting in QVector."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is replacing the erase operation with a swap-and-pop approach to avoid expensive element shifting in QVector.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "851c941b8b596e7e2914b00795c32e285668b389",
        "author": "Benjamin Kramer",
        "date": "2012-09-09T11:56:14+00:00",
        "message": "LiveVariables: Compute a set of defs and kills to speed up updating LV during critical edge splitting.\n\nPreviously we checked if the register is def'd in a block via the def/use list a\nnd walked the list of kills to check if the register is killed in a block. Both\nof these checks can be made much cheaper by walking the block first and\nrecording all defs and kills.\n\nThis reduces the compile time of the test case from PR13651 from 40s to 15s at\n-O2. The compile time is still dominated by LV updating but now the main culprit\nis SparseBitVector's slowness.\n\nllvm-svn: 163478",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/LiveVariables.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/851c941b8b596e7e2914b00795c32e285668b389",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved precomputing and caching sets of definitions and kills for each block to avoid repeatedly walking def/use lists and kill lists during live variable updates.",
            "The optimization strategy involved precomputing and caching sets of definitions and kills for each block to avoid repeatedly traversing def/use lists and kill lists during live variable updates.",
            "The optimization strategy involved precomputing and caching sets of definitions and kills for each block to reduce redundant checks during live variable updates.",
            "The optimization strategy involved precomputing and caching sets of definitions and kills for each block to avoid repeatedly walking def/use lists and kill lists during live variable updates.",
            "The optimization strategy involved precomputing and caching the sets of definitions and kills for each block to avoid repeatedly walking the def/use list and kill list during live variable updates."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved precomputing and caching sets of definitions and kills for each block to avoid repeatedly walking def/use lists and kill lists during live variable updates.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "PX4-Autopilot",
        "hash": "5d441d65e1d4c7c72bec8e74be68b92dbadcaf28",
        "author": "bresch",
        "date": "2021-03-04T19:43:01+11:00",
        "message": "Accelerate tilt fine alignment by reducing obs noise when at rest\n\nFine tilt alignment is accomplished by fusing fake position data after\na coarse tilt leveling. The observation noise can be reduced if the\nvehicle is at rest to speed up the process.",
        "modified_files_count": 1,
        "modified_files": [
            "EKF/control.cpp"
        ],
        "github_commit_url": "https://github.com/PX4/PX4-Autopilot/commit/5d441d65e1d4c7c72bec8e74be68b92dbadcaf28",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Ekf::controlFakePosFusion"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces observation noise in the fine tilt alignment process when the vehicle is at rest to accelerate convergence.",
            "The optimization reduces observation noise in the fine tilt alignment process when the vehicle is at rest to accelerate convergence.",
            "The optimization reduces observation noise in the fine tilt alignment process when the vehicle is at rest to accelerate convergence.",
            "The optimization reduces observation noise in the fine tilt alignment process when the vehicle is at rest to accelerate convergence.",
            "The optimization reduces observation noise in the fine tilt alignment process when the vehicle is at rest to accelerate convergence."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces observation noise in the fine tilt alignment process when the vehicle is at rest to accelerate convergence.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "otter-browser",
        "hash": "8dda7673a6f5bdd2d1277ede696b57499e1b9bc3",
        "author": "Michał Dutkiewicz",
        "date": "2017-05-31T21:16:35+02:00",
        "message": "Add missing optimization flag",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/windows/passwords/PasswordsContentsWidget.cpp"
        ],
        "github_commit_url": "https://github.com/OtterBrowser/otter-browser/commit/8dda7673a6f5bdd2d1277ede696b57499e1b9bc3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PasswordsContentsWidget::populatePasswords"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adding a missing compiler optimization flag to improve the performance of the `populatePasswords` function.",
            "The optimization strategy involved adding a missing compiler optimization flag to improve the performance of the `populatePasswords` function.",
            "The optimization strategy involved adding a missing compiler optimization flag to improve the performance of the `populatePasswords` function.",
            "The optimization strategy involved adding a missing compiler optimization flag to improve the performance of the `populatePasswords` function.",
            "The optimization strategy involved adding a missing compiler optimization flag to improve the performance of the `populatePasswords` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved adding a missing compiler optimization flag to improve the performance of the `populatePasswords` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "fbe965591f8a0a32c805a279a2505d4c20d22d26",
        "author": "Rick Macklem",
        "date": "2024-05-09T18:35:10-07:00",
        "message": "nfscl: Do not do readahead for directories\n\nFor a very long time, the NFS client has done readahead for\ndirectory blocks.  Unlike data blocks, the readahead cannot\nbegin until the Readdir RPC reply has been received, since\nthe directory offset cookie in that Readdir RPC reply is needed.\nAs such, the readahead is serialized and does not seem to\nprovide any real benefit.\n\nRecent testing/benchmarking shows that removing this\nreadahead code for Readdir does not have a negative impact\non performance.\n\nTherefore, this patch deletes the readahead code for Readdir,\nwhich simplifies the code and may make future changes simpler.\n\nMFC after:\t1 month",
        "modified_files_count": 1,
        "modified_files": [
            "sys/fs/nfsclient/nfs_clbio.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/fbe965591f8a0a32c805a279a2505d4c20d22d26",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ncl_bioread"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing unnecessary readahead logic for directory blocks in NFS client operations, as it provided no performance benefit and added complexity.",
            "The optimization strategy involved removing unnecessary readahead logic for directory blocks in NFS client operations, which simplifies the code and avoids serialized overhead without negatively impacting performance.",
            "The optimization strategy involved removing unnecessary readahead logic for directory blocks in NFS client operations, as it provided no performance benefit and added complexity.",
            "The optimization strategy involved removing unnecessary readahead code for directory blocks in the NFS client, which simplifies the code and avoids serialized operations without negatively impacting performance.",
            "The optimization strategy involved removing unnecessary readahead logic for directory blocks in NFS client operations, as it provided no performance benefit and added complexity."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing unnecessary readahead logic for directory blocks in NFS client operations, as it provided no performance benefit and added complexity.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "prboom-plus-rt",
        "hash": "de202d8ac5235c11f6e64d2e398a471c0a14a72c",
        "author": "entryway",
        "date": "2006-08-08T06:59:47+00:00",
        "message": "R_ShowStats() was rewritten. Now this function is faster and more universal. There is no more a static array and copying of memory.",
        "modified_files_count": 1,
        "modified_files": [
            "prboom2/src/r_main.c"
        ],
        "github_commit_url": "https://github.com/sultim-t/prboom-plus-rt/commit/de202d8ac5235c11f6e64d2e398a471c0a14a72c",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a static array and memory copying with a more efficient and universal implementation in the R_ShowStats() function.",
            "The optimization strategy involved replacing a static array and memory copying with a more efficient and universal implementation in the R_ShowStats() function.",
            "The optimization strategy involved replacing a static array and memory copying with a more efficient and universal implementation in the R_ShowStats() function.",
            "The optimization strategy involved replacing a static array and memory copying with a more efficient and universal implementation in the R_ShowStats() function.",
            "The optimization strategy involved replacing a static array with dynamic memory handling to eliminate unnecessary memory copying and improve the function's universality."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a static array and memory copying with a more efficient and universal implementation in the R_ShowStats() function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "a875fd1620ffb65f4e0d488f7fe1fba62cf9fedd",
        "author": "Julian Wiedmann",
        "date": "2020-05-06T14:11:26-07:00",
        "message": "s390/qeth: indicate contiguous TX buffer elements\n\nThe TX path usually maps the full content of a page into a buffer\nelement. But there's specific skb layouts (ie. linearized TSO skbs)\nwhere the HW header (1) requires a separate buffer element, and (2) is\npage-contiguous with the packet data that's mapped into the next buffer\nelement.\nFlag such buffer elements accordingly, so that HW can optimize its data\naccess for them.\n\nSigned-off-by: Julian Wiedmann <jwi@linux.ibm.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/s390/net/qeth_core_main.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/a875fd1620ffb65f4e0d488f7fe1fba62cf9fedd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "qeth_fill_buffer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization flags contiguous TX buffer elements to enable hardware to optimize data access for specific skb layouts.",
            "The optimization flags contiguous TX buffer elements to enable hardware-level data access optimizations for specific skb layouts.",
            "The optimization flags contiguous TX buffer elements to enable hardware to optimize data access for specific skb layouts.",
            "The optimization flags contiguous TX buffer elements to enable hardware-level data access optimizations for specific skb layouts.",
            "The optimization flags contiguous TX buffer elements to enable hardware-level data access optimizations for specific skb layouts."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization flags contiguous TX buffer elements to enable hardware-level data access optimizations for specific skb layouts.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pioneer",
        "hash": "1dbd9fd1d1242d73744ae2b1a08570528c3370a6",
        "author": "mr555",
        "date": "2015-06-15T01:35:22+03:00",
        "message": "Allow faster rotating stations",
        "modified_files_count": 1,
        "modified_files": [
            "src/galaxy/StarSystemGenerator.cpp"
        ],
        "github_commit_url": "https://github.com/pioneerspacesim/pioneer/commit/1dbd9fd1d1242d73744ae2b1a08570528c3370a6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PopulateStarSystemGenerator::PopulateAddStations"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations or iterations when adding stations to a star system by improving the logic for station placement or rotation.",
            "The optimization strategy involved reducing unnecessary computations in the station rotation logic by caching and reusing previously calculated values.",
            "The optimization strategy involved reducing unnecessary computations in station rotation by caching or precomputing values.",
            "The optimization strategy involved reducing unnecessary computations in station rotation by caching and reusing previously calculated values.",
            "The optimization strategy involved reducing unnecessary computations or iterations when adding stations to star systems by streamlining the logic for station placement."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations in the station rotation logic by caching and reusing previously calculated values.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "stockfish.wasm",
        "hash": "68fbb1e0522056e0ab8062fe68c26b3af5cffed3",
        "author": "mstembera",
        "date": "2015-09-17T17:33:40-07:00",
        "message": "Reduce writes in TT::probe().\n\nOnly refresh TT entry when it's really necessary.\nThis should give a small speed boost for some machines.\nAnd it's a risk-free change.\n\nNo functional change.\n\nResolves #429",
        "modified_files_count": 1,
        "modified_files": [
            "src/tt.cpp"
        ],
        "github_commit_url": "https://github.com/lichess-org/stockfish.wasm/commit/68fbb1e0522056e0ab8062fe68c26b3af5cffed3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TranspositionTable::probe"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces unnecessary writes to the transposition table by refreshing entries only when necessary, minimizing memory operations for speed improvement.",
            "The optimization strategy reduces unnecessary writes to the transposition table by refreshing entries only when necessary, minimizing memory operations for performance improvement.",
            "The optimization strategy reduces unnecessary writes to the transposition table by refreshing entries only when necessary, minimizing memory operations for performance improvement.",
            "The optimization strategy reduces unnecessary writes to the transposition table by refreshing entries only when necessary, minimizing memory operations for potential speed gains.",
            "The optimization strategy reduces unnecessary writes to the transposition table by refreshing entries only when necessary, minimizing memory operations for speed improvement."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy reduces unnecessary writes to the transposition table by refreshing entries only when necessary, minimizing memory operations for speed improvement.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "plumed2",
        "hash": "c0743209e2d380fd03a6042650c7cda2bf4d0674",
        "author": "Giovanni Bussi",
        "date": "2012-12-06T09:48:07+01:00",
        "message": "Small optimization in image search\n\nSince we have now the reduced cell, it is not necessary to\ntest all the shift vectors.",
        "modified_files_count": 1,
        "modified_files": [
            "src/Pbc.cpp"
        ],
        "github_commit_url": "https://github.com/plumed/plumed2/commit/c0743209e2d380fd03a6042650c7cda2bf4d0674",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves reducing the number of shift vectors tested by leveraging the reduced cell information.",
            "The optimization reduces unnecessary computations by leveraging a reduced cell to limit the number of shift vectors tested.",
            "The optimization strategy involves reducing the number of shift vectors tested by leveraging the reduced cell information.",
            "The optimization strategy reduces unnecessary computations by limiting the number of shift vectors tested, leveraging the reduced cell information.",
            "The optimization strategy reduces unnecessary computations by leveraging a reduced cell to limit the number of shift vectors tested."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces unnecessary computations by limiting the number of shift vectors tested, leveraging the reduced cell information.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow",
        "hash": "3d8ee770a03559fa82b14f02e9759430cb030bae",
        "author": "Emilio Cota",
        "date": "2023-02-09T09:26:58-08:00",
        "message": "[xla:runtime] Do not duplicate single-use argument loads out of the entry block\n\nThis is effectively deoptimizing hoisted loads out of loops.\nRemoving it allows us to achieve with XLA Runtime similar performance\nas XLA:CPU Classic in math microbenchmarks.\n\nThis was originally introduced to reduce the size of the entry\nblock, which was causing overly long compilation times. It is likely\nthat this problem has now been fixed elsewhere, making the deoptimization\nunnecessary.\n\nPiperOrigin-RevId: 508392023",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/compiler/xla/runtime/execution_engine.cc"
        ],
        "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/3d8ee770a03559fa82b14f02e9759430cb030bae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SetUpExportedFunction"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes unnecessary duplication of single-use argument loads to improve performance by avoiding deoptimization of hoisted loads.",
            "The optimization strategy removes unnecessary duplication of single-use argument loads to improve performance by avoiding deoptimization of hoisted loads.",
            "The optimization strategy removes unnecessary duplication of single-use argument loads to improve performance by avoiding deoptimization of hoisted loads.",
            "The optimization strategy removes unnecessary duplication of single-use argument loads to improve performance by avoiding deoptimization of hoisted loads.",
            "The optimization strategy removes unnecessary duplication of single-use argument loads to improve performance by avoiding deoptimization of hoisted loads."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy removes unnecessary duplication of single-use argument loads to improve performance by avoiding deoptimization of hoisted loads.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "coreutils",
        "hash": "8c92bb3441c628fe87ccf4a946b1c8b14cb0a0d2",
        "author": "Pádraig Brady",
        "date": "2009-09-22T10:07:21+01:00",
        "message": "ls: fix a performance regression\n\n* src/ls.c (print_color_indicator): This reinstates commit f3f1ccfd,\n21-10-2008, \"ls: make it possible to disable file capabilities checking\"\nwhich was inadvertently reverted with commit 3a169f4c, 14-09-2009,\n\"ls: handle disabling of colors consistently ...\".",
        "modified_files_count": 1,
        "modified_files": [
            "src/ls.c"
        ],
        "github_commit_url": "https://github.com/coreutils/coreutils/commit/8c92bb3441c628fe87ccf4a946b1c8b14cb0a0d2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "print_color_indicator"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reinstates a previous commit to disable unnecessary file capabilities checking, reducing overhead in the `print_color_indicator` function.",
            "The optimization reinstates a previous commit to disable unnecessary file capabilities checking, reducing overhead in the `print_color_indicator` function.",
            "The optimization strategy reinstates a previous commit to disable unnecessary file capabilities checking, reducing overhead in the `print_color_indicator` function.",
            "The optimization strategy reinstates a previous commit to disable file capabilities checking, reducing unnecessary overhead in the `print_color_indicator` function.",
            "The optimization strategy reinstates a previous commit to disable file capabilities checking, reducing unnecessary overhead in the `print_color_indicator` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reinstates a previous commit to disable unnecessary file capabilities checking, reducing overhead in the `print_color_indicator` function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ga",
        "hash": "787fda2b57bf3f1c0dd2a0dbcf3d002bb890630e",
        "author": "Jeff Daily",
        "date": "2011-10-13T17:38:37+00:00",
        "message": "smaller default memory footprint for copy_test.x (from 2GB down to <0.5GB)",
        "modified_files_count": 1,
        "modified_files": [
            "armci/testing/copy_test.c"
        ],
        "github_commit_url": "https://github.com/GlobalArrays/ga/commit/787fda2b57bf3f1c0dd2a0dbcf3d002bb890630e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduced the default memory allocation in a test program to decrease its memory footprint.",
            "The optimization strategy reduced the default memory allocation for a test program to decrease its memory footprint.",
            "The optimization reduces the default memory allocation in a test program to decrease its memory footprint.",
            "The optimization strategy reduced the default memory allocation for a test program to decrease its memory footprint.",
            "The optimization strategy reduced the default memory allocation for a testing utility to decrease its memory footprint."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduced the default memory allocation for a test program to decrease its memory footprint.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "0a9dec60b58cd63aaa7048d0d348b93187f5aa51",
        "author": "Miika Pekkarinen",
        "date": "2005-07-03T19:58:33+00:00",
        "message": "Make sure we unboost the cpu while stopping playback.\n\n\ngit-svn-id: svn://svn.rockbox.org/rockbox/trunk@6998 a1c6a512-1295-4272-9138-f99709370657",
        "modified_files_count": 1,
        "modified_files": [
            "firmware/pcm_playback.c"
        ],
        "github_commit_url": "https://github.com/Rockbox/rockbox/commit/0a9dec60b58cd63aaa7048d0d348b93187f5aa51",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pcm_play_stop"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rockbox",
        "optimization_summary": [
            "The optimization strategy ensures the CPU is unboosted while stopping playback to reduce unnecessary resource usage.",
            "The optimization strategy ensures the CPU is unboosted while stopping playback to reduce unnecessary resource usage.",
            "The optimization strategy ensures the CPU is unboosted while stopping playback to reduce unnecessary resource usage.",
            "The optimization strategy ensures the CPU is unboosted while stopping playback to reduce unnecessary power consumption.",
            "The optimization strategy ensures the CPU is unboosted while stopping playback to reduce unnecessary power consumption."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy ensures the CPU is unboosted while stopping playback to reduce unnecessary resource usage.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "geeqie",
        "hash": "737a3dc19275ac11d8a6225dbd03639e73b22fee",
        "author": "Colin Clark",
        "date": "2021-04-04T13:12:11+01:00",
        "message": "Bug fix #880: Optimize file loading when looking for duplicates\n\nReversed logic, resulting in items being processed twice",
        "modified_files_count": 1,
        "modified_files": [
            "src/dupe.c"
        ],
        "github_commit_url": "https://github.com/BestImageViewer/geeqie/commit/737a3dc19275ac11d8a6225dbd03639e73b22fee",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dupe_insert_in_list_cache"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reversed the logic in the function to prevent items from being processed twice, thereby reducing redundant operations.",
            "The optimization strategy involved reversing the logic to prevent redundant processing of items in the duplicate file loading mechanism.",
            "The optimization strategy involved reversing the logic to prevent items from being processed twice, thereby reducing redundant operations.",
            "The optimization strategy reversed the logic in the duplicate file loading process to prevent items from being processed twice, thereby reducing redundant operations.",
            "The optimization strategy involved reversing the logic to prevent redundant processing of items in the duplicate file loading mechanism."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reversed the logic in the duplicate file loading process to prevent items from being processed twice, thereby reducing redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mpv",
        "hash": "bf0569765349701b83a3902804f22bcb1d51e0c7",
        "author": "wm4",
        "date": "2018-06-30T17:55:21+02:00",
        "message": "HACK: prefetch subtitles on track switch a bit more\n\nTo get overlapping shit etc.",
        "modified_files_count": 1,
        "modified_files": [
            "player/loadfile.c"
        ],
        "github_commit_url": "https://github.com/mpv-player/mpv/commit/bf0569765349701b83a3902804f22bcb1d51e0c7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "reselect_demux_stream"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy prefetches subtitles during track switches to improve loading overlap and reduce delays.",
            "The optimization strategy prefetches subtitles during track switches to improve loading efficiency and overlap processing.",
            "The optimization strategy prefetches subtitles during track switches to improve loading performance by overlapping operations.",
            "The optimization strategy prefetches subtitles during track switches to improve loading overlap and reduce delays.",
            "The optimization strategy prefetches subtitles during track switches to improve loading performance by overlapping operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy prefetches subtitles during track switches to improve loading performance by overlapping operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libcuckoo",
        "hash": "38e08df7ef93121e4ef2d51a6f3c8576795773e9",
        "author": "Manu Goyal",
        "date": "2015-03-10T18:04:25-07:00",
        "message": "In read_throughput proportioned number of threads based on load factor\n\nWe were using half the threads for reading keys in the table and half\nfor keys not in the table, but we really should divide the threads based\non the load factor. Doing this improves the performance of the benchmark\nnoticeably.",
        "modified_files_count": 1,
        "modified_files": [
            "tests/read_throughput.cc"
        ],
        "github_commit_url": "https://github.com/efficient/libcuckoo/commit/38e08df7ef93121e4ef2d51a6f3c8576795773e9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ReadThroughputTest"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved dynamically adjusting the proportion of threads used for reading keys based on the load factor to better balance workload distribution.",
            "The optimization strategy involved dynamically adjusting the proportion of threads allocated for reading keys based on the load factor to better balance workload distribution.",
            "The optimization strategy involved dynamically adjusting the proportion of threads used for reading keys based on the load factor to better balance workload distribution.",
            "The optimization strategy involved dynamically adjusting the proportion of threads used for reading keys based on the load factor to better balance workload distribution.",
            "The optimization strategy involved dynamically adjusting the proportion of threads used for reading keys based on the load factor to better balance workload distribution."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved dynamically adjusting the proportion of threads used for reading keys based on the load factor to better balance workload distribution.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "metamage_1",
        "hash": "c5e041aa691b847b590db211c08fe8b23498833a",
        "author": "Josh Juran",
        "date": "2014-03-21T02:56:37-07:00",
        "message": "v68k:  Refactor decode_ADD_SUB() for efficiency",
        "modified_files_count": 1,
        "modified_files": [
            "engines/v68k/v68k/decode.cc"
        ],
        "github_commit_url": "https://github.com/jjuran/metamage_1/commit/c5e041aa691b847b590db211c08fe8b23498833a",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy refactors the `decode_ADD_SUB()` function to improve efficiency by restructuring its logic or reducing unnecessary operations.",
            "The optimization strategy refactors the `decode_ADD_SUB()` function to improve efficiency by restructuring its logic or reducing unnecessary operations.",
            "The optimization strategy refactors the `decode_ADD_SUB()` function to improve efficiency by restructuring its logic or reducing unnecessary operations.",
            "The optimization strategy refactors the `decode_ADD_SUB()` function to improve efficiency by restructuring its logic or reducing unnecessary operations.",
            "The optimization strategy refactors the `decode_ADD_SUB()` function to improve efficiency by restructuring its logic or reducing unnecessary operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy refactors the `decode_ADD_SUB()` function to improve efficiency by restructuring its logic or reducing unnecessary operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "grpc",
        "hash": "94fad8119eb93dd4116eabc0e446e20f4feaee7a",
        "author": "Craig Tiller",
        "date": "2015-07-30T07:55:02-07:00",
        "message": "Tune down number of channels for qps_test",
        "modified_files_count": 1,
        "modified_files": [
            "test/cpp/qps/qps_test.cc"
        ],
        "github_commit_url": "https://github.com/grpc/grpc/commit/94fad8119eb93dd4116eabc0e446e20f4feaee7a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RunQPS"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces the number of channels in the qps_test to decrease resource usage and improve performance.",
            "The optimization strategy involved reducing the number of channels in the qps_test to decrease resource usage and improve performance.",
            "The optimization strategy reduces the number of channels in the qps_test to decrease resource usage and improve performance.",
            "The optimization strategy reduces the number of channels used in the `qps_test` to decrease resource overhead and improve test execution efficiency.",
            "The optimization strategy reduced the number of channels in the qps_test to decrease resource usage and improve test execution efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces the number of channels in the qps_test to decrease resource usage and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pgcopydb",
        "hash": "385ee3d5c110a1643be2d4625754790f72bfd7f8",
        "author": "Shubham Dhama",
        "date": "2023-11-08T16:28:19+01:00",
        "message": "Improve migration speed by using same connection in a LOB worker. (#533)\n\nPresently, each LOB worker creates a new connection for every object copy,\r\nimpacting migration performance, especially with a large number of objects.\r\nThe fix here is simple: use the same connection within each worker.\r\n\r\nHowever, while doing so, we encountered an unexpected error:\r\n\r\n`BUG: call to pgsql_commit() without holding an open multi statement\r\nconnection`\r\n\r\nUpon investigation, we discovered that the `connectionStatementType` was\r\nset to an unusual value of 32767. In GDB, it was\r\n(PGSQL_CONNECTION_MULTI_STATEMENT | unknown: 32766). This happens only\r\nafter the call of `msgrcv` function. There are a few theories; one suggests\r\nthat because both `msg` and `dst` are on the stack, `msgrcv` is overwriting\r\n`dst` data when it should only change `msg`. Despite having\r\n`-fstack-protector` enabled, we did not observe a \"stack smashing detected\"\r\nerror, so maybe this theory is incorrect.\r\n\r\nIn any case, moving `msg` to the heap seemed to resolve the issue. However,\r\nit's important to fully understand this problem, as it may have\r\nimplications in other areas of the code as well.",
        "modified_files_count": 1,
        "modified_files": [
            "src/bin/pgcopydb/blobs.c"
        ],
        "github_commit_url": "https://github.com/dimitri/pgcopydb/commit/385ee3d5c110a1643be2d4625754790f72bfd7f8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "copydb_blob_worker"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reusing a single database connection within each LOB worker instead of creating a new connection for every object copy to reduce overhead and improve migration speed.",
            "The optimization strategy involved reusing a single database connection within each LOB worker instead of creating a new connection for every object copy to reduce overhead and improve migration speed.",
            "The optimization strategy involved reusing the same database connection within each LOB worker instead of creating a new connection for every object copy to reduce overhead and improve migration speed.",
            "The optimization strategy involved reusing the same database connection within each LOB worker instead of creating a new connection for every object copy to reduce overhead and improve migration speed.",
            "The optimization strategy involved reusing the same database connection within each LOB worker instead of creating a new connection for every object copy to reduce overhead and improve migration speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reusing the same database connection within each LOB worker instead of creating a new connection for every object copy to reduce overhead and improve migration speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MonetDB",
        "hash": "2be1b9e49b4b3ca085757d5314320a5d35e75100",
        "author": "Pedro Ferreira",
        "date": "2021-07-06T13:04:37+02:00",
        "message": "Small optimization, test if the next dependency exists in the storage before adding",
        "modified_files_count": 1,
        "modified_files": [
            "sql/storage/store.c"
        ],
        "github_commit_url": "https://github.com/MonetDB/MonetDB/commit/2be1b9e49b4b3ca085757d5314320a5d35e75100",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "transaction_add_hash_entry"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves checking for the existence of a dependency in storage before adding it to avoid unnecessary operations.",
            "The optimization strategy involves checking for the existence of a dependency in storage before adding it, to avoid unnecessary additions.",
            "The optimization strategy involves checking for the existence of a dependency in storage before adding it, to avoid unnecessary additions.",
            "The optimization strategy involves checking for the existence of a dependency in storage before adding it, to avoid unnecessary additions.",
            "The optimization strategy involves checking for the existence of a dependency in storage before adding it, to avoid unnecessary additions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves checking for the existence of a dependency in storage before adding it, to avoid unnecessary additions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "zstd",
        "hash": "1bee2d5e08208b01e496efa55c36c28422eaf35f",
        "author": "Yann Collet",
        "date": "2016-08-20T02:59:04+02:00",
        "message": "slight decompression speed improvement",
        "modified_files_count": 1,
        "modified_files": [
            "lib/decompress/zstd_decompress.c"
        ],
        "github_commit_url": "https://github.com/facebook/zstd/commit/1bee2d5e08208b01e496efa55c36c28422eaf35f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ZSTD_execSequence"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the decompression loop to reduce branch mispredictions and improve instruction cache utilization.",
            "The optimization strategy involved reducing unnecessary memory operations by reordering and minimizing data movement within the decompression sequence execution.",
            "The optimization strategy involved restructuring the decompression loop to reduce branch mispredictions and improve instruction-level parallelism.",
            "The optimization strategy involved reducing unnecessary memory operations by reordering and minimizing data movement within the decompression loop.",
            "The optimization strategy involved reducing unnecessary memory operations by reusing previously computed values within the decompression loop."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary memory operations by reordering and minimizing data movement within the decompression loop.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "63a3565e972aa6466286ecd77d66ed092041d561",
        "author": "Tim Ruffing",
        "date": "2022-07-07T20:08:17+02:00",
        "message": "Merge bitcoin-core/secp256k1#1120: ecmult_gen: Skip RNG when creating blinding if no seed is available\n\n55f8bc99dce8846e0da99b92e52353c8cf893287 ecmult_gen: Improve comments about projective blinding (Tim Ruffing)\n7a869558004b70803717d8169dd8b090e04df4af ecmult_gen: Simplify code (no observable change) (Tim Ruffing)\n4cc0b1b669392d38770f74cb3fb5c801c82f67a0 ecmult_gen: Skip RNG when creating blinding if no seed is available (Tim Ruffing)\n\nPull request description:\n\n  Running the RNG is pointless if no seed is available because the key\n  will be fixed. The computation just wastes time.\n\n  Previously, users could avoid this computation at least by asking for\n  a context without signing capabilities. But since 3b0c218 we always\n  build an ecmult_gen context, ignoring the context flags. Moreover,\n  users could never avoid this pointless computation when asking for\n  the creation of a signing context.\n\n  This fixes one item in #1065.\n\nACKs for top commit:\n  sipa:\n    ACK 55f8bc99dce8846e0da99b92e52353c8cf893287\n  apoelstra:\n    ACK 55f8bc99dce8846e0da99b92e52353c8cf893287\n\nTree-SHA512: 5ccba56041f94fa8f40a8a56ce505369ff2e0ed20cd7f0bfc3fdfffa5fa7bf826a93602b9b2455a352865a9548ab4928e858c19bb5af7ec221594a3bf25c4f3d",
        "modified_files_count": 1,
        "modified_files": [
            "src/ecmult_gen_impl.h"
        ],
        "github_commit_url": "https://github.com/bitcoin-core/secp256k1/commit/63a3565e972aa6466286ecd77d66ed092041d561",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "secp256k1_ecmult_gen_blind"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "secp256k1",
        "optimization_summary": [
            "The optimization skips unnecessary random number generation when no seed is available, avoiding redundant computation.",
            "The optimization skips unnecessary random number generation when no seed is available, avoiding redundant computation.",
            "The optimization skips unnecessary RNG computations when no seed is available, avoiding wasted time during blinding key generation.",
            "The optimization skips unnecessary random number generation when no seed is available, avoiding pointless computation.",
            "The optimization skips unnecessary random number generation when no seed is available, avoiding redundant computation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization skips unnecessary random number generation when no seed is available, avoiding redundant computation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "739294fb03f590401bbd7faa6d31a507e3ffada5",
        "author": "Rik van Riel",
        "date": "2017-06-24T08:57:46+02:00",
        "message": "sched/numa: Override part of migrate_degrades_locality() when idle balancing\n\nSeveral tests in the NAS benchmark seem to run a lot slower with\nNUMA balancing enabled, than with NUMA balancing disabled. The\nslower run time corresponds with increased idle time.\n\nOverriding the final test of migrate_degrades_locality (but still\ndoing the other NUMA tests first) seems to improve performance\nof those benchmarks.\n\nReported-by: Jirka Hladky <jhladky@redhat.com>\nSigned-off-by: Rik van Riel <riel@redhat.com>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Mike Galbraith <efault@gmx.de>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: linux-kernel@vger.kernel.org\nLink: http://lkml.kernel.org/r/20170623165530.22514-2-riel@redhat.com\nSigned-off-by: Ingo Molnar <mingo@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/sched/fair.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/739294fb03f590401bbd7faa6d31a507e3ffada5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "migrate_degrades_locality"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves conditionally skipping the final test in the migrate_degrades_locality function during idle balancing to reduce unnecessary overhead and improve performance in NUMA balancing scenarios.",
            "The optimization strategy involves conditionally skipping the final test in the migrate_degrades_locality function during idle balancing to reduce unnecessary computations and improve performance.",
            "The optimization strategy involves conditionally skipping a specific locality degradation check during idle balancing to reduce unnecessary overhead in NUMA balancing.",
            "The optimization strategy involves conditionally overriding the final test in the migrate_degrades_locality function during idle balancing to reduce unnecessary NUMA-related checks and improve performance for specific benchmarks.",
            "The optimization strategy involves conditionally overriding the final test in the migrate_degrades_locality function during idle balancing to reduce unnecessary NUMA-related checks and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves conditionally overriding the final test in the migrate_degrades_locality function during idle balancing to reduce unnecessary NUMA-related checks and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "php-src",
        "hash": "5d20a8f80193685877ae3c57e676240e6f2384b3",
        "author": "Felipe Pena",
        "date": "2011-07-10T02:00:00+00:00",
        "message": "- Minor optimization, use the computed hash when available",
        "modified_files_count": 1,
        "modified_files": [
            "Zend/zend_API.c"
        ],
        "github_commit_url": "https://github.com/php/php-src/commit/5d20a8f80193685877ae3c57e676240e6f2384b3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "zend_register_functions"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reusing a precomputed hash value instead of recalculating it, reducing redundant computations.",
            "The optimization strategy involves reusing a precomputed hash value instead of recalculating it, reducing redundant computations.",
            "The optimization strategy involved reusing a precomputed hash value instead of recalculating it when registering functions.",
            "The optimization strategy involved reusing a precomputed hash value instead of recalculating it, reducing redundant computations.",
            "The optimization avoids recomputing a hash by reusing a precomputed value when available."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reusing a precomputed hash value instead of recalculating it, reducing redundant computations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "cadical",
        "hash": "821da6a556fb94425080b975d177ebfba624c10e",
        "author": "Florian",
        "date": "2023-07-18T14:14:19+02:00",
        "message": "lrat for assume more memory efficient",
        "modified_files_count": 1,
        "modified_files": [
            "src/assume.cpp"
        ],
        "github_commit_url": "https://github.com/arminbiere/cadical/commit/821da6a556fb94425080b975d177ebfba624c10e",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved making the LRAT (Linear RAT) proof generation for assumptions more memory efficient by reducing unnecessary memory allocations or usage.",
            "The optimization strategy involved making the LRAT (Linear RAT) proof generation for assumptions more memory efficient by reducing unnecessary memory allocations or usage.",
            "The optimization strategy involved making the LRAT (Linear RAT) proof generation for assumptions more memory efficient by reducing unnecessary memory allocations or usage.",
            "The optimization strategy involved making the LRAT (Linear RAT) proof generation for assumptions more memory efficient by reducing unnecessary memory allocations or usage.",
            "The optimization strategy involved making the LRAT (Linear RAT) proof generation for assumptions more memory efficient by reducing unnecessary memory allocations or usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved making the LRAT (Linear RAT) proof generation for assumptions more memory efficient by reducing unnecessary memory allocations or usage.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "uarch-configure",
        "hash": "2cac4ab6bc7248a9f3a826002c679165434ba92a",
        "author": "Vince Weaver",
        "date": "2019-12-11T14:48:06-05:00",
        "message": "intel-prefetch-disable: update with some newer cpuids",
        "modified_files_count": 1,
        "modified_files": [
            "intel-prefetch/intel-prefetch-disable.c"
        ],
        "github_commit_url": "https://github.com/deater/uarch-configure/commit/2cac4ab6bc7248a9f3a826002c679165434ba92a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "detect_cpu"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved updating CPU detection logic to include newer CPUIDs, potentially improving the efficiency of prefetch disabling on supported processors.",
            "The optimization strategy involved updating CPU detection logic to include newer CPUIDs, potentially improving the efficiency of prefetch disabling on supported processors.",
            "The optimization strategy involved updating CPU detection logic to include newer CPUIDs, potentially improving the efficiency of prefetch disabling on supported processors.",
            "The optimization strategy involved updating CPU detection logic to include newer CPUIDs, potentially improving the efficiency of prefetch disabling on supported processors.",
            "The optimization strategy involved updating CPU detection logic to include newer CPUIDs, potentially improving the precision of feature detection."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved updating CPU detection logic to include newer CPUIDs, potentially improving the efficiency of prefetch disabling on supported processors.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sse2neon",
        "hash": "e0b19883fd76595b3ec215a5f82e894ff0a518bf",
        "author": "easyaspi314 (Devin)",
        "date": "2020-03-12T23:17:42-04:00",
        "message": "Implement vectorized _mm_shuffle_epi8 for ARMv7a\n\nUses 2 vtbl2 to simulate vqtbl1q.\n\nChanged to use inline assembly instead of a cast. This doesn't\nbreak the strict aliasing rule.",
        "modified_files_count": 1,
        "modified_files": [
            "sse2neon.h"
        ],
        "github_commit_url": "https://github.com/DLTcollab/sse2neon/commit/e0b19883fd76595b3ec215a5f82e894ff0a518bf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_mm_shuffle_epi8"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a cast with inline assembly to avoid breaking the strict aliasing rule and improve performance by using vectorized operations.",
            "The optimization strategy involved replacing a cast with inline assembly to simulate a vectorized operation while avoiding strict aliasing rule violations.",
            "The optimization strategy involved replacing a cast with inline assembly to simulate a vectorized operation while avoiding strict aliasing rule violations.",
            "The optimization strategy involved replacing a cast with inline assembly to avoid breaking the strict aliasing rule and improve performance by using vectorized operations.",
            "The optimization strategy involved replacing a cast with inline assembly to simulate a vectorized operation while avoiding strict aliasing rule violations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a cast with inline assembly to simulate a vectorized operation while avoiding strict aliasing rule violations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "754f9ae80e4fc3a42cfb7e2c680fdf7710ff8273",
        "author": "Peter Chiu",
        "date": "2022-07-11T13:40:02+02:00",
        "message": "mt76: mt7915: update mpdu density in 6g capability\n\nSet mpdu density to 2 usec in 6g capability to meet hardware\ncapability and also enhance throughput.\n\nSigned-off-by: Peter Chiu <chui-hao.chiu@mediatek.com>\nSigned-off-by: Felix Fietkau <nbd@nbd.name>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/wireless/mediatek/mt76/mt7915/init.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/754f9ae80e4fc3a42cfb7e2c680fdf7710ff8273",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mt7915_init_he_caps"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved updating the MPDU density in the 6GHz capability to align with hardware requirements and improve throughput.",
            "The optimization strategy involved updating the MPDU density in the 6GHz capability to align with hardware specifications and improve throughput.",
            "The optimization strategy involved updating the MPDU density in the 6 GHz capability to align with hardware specifications and improve throughput.",
            "The optimization strategy involved updating the MPDU density in the 6 GHz capability to align with hardware specifications and improve throughput.",
            "The optimization strategy involved setting the MPDU density to 2 microseconds in the 6 GHz capability to align with hardware requirements and improve throughput."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved updating the MPDU density in the 6 GHz capability to align with hardware specifications and improve throughput.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cel-cpp",
        "hash": "bf7c7913a23289a2ead345fa45083b1cda5875ba",
        "author": "Justin King",
        "date": "2024-02-09T12:57:09-08:00",
        "message": "Avoid copying from the value stack in `container_access_step.cc`\n\nPiperOrigin-RevId: 605708781",
        "modified_files_count": 1,
        "modified_files": [
            "eval/eval/container_access_step.cc"
        ],
        "github_commit_url": "https://github.com/google/cel-cpp/commit/bf7c7913a23289a2ead345fa45083b1cda5875ba",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary copying from the value stack by directly accessing or referencing the data in `container_access_step.cc`.",
            "The optimization strategy avoids unnecessary copying from the value stack by directly accessing or referencing the data.",
            "The optimization avoids unnecessary copying from the value stack by directly accessing or referencing the data.",
            "The optimization avoids unnecessary copying from the value stack by directly accessing or referencing the data.",
            "The optimization strategy avoids unnecessary copying from the value stack by directly accessing or referencing the data."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary copying from the value stack by directly accessing or referencing the data.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Floorp",
        "hash": "7944bea083deb466016eb8e012430593d5a664d1",
        "author": "Doug Thayer",
        "date": "2021-02-05T16:43:02+00:00",
        "message": "Bug 1690925 - Don't animate the skeleton UI if we're in a fast startup r=mconley,emalysz\n\nThis avoids paying a cost for animating the skeleton UI for faster startups.\nSlow startups don't seem to be affected, given the data available. This is\nlikely due to slow startups being dominated by IO.\n\nDifferential Revision: https://phabricator.services.mozilla.com/D104118",
        "modified_files_count": 1,
        "modified_files": [
            "mozglue/misc/PreXULSkeletonUI.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/7944bea083deb466016eb8e012430593d5a664d1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AnimateSkeletonUI"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary animation of the skeleton UI during fast startups to reduce computational overhead.",
            "The optimization avoids unnecessary animation of the skeleton UI during fast startups to reduce computational overhead.",
            "The optimization strategy avoids unnecessary animation of the skeleton UI during fast startups to reduce computational overhead.",
            "The optimization strategy avoids unnecessary animation of the skeleton UI during fast startups to reduce computational overhead.",
            "The optimization strategy avoids unnecessary animation of the skeleton UI during fast startups to reduce computational overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary animation of the skeleton UI during fast startups to reduce computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "forestdb",
        "hash": "906231e9e8a5bfdcf5c5aa2e7474e405895f2351",
        "author": "Sundar Sridharan",
        "date": "2016-05-20T22:02:38+00:00",
        "message": "MB-19390: Measure timing correctly on Windows\n\nUse QueryPerformanceCounter to get high resolution\nclock ticks as opposed to GetTickCount64() which has\nresolution only in milliseconds on Windows.\n\nChange-Id: I6c081fb6b4dfea5584d2077e26f0445952dbb96c\nReviewed-on: http://review.couchbase.org/64259\nReviewed-by: Chiyoung Seo <chiyoung@couchbase.com>\nTested-by: buildbot <build@couchbase.com>",
        "modified_files_count": 1,
        "modified_files": [
            "utils/time_utils.cc"
        ],
        "github_commit_url": "https://github.com/couchbase/forestdb/commit/906231e9e8a5bfdcf5c5aa2e7474e405895f2351",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_monotonic_ts"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a low-resolution timing function with a high-resolution one to improve measurement accuracy on Windows.",
            "The optimization strategy replaced a low-resolution timing function with a high-resolution one to improve measurement accuracy on Windows.",
            "The optimization strategy replaced a low-resolution timing function with a high-resolution one to improve the accuracy of time measurements on Windows.",
            "The optimization strategy replaced a low-resolution timing function with a high-resolution one to improve measurement accuracy on Windows.",
            "The optimization strategy involved replacing a low-resolution timing function with a high-resolution one to improve measurement accuracy on Windows."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a low-resolution timing function with a high-resolution one to improve measurement accuracy on Windows.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "jpegli",
        "hash": "50319f8e4f176046c61fdbf94523af7326c9fb3c",
        "author": "Luca Versari",
        "date": "2023-03-31T11:52:36+02:00",
        "message": "Re-enable accidentally disabled AVX2/AVX512 fast lossless.",
        "modified_files_count": 1,
        "modified_files": [
            "lib/jxl/enc_fast_lossless.cc"
        ],
        "github_commit_url": "https://github.com/google/jpegli/commit/50319f8e4f176046c61fdbf94523af7326c9fb3c",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization re-enables previously disabled AVX2/AVX512 instructions to accelerate fast lossless encoding.",
            "The optimization re-enables previously disabled AVX2/AVX512 instructions to accelerate lossless encoding.",
            "The optimization re-enables previously disabled AVX2/AVX512 instructions to leverage hardware acceleration for faster lossless encoding.",
            "The optimization re-enables previously disabled AVX2/AVX512 instructions to accelerate fast lossless encoding.",
            "The optimization re-enables previously disabled AVX2/AVX512 instructions to leverage hardware acceleration for faster lossless encoding."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization re-enables previously disabled AVX2/AVX512 instructions to accelerate fast lossless encoding.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "380e5a4242061b332e0d91326b77f295f1402593",
        "author": "Luke Wagner",
        "date": "2013-09-03T11:00:24-05:00",
        "message": "Bug 911842 - OdinMonkey: disable Ion optimization passes that don't help (r=jandem)",
        "modified_files_count": 1,
        "modified_files": [
            "js/src/jit/Ion.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/380e5a4242061b332e0d91326b77f295f1402593",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OptimizeMIR"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves disabling specific Ion optimization passes in OdinMonkey that do not contribute to performance improvements.",
            "The optimization strategy involves disabling specific Ion optimization passes in OdinMonkey that do not contribute to performance improvements.",
            "The optimization strategy involved disabling specific Ion optimization passes in OdinMonkey that were determined to not provide performance benefits.",
            "The optimization strategy involves disabling specific Ion optimization passes in OdinMonkey that do not contribute to performance improvements.",
            "The optimization strategy involved disabling specific Ion optimization passes in OdinMonkey that were determined to not provide performance benefits."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves disabling specific Ion optimization passes in OdinMonkey that do not contribute to performance improvements.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "abc",
        "hash": "f404f9ffb49b307a52deeb92108249430afaf5ed",
        "author": "Alan Mishchenko",
        "date": "2010-11-29T01:38:31-08:00",
        "message": "Performance bug fix in area-only mapping \"map -a\".",
        "modified_files_count": 1,
        "modified_files": [
            "src/map/mapper/mapperMatch.c"
        ],
        "github_commit_url": "https://github.com/berkeley-abc/abc/commit/f404f9ffb49b307a52deeb92108249430afaf5ed",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Map_NodeTryDroppingOnePhase"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations by skipping certain checks when they are guaranteed to be irrelevant.",
            "The optimization strategy involved reducing unnecessary computations by skipping certain checks when they are guaranteed to be irrelevant.",
            "The optimization strategy involved reducing unnecessary computations by adding an early exit condition in the mapping process.",
            "The optimization strategy involved reducing unnecessary computations by skipping certain checks when they are guaranteed to be redundant.",
            "The optimization strategy involved reducing unnecessary computations by skipping certain checks when they are guaranteed to be irrelevant."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations by skipping certain checks when they are guaranteed to be irrelevant.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qrack",
        "hash": "4c9edd9f1956aa133b71aeabc878fef9ba4b1c30",
        "author": "Dan Strano",
        "date": "2023-06-12T09:04:25-04:00",
        "message": "Optimize QStabilizerHybrid::ForceM()",
        "modified_files_count": 1,
        "modified_files": [
            "src/qstabilizerhybrid.cpp"
        ],
        "github_commit_url": "https://github.com/unitaryfund/qrack/commit/4c9edd9f1956aa133b71aeabc878fef9ba4b1c30",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "IS_SAME"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to reduce redundant calculations by caching and reusing intermediate results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing intermediate results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
            "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to reduce redundant calculations by caching and reusing results within the function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "notepad4",
        "hash": "d6845ac2b0e506ee39ec42a5abdca688f202b9b7",
        "author": "YX Hao",
        "date": "2021-08-28T15:27:55+08:00",
        "message": "Improve `Remember Recent Files` performance\n\nClean up SHAddToRecentDocs to obey flagUseSystemMRU.\nFileLoad or FileSave will do that.\nFix issue #363.",
        "modified_files_count": 1,
        "modified_files": [
            "src/Helpers.c"
        ],
        "github_commit_url": "https://github.com/zufuliu/notepad4/commit/d6845ac2b0e506ee39ec42a5abdca688f202b9b7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MRU_AddFile"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing redundant calls to SHAddToRecentDocs by leveraging the flagUseSystemMRU setting to conditionally handle recent file additions.",
            "The optimization strategy involved modifying the `MRU_AddFile` function to conditionally call `SHAddToRecentDocs` based on a flag, reducing unnecessary operations.",
            "The optimization strategy involved removing redundant calls to SHAddToRecentDocs by leveraging the flagUseSystemMRU setting to conditionally handle recent file updates.",
            "The optimization avoids unnecessary calls to SHAddToRecentDocs by respecting the flagUseSystemMRU setting, reducing redundant operations.",
            "The optimization strategy involved modifying the `MRU_AddFile` function to conditionally call `SHAddToRecentDocs` based on a flag, reducing unnecessary system calls."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing redundant calls to SHAddToRecentDocs by leveraging the flagUseSystemMRU setting to conditionally handle recent file additions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "darktable",
        "hash": "76ca7db7dbf9e324da3823fafd03e138b53c3415",
        "author": "Rostyslav Pidgornyi",
        "date": "2011-09-09T19:21:35+03:00",
        "message": "make gcc 4.5 happier with artous.c optimization\n\ntriggers better optimization for gcc 4.5 of artous plugin\ndoesn't change anything for 4.6",
        "modified_files_count": 1,
        "modified_files": [
            "src/iop/atrous.c"
        ],
        "github_commit_url": "https://github.com/darktable-org/darktable/commit/76ca7db7dbf9e324da3823fafd03e138b53c3415",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "eaw_decompose"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved modifying the code to better align with GCC 4.5's optimization capabilities, specifically improving how the compiler optimizes the `eaw_decompose` function in the `atrous.c` file.",
            "The optimization strategy involved modifying the code to better align with GCC 4.5's optimization capabilities, specifically by restructuring or tweaking the implementation in a way that triggers more efficient compilation without altering functionality.",
            "The optimization strategy involved modifying the code to better align with GCC 4.5's optimization capabilities, specifically improving loop or function handling without altering functionality.",
            "The optimization strategy involved modifying the code to better align with GCC 4.5's optimization capabilities, specifically by restructuring or tweaking the implementation in a way that triggers improved compiler optimizations without altering functionality.",
            "The optimization strategy involved modifying the code to better align with GCC 4.5's optimization capabilities, specifically by restructuring or tweaking the implementation to enable more efficient compilation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved modifying the code to better align with GCC 4.5's optimization capabilities, specifically by restructuring or tweaking the implementation to enable more efficient compilation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kicad-source-mirror",
        "hash": "21900ad3e13e8533e85f4c2c21c4e56c1de9bb65",
        "author": "Seth Hillbrand",
        "date": "2024-07-21T07:23:00-07:00",
        "message": "Maintain std::move to avoid copy penalty\n\nCaching lib models is a slow point when loading libraries when many\nfootprints have embedded models.  We want to speed this by not copying\ndata unneccesarily.  Some compilers will invalidate the models structure\nright-to-left in the function call (the order is unspecified by the\nstandard), leading to broken model names unless we cache the name before\nhand.",
        "modified_files_count": 1,
        "modified_files": [
            "pcbnew/pcb_io/altium/altium_pcb_compound_file.cpp"
        ],
        "github_commit_url": "https://github.com/KiCad/kicad-source-mirror/commit/21900ad3e13e8533e85f4c2c21c4e56c1de9bb65",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ALTIUM_PCB_COMPOUND_FILE::CacheLibModels"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary data copying by maintaining `std::move` semantics during function calls.",
            "The optimization strategy avoids unnecessary data copying by maintaining `std::move` semantics during function calls to improve performance when caching library models.",
            "The optimization strategy avoids unnecessary data copying by maintaining `std::move` semantics during function calls, ensuring efficient handling of model names.",
            "The optimization strategy avoids unnecessary data copying by maintaining `std::move` semantics during function calls, ensuring efficient handling of model names.",
            "The optimization strategy avoids unnecessary data copying by maintaining `std::move` semantics, ensuring efficient handling of model names during library caching."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary data copying by maintaining `std::move` semantics during function calls, ensuring efficient handling of model names.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ceph",
        "hash": "f5a7a3b1dc4088be4ca1a845832c76e60446ba64",
        "author": "Piotr Dałek",
        "date": "2015-12-07T14:26:33+01:00",
        "message": "mon/MonitorDBStore: use single-key LevelDB::get() method\n\nMake MonitorDBStore use single-key ::get() method for some performance\nincrease in heavy K/V workloads.\n\nSigned-off-by: Piotr Dałek <piotr.dalek@ts.fujitsu.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/mon/MonitorDBStore.h"
        ],
        "github_commit_url": "https://github.com/ceph/ceph/commit/f5a7a3b1dc4088be4ca1a845832c76e60446ba64",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a multi-key retrieval method with a single-key retrieval method in LevelDB to improve performance for heavy key/value workloads.",
            "The optimization strategy involved replacing a potentially less efficient key-value retrieval method with a direct single-key LevelDB::get() call to improve performance in heavy key/value workloads.",
            "The optimization strategy involved replacing a potentially less efficient key-value retrieval method with a direct single-key LevelDB::get() call to improve performance in heavy workloads.",
            "The optimization strategy involved replacing a potentially less efficient key-value retrieval method with a direct single-key LevelDB::get() call to improve performance in heavy workloads.",
            "The optimization strategy involved replacing a multi-key retrieval method with a single-key retrieval method in LevelDB to improve performance for heavy key-value workloads."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a potentially less efficient key-value retrieval method with a direct single-key LevelDB::get() call to improve performance in heavy workloads.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Stockfish",
        "hash": "65e2150501b87e6ce00fae4e3f056444f39462fd",
        "author": "Michael Chaly",
        "date": "2023-05-07T22:36:57+02:00",
        "message": "Refine deeper post-lmr searches\n\nThis patch improves logic conditions for performing deeper searches after passed LMR.\n\nInstead of exceeding alpha by some margin now it requires to exceed the\ncurrent best value - which may be lower than alpha (but never bigger since we\nupdate alpha with bestvalue if it exceeds alpha).\n\nPassed STC:\nhttps://tests.stockfishchess.org/tests/view/6455f78008858de8313775b6\nLLR: 2.94 (-2.94,2.94) <0.00,2.00>\nTotal: 209344 W: 55993 L: 55448 D: 97903\nPtnml(0-2): 507, 22798, 57526, 23325, 516\n\nPassed LTC:\nhttps://tests.stockfishchess.org/tests/view/64572d46eb75932ccfebff97\nLLR: 2.94 (-2.94,2.94) <0.50,2.50>\nTotal: 66288 W: 17867 L: 17514 D: 30907\nPtnml(0-2): 21, 6240, 20269, 6593, 21\n\ncloses https://github.com/official-stockfish/Stockfish/pull/4559\n\nbench 3808503",
        "modified_files_count": 1,
        "modified_files": [
            "src/search.cpp"
        ],
        "github_commit_url": "https://github.com/official-stockfish/Stockfish/commit/65e2150501b87e6ce00fae4e3f056444f39462fd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "search"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization refines the condition for deeper searches after Late Move Reductions (LMR) by requiring a move to exceed the current best value instead of a fixed margin above alpha.",
            "The optimization refines the condition for performing deeper searches after Late Move Reductions (LMR) by requiring the score to exceed the current best value instead of exceeding alpha by a margin.",
            "The optimization refines the condition for performing deeper searches after Late Move Reductions (LMR) by using the current best value instead of a fixed margin relative to alpha.",
            "The optimization refines the condition for performing deeper searches after Late Move Reductions (LMR) by requiring the score to exceed the current best value instead of a fixed margin above alpha.",
            "The optimization refines the condition for performing deeper searches after Late Move Reductions (LMR) by requiring the score to exceed the current best value instead of a fixed margin above alpha."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization refines the condition for performing deeper searches after Late Move Reductions (LMR) by requiring the score to exceed the current best value instead of a fixed margin above alpha.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "opencryptoki",
        "hash": "a66bbe321045dd1fb64302aad7ba1b2749a37226",
        "author": "Ingo Franzki",
        "date": "2024-02-09T14:02:18+01:00",
        "message": "ICSF: Optimize C_GetAttributeValue by using cached result\n\nFunction icsftok_get_attribute_value() is called during C_GetAttributeValue and\nit might need to obtain the attributes from ICSF twice. Cache the retrieved\nattributes from the first retrieval for the second one.\n\nSigned-off-by: Ingo Franzki <ifranzki@linux.ibm.com>",
        "modified_files_count": 1,
        "modified_files": [
            "usr/lib/icsf_stdll/icsf_specific.c"
        ],
        "github_commit_url": "https://github.com/opencryptoki/opencryptoki/commit/a66bbe321045dd1fb64302aad7ba1b2749a37226",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "icsftok_get_attribute_value"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy caches the result of the first attribute retrieval to avoid redundant calls to obtain the same attributes from ICSF.",
            "The optimization strategy caches the result of the first attribute retrieval to avoid redundant calls to obtain the same attributes.",
            "The optimization strategy caches the result of the first attribute retrieval to avoid redundant calls to obtain the same attributes from ICSF.",
            "The optimization strategy caches the result of the first attribute retrieval to avoid redundant calls to obtain the same attributes from ICSF.",
            "The optimization strategy caches the result of the first attribute retrieval to avoid redundant calls to obtain the same attributes from ICSF."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy caches the result of the first attribute retrieval to avoid redundant calls to obtain the same attributes from ICSF.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "da966809fdbcab05d8929528153d834fe5a7246d",
        "author": "Jeremie Gaidamour",
        "date": "2011-06-30T11:14:08-06:00",
        "message": "MueLu Aggregation: Minor optimization: use the Importer twice instead of creating an Exporter for the second communication",
        "modified_files_count": 1,
        "modified_files": [
            "packages/muelu/src/Graph/MueLu_UCAggregationCommHelper.hpp"
        ],
        "github_commit_url": "https://github.com/trilinos/Trilinos/commit/da966809fdbcab05d8929528153d834fe5a7246d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ArbitrateAndCommunicate"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "Trilinos",
        "optimization_summary": [
            "The optimization strategy avoids creating an additional Exporter by reusing an existing Importer for communication, reducing resource overhead.",
            "The optimization strategy involved reusing an existing Importer for two communication steps instead of creating a separate Exporter for the second step, thereby reducing resource overhead.",
            "The optimization strategy avoids creating an additional Exporter by reusing an existing Importer for communication.",
            "The optimization strategy involved reusing an existing Importer for two communications instead of creating a separate Exporter for the second communication, thereby reducing resource overhead.",
            "The optimization strategy avoids creating an additional Exporter by reusing an existing Importer for communication, reducing resource overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids creating an additional Exporter by reusing an existing Importer for communication, reducing resource overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "calligra",
        "hash": "5d59037a698493b54fa1837de26c6396fbfb72ea",
        "author": "Norbert Andres",
        "date": "2002-04-17T20:22:04+00:00",
        "message": "Enhanced performance  a little bit when inserting a series\n  (5000 elements about 7 seconds faster - but it still takes nearly 50 sec\n   on a 1.1 GHz PC)\n\nsvn path=/trunk/koffice/; revision=150129",
        "modified_files_count": 1,
        "modified_files": [
            "kspread/kspread_table.cc"
        ],
        "github_commit_url": "https://github.com/KDE/calligra/commit/5d59037a698493b54fa1837de26c6396fbfb72ea",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary operations or iterations when inserting a series of elements into a table.",
            "The optimization strategy involved reducing unnecessary computations or iterations when inserting a series of elements.",
            "The optimization strategy involved reducing unnecessary computations or iterations when inserting a series of elements.",
            "The optimization strategy involved reducing unnecessary computations or iterations when inserting a series of elements.",
            "The optimization strategy involved reducing unnecessary computations or iterations when inserting a series of elements."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations or iterations when inserting a series of elements.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenDDS",
        "hash": "849c3e45173f4dee3c3797b49382e8f4efb5dc37",
        "author": "Timothy Simpson",
        "date": "2022-02-03T16:18:35-06:00",
        "message": "Improve Mutex Contention in Thrasher Test's PublisherService",
        "modified_files_count": 1,
        "modified_files": [
            "tests/DCPS/Thrasher/PublisherService.cpp"
        ],
        "github_commit_url": "https://github.com/OpenDDS/OpenDDS/commit/849c3e45173f4dee3c3797b49382e8f4efb5dc37",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PublisherService::createPublisher"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing mutex contention by restructuring the code to minimize the time spent holding a lock.",
            "The optimization strategy involved reducing mutex contention by restructuring the locking mechanism in the Thrasher Test's PublisherService.",
            "The optimization strategy involved reducing mutex contention by restructuring the code to minimize the time spent holding a lock.",
            "The optimization strategy involved reducing mutex contention by restructuring the locking mechanism in the Thrasher Test's PublisherService.",
            "The optimization strategy involved reducing mutex contention by restructuring the locking mechanism in the Thrasher Test's PublisherService."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing mutex contention by restructuring the locking mechanism in the Thrasher Test's PublisherService.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "aaccb8899d5d1fdf78ad6687eb9e120cd298a474",
        "author": "Michael Layzell",
        "date": "2017-07-10T15:54:55-04:00",
        "message": "Bug 1378201 - Improve the performance of TableRowsCollection, r=ehsan\n\nMozReview-Commit-ID: 4joB73SXNGA",
        "modified_files_count": 1,
        "modified_files": [
            "dom/html/HTMLTableElement.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/aaccb8899d5d1fdf78ad6687eb9e120cd298a474",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "NS_IMPL_NS_NEW_HTML_ELEMENT"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations or memory allocations within the TableRowsCollection to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or memory allocations within the TableRowsCollection to improve its performance.",
            "The optimization strategy involved reducing unnecessary computations or memory allocations within the TableRowsCollection to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or memory allocations within the TableRowsCollection to improve its performance.",
            "The optimization strategy involved reducing unnecessary computations or memory allocations within the TableRowsCollection to improve its performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations or memory allocations within the TableRowsCollection to improve its performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "hhvm",
        "hash": "a5cbc97a81c4f50212c2fd8feccb1c31b812c179",
        "author": "Nicolas De Carli",
        "date": "2024-12-06T02:54:23-08:00",
        "message": "Optimize writeVarintSlow for aarch64\n\nSummary:\nCompress writeVarintSlow into a loop.\n\nBenchmarks show 1% to 25% improvement, depending on the case.\n\nBefore: P1687797106\n\nAfter: P1687797268\n\nReviewed By: psaab\n\nDifferential Revision: D66547873\n\nfbshipit-source-id: f4f6084818c807371eb47eb32da7629424de00f1",
        "modified_files_count": 1,
        "modified_files": [
            "third-party/thrift/src/thrift/lib/cpp/util/VarintUtils-inl.h"
        ],
        "github_commit_url": "https://github.com/facebook/hhvm/commit/a5cbc97a81c4f50212c2fd8feccb1c31b812c179",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "writeVarintSlow"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is compressing the `writeVarintSlow` function into a loop to reduce redundancy and improve performance.",
            "The optimization strategy involved restructuring the `writeVarintSlow` function by compressing its logic into a loop to reduce redundancy and improve performance.",
            "The optimization strategy involved restructuring the `writeVarintSlow` function by compressing its logic into a loop to reduce redundancy and improve performance.",
            "The optimization strategy involved restructuring the `writeVarintSlow` function by compressing its logic into a loop to reduce redundancy and improve performance.",
            "The optimization strategy involved restructuring the `writeVarintSlow` function by compressing its logic into a loop to reduce redundancy and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the `writeVarintSlow` function by compressing its logic into a loop to reduce redundancy and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "android_kernel_xiaomi_sdm845",
        "hash": "b42b97a5657f49c51f523f691e8a867708a38b80",
        "author": "NeilBrown",
        "date": "2018-03-22T09:17:50+01:00",
        "message": "md/raid6: Fix anomily when recovering a single device in RAID6.\n\n\n[ Upstream commit 7471fb77ce4dc4cb81291189947fcdf621a97987 ]\n\nWhen recoverying a single missing/failed device in a RAID6,\nthose stripes where the Q block is on the missing device are\nhandled a bit differently.  In these cases it is easy to\ncheck that the P block is correct, so we do.  This results\nin the P block be destroy.  Consequently the P block needs\nto be read a second time in order to compute Q.  This causes\nlots of seeks and hurts performance.\n\nIt shouldn't be necessary to re-read P as it can be computed\nfrom the DATA.  But we only compute blocks on missing\ndevices, since c337869d9501 (\"md: do not compute parity\nunless it is on a failed drive\").\n\nSo relax the change made in that commit to allow computing\nof the P block in a RAID6 which it is the only missing that\nblock.\n\nThis makes RAID6 recovery run much faster as the disk just\n\"before\" the recovering device is no longer seeking\nback-and-forth.\n\nReported-by-tested-by: Brad Campbell <lists2009@fnarfbargle.com>\nReviewed-by: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: NeilBrown <neilb@suse.com>\nSigned-off-by: Shaohua Li <shli@fb.com>\nSigned-off-by: Sasha Levin <alexander.levin@microsoft.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/md/raid5.c"
        ],
        "github_commit_url": "https://github.com/LineageOS/android_kernel_xiaomi_sdm845/commit/b42b97a5657f49c51f523f691e8a867708a38b80",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fetch_block"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant disk reads by computing the P block from DATA instead of re-reading it during RAID6 single-device recovery.",
            "The optimization strategy involves computing the P block from DATA instead of re-reading it, reducing unnecessary disk seeks during RAID6 recovery.",
            "The optimization strategy involves avoiding unnecessary re-reading of the P block during RAID6 recovery by computing it from available data instead of requiring a second disk read.",
            "The optimization avoids redundant disk reads by computing the P block from DATA instead of re-reading it during RAID6 single-device recovery.",
            "The optimization avoids redundant disk reads by computing the P block from DATA instead of re-reading it during RAID6 single-device recovery."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids redundant disk reads by computing the P block from DATA instead of re-reading it during RAID6 single-device recovery.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "1d068cc0b07694799e077b28dbd272b7982727e2",
        "author": "Chris Lattner",
        "date": "2011-05-22T04:53:24+00:00",
        "message": "switch to using a smallvector to avoid allocations for most normal size instructions.\n\nllvm-svn: 131837",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/MC/MCDisassembler/Disassembler.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/1d068cc0b07694799e077b28dbd272b7982727e2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LLVMDisasmInstruction"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to minimize dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to minimize dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "postgresql_modified_for_babelfish",
        "hash": "75b18d44a65f43b4358b294e529aa1b2bab923c5",
        "author": "Fujii Masao",
        "date": "2023-11-30T15:15:12-08:00",
        "message": "Reduce overhead of renaming archive status files.\n\nPresently, archive status files are durably renamed from .ready to\n.done to indicate that a file has been archived.  Persisting this\nrename to disk accounts for a significant amount of the overhead\nassociated with archiving.  While durably renaming the file\nprevents re-archiving in most cases, archive commands and libraries\nmust already gracefully handle attempts to re-archive the last\narchived file after a crash (e.g., a crash immediately after\narchive_command exits but before the server renames the status\nfile).\n\nThis change reduces the amount of overhead associated with\narchiving by using rename() instead of durable_rename() to rename\nthe archive status files.  As a consequence, the server is more\nlikely to attempt to re-archive files after a crash, but as noted\nabove, archive commands and modules are already expected to handle\nthis.  It is also possible that the server will attempt to re-\narchive files that have been removed or recycled, but the archiver\nalready handles this, too.\n\nAuthor: Nathan Bossart\nReviewed-by: Kyotaro Horiguchi, Fujii Masao\nDiscussion: https://postgr.es/m/20220222011948.GA3850532@nathanxps13\n(cherry picked from commit 756e221db610f333649385f7fef96e7e9e23ed71)",
        "modified_files_count": 1,
        "modified_files": [
            "src/backend/postmaster/pgarch.c"
        ],
        "github_commit_url": "https://github.com/babelfish-for-postgresql/postgresql_modified_for_babelfish/commit/75b18d44a65f43b4358b294e529aa1b2bab923c5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pgarch_archiveDone"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces overhead by replacing durable_rename() with rename() for archive status files, trading durability for performance while relying on existing archiver logic to handle potential re-archiving after crashes.",
            "The optimization strategy reduces overhead by replacing durable_rename() with rename() for archive status files, trading durability for performance while relying on existing archiver resilience to handle potential re-archiving after crashes.",
            "The optimization strategy reduces archiving overhead by replacing durable_rename() with rename() for archive status files, leveraging existing archiver resilience to handle potential re-archiving after crashes.",
            "The optimization strategy reduces overhead by replacing durable_rename() with rename() for archive status files, trading durability for performance while relying on existing archiver resilience to handle re-archiving after crashes.",
            "The optimization strategy reduces overhead by replacing durable_rename() with rename() for archive status files, trading durability for performance while relying on existing archiver resilience to handle potential re-archiving after crashes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces overhead by replacing durable_rename() with rename() for archive status files, trading durability for performance while relying on existing archiver resilience to handle potential re-archiving after crashes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "selinux-kernel",
        "hash": "9cd20f3fe045af95a8fe7a12328b21bfd2f3b8bf",
        "author": "Charan Teja Kalla",
        "date": "2023-12-10T16:51:52-08:00",
        "message": "mm: page_alloc: enforce minimum zone size to do high atomic reserves\n\nHighatomic reserves are set to roughly 1% of zone for maximum and a\npageblock size for minimum.  Encountered a system with the below\nconfiguration:\nNormal free:7728kB boost:0kB min:804kB low:1004kB high:1204kB\nreserved_highatomic:8192KB managed:49224kB\n\nOn such systems, even a single pageblock makes highatomic reserves are set\nto ~8% of the zone memory.  This high value can easily exert pressure on\nthe zone.\n\nPer discussion with Michal and Mel, it is not much useful to reserve the\nmemory for highatomic allocations on such small systems[1].  Since the\nminimum size for high atomic reserves is always going to be a pageblock\nsize and if 1% of zone managed pages is going to be below pageblock size,\ndon't reserve memory for high atomic allocations.  Thanks Michal for this\nsuggestion[2].\n\nSince no memory is being reserved for high atomic allocations and if\nrespective allocation failures are seen, this patch can be reverted.\n\n[1] https://lore.kernel.org/linux-mm/20231117161956.d3yjdxhhm4rhl7h2@techsingularity.net/\n[2] https://lore.kernel.org/linux-mm/ZVYRJMUitykepLRy@tiehlicka/\n\nLink: https://lkml.kernel.org/r/c3a2a48e2cfe08176a80eaf01c110deb9e918055.1700821416.git.quic_charante@quicinc.com\nSigned-off-by: Charan Teja Kalla <quic_charante@quicinc.com>\nAcked-by: David Rientjes <rientjes@google.com>\nCc: David Hildenbrand <david@redhat.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Mel Gorman <mgorman@techsingularity.net>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Pavankumar Kondeti <quic_pkondeti@quicinc.com>\nCc: Vlastimil Babka <vbabka@suse.cz>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/page_alloc.c"
        ],
        "github_commit_url": "https://github.com/SELinuxProject/selinux-kernel/commit/9cd20f3fe045af95a8fe7a12328b21bfd2f3b8bf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "reserve_highatomic_pageblock"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids reserving memory for highatomic allocations on small systems where the zone size is below a certain threshold, reducing memory pressure.",
            "The optimization strategy avoids reserving memory for highatomic allocations on small systems where the reservation would exceed a reasonable percentage of zone memory.",
            "The optimization strategy avoids reserving memory for highatomic allocations on small systems where the reservation would exceed a reasonable percentage of zone memory.",
            "The optimization strategy avoids reserving memory for highatomic allocations on small systems where the reservation would exceed a reasonable percentage of zone memory.",
            "The optimization strategy avoids reserving memory for highatomic allocations on small systems where the reservation would exceed a reasonable percentage of zone memory."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids reserving memory for highatomic allocations on small systems where the reservation would exceed a reasonable percentage of zone memory.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lpython",
        "hash": "c5f6087354f0fc5448fdc0505ebdd17255e5eb31",
        "author": "Thirumalai Shaktivel",
        "date": "2023-11-20T09:31:57+05:30",
        "message": "[ASR Pass] Skip the direct multi-dimensional ArraySection assignment to the `SIMDArray`; use do_loop instead",
        "modified_files_count": 1,
        "modified_files": [
            "src/libasr/pass/array_op.cpp"
        ],
        "github_commit_url": "https://github.com/lcompilers/lpython/commit/c5f6087354f0fc5448fdc0505ebdd17255e5eb31",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "visit_Assignment"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces direct multi-dimensional array assignments with a loop-based approach to improve performance by avoiding unnecessary memory operations.",
            "The optimization strategy replaces direct multi-dimensional array assignments with a loop-based approach to improve performance by avoiding unnecessary memory operations.",
            "The optimization strategy replaces direct multi-dimensional array assignments with a loop-based approach to improve performance by avoiding unnecessary overhead.",
            "The optimization strategy replaces direct multi-dimensional array assignments with a loop-based approach to improve performance by avoiding unnecessary operations.",
            "The optimization strategy replaces direct multi-dimensional array assignments with a loop-based approach to improve performance by avoiding unnecessary memory operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaces direct multi-dimensional array assignments with a loop-based approach to improve performance by avoiding unnecessary memory operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dolphin",
        "hash": "73067b1ef11ea1f085ccc2f721c46be7a30c0438",
        "author": "Markus Wick",
        "date": "2015-08-23T13:24:15+02:00",
        "message": "Merge pull request #2888 from degasus/jit64\n\nJit64: Faster linking of continuous blocks",
        "modified_files_count": 1,
        "modified_files": [
            "Source/Core/Core/PowerPC/JitCommon/JitCache.cpp"
        ],
        "github_commit_url": "https://github.com/dolphin-emu/dolphin/commit/73067b1ef11ea1f085ccc2f721c46be7a30c0438",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "JitBlockCache::WriteLinkBlock"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of linking continuous blocks in the JIT compiler by reducing unnecessary operations or overhead.",
            "The optimization strategy involved improving the efficiency of linking continuous blocks in the JIT compiler by reducing unnecessary operations or checks.",
            "The optimization strategy involved improving the efficiency of linking continuous blocks in the JIT compiler by reducing unnecessary operations or overhead.",
            "The optimization strategy involved improving the efficiency of linking continuous blocks in the JIT compiler by reducing unnecessary operations or checks.",
            "The optimization strategy involved improving the efficiency of linking continuous blocks in the JIT compiler by reducing redundant operations or improving cache utilization."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of linking continuous blocks in the JIT compiler by reducing unnecessary operations or overhead.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "7f7c5a5c90e1c504d0b125b922dec99500e73a28",
        "author": "Xu Guangxin",
        "date": "2016-02-19T09:16:34+08:00",
        "message": "tests: transocde, fix threaded input\n\nPrevious code return VppInput too early, the VppInputAsync did not added.\nthis patch will improve performance.",
        "modified_files_count": 1,
        "modified_files": [
            "tests/yamitranscode.cpp"
        ],
        "github_commit_url": "https://github.com/intel/libyami/commit/7f7c5a5c90e1c504d0b125b922dec99500e73a28",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "createInput"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "libyami",
        "optimization_summary": [
            "The optimization strategy involved ensuring proper asynchronous input handling by delaying the return of VppInput until after VppInputAsync was added, thereby improving threaded performance.",
            "The optimization strategy involved ensuring proper asynchronous input handling by delaying the return of VppInput until after VppInputAsync was added, thereby improving performance.",
            "The optimization strategy involved ensuring proper asynchronous input handling by delaying the return of VppInput until after VppInputAsync was added, thereby improving performance.",
            "The optimization strategy involved ensuring proper asynchronous input handling by delaying the return of VppInput until after VppInputAsync was added, thereby improving performance.",
            "The optimization strategy involved ensuring proper asynchronous input handling by delaying the return of VppInput to improve threading performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved ensuring proper asynchronous input handling by delaying the return of VppInput until after VppInputAsync was added, thereby improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dealii",
        "hash": "a73744da1125385bf240fa4a43ba5ae9e135c8bc",
        "author": "Wolfgang Bangerth",
        "date": "2015-04-22T06:32:22-05:00",
        "message": "Merge pull request #859 from kronbichler/master\n\nImprove performance of renumber_dofs for parallel triangulation",
        "modified_files_count": 1,
        "modified_files": [
            "source/dofs/dof_handler_policy.cc"
        ],
        "github_commit_url": "https://github.com/dealii/dealii/commit/a73744da1125385bf240fa4a43ba5ae9e135c8bc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "renumber_dofs"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the `renumber_dofs` function to reduce redundant computations and improve cache locality during parallel triangulation processing.",
            "The optimization strategy involved restructuring the renumbering logic to reduce redundant computations and improve cache locality during parallel DOF renumbering.",
            "The optimization strategy involved restructuring the `renumber_dofs` function to reduce redundant computations and improve cache locality during parallel triangulation processing.",
            "The optimization strategy involved restructuring the `renumber_dofs` function to reduce redundant computations and improve cache locality during parallel triangulation processing.",
            "The optimization strategy involved restructuring the `renumber_dofs` function to reduce redundant computations and improve cache locality during parallel triangulation processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the `renumber_dofs` function to reduce redundant computations and improve cache locality during parallel triangulation processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "plasma-workspace",
        "hash": "4d7022837c838191f6a1a5ebab52ff25aa02ae24",
        "author": "Eike Hein",
        "date": "2014-05-02T14:01:29+02:00",
        "message": "More efficient runner matches model updates.",
        "modified_files_count": 1,
        "modified_files": [
            "runnermatchesmodel.cpp"
        ],
        "github_commit_url": "https://github.com/KDE/plasma-workspace/commit/4d7022837c838191f6a1a5ebab52ff25aa02ae24",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RunnerMatchesModel::setMatches"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
            "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary updates by checking if the matches have actually changed before updating the model.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "fbthrift",
        "hash": "9187dd90a98254d7b40a1e50e95d20e5562565fc",
        "author": "Dave Kwon",
        "date": "2024-04-26T19:26:59-07:00",
        "message": "Refactor `emplace_back_default` to avoid default ctor for emplace_back when allocator is not used\n\nSummary:\nThis avoid default ctor for cases where allocator is not used so that we can avoid 1 move ctor and 1 dtor. Therefore, we see big improvement in `LargeListMixed ` about ~11% in deserialization.\n\nBenchmark:\nWith fdo turned off\n```\n// before\n=============================================================================================\nfbcode/thrift/lib/cpp2/test/ProtocolBench.cpp     relative  time/iter   iters/s  serialized_size\n=============================================================================================\nBinaryProtocol_read_SmallListInt                                            37.18ns    26.90M               49\nBinaryProtocol_read_BigListInt                                              20.04us    49.89K            40009\nBinaryProtocol_read_BigListMixed                                           456.61us     2.19K           500009\nBinaryProtocol_read_BigListMixedInt                                        280.56us     3.56K           850009\nBinaryProtocol_read_LargeListMixed                                          56.48ms     17.71         50000009\nOpEncodeBinaryProtocol_read_SmallListInt                                    36.91ns    27.09M               49\nOpEncodeBinaryProtocol_read_BigListInt                                      19.45us    51.41K            40009\nOpEncodeBinaryProtocol_read_BigListMixed                                   461.38us     2.17K           500009\nOpEncodeBinaryProtocol_read_BigListMixedInt                                268.13us     3.73K           850009\nOpEncodeBinaryProtocol_read_LargeListMixed                                  55.58ms     17.99         50000009\n=============================================================================================\n```\nvs\n```\n//after\n=============================================================================================\nfbcode/thrift/lib/cpp2/test/ProtocolBench.cpp     relative  time/iter   iters/s  serialized_size\n=============================================================================================\nBinaryProtocol_read_SmallListInt                                            38.50ns    25.97M               49\nBinaryProtocol_read_BigListInt                                              20.78us    48.13K            40009\nBinaryProtocol_read_BigListMixed                                           449.85us     2.22K           500009\nBinaryProtocol_read_BigListMixedInt                                        274.56us     3.64K           850009\nBinaryProtocol_read_LargeListMixed                                          51.57ms     19.39         50000009\nOpEncodeBinaryProtocol_read_SmallListInt                                    36.17ns    27.64M               49\nOpEncodeBinaryProtocol_read_BigListInt                                      19.73us    50.68K            40009\nOpEncodeBinaryProtocol_read_BigListMixed                                   410.18us     2.44K           500009\nOpEncodeBinaryProtocol_read_BigListMixedInt                                266.42us     3.75K           850009\nOpEncodeBinaryProtocol_read_LargeListMixed                                  50.09ms     19.96         50000009\n=============================================================================================\n```\n\nReviewed By: yfeldblum\n\nDifferential Revision: D56656403\n\nfbshipit-source-id: e473c2cc1127490fa554ffc174e0ae72def17167",
        "modified_files_count": 1,
        "modified_files": [
            "thrift/lib/cpp2/protocol/detail/protocol_methods.h"
        ],
        "github_commit_url": "https://github.com/facebook/fbthrift/commit/9187dd90a98254d7b40a1e50e95d20e5562565fc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "emplace_back_default"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary default constructor calls in `emplace_back_default` by directly constructing objects in place when no allocator is used, reducing move and destructor overhead.",
            "The optimization avoids unnecessary default constructor calls in `emplace_back_default` by directly constructing objects in place when no allocator is used, reducing move and destructor overhead.",
            "The optimization avoids unnecessary default constructor calls in `emplace_back_default` by directly constructing objects in place when no allocator is used, reducing overhead from move and destructor operations.",
            "The optimization avoids unnecessary default constructor calls in `emplace_back_default` by directly constructing objects in place when no allocator is used, reducing overhead from move constructors and destructors.",
            "The optimization avoids unnecessary default constructor calls in `emplace_back_default` by directly constructing objects in place when no allocator is used, reducing move and destructor overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary default constructor calls in `emplace_back_default` by directly constructing objects in place when no allocator is used, reducing move and destructor overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "415b1a0105cd05a428f8b28ac1bf406ca2b4bbd7",
        "author": "Sean Christopherson",
        "date": "2021-06-17T13:09:52-04:00",
        "message": "KVM: x86: Uncondtionally skip MMU sync/TLB flush in MOV CR3's PGD switch\n\nStop leveraging the MMU sync and TLB flush requested by the fast PGD\nswitch helper now that kvm_set_cr3() manually handles the necessary sync,\nfrees, and TLB flush.  This will allow dropping the params from the fast\nPGD helpers since nested SVM is now the odd blob out.\n\nSigned-off-by: Sean Christopherson <seanjc@google.com>\nMessage-Id: <20210609234235.1244004-6-seanjc@google.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/kvm/x86.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/415b1a0105cd05a428f8b28ac1bf406ca2b4bbd7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "kvm_set_cr3"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy eliminates redundant MMU sync and TLB flush operations during a fast PGD switch by relying on manual handling in `kvm_set_cr3`.",
            "The optimization strategy eliminates redundant MMU sync and TLB flush operations during a fast PGD switch by relying on manual handling in `kvm_set_cr3`.",
            "The optimization strategy eliminates redundant MMU sync and TLB flush operations during a fast PGD switch by relying on manual handling in `kvm_set_cr3`.",
            "The optimization strategy eliminates redundant MMU sync and TLB flush operations during a CR3 register update by relying on manual handling in `kvm_set_cr3`.",
            "The optimization strategy eliminates redundant MMU sync and TLB flush operations during a fast PGD switch by relying on manual handling in `kvm_set_cr3`."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy eliminates redundant MMU sync and TLB flush operations during a fast PGD switch by relying on manual handling in `kvm_set_cr3`.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "rapidjson",
        "hash": "b67ff2fb11307dfe03926f5433175fb67072cc64",
        "author": "fuzhufang",
        "date": "2016-07-14T17:50:48+08:00",
        "message": "if define RAPIDJSON_HAS_STDSTRING, FindMember use std::string, but it\nalso use internal::StrLen to get the string lengtht,\nwhen it call FindMember(StringRef(name)).\nNow use GenericValue construct it, then can use the std::string.size.\nnow it will be faster.",
        "modified_files_count": 1,
        "modified_files": [
            "include/rapidjson/document.h"
        ],
        "github_commit_url": "https://github.com/Tencent/rapidjson/commit/b67ff2fb11307dfe03926f5433175fb67072cc64",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FindMember"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant string length calculations by leveraging `std::string::size` instead of calling `internal::StrLen` when using `FindMember` with `StringRef`.",
            "The optimization avoids redundant string length calculations by leveraging `std::string::size` instead of calling `internal::StrLen` when using `FindMember` with `StringRef`.",
            "The optimization avoids redundant string length calculations by leveraging `std::string::size` instead of calling `internal::StrLen` when using `FindMember` with `StringRef`.",
            "The optimization avoids redundant string length calculations by leveraging `std::string::size` instead of calling `internal::StrLen` when using `FindMember` with `StringRef`.",
            "The optimization avoids redundant string length calculations by leveraging `std::string::size` instead of calling `internal::StrLen` when using `FindMember` with `StringRef`."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids redundant string length calculations by leveraging `std::string::size` instead of calling `internal::StrLen` when using `FindMember` with `StringRef`.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "415be93bec7d1d7b594d1132cc05b471e3443142",
        "author": "Marc-André Moreau",
        "date": "2013-02-26T07:06:57-08:00",
        "message": "Merge pull request #1008 from mfleisz/perfflags\n\nAndroid: Fixed incorrect handling of performance flags",
        "modified_files_count": 1,
        "modified_files": [
            "client/Android/FreeRDPCore/jni/android_freerdp.c"
        ],
        "github_commit_url": "https://github.com/FreeRDP/FreeRDP/commit/415be93bec7d1d7b594d1132cc05b471e3443142",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "jni_freerdp_set_performance_flags"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "FreeRDP",
        "optimization_summary": [
            "The optimization strategy involved correcting the handling of performance flags to ensure proper functionality and potentially improve performance.",
            "The optimization strategy involved correcting the handling of performance flags to ensure proper functionality and potentially improve performance.",
            "The optimization strategy involved correcting the handling of performance flags to ensure proper functionality and potentially improve performance.",
            "The optimization strategy involved correcting the handling of performance flags to ensure proper functionality and potentially improve performance.",
            "The optimization strategy involved correcting the handling of performance flags to ensure proper functionality and potentially improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved correcting the handling of performance flags to ensure proper functionality and potentially improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "6994dd82c4f8c3f686f73801fc92a859a5eecb7f",
        "author": "Josh Coalson",
        "date": "2001-04-18T02:21:21+00:00",
        "message": "minor speed optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/libFLAC/encoder_framing.c"
        ],
        "github_commit_url": "https://github.com/xiph/flac/commit/6994dd82c4f8c3f686f73801fc92a859a5eecb7f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "subframe_add_residual_partitioned_rice_"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "flac",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop to reduce redundant calculations and improve cache locality.",
            "The optimization strategy involved restructuring the loop to reduce redundant calculations and improve cache locality.",
            "The optimization strategy involved restructuring the loop to reduce redundant calculations and improve cache locality.",
            "The optimization strategy involved restructuring the loop to reduce redundant calculations and improve cache locality by reordering operations.",
            "The optimization strategy involved restructuring the loop to reduce redundant calculations and improve cache locality."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop to reduce redundant calculations and improve cache locality.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ain",
        "hash": "28caf97f02c72e4ab39645be8203adc5bb015718",
        "author": "lucash.dev@gmail.com",
        "date": "2018-06-06T06:50:25-07:00",
        "message": "speed up of tx_validationcache_tests by reusing of CTransaction.\n\nThe code was converting CMutableTransaction to CTransaction multiple times, which implies recalculating the hash multiple times. This commit fixes this by reusing a single CTransaction.",
        "modified_files_count": 1,
        "modified_files": [
            "src/test/txvalidationcache_tests.cpp"
        ],
        "github_commit_url": "https://github.com/DeFiCh/ain/commit/28caf97f02c72e4ab39645be8203adc5bb015718",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ValidateCheckInputsForAllFlags"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reusing a single CTransaction object to avoid redundant conversions and hash recalculations.",
            "The optimization strategy involved reusing a single CTransaction object to avoid redundant conversions and hash recalculations.",
            "The optimization strategy involved reusing a single CTransaction object to avoid redundant conversions and hash recalculations.",
            "The optimization strategy involved reusing a single CTransaction object to avoid redundant conversions and hash recalculations.",
            "The optimization strategy involved reusing a single CTransaction object to avoid redundant conversions and hash recalculations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reusing a single CTransaction object to avoid redundant conversions and hash recalculations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "n3n",
        "hash": "e3951631b987e2be6f9fd46df8c48d23c68e09fb",
        "author": "emanuele-f",
        "date": "2019-04-11T00:46:34+02:00",
        "message": "Improve benchmark\n\nSample on i3 2GHz:\n\nRun [transop_null] for 3s (512 bytes):   \t    11203585 packets\t  3734.5 Kpps\t  1912.1 MB/s\nRun [transop_twofish] for 3s (512 bytes):   \t       60705 packets\t    20.2 Kpps\t    10.4 MB/s\nRun [transop_aes] for 3s (512 bytes):   \t      467937 packets\t   156.0 Kpps\t    79.9 MB/s",
        "modified_files_count": 1,
        "modified_files": [
            "benchmark.c"
        ],
        "github_commit_url": "https://github.com/n42n/n3n/commit/e3951631b987e2be6f9fd46df8c48d23c68e09fb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "run_transop_benchmark"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary overhead in the benchmark loop to improve packet processing speed.",
            "The optimization strategy involved reducing unnecessary overhead in the benchmark loop to improve packet processing speed.",
            "The optimization strategy involved reducing unnecessary overhead in the benchmark loop by minimizing redundant operations or improving data handling efficiency.",
            "The optimization strategy involved reducing unnecessary overhead in the benchmark loop to improve packet processing speed.",
            "The optimization strategy involved reducing the computational overhead in the benchmark by minimizing redundant operations or improving loop efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary overhead in the benchmark loop to improve packet processing speed.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "a662fdad03ab436c3058c786328bdd2cf6a8f932",
        "author": "spotlessmind1975",
        "date": "2024-09-01T15:55:29+00:00",
        "message": "Increased performance of 6502 optimizer.",
        "modified_files_count": 1,
        "modified_files": [
            "ugbc/src/targets/atari/_optimizer.c"
        ],
        "github_commit_url": "https://github.com/spotlessmind1975/ugbasic/commit/a662fdad03ab436c3058c786328bdd2cf6a8f932",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vars_remove"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "ugbasic",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant variable checks and simplifying logic in the variable removal process to improve efficiency.",
            "The optimization strategy involved restructuring the variable removal process to reduce redundant operations and improve efficiency.",
            "The optimization strategy involved restructuring the variable removal process to reduce redundant operations and improve efficiency.",
            "The optimization strategy involved reducing redundant operations within the `vars_remove` function to improve its efficiency.",
            "The optimization strategy involved restructuring the logic in the `vars_remove` function to reduce redundant operations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the variable removal process to reduce redundant operations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "openmv",
        "hash": "59fea5bc52848f330f1bce6079df5f6b392d91c3",
        "author": "Kwabena W. Agyeman",
        "date": "2024-02-16T16:51:12-08:00",
        "message": "imlib/jpege: Improve jpeg YUV422/420 UV sub-sampling speed.",
        "modified_files_count": 1,
        "modified_files": [
            "src/omv/imlib/jpege.c"
        ],
        "github_commit_url": "https://github.com/openmv/openmv/commit/59fea5bc52848f330f1bce6079df5f6b392d91c3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "jpeg_compress"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used loop unrolling and direct memory access to improve the speed of UV sub-sampling in JPEG compression.",
            "The optimization strategy involved improving the efficiency of UV sub-sampling in JPEG compression by reducing unnecessary computations or memory accesses.",
            "The optimization strategy involved improving the efficiency of UV sub-sampling in JPEG compression by reducing unnecessary computations or memory accesses.",
            "The optimization strategy used loop unrolling and direct memory access to improve the speed of YUV422/420 UV sub-sampling in JPEG compression.",
            "The optimization strategy used loop unrolling and direct memory access to improve the speed of UV sub-sampling in JPEG compression."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used loop unrolling and direct memory access to improve the speed of UV sub-sampling in JPEG compression.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "0954d4199a2387b23234a60cf4cd4b4854ce6f71",
        "author": "Jakob Stoklund Olesen",
        "date": "2012-08-10T20:11:38+00:00",
        "message": "Include loop-carried dependencies when computing instr heights.\n\nWhen a trace ends with a back-edge, include PHIs in the loop header in\nthe height computations. This makes the critical path through a loop\nmore accurate by including the latencies of the last instructions in the\nloop.\n\nllvm-svn: 161688",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/MachineTraceMetrics.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/0954d4199a2387b23234a60cf4cd4b4854ce6f71",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves improving the accuracy of critical path computation in loops by including loop-carried dependencies and PHIs in height calculations.",
            "The optimization strategy involves improving the accuracy of critical path computation in loops by including loop-carried dependencies and PHIs in height calculations.",
            "The optimization strategy involves improving the accuracy of critical path computation in loops by including loop-carried dependencies and PHIs in the height calculations.",
            "The optimization strategy involves improving the accuracy of critical path computation in loops by including loop-carried dependencies and PHIs in height calculations.",
            "The optimization strategy involves improving the accuracy of critical path computation in loops by including loop-carried dependencies and PHIs in height calculations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves improving the accuracy of critical path computation in loops by including loop-carried dependencies and PHIs in height calculations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sysrepo",
        "hash": "428ecf89d76422312025f06b5575a5d5ce747e00",
        "author": "Michal Vasko",
        "date": "2023-08-10T09:54:37+02:00",
        "message": "sysrepo OPTIMIZE skip discard changes if redundant\n\nAvoid all the locks and code is there are no\nstored oper changes for a connection.",
        "modified_files_count": 1,
        "modified_files": [
            "src/sysrepo.c"
        ],
        "github_commit_url": "https://github.com/sysrepo/sysrepo/commit/428ecf89d76422312025f06b5575a5d5ce747e00",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sr_discard_oper_changes"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary locks and function execution by skipping discard operations when there are no stored operational changes for a connection.",
            "The optimization avoids unnecessary locks and function execution by skipping discard operations when there are no stored operational changes for a connection.",
            "The optimization strategy skips unnecessary operations by checking for the absence of stored operational changes before proceeding with locks and code execution.",
            "The optimization strategy skips unnecessary locking and function execution when there are no stored operational changes for a connection, reducing overhead.",
            "The optimization avoids unnecessary locks and operations by skipping discard changes when there are no stored operational changes for a connection."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary locks and function execution by skipping discard operations when there are no stored operational changes for a connection.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "0b26a15b6223e490a8553cbf5b4be0ebb28c24b8",
        "author": "Benjamin Otte",
        "date": "2011-11-16T04:39:24+01:00",
        "message": "a11y: Make find by index lookup use the hash table again\n\nThis should give back the performance that was lost with the commit\n\"a11y: Make the cache lookup function inefficient\".",
        "modified_files_count": 1,
        "modified_files": [
            "gtk/a11y/gtktreeviewaccessible.c"
        ],
        "github_commit_url": "https://github.com/GNOME/gtk/commit/0b26a15b6223e490a8553cbf5b4be0ebb28c24b8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "find_cell"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "gtk",
        "optimization_summary": [
            "The optimization strategy involved reverting to using a hash table for index lookup to improve performance.",
            "The optimization strategy involved reverting to using a hash table for index lookup to improve performance.",
            "The optimization strategy involved reverting to using a hash table for index lookups to improve performance.",
            "The optimization strategy involved reverting to using a hash table for index lookups to improve performance.",
            "The optimization strategy involved restoring the use of a hash table for index lookups to improve cache lookup efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reverting to using a hash table for index lookups to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kernel_xiaomi_sm8250",
        "hash": "dc5e65028a8e43432829bd0546ee14935a3cd415",
        "author": "Mark-PK Tsai",
        "date": "2024-03-29T01:35:10+02:00",
        "message": "zram: use copy_page for full page copy\nSome architectures, such as arm, have implemented optimized copy_page for\nfull page copying.\n\nReplace the full page memcpy with copy_page to take advantage of the\noptimization.\n\nLink: https://lkml.kernel.org/r/20231007070554.8657-1-mark-pk.tsai@mediatek.com\nSigned-off-by: Mark-PK Tsai <mark-pk.tsai@mediatek.com>\nReviewed-by: Sergey Senozhatsky <senozhatsky@chromium.org>\nCc: AngeloGioacchino Del Regno <angelogioacchino.delregno@collabora.com>\nCc: Jens Axboe <axboe@kernel.dk>\nCc: Matthias Brugger <matthias.bgg@gmail.com>\nCc: Minchan Kim <minchan@kernel.org>\nCc: YJ Chiang <yj.chiang@mediatek.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/block/zram/zram_drv.c"
        ],
        "github_commit_url": "https://github.com/EmanuelCN/kernel_xiaomi_sm8250/commit/dc5e65028a8e43432829bd0546ee14935a3cd415",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__zram_bvec_read"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces a generic `memcpy` with an architecture-specific `copy_page` function to leverage hardware-optimized full-page copying.",
            "The optimization replaces a generic memcpy with an architecture-specific optimized copy_page function for full-page copying.",
            "The optimization replaces a generic `memcpy` with an architecture-specific `copy_page` function to leverage hardware-optimized full-page copying.",
            "The optimization replaces a generic `memcpy` with an architecture-specific `copy_page` function to leverage hardware-optimized full-page copying.",
            "The optimization replaces a generic `memcpy` with an architecture-specific `copy_page` function to leverage hardware-optimized full-page copying."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization replaces a generic `memcpy` with an architecture-specific `copy_page` function to leverage hardware-optimized full-page copying.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "b4724dbda23aed9148c91fb0cfc5f9052e376bee",
        "author": "Owen Anderson",
        "date": "2008-02-20T08:23:02+00:00",
        "message": "When performing return slot optimization, remember to inform memdep when we're removing the memcpy.\n\nllvm-svn: 47364",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Transforms/Scalar/GVN.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/b4724dbda23aed9148c91fb0cfc5f9052e376bee",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves improving return slot optimization by notifying memdep when removing memcpy operations to enhance memory dependency analysis.",
            "The optimization strategy involves improving return slot optimization by notifying memdep when removing memcpy operations to enhance memory dependency analysis.",
            "The optimization strategy involves improving return slot optimization by notifying memdep when removing memcpy operations to enhance memory dependency analysis.",
            "The optimization strategy involves improving return slot optimization by notifying memdep when removing memcpy operations to enhance memory dependency analysis.",
            "The optimization strategy involves improving return slot optimization by notifying memdep when removing memcpy operations to enhance memory dependency analysis."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves improving return slot optimization by notifying memdep when removing memcpy operations to enhance memory dependency analysis.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "KeyDB",
        "hash": "05f0492a035e530c5aa69b75d109bab5c184e542",
        "author": "antirez",
        "date": "2013-03-09T11:48:54+01:00",
        "message": "Optimize inner loop of activeExpireCycle() for no-expires case.",
        "modified_files_count": 1,
        "modified_files": [
            "src/redis.c"
        ],
        "github_commit_url": "https://github.com/Snapchat/KeyDB/commit/05f0492a035e530c5aa69b75d109bab5c184e542",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "activeExpireCycle"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary iterations in the inner loop of `activeExpireCycle()` by skipping processing when there are no keys with expiration set.",
            "The optimization strategy avoids unnecessary iterations in the inner loop of `activeExpireCycle()` by skipping processing when there are no keys with expiration set.",
            "The optimization avoids unnecessary iterations in the inner loop of `activeExpireCycle()` by skipping processing when there are no keys with expiration set.",
            "The optimization strategy avoids unnecessary iterations in the inner loop of `activeExpireCycle()` by skipping processing when there are no keys with expiration.",
            "The optimization strategy avoids unnecessary iterations in the inner loop of `activeExpireCycle()` by skipping processing when there are no keys with expiration set."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary iterations in the inner loop of `activeExpireCycle()` by skipping processing when there are no keys with expiration set.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_msm-5.4_nothing_sm7325",
        "hash": "059c1996017df7a8af791f8855b148d23b9460c2",
        "author": "Torin Cooper-Bennun",
        "date": "2021-03-30T14:35:26+02:00",
        "message": "can: m_can: m_can_do_rx_poll(): fix extraneous msg loss warning\n\n[ Upstream commit c0e399f3baf42279f48991554240af8c457535d1 ]\n\nMessage loss from RX FIFO 0 is already handled in\nm_can_handle_lost_msg(), with netdev output included.\n\nRemoving this warning also improves driver performance under heavy\nload, where m_can_do_rx_poll() may be called many times before this\ninterrupt is cleared, causing this message to be output many\ntimes (thanks Mariusz Madej for this report).\n\nFixes: e0d1f4816f2a (\"can: m_can: add Bosch M_CAN controller support\")\nLink: https://lore.kernel.org/r/20210303103151.3760532-1-torin@maxiluxsystems.com\nReported-by: Mariusz Madej <mariusz.madej@xtrack.com>\nSigned-off-by: Torin Cooper-Bennun <torin@maxiluxsystems.com>\nSigned-off-by: Marc Kleine-Budde <mkl@pengutronix.de>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/can/m_can/m_can.c"
        ],
        "github_commit_url": "https://github.com/NothingOSS/android_kernel_msm-5.4_nothing_sm7325/commit/059c1996017df7a8af791f8855b148d23b9460c2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "m_can_do_rx_poll"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing redundant warning messages in the RX FIFO handling to reduce excessive logging during heavy load conditions.",
            "The optimization removes redundant warning messages during heavy load to reduce unnecessary output and improve performance.",
            "The optimization removes redundant warning messages during heavy load to reduce unnecessary output and improve performance.",
            "The optimization strategy involved removing redundant warning messages in a CAN driver to prevent excessive logging under heavy load, thereby improving performance.",
            "The optimization removes redundant warning messages during heavy load to prevent excessive logging, which improves performance by reducing unnecessary output operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes redundant warning messages during heavy load to prevent excessive logging, which improves performance by reducing unnecessary output operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mygui",
        "hash": "964d8e5432aaac9be8044a17ba5ff49ef987a7c2",
        "author": "scrawl",
        "date": "2014-09-12T02:46:46+02:00",
        "message": "Improve performance in OgreDataManager::isDataExist",
        "modified_files_count": 1,
        "modified_files": [
            "Platforms/Ogre/OgrePlatform/src/MyGUI_OgreDataManager.cpp"
        ],
        "github_commit_url": "https://github.com/MyGUI/mygui/commit/964d8e5432aaac9be8044a17ba5ff49ef987a7c2",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant file existence checks by caching results for faster subsequent lookups.",
            "The optimization strategy involved reducing redundant file existence checks by caching results for faster subsequent lookups.",
            "The optimization strategy involved reducing redundant file existence checks by caching results for faster subsequent lookups.",
            "The optimization strategy involved reducing redundant file existence checks by caching results for faster subsequent lookups.",
            "The optimization strategy involved reducing unnecessary file existence checks by caching results or skipping redundant operations in OgreDataManager::isDataExist."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant file existence checks by caching results for faster subsequent lookups.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "wesnoth",
        "hash": "53bdb06987fc1381dffe93209d850931588df616",
        "author": "Ali El Gariani",
        "date": "2007-07-09T04:01:28+00:00",
        "message": "Fix an old small cache bug:\n\na stoned unit facing west added a new greyscaled image in the\nreversed_cache for each redraw.\n\nFlushed at ToD change, but long day or game without ToD had an\ninfinitly growing cache.\n\nI will try to improve this cache later, because this flushing at ToD\nis stupid since units are not ToD colored but need to add a smarter\nflush before remove it.",
        "modified_files_count": 1,
        "modified_files": [
            "src/unit.cpp"
        ],
        "github_commit_url": "https://github.com/wesnoth/wesnoth/commit/53bdb06987fc1381dffe93209d850931588df616",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "unit::redraw_unit"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved fixing a cache bug by preventing redundant image additions to the reversed_cache during redraws, thus avoiding infinite cache growth.",
            "The optimization strategy fixed a memory leak by preventing redundant additions to a cache that was not properly flushed, ensuring the cache does not grow infinitely.",
            "The optimization strategy fixed a memory leak by preventing redundant additions to a cache that was not properly flushed, thus avoiding unbounded growth.",
            "The optimization strategy fixed a cache bug by preventing redundant greyscale image additions to the reversed_cache during redraws, which could grow infinitely without proper flushing.",
            "The optimization strategy fixed a memory leak by preventing redundant additions to a cache that was not properly cleared, thus avoiding unbounded growth."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy fixed a memory leak by preventing redundant additions to a cache that was not properly flushed, thus avoiding unbounded growth.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow-directml",
        "hash": "0a4652663e3cd378113d51e1d076504c8e96b308",
        "author": "Amit Srivastava",
        "date": "2019-03-05T08:53:43+05:30",
        "message": "Speedup fix for the push_back function\n\nReserve the space in advance for speedup",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/lite/toco/tflite/export.cc"
        ],
        "github_commit_url": "https://github.com/microsoft/tensorflow-directml/commit/0a4652663e3cd378113d51e1d076504c8e96b308",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ExportTensors"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reserving space in advance for a vector to reduce the overhead of repeated memory reallocations during push_back operations.",
            "The optimization strategy involved reserving space in advance for a vector to reduce the overhead of repeated reallocations during push_back operations.",
            "The optimization strategy involved reserving space in advance for a vector to reduce the overhead of repeated memory reallocations during push_back operations.",
            "The optimization strategy involved reserving space in advance for a vector to reduce the overhead of repeated memory allocations during push_back operations.",
            "The optimization strategy involved reserving space in advance for a vector to reduce the overhead of repeated reallocations during `push_back` operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reserving space in advance for a vector to reduce the overhead of repeated memory reallocations during push_back operations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "tdme2",
        "hash": "c3fc3f87b5ded6df1f11b360c47d2bdd89d735e9",
        "author": "Andreas Drewke",
        "date": "2021-07-29T17:25:28+02:00",
        "message": "tests/FlowMapTest2: Some flowmap merge performance improvement",
        "modified_files_count": 1,
        "modified_files": [
            "src/tdme/utilities/FlowMap.h"
        ],
        "github_commit_url": "https://github.com/andreasdr/tdme2/commit/c3fc3f87b5ded6df1f11b360c47d2bdd89d735e9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "merge"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the merge function to reduce redundant computations during flowmap merging.",
            "The optimization strategy involved restructuring the merge function to reduce redundant computations during flowmap merging.",
            "The optimization strategy involved restructuring the merge function to reduce redundant computations during flowmap merging.",
            "The optimization strategy involved restructuring the merge function to reduce redundant computations during flowmap merging.",
            "The optimization strategy involved reducing redundant computations during flow map merging by caching intermediate results."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the merge function to reduce redundant computations during flowmap merging.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "hurd",
        "hash": "9b3a87f37c4e829386ceb10de974d409a31adcf7",
        "author": "Samuel Thibault",
        "date": "2013-08-28T23:20:41+02:00",
        "message": "Optimize translator string copy\n\n* libnetfs/file-get-translator.c (netfs_S_file_get_translator): Call memcpy\ninstead of memmove.",
        "modified_files_count": 1,
        "modified_files": [
            "libnetfs/file-get-translator.c"
        ],
        "github_commit_url": "https://github.com/joshumax/hurd/commit/9b3a87f37c4e829386ceb10de974d409a31adcf7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "netfs_S_file_get_translator"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced `memmove` with `memcpy` to improve performance by avoiding unnecessary overlap checks.",
            "The optimization strategy replaced `memmove` with `memcpy` to improve performance by avoiding unnecessary overlap checks during memory copying.",
            "The optimization strategy replaced `memmove` with `memcpy` to improve performance by avoiding unnecessary overlap checks.",
            "The optimization strategy replaced a `memmove` call with a `memcpy` call to improve performance by avoiding unnecessary overlap checks.",
            "The optimization strategy replaced `memmove` with `memcpy` to improve performance by avoiding unnecessary overlap checks during memory copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaced `memmove` with `memcpy` to improve performance by avoiding unnecessary overlap checks.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "poedit",
        "hash": "0d722d8b4814c594fd37eb838ea68b895d171b28",
        "author": "Václav Slavík",
        "date": "2017-05-20T17:41:07+02:00",
        "message": "Optimize UnescapeCString if no escaping needed\n\nMake the common case faster. Reduces time spent in this function when\nreading a PO file from ~3% to ~1%.",
        "modified_files_count": 1,
        "modified_files": [
            "src/utility.h"
        ],
        "github_commit_url": "https://github.com/vslavik/poedit/commit/0d722d8b4814c594fd37eb838ea68b895d171b28",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "UnescapeCString"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary processing in the common case by checking if escaping is needed before performing the unescaping operation.",
            "The optimization avoids unnecessary processing in the common case by checking if escaping is needed before performing the unescaping operation.",
            "The optimization avoids unnecessary processing in the common case where no escaping is needed by adding an early exit condition.",
            "The optimization strategy used is to make the common case faster by reducing unnecessary processing when no escaping is needed in the `UnescapeCString` function.",
            "The optimization avoids unnecessary processing in the common case by checking if escaping is needed before performing the unescaping operation."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary processing in the common case by checking if escaping is needed before performing the unescaping operation.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "llvm-leg",
        "hash": "85a5ac00e0c5335309d5e7951e9f2a5d32b8024e",
        "author": "Akira Hatanaka",
        "date": "2014-11-03T23:06:31+00:00",
        "message": "[AArch64] Make function processLogicalImmediate more efficient. NFC.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@221199 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Target/AArch64/MCTargetDesc/AArch64AddressingModes.h"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/85a5ac00e0c5335309d5e7951e9f2a5d32b8024e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "processLogicalImmediate"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the function to reduce unnecessary computations and improve the efficiency of processing logical immediates.",
            "The optimization strategy involved restructuring the function to reduce unnecessary computations and improve the efficiency of processing logical immediates.",
            "The optimization strategy involved restructuring the function to reduce unnecessary computations and improve the efficiency of processing logical immediates.",
            "The optimization strategy involved restructuring the function to reduce unnecessary computations and improve the efficiency of processing logical immediates.",
            "The optimization strategy involved restructuring the `processLogicalImmediate` function to improve its efficiency by reducing unnecessary computations or improving logical flow."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the function to reduce unnecessary computations and improve the efficiency of processing logical immediates.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cheribsd",
        "hash": "0f3cc9a72e193e7ade68889ab030729cae2c8ba0",
        "author": "jeff",
        "date": "2007-08-20T06:34:20+00:00",
        "message": "- Set steal_thresh to log2(ncpus).  This improves idle-time load balancing\n   on 2cpu machines by reducing it to 1 by default.  This improves loaded\n   operation on 8cpu machines by increasing it to 3 where the extra idle\n   time is not as critical.\n\nApproved by:\tre",
        "modified_files_count": 1,
        "modified_files": [
            "sys/kern/sched_ule.c"
        ],
        "github_commit_url": "https://github.com/CTSRD-CHERI/cheribsd/commit/0f3cc9a72e193e7ade68889ab030729cae2c8ba0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sched_initticks"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy adjusts the `steal_thresh` parameter based on the number of CPUs to improve load balancing efficiency.",
            "The optimization strategy adjusts the `steal_thresh` parameter to be dynamically set based on the logarithm of the number of CPUs, improving load balancing efficiency across different machine configurations.",
            "The optimization adjusts the `steal_thresh` parameter to be dynamically set based on the logarithm of the number of CPUs, improving load balancing efficiency across different machine configurations.",
            "The optimization strategy adjusts the `steal_thresh` parameter based on the number of CPUs to improve load balancing efficiency.",
            "The optimization strategy adjusts the `steal_thresh` parameter to be dynamically set based on the logarithm of the number of CPUs, improving load balancing efficiency across different CPU configurations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy adjusts the `steal_thresh` parameter to be dynamically set based on the logarithm of the number of CPUs, improving load balancing efficiency across different CPU configurations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "a89c91020c4860adcec46458a1e8fb9b1297767d",
        "author": "Chris Lattner",
        "date": "2003-10-09T20:30:04+00:00",
        "message": "Remove potentially N^2 algorithm from symbol table reader.  No speedup\nin practice though\n\nllvm-svn: 8985",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Bytecode/Reader/Reader.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/a89c91020c4860adcec46458a1e8fb9b1297767d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a potentially quadratic algorithm with a more efficient approach in the symbol table reader.",
            "The optimization strategy involved replacing a potentially N^2 algorithm with a more efficient approach in the symbol table reader.",
            "The optimization strategy involved replacing a potentially N^2 algorithm with a more efficient approach in the symbol table reader.",
            "The commit removes a potentially quadratic-time algorithm from the symbol table reader to improve theoretical performance.",
            "The optimization strategy involved replacing a potentially N^2 algorithm with a more efficient approach in the symbol table reader."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a potentially N^2 algorithm with a more efficient approach in the symbol table reader.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "clazy",
        "hash": "5ae29fffa06a25a5537ea6944b676b78575d9a57",
        "author": "Sergio Martins",
        "date": "2018-01-21T22:38:14+00:00",
        "message": "Minor performance optimization: do the cheapeast condition first",
        "modified_files_count": 1,
        "modified_files": [
            "src/AccessSpecifierManager.cpp"
        ],
        "github_commit_url": "https://github.com/KDE/clazy/commit/5ae29fffa06a25a5537ea6944b676b78575d9a57",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AccessSpecifierManager::qtAccessSpecifierType"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reorders conditions in an if-statement to evaluate the cheapest condition first, reducing unnecessary computations.",
            "The optimization strategy reorders conditional checks to evaluate the least expensive condition first, reducing unnecessary computations.",
            "The optimization strategy reorders conditions in an if-statement to evaluate the cheapest condition first, reducing unnecessary evaluations.",
            "The optimization strategy reorders conditions in an if-statement to evaluate the cheapest condition first, reducing unnecessary computations.",
            "The optimization strategy reorders conditional checks to evaluate the least expensive condition first, reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy reorders conditions in an if-statement to evaluate the cheapest condition first, reducing unnecessary computations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "psi",
        "hash": "724f04cf5b40599d7d9eff436f3c880df1302d0c",
        "author": "Rion",
        "date": "2013-05-04T14:17:56-07:00",
        "message": "Merge pull request #60 from liuch/master\n\ncode optimization in HistoryDlg::displayResult",
        "modified_files_count": 1,
        "modified_files": [
            "src/historydlg.cpp"
        ],
        "github_commit_url": "https://github.com/psi-im/psi/commit/724f04cf5b40599d7d9eff436f3c880df1302d0c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HistoryDlg::displayResult"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations or unnecessary operations within the `HistoryDlg::displayResult` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or unnecessary operations within the `HistoryDlg::displayResult` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or unnecessary operations within the `HistoryDlg::displayResult` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or unnecessary operations within the `HistoryDlg::displayResult` function to improve performance.",
            "The optimization strategy involved reducing redundant computations or unnecessary operations within the `HistoryDlg::displayResult` function to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations or unnecessary operations within the `HistoryDlg::displayResult` function to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "powertabeditor",
        "hash": "f03e1c4d075022ca89fee2a279e04df3a0109c41",
        "author": "Cameron White",
        "date": "2011-02-03T01:14:35+00:00",
        "message": "Whole rests are now used when creating the blank staves to replace guitar-ins.\n\nThis brings a nice performance improvement when loading files, since there's less memory allocation, and looks a lot cleaner visually.\n\ngit-svn-id: http://svn.powertabs.org/svn/ptedev/trunk@174 5b1460fe-822e-4aa1-ac1b-8a6412c92c8c",
        "modified_files_count": 1,
        "modified_files": [
            "source/powertabdocument/score.cpp"
        ],
        "github_commit_url": "https://github.com/powertab/powertabeditor/commit/f03e1c4d075022ca89fee2a279e04df3a0109c41",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Score::UpdateToVer2Structure"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing guitar-instrument staves with blank staves containing whole rests to reduce memory allocation during file loading.",
            "The optimization strategy involved replacing guitar-instrument placeholders with whole rests to reduce memory allocation during file loading.",
            "The optimization strategy involved replacing guitar-instrument placeholders with whole rests in blank staves to reduce memory allocation and improve visual clarity during file loading.",
            "The optimization strategy involved replacing guitar-instrument staves with blank staves containing whole rests to reduce memory allocation during file loading.",
            "The optimization strategy involved replacing guitar-instrument placeholders with whole rests to reduce memory allocation during file loading."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing guitar-instrument staves with blank staves containing whole rests to reduce memory allocation during file loading.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "canairio_firmware",
        "hash": "46194b4f5c2f266c59d9c38d7d7a29ad08042ab7",
        "author": "Hpsaturn",
        "date": "2022-02-24T10:49:44+01:00",
        "message": "changed the order of OTA loop for improve memory free flow",
        "modified_files_count": 1,
        "modified_files": [
            "src/main.cpp"
        ],
        "github_commit_url": "https://github.com/kike-canaries/canairio_firmware/commit/46194b4f5c2f266c59d9c38d7d7a29ad08042ab7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "loop"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reordering the OTA loop to improve memory management and free flow during execution.",
            "The optimization strategy involved reordering operations in the OTA loop to improve memory management and free flow.",
            "The optimization strategy involved reordering the OTA loop to improve memory management and free flow during execution.",
            "The optimization strategy involved reordering the OTA loop to improve memory management and free flow during execution.",
            "The optimization strategy involved reordering the OTA loop to improve memory management and free flow during execution."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reordering the OTA loop to improve memory management and free flow during execution.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tengine",
        "hash": "ff9004d0891974fed7dd22ef0eed0627b9277078",
        "author": "Weibin Yao(姚伟斌)",
        "date": "2013-07-28T08:18:17-07:00",
        "message": "Merge pull request #279 from chobits/master\n\nround robin: optimize loop in ngx_http_upstream_init_round_robin()",
        "modified_files_count": 1,
        "modified_files": [
            "src/http/ngx_http_upstream_round_robin.c"
        ],
        "github_commit_url": "https://github.com/alibaba/tengine/commit/ff9004d0891974fed7dd22ef0eed0627b9277078",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ngx_http_upstream_init_round_robin"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop in ngx_http_upstream_init_round_robin() to reduce redundant computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the loop in ngx_http_upstream_init_round_robin() to reduce redundant computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the loop in ngx_http_upstream_init_round_robin() to reduce redundant iterations and improve efficiency.",
            "The optimization strategy involved restructuring the loop in ngx_http_upstream_init_round_robin() to reduce redundant computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the loop in ngx_http_upstream_init_round_robin() to reduce redundant computations and improve iteration efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop in ngx_http_upstream_init_round_robin() to reduce redundant computations and improve iteration efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "suricata",
        "hash": "fd4ca53eb7110a2ab0f24d08902d5c2a04f00a8c",
        "author": "Victor Julien",
        "date": "2024-01-08T20:23:28+01:00",
        "message": "app-layer: micro optimization for AppProtoEquals\n\nAdd most common condition first.",
        "modified_files_count": 1,
        "modified_files": [
            "src/app-layer-protos.h"
        ],
        "github_commit_url": "https://github.com/OISF/suricata/commit/fd4ca53eb7110a2ab0f24d08902d5c2a04f00a8c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AppProtoEquals"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reorders conditions in the AppProtoEquals function to evaluate the most common case first, reducing average execution time.",
            "The optimization strategy reorders conditions in the AppProtoEquals function to evaluate the most common case first, reducing average execution time.",
            "The optimization strategy reorders conditions in the `AppProtoEquals` function to check the most common case first, reducing unnecessary comparisons.",
            "The optimization strategy reorders conditions in the `AppProtoEquals` function to check the most common case first, reducing average execution time.",
            "The optimization strategy reorders conditions in the AppProtoEquals function to evaluate the most common case first, reducing average execution time."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy reorders conditions in the AppProtoEquals function to evaluate the most common case first, reducing average execution time.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "dsc",
        "hash": "a1dcdf189ff0c19f13ebf519aed2376c708a363b",
        "author": "Klaus Darilion",
        "date": "2016-05-02T15:33:22+02:00",
        "message": "Avoid the checks for newer .dat files, this may have performance impacts.",
        "modified_files_count": 1,
        "modified_files": [
            "src/country_index.c"
        ],
        "github_commit_url": "https://github.com/DNS-OARC/dsc/commit/a1dcdf189ff0c19f13ebf519aed2376c708a363b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "country_indexer_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes checks for newer .dat files to reduce unnecessary file system operations.",
            "The optimization strategy avoids unnecessary checks for newer .dat files to reduce computational overhead.",
            "The optimization strategy avoids unnecessary checks for newer .dat files to reduce computational overhead.",
            "The optimization strategy removes checks for newer .dat files to reduce unnecessary file system operations.",
            "The optimization strategy avoids unnecessary checks for newer .dat files to reduce computational overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary checks for newer .dat files to reduce computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_google_wahoo",
        "hash": "440a57717bcc2a86a5e9800bce62e14d8115a001",
        "author": "Daniel Kurtz",
        "date": "2016-03-31T11:31:10-07:00",
        "message": "cpufreq: interactive: only apply interactive boost when enabled\n\nOnly apply the interactive boost when the interactive governor is\nenabled.  This seems like the right thing to do.\n\nThis was originally reviewed on\n\thttps://chromium-review.googlesource.com/273501\n\nChange-Id: I5f4a7320683eada099f9a4253e3d6b0f03057fe8\nSigned-off-by: Daniel Kurtz <djkurtz@chromium.org>\nReviewed-by: Douglas Anderson <dianders@chromium.org>\nSigned-off-by: Dmitry Torokhov <dtor@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/cpufreq/cpufreq_interactive.c"
        ],
        "github_commit_url": "https://github.com/kerneltoast/android_kernel_google_wahoo/commit/440a57717bcc2a86a5e9800bce62e14d8115a001",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cpufreq_interactive_boost"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary application of an interactive boost by checking if the interactive governor is enabled before applying it.",
            "The optimization strategy avoids applying an interactive boost when the interactive governor is not enabled, reducing unnecessary computations.",
            "The optimization strategy avoids applying an interactive boost when the interactive governor is not enabled, reducing unnecessary computations.",
            "The optimization strategy avoids applying an interactive boost when the interactive governor is not enabled, reducing unnecessary operations.",
            "The optimization strategy avoids applying an interactive boost when the interactive governor is not enabled, reducing unnecessary operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids applying an interactive boost when the interactive governor is not enabled, reducing unnecessary operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mutter",
        "hash": "d8696c17bef80617fbe53ac412959a77d8e24e7d",
        "author": "Owen W. Taylor",
        "date": "2013-02-13T09:48:26-05:00",
        "message": "Use clutter_stage_set_sync_delay()\n\nUsing a \"sync delay\" where we wait for 2 ms after the vblank before\nstarting to draw the next frame provides for much more predictable\nlatency for applications. An application can know that if it completes\na frame any time between 8ms before the vblank to the vblank,\nit will reliably be drawn on the following vblank period, rather than\nhaving an unpredictable latency depending on whether the compositor\nis currently busy drawing a frame or not.\n\nhttps://bugzilla.gnome.org/show_bug.cgi?id=685463",
        "modified_files_count": 1,
        "modified_files": [
            "src/compositor/compositor.c"
        ],
        "github_commit_url": "https://github.com/GNOME/mutter/commit/d8696c17bef80617fbe53ac412959a77d8e24e7d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "meta_compositor_manage_screen"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization introduces a \"sync delay\" to improve latency predictability by waiting 2 ms after vblank before starting to draw the next frame.",
            "The optimization introduces a 2ms sync delay after vblank to improve frame drawing predictability by aligning application frame completion with compositor rendering cycles.",
            "The optimization introduces a 2 ms sync delay after vblank to reduce latency unpredictability for frame rendering.",
            "The optimization introduces a \"sync delay\" to improve latency predictability by waiting 2 ms after vblank before starting to draw the next frame.",
            "The optimization introduces a \"sync delay\" to improve latency predictability by waiting 2 ms after vblank before starting to draw the next frame."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization introduces a \"sync delay\" to improve latency predictability by waiting 2 ms after vblank before starting to draw the next frame.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ffmpeg",
        "hash": "8ba694548782c1821ab119c18fe02360a81c6768",
        "author": "Michael Niedermayer",
        "date": "2014-09-29T12:56:45+02:00",
        "message": "avcodec/utils: Fix off by 1 error causing unneeded allocation in ff_fast_malloc()\n\nReviewed-by: Benoit Fouet <benoit.fouet@free.fr>\nSigned-off-by: Michael Niedermayer <michaelni@gmx.at>",
        "modified_files_count": 1,
        "modified_files": [
            "libavcodec/utils.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/8ba694548782c1821ab119c18fe02360a81c6768",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ff_fast_malloc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization fixes an off-by-one error in memory allocation logic to prevent unnecessary large allocations.",
            "The optimization fixes an off-by-one error in memory allocation logic to prevent unnecessary large allocations in ff_fast_malloc().",
            "The optimization fixes an off-by-one error in memory allocation logic to prevent unnecessary allocations in ff_fast_malloc().",
            "The optimization fixes an off-by-one error in memory allocation logic to prevent unnecessary allocations in ff_fast_malloc().",
            "The optimization fixes an off-by-one error in memory allocation logic to prevent unnecessary large allocations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization fixes an off-by-one error in memory allocation logic to prevent unnecessary large allocations in ff_fast_malloc().",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "7ab345a8973017c89a1be87b6c8722d1fee1fd95",
        "author": "Muchun Song",
        "date": "2021-04-30T11:20:38-07:00",
        "message": "mm: memcontrol: change ug->dummy_page only if memcg changed\n\nJust like assignment to ug->memcg, we only need to update ug->dummy_page\nif memcg changed.  So move it to there.  This is a very small\noptimization.\n\nLink: https://lkml.kernel.org/r/20210319163821.20704-5-songmuchun@bytedance.com\nSigned-off-by: Muchun Song <songmuchun@bytedance.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nReviewed-by: Shakeel Butt <shakeelb@google.com>\nCc: Michal Hocko <mhocko@kernel.org>\nCc: Roman Gushchin <guro@fb.com>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nCc: Xiongchun Duan <duanxiongchun@bytedance.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/memcontrol.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/7ab345a8973017c89a1be87b6c8722d1fee1fd95",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "uncharge_page"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary updates to `ug->dummy_page` by only modifying it when `memcg` changes, reducing redundant operations.",
            "The optimization avoids unnecessary updates to `ug->dummy_page` by performing the update only when `memcg` changes, reducing redundant operations.",
            "The optimization avoids unnecessary updates to `ug->dummy_page` by only modifying it when `memcg` changes, reducing redundant operations.",
            "The optimization avoids unnecessary updates to `ug->dummy_page` by performing the update only when `memcg` changes, reducing redundant operations.",
            "The optimization avoids unnecessary updates to `ug->dummy_page` by performing the update only when `memcg` changes, reducing redundant operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary updates to `ug->dummy_page` by performing the update only when `memcg` changes, reducing redundant operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "server",
        "hash": "9f7c9aa7d5eed311e3d40c8f7d1a55abb7d4566c",
        "author": "unknown",
        "date": "2005-02-03T23:56:13+01:00",
        "message": "ndb - sol9x86: cc -xO3: fix optimizer error.\n\n\nndb/src/common/util/NdbSqlUtil.cpp:\n  sol9x86: cc -xO3: fix optimizer error.\n  Note: same expression remains in Field_newdate::val_int().",
        "modified_files_count": 1,
        "modified_files": [
            "ndb/src/common/util/NdbSqlUtil.cpp"
        ],
        "github_commit_url": "https://github.com/MariaDB/server/commit/9f7c9aa7d5eed311e3d40c8f7d1a55abb7d4566c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "NdbSqlUtil::cmpDate"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved modifying the code to prevent a compiler optimizer error under specific build conditions.",
            "The optimization strategy involved modifying the code to prevent a compiler optimizer error under specific build conditions.",
            "The optimization strategy involved modifying the code to prevent a compiler optimizer error under specific build conditions.",
            "The optimization strategy involved modifying the code to prevent a compiler optimizer error under specific build conditions.",
            "The optimization strategy involved modifying the code to prevent a compiler optimizer error under specific build conditions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved modifying the code to prevent a compiler optimizer error under specific build conditions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "q5Go",
        "hash": "a21004eee58137f194374850dd36cd47375f49e8",
        "author": "Bernd Schmidt",
        "date": "2019-03-25T13:09:16+01:00",
        "message": "Improve order of walk_tree traversal\n\nMake sure the main branch is visited first, even at the cost of walking it\ntwice to avoid recursion.",
        "modified_files_count": 1,
        "modified_files": [
            "src/gogame.cc"
        ],
        "github_commit_url": "https://github.com/bernds/q5Go/commit/a21004eee58137f194374850dd36cd47375f49e8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "game_state::walk_tree"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reorders the traversal logic to prioritize visiting the main branch first, even if it results in walking it twice, to avoid recursion overhead.",
            "The optimization strategy reorders the traversal logic to prioritize visiting the main branch first, even if it results in walking it twice, to avoid recursion overhead.",
            "The optimization strategy reorders the traversal logic to prioritize visiting the main branch first, even if it results in walking it twice, to avoid recursion overhead.",
            "The optimization strategy reorders the traversal logic to prioritize visiting the main branch first, even if it results in walking it twice, to avoid recursion overhead.",
            "The optimization strategy reorders the traversal of branches in a tree-walking function to prioritize the main branch, reducing recursion depth at the cost of potentially visiting it twice."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reorders the traversal logic to prioritize visiting the main branch first, even if it results in walking it twice, to avoid recursion overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_xiaomi_sdm845",
        "hash": "4b7c09a5f74ad25dd2e3ee6d43732f9a0e0c1ff3",
        "author": "Josef Bacik",
        "date": "2018-11-10T07:42:52-08:00",
        "message": "nbd: only set MSG_MORE when we have more to send\n\n[ Upstream commit d61b7f972dab2a7d187c38254845546dfc8eed85 ]\n\nA user noticed that write performance was horrible over loopback and we\ntraced it to an inversion of when we need to set MSG_MORE.  It should be\nset when we have more bvec's to send, not when we are on the last bvec.\nThis patch made the test go from 20 iops to 78k iops.\n\nSigned-off-by: Josef Bacik <jbacik@fb.com>\nFixes: 429a787be679 (\"nbd: fix use-after-free of rq/bio in the xmit path\")\nSigned-off-by: Jens Axboe <axboe@fb.com>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/block/nbd.c"
        ],
        "github_commit_url": "https://github.com/LineageOS/android_kernel_xiaomi_sdm845/commit/4b7c09a5f74ad25dd2e3ee6d43732f9a0e0c1ff3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nbd_send_cmd"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved correcting the logic for setting the MSG_MORE flag to accurately reflect when more data needs to be sent, thereby improving write performance.",
            "The optimization strategy involved correcting the logic for setting the MSG_MORE flag to ensure it is only set when there are additional data vectors (bvecs) to send, avoiding unnecessary performance overhead.",
            "The optimization strategy involved correcting the logic for setting the MSG_MORE flag to accurately reflect when more data needs to be sent, thereby improving write performance.",
            "The optimization strategy involved correcting the logic for setting the MSG_MORE flag to accurately reflect when more data needs to be sent, thereby improving write performance.",
            "The optimization strategy involved correcting the logic for setting the MSG_MORE flag to ensure it is only set when there are additional data vectors (bvecs) to send, avoiding unnecessary performance overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved correcting the logic for setting the MSG_MORE flag to accurately reflect when more data needs to be sent, thereby improving write performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "quda",
        "hash": "fb643c9b0f764534dac34833c1dfa9a86684ec41",
        "author": "Mathias Wagner",
        "date": "2016-02-05T10:55:17+01:00",
        "message": "Do not increase n_calls while performing the initial tuning",
        "modified_files_count": 1,
        "modified_files": [
            "lib/tune.cpp"
        ],
        "github_commit_url": "https://github.com/lattice/quda/commit/fb643c9b0f764534dac34833c1dfa9a86684ec41",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tuneLaunch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids incrementing the `n_calls` counter during the initial tuning phase to prevent unnecessary overhead.",
            "The optimization avoids incrementing the `n_calls` counter during the initial tuning phase to prevent unnecessary overhead.",
            "The optimization avoids incrementing the `n_calls` counter during the initial tuning phase to prevent unnecessary overhead.",
            "The optimization avoids incrementing the `n_calls` counter during the initial tuning phase to prevent unnecessary overhead.",
            "The optimization avoids incrementing the `n_calls` counter during the initial tuning phase to prevent unnecessary overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids incrementing the `n_calls` counter during the initial tuning phase to prevent unnecessary overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "wfmash",
        "hash": "0e123bdb5ad62d3ea82a9920ba2b7929fad97fe2",
        "author": "Erik Garrison (aider)",
        "date": "2024-11-07T14:05:13-06:00",
        "message": "feat: Add parallel index building to improve performance",
        "modified_files_count": 1,
        "modified_files": [
            "src/map/include/winSketch.hpp"
        ],
        "github_commit_url": "https://github.com/waveygang/wfmash/commit/0e123bdb5ad62d3ea82a9920ba2b7929fad97fe2",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adding parallel index building to improve performance by leveraging concurrent processing.",
            "The optimization strategy involved adding parallel index building to improve performance by leveraging concurrent processing.",
            "The optimization strategy involved adding parallel index building to improve performance by leveraging concurrent processing.",
            "The optimization strategy involved adding parallel index building to improve performance by leveraging concurrent processing.",
            "The optimization strategy involved adding parallel index building to improve performance by leveraging concurrent processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adding parallel index building to improve performance by leveraging concurrent processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Cocos2d-Lua-Community",
        "hash": "e073674f2c5ef23d4f88afb8d36e5e8886cde1c5",
        "author": "u0u0",
        "date": "2021-07-23T18:06:09+08:00",
        "message": "optimized plist loading",
        "modified_files_count": 1,
        "modified_files": [
            "cocos/2d/CCSpriteFrameCache.cpp"
        ],
        "github_commit_url": "https://github.com/u0u0/Cocos2d-Lua-Community/commit/e073674f2c5ef23d4f88afb8d36e5e8886cde1c5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SpriteFrameCache::addSpriteFramesWithFile"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant file parsing operations during the loading of sprite frame plists by caching parsed data.",
            "The optimization strategy involved reducing redundant file parsing operations during the loading of sprite frame data.",
            "The optimization strategy involved reducing redundant file parsing operations during the loading of sprite frame plists by caching parsed data.",
            "The optimization strategy involved reducing redundant file parsing operations during the loading of sprite frame plists by caching parsed data.",
            "The optimization strategy involved reducing redundant file parsing operations during the loading of sprite frame data."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant file parsing operations during the loading of sprite frame plists by caching parsed data.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow",
        "hash": "d75eb4eed1020c37d5d5572a70c58194f00c0f74",
        "author": "Frederic Bastien",
        "date": "2020-03-04T12:13:41-08:00",
        "message": "Remove a condition that is optimized by LLVM and doesn't remove vectorization.",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc"
        ],
        "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/d75eb4eed1020c37d5d5572a70c58194f00c0f74",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "IrEmitterUnnested::EmitTile"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes a redundant condition that is already handled by LLVM, thereby improving performance without affecting functionality.",
            "The optimization removes a redundant condition that is already handled by LLVM, thereby improving performance without affecting functionality.",
            "The optimization removes a redundant condition that is already handled by LLVM, thereby improving performance without affecting functionality.",
            "The optimization removes a redundant condition that is already handled by LLVM, thereby improving performance without affecting functionality.",
            "The optimization removes a redundant condition that is already handled by LLVM, thereby improving performance without affecting functionality."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization removes a redundant condition that is already handled by LLVM, thereby improving performance without affecting functionality.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "mongoose",
        "hash": "4e5e186784fa234a2f1b4b3a2fffe2eb4d92553a",
        "author": "Sergio R. Caprile",
        "date": "2023-06-06T10:44:18-03:00",
        "message": "speed up MQTT tests",
        "modified_files_count": 1,
        "modified_files": [
            "test/unit_test.c"
        ],
        "github_commit_url": "https://github.com/cesanta/mongoose/commit/4e5e186784fa234a2f1b4b3a2fffe2eb4d92553a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "test_mqtt_ver"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of iterations in a loop to decrease execution time.",
            "The optimization strategy involved reducing the number of iterations in a loop to decrease execution time for MQTT tests.",
            "The optimization strategy involved reducing the number of iterations in a loop to decrease execution time.",
            "The optimization strategy involved reducing the number of iterations in a loop to decrease execution time.",
            "The optimization strategy involved reducing the number of iterations in a loop to decrease execution time for MQTT tests."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of iterations in a loop to decrease execution time.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gemrb",
        "hash": "082aa141b08784f4f05a70d3dbf54a645967115d",
        "author": "Brad Allred",
        "date": "2022-09-08T18:00:27-06:00",
        "message": "Scriptable: take an optimization pass at DoStep\n\nI dont expect it to amount to much on a release build, but possibly debug builds can benefit\n\nwe were spending a lot of time inside NormalizeDeltas and we dont need to call it every time\n\n#1692",
        "modified_files_count": 1,
        "modified_files": [
            "gemrb/core/Scriptable/Scriptable.cpp"
        ],
        "github_commit_url": "https://github.com/gemrb/gemrb/commit/082aa141b08784f4f05a70d3dbf54a645967115d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Movable::DoStep"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves reducing the frequency of calls to a computationally expensive function by invoking it only when necessary.",
            "The optimization strategy involves reducing the frequency of calls to a computationally expensive function by avoiding unnecessary invocations within a loop.",
            "The optimization strategy avoids redundant calls to `NormalizeDeltas` by invoking it only when necessary within the `DoStep` function.",
            "The optimization strategy involved reducing the frequency of calls to a computationally expensive function by invoking it only when necessary.",
            "The optimization strategy avoids redundant calls to a normalization function by invoking it only when necessary within the `DoStep` method."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reducing the frequency of calls to a computationally expensive function by invoking it only when necessary.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pcre2",
        "hash": "1381c3fe286e46eb43b2f8a10091adc9fb7469fc",
        "author": "Zoltán Herczeg",
        "date": "2017-06-08T12:07:05+00:00",
        "message": "Improve char range match in JIT.",
        "modified_files_count": 1,
        "modified_files": [
            "src/pcre2_jit_compile.c"
        ],
        "github_commit_url": "https://github.com/PCRE2Project/pcre2/commit/1381c3fe286e46eb43b2f8a10091adc9fb7469fc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "optimize_class_chars"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the character range matching logic in JIT to reduce unnecessary comparisons and improve efficiency.",
            "The optimization strategy involved restructuring the character range matching logic in the JIT compiler to reduce unnecessary checks and improve efficiency.",
            "The optimization strategy involved restructuring character range matching in JIT to reduce unnecessary checks and improve efficiency.",
            "The optimization strategy involved restructuring the character range matching logic in the JIT compiler to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the character range matching logic in the JIT compiler to reduce unnecessary checks and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the character range matching logic in the JIT compiler to reduce unnecessary checks and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "angle",
        "hash": "2611f98b369358fe40134ff9fc779bca695c2361",
        "author": "Charlie Lao",
        "date": "2020-06-02T18:07:54+00:00",
        "message": "Vulkan: Add IMAGE_USE_STORAGE bit only if necessary.\n\nThe VK_IMAGE_USAGE_STORAGE_BIT has negative performance impact. Right\nnow we needed for overlay widgets. This CL will only add the bit if we\nactually have widget enabled.\n\nBug: b/157774833\nChange-Id: I3027df886c9b34ccfd667152fa4fb090dfadb45b\nReviewed-on: https://chromium-review.googlesource.com/c/angle/angle/+/2225810\nReviewed-by: Shahbaz Youssefi <syoussefi@chromium.org>\nReviewed-by: Jamie Madill <jmadill@chromium.org>\nCommit-Queue: Charlie Lao <cclao@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/libANGLE/renderer/vulkan/SurfaceVk.cpp"
        ],
        "github_commit_url": "https://github.com/google/angle/commit/2611f98b369358fe40134ff9fc779bca695c2361",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WindowSurfaceVk::createSwapChain"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves conditionally adding the VK_IMAGE_USAGE_STORAGE_BIT only when necessary to avoid unnecessary performance overhead.",
            "The optimization strategy involves conditionally adding the VK_IMAGE_USAGE_STORAGE_BIT flag only when necessary to avoid unnecessary performance overhead.",
            "The optimization strategy involves conditionally adding a performance-impacting Vulkan image usage flag only when necessary, avoiding unnecessary overhead.",
            "The optimization strategy involves conditionally adding a performance-impacting bit (VK_IMAGE_USAGE_STORAGE_BIT) only when necessary, specifically when overlay widgets are enabled.",
            "The optimization strategy involves conditionally adding a performance-impacting Vulkan image usage flag only when necessary, specifically when overlay widgets are enabled."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves conditionally adding the VK_IMAGE_USAGE_STORAGE_BIT only when necessary to avoid unnecessary performance overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cmssw",
        "hash": "576e130cdc8e002350d5f28c53396003296e4017",
        "author": "Christopher Jones",
        "date": "2006-08-08T00:40:51+00:00",
        "message": "use 'copySlotsTo' rather than connectTo for the ActivityRegistry in order to improve performance",
        "modified_files_count": 1,
        "modified_files": [
            "FWCore/Framework/src/EventProcessor.cc"
        ],
        "github_commit_url": "https://github.com/cms-sw/cmssw/commit/576e130cdc8e002350d5f28c53396003296e4017",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "schedule_"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a potentially expensive connection operation with a more efficient slot copying mechanism to reduce overhead.",
            "The optimization strategy replaced a potentially expensive connection operation with a more efficient slot copying mechanism for the ActivityRegistry.",
            "The optimization strategy replaced a potentially expensive connection operation with a more efficient slot copying mechanism to reduce overhead in event processing.",
            "The optimization strategy replaced a potentially costly connection method (`connectTo`) with a more efficient slot copying method (`copySlotsTo`) for the ActivityRegistry to reduce overhead.",
            "The optimization strategy replaced a potentially expensive connection operation with a more efficient slot copying mechanism to reduce overhead in event processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a potentially expensive connection operation with a more efficient slot copying mechanism to reduce overhead in event processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kernel_xiaomi_sm8250",
        "hash": "66a013879cdb304c214e94a49d2129363f29e174",
        "author": "Li Xinhai",
        "date": "2021-03-07T12:18:55+01:00",
        "message": "mm/hugetlb.c: fix unnecessary address expansion of pmd sharing\n\ncommit a1ba9da8f0f9a37d900ff7eff66482cf7de8015e upstream.\n\nThe current code would unnecessarily expand the address range.  Consider\none example, (start, end) = (1G-2M, 3G+2M), and (vm_start, vm_end) =\n(1G-4M, 3G+4M), the expected adjustment should be keep (1G-2M, 3G+2M)\nwithout expand.  But the current result will be (1G-4M, 3G+4M).  Actually,\nthe range (1G-4M, 1G) and (3G, 3G+4M) would never been involved in pmd\nsharing.\n\nAfter this patch, we will check that the vma span at least one PUD aligned\nsize and the start,end range overlap the aligned range of vma.\n\nWith above example, the aligned vma range is (1G, 3G), so if (start, end)\nrange is within (1G-4M, 1G), or within (3G, 3G+4M), then no adjustment to\nboth start and end.  Otherwise, we will have chance to adjust start\ndownwards or end upwards without exceeding (vm_start, vm_end).\n\nMike:\n\n: The 'adjusted range' is used for calls to mmu notifiers and cache(tlb)\n: flushing.  Since the current code unnecessarily expands the range in some\n: cases, more entries than necessary would be flushed.  This would/could\n: result in performance degradation.  However, this is highly dependent on\n: the user runtime.  Is there a combination of vma layout and calls to\n: actually hit this issue?  If the issue is hit, will those entries\n: unnecessarily flushed be used again and need to be unnecessarily reloaded?\n\nLink: https://lkml.kernel.org/r/20210104081631.2921415-1-lixinhai.lxh@gmail.com\nFixes: 75802ca66354 (\"mm/hugetlb: fix calculation of adjust_range_if_pmd_sharing_possible\")\nSigned-off-by: Li Xinhai <lixinhai.lxh@gmail.com>\nSuggested-by: Mike Kravetz <mike.kravetz@oracle.com>\nReviewed-by: Mike Kravetz <mike.kravetz@oracle.com>\nCc: Peter Xu <peterx@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/hugetlb.c"
        ],
        "github_commit_url": "https://github.com/EmanuelCN/kernel_xiaomi_sm8250/commit/66a013879cdb304c214e94a49d2129363f29e174",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "adjust_range_if_pmd_sharing_possible"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary expansion of address ranges for PMD sharing by aligning the range adjustment logic with PUD boundaries, reducing excessive cache flushing and MMU notifier calls.",
            "The optimization strategy avoids unnecessary expansion of address ranges for PMD sharing by aligning the range adjustment logic with PUD boundaries, reducing excessive cache flushing and MMU notifier calls.",
            "The optimization strategy avoids unnecessary expansion of address ranges for PMD sharing by aligning the range adjustment logic with PUD boundaries, reducing excessive cache flushing and MMU notifier calls.",
            "The optimization strategy avoids unnecessary expansion of address ranges for PMD sharing by aligning the range adjustment logic with PUD boundaries, reducing excessive cache flushing and MMU notifier calls.",
            "The optimization strategy avoids unnecessary expansion of address ranges for PMD sharing by aligning the range adjustment logic with PUD boundaries, reducing excessive cache flushing and MMU notifier calls."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary expansion of address ranges for PMD sharing by aligning the range adjustment logic with PUD boundaries, reducing excessive cache flushing and MMU notifier calls.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "fbd02630c6e3c60feecc4688f5f98b015d264516",
        "author": "Jesper Dangaard Brouer",
        "date": "2015-09-04T16:54:41-07:00",
        "message": "slub: initial bulk free implementation\n\nThis implements SLUB specific kmem_cache_free_bulk().  SLUB allocator now\nboth have bulk alloc and free implemented.\n\nChoose to reenable local IRQs while calling slowpath __slab_free().  In\nworst case, where all objects hit slowpath call, the performance should\nstill be faster than fallback function __kmem_cache_free_bulk(), because\nlocal_irq_{disable+enable} is very fast (7-cycles), while the fallback\ninvokes this_cpu_cmpxchg() which is slightly slower (9-cycles).\nNitpicking, this should be faster for N>=4, due to the entry cost of\nlocal_irq_{disable+enable}.\n\nDo notice that the save+restore variant is very expensive, this is key to\nwhy this optimization works.\n\nCPU: i7-4790K CPU @ 4.00GHz\n * local_irq_{disable,enable}:  7 cycles(tsc) - 1.821 ns\n * local_irq_{save,restore}  : 37 cycles(tsc) - 9.443 ns\n\nMeasurements on CPU CPU i7-4790K @ 4.00GHz\nBaseline normal fastpath (alloc+free cost): 43 cycles(tsc) 10.834 ns\n\nBulk- fallback                   - this-patch\n  1 -  58 cycles(tsc) 14.542 ns  -  43 cycles(tsc) 10.811 ns  improved 25.9%\n  2 -  50 cycles(tsc) 12.659 ns  -  27 cycles(tsc)  6.867 ns  improved 46.0%\n  3 -  48 cycles(tsc) 12.168 ns  -  21 cycles(tsc)  5.496 ns  improved 56.2%\n  4 -  47 cycles(tsc) 11.987 ns  -  24 cycles(tsc)  6.038 ns  improved 48.9%\n  8 -  46 cycles(tsc) 11.518 ns  -  17 cycles(tsc)  4.280 ns  improved 63.0%\n 16 -  45 cycles(tsc) 11.366 ns  -  17 cycles(tsc)  4.483 ns  improved 62.2%\n 30 -  45 cycles(tsc) 11.433 ns  -  18 cycles(tsc)  4.531 ns  improved 60.0%\n 32 -  75 cycles(tsc) 18.983 ns  -  58 cycles(tsc) 14.586 ns  improved 22.7%\n 34 -  71 cycles(tsc) 17.940 ns  -  53 cycles(tsc) 13.391 ns  improved 25.4%\n 48 -  80 cycles(tsc) 20.077 ns  -  65 cycles(tsc) 16.268 ns  improved 18.8%\n 64 -  71 cycles(tsc) 17.799 ns  -  53 cycles(tsc) 13.440 ns  improved 25.4%\n128 -  91 cycles(tsc) 22.980 ns  -  79 cycles(tsc) 19.899 ns  improved 13.2%\n158 - 100 cycles(tsc) 25.241 ns  -  90 cycles(tsc) 22.732 ns  improved 10.0%\n250 - 102 cycles(tsc) 25.583 ns  -  95 cycles(tsc) 23.916 ns  improved  6.9%\n\nSigned-off-by: Jesper Dangaard Brouer <brouer@redhat.com>\nCc: Christoph Lameter <cl@linux.com>\nCc: Pekka Enberg <penberg@kernel.org>\nCc: David Rientjes <rientjes@google.com>\nCc: Joonsoo Kim <iamjoonsoo.kim@lge.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/slub.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/fbd02630c6e3c60feecc4688f5f98b015d264516",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "kmem_cache_free_bulk"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involved replacing a slower fallback function with a faster implementation by reenabling local IRQs during slowpath calls to reduce overhead in bulk-free operations.",
            "The optimization strategy involves reenabling local IRQs during slowpath calls in bulk freeing to reduce overhead compared to the fallback function.",
            "The optimization strategy involves reenabling local IRQs during slowpath calls in bulk freeing to reduce overhead compared to the fallback function.",
            "The optimization strategy reduces overhead by reenabling local IRQs during slowpath calls in bulk freeing, leveraging faster local_irq_{disable+enable} over more expensive operations.",
            "The optimization strategy reduces overhead by reenabling local IRQs during slowpath calls in bulk freeing, leveraging faster local_irq_{disable+enable} over more expensive operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reenabling local IRQs during slowpath calls in bulk freeing to reduce overhead compared to the fallback function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tcl",
        "hash": "5db8831fb0c3a4a23f76522925253fc64e07ff9d",
        "author": "dgp",
        "date": "2014-05-16T19:11:49+00:00",
        "message": "Improved use of EOF state to avoid worthless allocations.",
        "modified_files_count": 1,
        "modified_files": [
            "generic/tclIO.c"
        ],
        "github_commit_url": "https://github.com/tcltk/tcl/commit/5db8831fb0c3a4a23f76522925253fc64e07ff9d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetInput"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary memory allocations by leveraging the EOF state to prevent worthless buffer allocations during input operations.",
            "The optimization avoids unnecessary memory allocations by leveraging the EOF state to prevent worthless buffer allocations when no more data is available.",
            "The optimization avoids unnecessary memory allocations by leveraging the EOF state more effectively during input processing.",
            "The optimization avoids unnecessary memory allocations by leveraging the EOF state more effectively.",
            "The optimization avoids unnecessary memory allocations by leveraging the EOF state more effectively during input handling."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary memory allocations by leveraging the EOF state to prevent worthless buffer allocations during input operations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "be0e1e21ef707be4d16ea6a96ac9997463e4b8d2",
        "author": "Paul E. McKenney",
        "date": "2011-07-19T21:38:53-07:00",
        "message": "rcu: Streamline code produced by __rcu_read_unlock()\n\nGiven some common flag combinations, particularly -Os, gcc will inline\nrcu_read_unlock_special() despite its being in an unlikely() clause.\nUse noinline to prohibit this misoptimization.\n\nIn addition, move the second barrier() in __rcu_read_unlock() so that\nit is not on the common-case code path.  This will allow the compiler to\ngenerate better code for the common-case path through __rcu_read_unlock().\n\nSuggested-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>\nAcked-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/rcutree_plugin.h"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/be0e1e21ef707be4d16ea6a96ac9997463e4b8d2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rcu_read_unlock"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involves preventing the inlining of a function and repositioning a barrier to improve compiler code generation for the common execution path.",
            "The optimization strategy involves preventing the inlining of a function and repositioning a memory barrier to improve compiler-generated code for the common execution path.",
            "The optimization strategy involves preventing the inlining of a function and repositioning a memory barrier to improve compiler-generated code for the common execution path.",
            "The optimization strategy involves preventing the inlining of a function within an unlikely code path and repositioning a memory barrier to improve compiler-generated code for the common execution path.",
            "The optimization strategy involves preventing the inlining of a function and repositioning a memory barrier to improve compiler-generated code for the common execution path."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves preventing the inlining of a function and repositioning a memory barrier to improve compiler-generated code for the common execution path.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "02d2e8fcb48f1a9e2b435ccc75e3e2e95982550d",
        "author": "William Wu",
        "date": "2021-06-16T18:13:14+08:00",
        "message": "usb: gadget: uvc: allow zero bytesused for rockchip uvc\n\nFor rockchip platforms, the userspace uvc application use\nbytesused == 0 as a way to indicate that the data is all\nzero and unused. In that case, the uvc driver should use\nthe allow_zero_bytesused flag to keep bytesused 0 rather\nthan use the buf actual size instead. This can help to\npreview 1080P@MJPG faster.\n\nChange-Id: Ic4d561f18e85d759b5a2405db4f6fb48533e1781\nSigned-off-by: William Wu <william.wu@rock-chips.com>\nSigned-off-by: Frank Wang <frank.wang@rock-chips.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/usb/gadget/function/uvc_queue.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/02d2e8fcb48f1a9e2b435ccc75e3e2e95982550d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "uvcg_queue_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization allows zero bytesused for Rockchip UVC to avoid unnecessary data processing, improving performance for 1080P@MJPG preview.",
            "The optimization allows zero bytesused for Rockchip UVC to avoid unnecessary data processing, improving performance for 1080P@MJPG preview.",
            "The optimization allows zero bytesused for Rockchip UVC to avoid unnecessary data processing, improving performance for 1080P@MJPG preview.",
            "The optimization allows zero bytesused for Rockchip UVC to avoid unnecessary data processing, improving performance for 1080P@MJPG preview.",
            "The optimization allows zero bytesused for Rockchip UVC to avoid unnecessary data processing, improving performance for 1080P@MJPG preview."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization allows zero bytesused for Rockchip UVC to avoid unnecessary data processing, improving performance for 1080P@MJPG preview.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "selinux-kernel",
        "hash": "24436a540d16ca6a523b8e5441180001c31b6b35",
        "author": "Jonathan Marek",
        "date": "2024-10-14T13:16:17-07:00",
        "message": "drm/msm/dsi: improve/fix dsc pclk calculation\n\ndrm_mode_vrefresh() can introduce a large rounding error, avoid it.\n\nFixes: 7c9e4a554d4a (\"drm/msm/dsi: Reduce pclk rate for compression\")\nSigned-off-by: Jonathan Marek <jonathan@marek.ca>\nReviewed-by: Dmitry Baryshkov <dmitry.baryshkov@linaro.org>\nReviewed-by: Abhinav Kumar <quic_abhinavk@quicinc.com>\nPatchwork: https://patchwork.freedesktop.org/patch/618432/\nLink: https://lore.kernel.org/r/20241007050157.26855-1-jonathan@marek.ca\nSigned-off-by: Abhinav Kumar <quic_abhinavk@quicinc.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/msm/dsi/dsi_host.c"
        ],
        "github_commit_url": "https://github.com/SELinuxProject/selinux-kernel/commit/24436a540d16ca6a523b8e5441180001c31b6b35",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "parameters"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids a large rounding error in the pclk calculation by replacing the use of `drm_mode_vrefresh()` with a more precise method.",
            "The optimization strategy avoids a large rounding error in the pclk calculation by replacing the use of drm_mode_vrefresh() with a more precise method.",
            "The optimization avoids a large rounding error in the pclk calculation by replacing the use of drm_mode_vrefresh() with a more precise method.",
            "The optimization avoids a large rounding error in the pclk calculation by replacing the use of drm_mode_vrefresh() with a more precise method.",
            "The optimization avoids a large rounding error in the pclk calculation by replacing the use of `drm_mode_vrefresh()` with a more precise method."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids a large rounding error in the pclk calculation by replacing the use of drm_mode_vrefresh() with a more precise method.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qtbase",
        "hash": "0a5a41d9a4f33652f3a0be766b6b9a486075325b",
        "author": "Marc Mutz",
        "date": "2014-09-12T10:00:10+02:00",
        "message": "QImageReader: use qEnvironmentVariableIsEmpty()\n\nIt doesn't allocate memory, so cannot throw and is a lot faster\nthan qgetenv().\n\nChange-Id: I92805767b55adce478a4bf8eb1cbafaa544f96aa\nReviewed-by: Jędrzej Nowacki <jedrzej.nowacki@digia.com>\nReviewed-by: Gunnar Sletta <gunnar@sletta.org>",
        "modified_files_count": 1,
        "modified_files": [
            "src/gui/image/qimagereader.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qtbase/commit/0a5a41d9a4f33652f3a0be766b6b9a486075325b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "read"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a memory-allocating environment variable check with a faster, non-allocating alternative to improve performance.",
            "The optimization strategy replaced a memory-allocating environment variable check with a faster, non-allocating alternative to improve performance.",
            "The optimization strategy replaced a memory-allocating environment variable check with a faster, non-allocating alternative to improve performance.",
            "The optimization strategy replaced a memory-allocating environment variable check with a faster, non-allocating alternative to improve performance.",
            "The optimization strategy replaced a memory-allocating environment variable check with a faster, non-allocating alternative to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaced a memory-allocating environment variable check with a faster, non-allocating alternative to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "smaug",
        "hash": "3c6db98a1474bca34927562783bced836ac12892",
        "author": "Yuan Yao",
        "date": "2018-03-13T20:47:39-04:00",
        "message": "smv: Optimize the tiling strategy for the convolution layer.\n\nThe current tiling code will lead to hardware underutilization as it\ntries to maximize the number of output feature maps in an output tile.\nThis change rounds down it to the previous multiple of NUM_PE_INSTS.\nThis also refactors the tiling code a bit.\n\nChange-Id: I8a08707a85078caf1ce292ee71a325f876d1183e",
        "modified_files_count": 1,
        "modified_files": [
            "nnet_lib/src/arch/smv/convolution.c"
        ],
        "github_commit_url": "https://github.com/harvard-acc/smaug/commit/3c6db98a1474bca34927562783bced836ac12892",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "convolution_divide_work"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy adjusts the tiling approach for convolution layers by rounding down the number of output feature maps to a multiple of NUM_PE_INSTS to improve hardware utilization.",
            "The optimization strategy adjusts the tiling approach for convolution layers by rounding down the number of output feature maps to a multiple of NUM_PE_INSTS to improve hardware utilization.",
            "The optimization adjusts the tiling strategy for convolution layers by rounding down the number of output feature maps to a multiple of NUM_PE_INSTS to improve hardware utilization.",
            "The optimization strategy adjusts the tiling approach for convolution layers by rounding down the number of output feature maps to a multiple of NUM_PE_INSTS to improve hardware utilization.",
            "The optimization strategy adjusts the tiling approach for convolution layers by rounding down the number of output feature maps to a multiple of NUM_PE_INSTS to improve hardware utilization."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy adjusts the tiling approach for convolution layers by rounding down the number of output feature maps to a multiple of NUM_PE_INSTS to improve hardware utilization.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "CControl",
        "hash": "da0b10ca058ff87b6fba1a5db543196be7001f15",
        "author": "Daniel Mårtensson",
        "date": "2023-10-08T12:22:54+02:00",
        "message": "Faster cut.c",
        "modified_files_count": 1,
        "modified_files": [
            "src/CControl/Sources/Miscellaneous/cut.c"
        ],
        "github_commit_url": "https://github.com/DanielMartensson/CControl/commit/da0b10ca058ff87b6fba1a5db543196be7001f15",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "size"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the `size` function to improve its runtime efficiency.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the `size` function to improve its runtime efficiency.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in the `size` function.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in the `size` function."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in the `size` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "parrot",
        "hash": "4be1dea1d3a8212c5d8ea4175020162afb4bc485",
        "author": "chromatic",
        "date": "2007-09-30T07:15:29+00:00",
        "message": "[src] Optimized Parrot_byte_index(), which was surprisingly expensive.  It's a\nlittle bit tricky because C strings can't have embedded NULL characters, so the\nnaive use of the standard library's index() doesn't always work.  However, it's\na good place to start as it tends to run much faster than the inchworm code\nhere.\n\nAnother optimization is never paying the price of calling memcmp() if it's\nobvious that it will fail.\n\nThere are larger algorithmic optimizations to make calling this code less\nexpensive (by calling it less frequently), but this was a low-hanging\noptimization.  Amortized over the data of PGE's regexp tests, this function\nruns about three times faster than the previous version.\n\ngit-svn-id: https://svn.parrot.org/parrot/trunk@21669 d31e2699-5ff4-0310-a27c-f18f2fbe73fe",
        "modified_files_count": 1,
        "modified_files": [
            "src/utils.c"
        ],
        "github_commit_url": "https://github.com/parrot/parrot/commit/4be1dea1d3a8212c5d8ea4175020162afb4bc485",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Parrot_byte_index"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a slower custom implementation with a faster standard library function and avoiding unnecessary calls to `memcmp()` when failure is guaranteed.",
            "The optimization strategy involved replacing a custom byte-by-byte search with the standard library's `index()` function while avoiding unnecessary calls to `memcmp()` when failure is guaranteed.",
            "The optimization strategy involved replacing a custom byte-by-byte search with the standard library's `index()` function while avoiding unnecessary `memcmp()` calls when failure is guaranteed.",
            "The optimization strategy involved replacing a custom inchworm search implementation with the standard library's `index()` function while avoiding unnecessary calls to `memcmp()` when failure is guaranteed.",
            "The optimization strategy involved replacing a custom byte-by-byte search with the standard library's `index()` function and avoiding unnecessary `memcmp()` calls when failure is guaranteed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a custom byte-by-byte search with the standard library's `index()` function while avoiding unnecessary calls to `memcmp()` when failure is guaranteed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "NanoVNA",
        "hash": "992e51cf8b3017b3015c441a48c4aa93060a5ce0",
        "author": "ВшЫдщкв",
        "date": "2020-01-23T22:05:32+03:00",
        "message": "Optimize size of groupdelay_from_array function",
        "modified_files_count": 1,
        "modified_files": [
            "plot.c"
        ],
        "github_commit_url": "https://github.com/ttrftech/NanoVNA/commit/992e51cf8b3017b3015c441a48c4aa93060a5ce0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "groupdelay_from_array"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant calculations inside a loop by precomputing values outside the loop.",
            "The optimization strategy involved reducing the computational overhead by minimizing redundant calculations within the groupdelay_from_array function.",
            "The optimization strategy involved reducing redundant calculations inside a loop by precomputing values outside the loop.",
            "The optimization strategy involved reducing the computational overhead by minimizing redundant calculations within the `groupdelay_from_array` function.",
            "The optimization strategy involved reducing the computational overhead by simplifying the logic and minimizing redundant calculations within the `groupdelay_from_array` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the computational overhead by minimizing redundant calculations within the `groupdelay_from_array` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "link-grammar",
        "hash": "111905bf6bba581011629d73d7b491f486522924",
        "author": "Linas Vepštas",
        "date": "2019-11-30T00:26:31-06:00",
        "message": "Merge pull request #1055 from ampli/count-c1\n\ndo_count() minor speed improvements",
        "modified_files_count": 1,
        "modified_files": [
            "link-grammar/parse/count.c"
        ],
        "github_commit_url": "https://github.com/opencog/link-grammar/commit/111905bf6bba581011629d73d7b491f486522924",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "do_count"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations or iterations within the `do_count()` function to improve its execution speed.",
            "The optimization strategy involved simplifying or streamlining the logic within the `do_count()` function to reduce unnecessary computations or iterations.",
            "The optimization strategy involved reducing unnecessary computations or iterations within the `do_count` function to improve its execution speed.",
            "The optimization strategy involved simplifying or streamlining the logic within the `do_count()` function to reduce unnecessary computations or iterations.",
            "The optimization strategy involved simplifying or reducing unnecessary computations within the `do_count` function to improve its execution speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations or iterations within the `do_count` function to improve its execution speed.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "2f0aa30425414f3105bc29dd39bfdb40cb684393",
        "author": "Jesse Barnes",
        "date": "2013-11-28T11:01:30+01:00",
        "message": "drm/i915/vlv: use a lower RC6 timeout on VLV\n\nWe use timeout mode, and we need to lower the timeout to get good RC6\nresidency when loads are running.  This gets me from 0% residency during\nglxgears to 77%, which is a pretty good improvement.  This value also\nmatches the current BWG recommentations.\n\nTested-by: \"Meng, Mengmeng\" <mengmeng.meng@intel.com>\nSigned-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>\nReviewed-by: Deepak S <deepak.s@inel.com>\nSigned-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/i915/intel_pm.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/2f0aa30425414f3105bc29dd39bfdb40cb684393",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "valleyview_enable_rps"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involved reducing the RC6 timeout value to improve residency during active workloads.",
            "The optimization strategy involved reducing the RC6 timeout value to improve residency during active workloads.",
            "The optimization strategy involved reducing the RC6 timeout value to improve residency during active workloads.",
            "The optimization strategy involved reducing the RC6 timeout value to improve residency during loads on VLV.",
            "The optimization strategy involved reducing the RC6 timeout value to improve residency during loads, aligning with BWG recommendations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the RC6 timeout value to improve residency during active workloads.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "newsboat",
        "hash": "e6de9130d88d7737e4334b953578c08a90458716",
        "author": "Stefan Erben",
        "date": "2009-04-29T22:30:46+02:00",
        "message": "Performance of strprintf enhanced",
        "modified_files_count": 1,
        "modified_files": [
            "src/utils.cpp"
        ],
        "github_commit_url": "https://github.com/newsboat/newsboat/commit/e6de9130d88d7737e4334b953578c08a90458716",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "utils::strprintf"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a loop that appended characters one by one with a more efficient bulk append operation to reduce function call overhead.",
            "The optimization strategy involved replacing a loop that appended characters one by one with a more efficient bulk append operation to improve performance.",
            "The optimization strategy involved replacing a loop that appended characters one by one with a more efficient bulk operation to reduce overhead.",
            "The optimization strategy involved replacing a loop that appended characters one by one with a more efficient bulk append operation to reduce function call overhead.",
            "The optimization strategy involved replacing a loop that appended characters one by one with a more efficient bulk append operation to reduce function call overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a loop that appended characters one by one with a more efficient bulk append operation to reduce function call overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sycl",
        "hash": "3da0aeea080f84ebc5e3059403f799469b93b773",
        "author": "Snehasish Kumar",
        "date": "2021-04-23T10:00:38-07:00",
        "message": "[NFC] Use hasSection instead of getSection().empty()\n\nUse the optimized check hasSection() instead of calling\ngetSection().empty(). Originally suggested in D101004, but was dropped\nin the commit.",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/MachineFunctionSplitter.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/3da0aeea080f84ebc5e3059403f799469b93b773",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MachineFunctionSplitter::runOnMachineFunction"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces a potentially costly `getSection().empty()` call with a more efficient `hasSection()` check to improve performance.",
            "The optimization replaces a potentially costly method call and check (`getSection().empty()`) with a more direct and efficient method (`hasSection()`).",
            "The optimization strategy replaces a potentially costly method call and operation (`getSection().empty()`) with a direct, semantically equivalent check (`hasSection()`), reducing unnecessary overhead.",
            "The optimization replaces a potentially costly `getSection().empty()` call with a more efficient `hasSection()` check to improve performance.",
            "The optimization replaces a potentially costly `getSection().empty()` check with a more efficient `hasSection()` method to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaces a potentially costly `getSection().empty()` check with a more efficient `hasSection()` method to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "despacer",
        "hash": "6f8ba0f8128e42ae9bb34b70d2d6f72cdda7ad0b",
        "author": "Fabian Klötzl",
        "date": "2019-07-29T18:29:36+02:00",
        "message": "despace_ssse3_lut_1kb: faster comparison",
        "modified_files_count": 1,
        "modified_files": [
            "include/despacer.h"
        ],
        "github_commit_url": "https://github.com/lemire/despacer/commit/6f8ba0f8128e42ae9bb34b70d2d6f72cdda7ad0b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "despace_ssse3_lut_1kb"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of a function by processing multiple data elements in parallel.",
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of a function by processing multiple data elements in parallel.",
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of a function by processing multiple data elements in parallel.",
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of a function by processing multiple data points in parallel.",
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of a function by processing multiple data elements in parallel."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of a function by processing multiple data elements in parallel.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "eaa75527d673c76888921fa7678ddf00d9880458",
        "author": "Michele Spagnolo",
        "date": "2022-10-19T15:58:14+02:00",
        "message": "Measure::moveTicks() optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/engraving/libmscore/measure.cpp"
        ],
        "github_commit_url": "https://github.com/musescore/MuseScore/commit/eaa75527d673c76888921fa7678ddf00d9880458",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Measure::moveTicks"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "MuseScore",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations or iterations within the `moveTicks` function to improve its execution efficiency.",
            "The optimization strategy involved reducing redundant calculations by caching and reusing results within the `Measure::moveTicks()` function.",
            "The optimization strategy involved reducing redundant calculations by caching and reusing previously computed values within the `Measure::moveTicks` function.",
            "The optimization strategy involved reducing redundant calculations by caching and reusing results within the `Measure::moveTicks` function.",
            "The optimization strategy involved reducing redundant calculations by caching and reusing results within the `moveTicks` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant calculations by caching and reusing results within the `Measure::moveTicks` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "gcc",
        "hash": "e592ea8ddffb44bab52d36d9862bb39ffae4d144",
        "author": "Richard Biener",
        "date": "2024-10-02T08:15:44+02:00",
        "message": "tree-optimization/116654 - missed dr_explicit_realign[_optimized] with SLP\n\nWith single-lane SLP we miss to use the power realing loads causing\nsome testsuite FAILs.  r14-2430-g4736ddd11874fe exempted SLP of\nnon-grouped accesses because that could have been only splats\nwhere the scheme isn't used anyway, but now with single-lane SLP\nit can be contiguous accesses.\n\n\tPR tree-optimization/116654\n\t* tree-vect-data-refs.cc (vect_supportable_dr_alignment):\n\tTreat non-grouped accesses like non-SLP.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/tree-vect-data-refs.cc"
        ],
        "github_commit_url": "https://github.com/gcc-mirror/gcc/commit/e592ea8ddffb44bab52d36d9862bb39ffae4d144",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vect_supportable_dr_alignment"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves enabling the use of power-aligned loads for single-lane SLP by treating non-grouped accesses like non-SLP, resolving missed opportunities in vectorization.",
            "The optimization strategy involves enabling the use of power-aligned loads for single-lane SLP by treating non-grouped accesses like non-SLP, resolving missed opportunities in vectorization.",
            "The optimization strategy involves enabling the use of power-aligned loads for single-lane SLP by treating non-grouped accesses like non-SLP, resolving missed opportunities in vectorization.",
            "The optimization strategy involves enabling the use of power-aligned loads for single-lane SLP by treating non-grouped accesses like non-SLP, resolving missed opportunities in vectorization.",
            "The optimization strategy adjusts the handling of non-grouped accesses in single-lane SLP to enable the use of power realign loads, improving vectorization efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves enabling the use of power-aligned loads for single-lane SLP by treating non-grouped accesses like non-SLP, resolving missed opportunities in vectorization.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "skyrimse-test",
        "hash": "d2255f7e932024bca21b3c07f28e19bf51d7b84d",
        "author": "Nukem",
        "date": "2020-05-01T23:04:43-04:00",
        "message": "CKSSE: 3rd time for sub_1414974E0_SSE41. Maybe I shouldn't be allowed to write vectorized code.",
        "modified_files_count": 1,
        "modified_files": [
            "skyrim64_test/src/patches/CKSSE/Editor.cpp"
        ],
        "github_commit_url": "https://github.com/Nukem9/skyrimse-test/commit/d2255f7e932024bca21b3c07f28e19bf51d7b84d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sub_1414974E0_SSE41"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved rewriting the function to use more efficient SIMD (Single Instruction, Multiple Data) vectorized operations.",
            "The optimization strategy involved rewriting the function to use more efficient SIMD (Single Instruction, Multiple Data) vectorized operations.",
            "The optimization strategy involved rewriting the function to use more efficient SIMD (Single Instruction, Multiple Data) vectorized operations.",
            "The optimization strategy involved rewriting the function to use more efficient SIMD (Single Instruction, Multiple Data) vectorized operations.",
            "The optimization strategy involved rewriting the function to use more efficient SIMD (Single Instruction, Multiple Data) instructions for better vectorized performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved rewriting the function to use more efficient SIMD (Single Instruction, Multiple Data) vectorized operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "filament",
        "hash": "4f58be1ef1d881b04be530cc17d3a617d0e96a68",
        "author": "Pixelflinger",
        "date": "2020-08-13T23:44:38-07:00",
        "message": "minor micro optimizations",
        "modified_files_count": 1,
        "modified_files": [
            "filament/src/PostProcessManager.cpp"
        ],
        "github_commit_url": "https://github.com/google/filament/commit/4f58be1ef1d881b04be530cc17d3a617d0e96a68",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PostProcessManager::taa"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant calculations and improving memory access patterns within the function.",
            "The optimization strategy involved reducing redundant computations and improving memory access patterns within the `taa` function.",
            "The optimization strategy involved reducing redundant computations and improving memory access patterns within the `taa` function.",
            "The optimization strategy involved reducing redundant computations and improving memory access patterns within the function.",
            "The optimization strategy involved reducing redundant computations and improving memory access patterns within the `taa` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations and improving memory access patterns within the `taa` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ffmpeg",
        "hash": "1e68cefe546d8b8eda4248113f2635dbbf1df071",
        "author": "Kostya Shishkov",
        "date": "2009-12-04T08:18:13+00:00",
        "message": "100l trocadero: call emms_c() after doing decoding with SIMD in APE decoder\n\nOriginally committed as revision 20727 to svn://svn.ffmpeg.org/ffmpeg/trunk",
        "modified_files_count": 1,
        "modified_files": [
            "libavcodec/apedec.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/1e68cefe546d8b8eda4248113f2635dbbf1df071",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ape_decode_frame"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves calling `emms_c()` after decoding with SIMD to properly reset the MMX state.",
            "The optimization strategy involves calling `emms_c()` after decoding with SIMD to properly clear MMX registers and avoid potential performance penalties or incorrect behavior.",
            "The optimization strategy involves calling `emms_c()` after decoding with SIMD to properly reset the MMX state.",
            "The optimization strategy involves calling `emms_c()` after decoding with SIMD to properly reset the MMX state.",
            "The optimization strategy involves calling `emms_c()` after decoding with SIMD to properly reset the MMX state and avoid potential performance penalties or incorrect behavior."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves calling `emms_c()` after decoding with SIMD to properly reset the MMX state.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "7011ddd6528ce75491228efc001790090a8bb947",
        "author": "verwaest",
        "date": "2016-03-04T10:41:15+00:00",
        "message": "[LookupIterator] Add fast-path for reloading accessor property information\n\nThis is the equivalent of the fast-path in\nApplyTransitionToDataProperty.\n\nBUG=588893, 325923\nLOG=n\n\nReview URL: https://codereview.chromium.org/1765633003\n\nCr-Commit-Position: refs/heads/master@{#34488}",
        "modified_files_count": 1,
        "modified_files": [
            "src/lookup.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/7011ddd6528ce75491228efc001790090a8bb947",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LookupIterator::TransitionToAccessorProperty"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "A fast-path was added to reduce the overhead of reloading accessor property information by avoiding unnecessary computations when the property information is already available.",
            "A fast-path was added to reduce the overhead of reloading accessor property information by avoiding unnecessary computations when the property information is already available.",
            "A fast-path was added to reduce the overhead of reloading accessor property information by avoiding unnecessary computations when the property information is already available.",
            "Added a fast-path for reloading accessor property information to reduce redundant computations during property transitions.",
            "A fast-path was added to reduce the overhead of reloading accessor property information by avoiding unnecessary computations when the property information is already available."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "A fast-path was added to reduce the overhead of reloading accessor property information by avoiding unnecessary computations when the property information is already available.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "hdf5",
        "hash": "6543e55efad7ded7f5a0e0dc50786c966aea6b98",
        "author": "Quincey Koziol",
        "date": "2004-07-25T23:33:31-05:00",
        "message": "[svn-r8944] Purpose:\n    Code optimization\n\nDescription:\n    Eliminate duplicated call to H5T_detect_class()\n\nPlatforms tested:\n    Solaris 2.7 (arabica)\n    FreeBSD 4.10 (sleipnir) w/parallel\n    Too minor to require h5committest",
        "modified_files_count": 1,
        "modified_files": [
            "src/H5Tconv.c"
        ],
        "github_commit_url": "https://github.com/HDFGroup/hdf5/commit/6543e55efad7ded7f5a0e0dc50786c966aea6b98",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "H5T_conv_vlen"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy eliminated a redundant call to the function H5T_detect_class() to reduce unnecessary computations.",
            "The optimization strategy eliminated a redundant call to the function H5T_detect_class() to reduce unnecessary computations.",
            "The optimization strategy eliminates a redundant call to H5T_detect_class() within the H5T_conv_vlen function to reduce unnecessary computations.",
            "The optimization strategy eliminates a redundant call to H5T_detect_class() within the H5T_conv_vlen function to reduce unnecessary computations.",
            "The optimization strategy eliminates a redundant function call to H5T_detect_class() within the H5T_conv_vlen function to reduce unnecessary computations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy eliminates a redundant function call to H5T_detect_class() within the H5T_conv_vlen function to reduce unnecessary computations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "samsung-exynos9820",
        "hash": "fad3ec7ce4fc7c2b862014357be2dd660e5a5d3d",
        "author": "Davidlohr Bueso",
        "date": "2019-02-12T19:46:10+01:00",
        "message": "fs/epoll: drop ovflist branch prediction\n\n[ Upstream commit 76699a67f3041ff4c7af6d6ee9be2bfbf1ffb671 ]\n\nThe ep->ovflist is a secondary ready-list to temporarily store events\nthat might occur when doing sproc without holding the ep->wq.lock.  This\naccounts for every time we check for ready events and also send events\nback to userspace; both callbacks, particularly the latter because of\ncopy_to_user, can account for a non-trivial time.\n\nAs such, the unlikely() check to see if the pointer is being used, seems\nboth misleading and sub-optimal.  In fact, we go to an awful lot of\ntrouble to sync both lists, and populating the ovflist is far from an\nuncommon scenario.\n\nFor example, profiling a concurrent epoll_wait(2) benchmark, with\nCONFIG_PROFILE_ANNOTATED_BRANCHES shows that for a two threads a 33%\nincorrect rate was seen; and when incrementally increasing the number of\nepoll instances (which is used, for example for multiple queuing load\nbalancing models), up to a 90% incorrect rate was seen.\n\nSimilarly, by deleting the prediction, 3% throughput boost was seen\nacross incremental threads.\n\nLink: http://lkml.kernel.org/r/20181108051006.18751-4-dave@stgolabs.net\nSigned-off-by: Davidlohr Bueso <dbueso@suse.de>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Al Viro <viro@zeniv.linux.org.uk>\nCc: Jason Baron <jbaron@akamai.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "fs/eventpoll.c"
        ],
        "github_commit_url": "https://github.com/CruelKernel/samsung-exynos9820/commit/fad3ec7ce4fc7c2b862014357be2dd660e5a5d3d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ep_poll_callback"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes an incorrect branch prediction on a frequently used code path to improve performance by aligning the prediction with actual runtime behavior.",
            "The optimization removes an incorrect branch prediction on a frequently used code path to improve performance by aligning the prediction with actual runtime behavior.",
            "The optimization removes an incorrect branch prediction on the `ovflist` check, improving performance by aligning the code with actual runtime behavior.",
            "The optimization removes an incorrect branch prediction on the `ovflist` check, improving performance by aligning the code with actual runtime behavior.",
            "The optimization removes an incorrect branch prediction hint (unlikely()) for a frequently used code path, improving performance by aligning the prediction with actual usage patterns."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes an incorrect branch prediction on a frequently used code path to improve performance by aligning the prediction with actual runtime behavior.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "0708cc582f0fe2578eaab722841caf2b4f8cfe37",
        "author": "Paul Menzel",
        "date": "2010-02-22T08:37:15+01:00",
        "message": "ALSA: hda-intel: Add position_fix quirk for ASUS M2V-MX SE.\n\nWith PulseAudio and an application accessing an input device like `gnome-volume-manager` both have high CPU load as reported in [1].\n\nLoading `snd-hda-intel` with `position_fix=1` fixes this issue. Therefore add a quirk for ASUS M2V-MX SE.\n\nThe only downside is, when now exiting for example MPlayer when it is playing an audio file a high pitched sound is outputted by the speaker.\n\n$ lspci -vvnn | grep -A10 Audio\n20:01.0 Audio device [0403]: VIA Technologies, Inc. VT1708/A [Azalia HDAC] (VIA High Definition Audio Controller) [1106:3288] (rev 10)\n\tSubsystem: ASUSTeK Computer Inc. Device [1043:8290]\n\tControl: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx-\n\tStatus: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx-\n\tLatency: 0, Cache Line Size: 64 bytes\n\tInterrupt: pin A routed to IRQ 17\n\tRegion 0: Memory at fbffc000 (64-bit, non-prefetchable) [size=16K]\n\tCapabilities: <access denied>\n\tKernel driver in use: HDA Intel\n\n[1] http://sourceforge.net/mailarchive/forum.php?thread_name=1265550675.4642.24.camel%40mattotaupa&forum_name=alsa-user\n\nSigned-off-by: Paul Menzel <paulepanter@users.sourceforge.net>\nSigned-off-by: Takashi Iwai <tiwai@suse.de>",
        "modified_files_count": 1,
        "modified_files": [
            "sound/pci/hda/hda_intel.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/0708cc582f0fe2578eaab722841caf2b4f8cfe37",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SND_PCI_QUIRK"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involved adding a hardware-specific quirk to reduce CPU load by adjusting the `position_fix` parameter for a specific audio device.",
            "The optimization strategy involves adding a hardware-specific quirk to reduce CPU load by adjusting the `position_fix` parameter for a specific audio device.",
            "The optimization strategy involved adding a hardware-specific quirk to reduce CPU load by adjusting the `position_fix` parameter for a specific audio device.",
            "The optimization strategy involved adding a hardware-specific quirk to reduce CPU load by adjusting the `position_fix` parameter for a specific audio device.",
            "The optimization strategy involved adding a hardware-specific quirk to reduce CPU load by adjusting the `position_fix` parameter for a specific audio device."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adding a hardware-specific quirk to reduce CPU load by adjusting the `position_fix` parameter for a specific audio device.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "clang-wasm",
        "hash": "9bfbb7581358686c837f08f8f340b99e114dfed8",
        "author": "Petter Strandmark",
        "date": "2019-03-23T18:39:41+01:00",
        "message": "Optimize realloc for the last memory block.",
        "modified_files_count": 1,
        "modified_files": [
            "nanolibc/memory.cpp"
        ],
        "github_commit_url": "https://github.com/PetterS/clang-wasm/commit/9bfbb7581358686c837f08f8f340b99e114dfed8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "realloc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary memory reallocation by directly extending the last memory block when possible.",
            "The optimization strategy avoids unnecessary memory reallocation by directly extending the last memory block when possible.",
            "The optimization strategy avoids unnecessary memory reallocation by directly extending the last memory block when possible.",
            "The optimization strategy avoids unnecessary memory reallocation by directly extending the last memory block when possible.",
            "The optimization strategy avoids unnecessary memory reallocation by directly extending the last memory block when possible."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids unnecessary memory reallocation by directly extending the last memory block when possible.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qt",
        "hash": "bdad106358ae177d1345f5ff85c0e38cfeb5ca90",
        "author": "Thiago Macieira",
        "date": "2011-06-14T11:08:58+02:00",
        "message": "Improve toLatin1 x86 SIMD by using a new SSE4.1 instruction\n\nThe new instruction is PBLENDVB, which creates a result by selecting\nbytes from one of two registers, depending on whether the mask\ncontains a 1 (0xff) or a zero.\n\nThe SSE2 code requires three instructions (and, andnot, or).\n\nThe equivalent Neon instruction is VBSL (bit select).\n\nReviewed-by: Samuel Rødal",
        "modified_files_count": 1,
        "modified_files": [
            "src/corelib/tools/qstring.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qt/commit/bdad106358ae177d1345f5ff85c0e38cfeb5ca90",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "toLocal8Bit"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization leverages the SSE4.1 instruction PBLENDVB to replace multiple SSE2 instructions, reducing the number of operations required for byte selection in the `toLatin1` function.",
            "The optimization leverages the SSE4.1 instruction PBLENDVB to replace multiple SSE2 instructions, reducing instruction count and improving SIMD performance for the `toLatin1` function.",
            "The optimization strategy replaced multiple SSE2 instructions with a single SSE4.1 instruction (PBLENDVB) to improve the performance of the `toLatin1` function by reducing instruction count and leveraging advanced SIMD capabilities.",
            "The optimization leverages the SSE4.1 instruction PBLENDVB to replace multiple SSE2 instructions, reducing instruction count and improving SIMD performance for the `toLatin1` function.",
            "The optimization leverages the SSE4.1 instruction PBLENDVB to replace three SSE2 instructions (and, andnot, or) for improved SIMD performance in the `toLatin1` function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization leverages the SSE4.1 instruction PBLENDVB to replace multiple SSE2 instructions, reducing instruction count and improving SIMD performance for the `toLatin1` function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "omr",
        "hash": "0d64043d74024e337119adc637cd27f767171794",
        "author": "Filip Jeremic",
        "date": "2021-09-20T10:33:12-04:00",
        "message": "Merge pull request #6182 from dchopra001/gridGainFix\n\nRestrict rotate instruction optimization for lshl+land nodes",
        "modified_files_count": 1,
        "modified_files": [
            "compiler/z/codegen/BinaryEvaluator.cpp"
        ],
        "github_commit_url": "https://github.com/eclipse-omr/omr/commit/0d64043d74024e337119adc637cd27f767171794",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization restricts the use of rotate instructions for specific nodes (lshl+land) to improve performance or correctness in generated code.",
            "The optimization restricts the use of rotate instructions for specific nodes (lshl+land) to improve performance or correctness in handling bitwise operations.",
            "The optimization restricts the use of rotate instructions for specific nodes (lshl+land) to improve performance or correctness in handling bitwise operations.",
            "The optimization restricts the use of rotate instructions for specific nodes (lshl+land) to improve performance or correctness in generated code.",
            "The optimization restricts the use of rotate instructions for specific nodes (lshl+land) to improve performance or correctness in generated code."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization restricts the use of rotate instructions for specific nodes (lshl+land) to improve performance or correctness in generated code.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mOS",
        "hash": "9655215689729527c501184f5dd1ae8e1e100f99",
        "author": "Andrew Morton",
        "date": "2003-03-08T03:22:49-08:00",
        "message": "[PATCH] fix possible latency in balance_dirty_pages()\n\nTasks which throttle in balance_dirty_pages() will loop until the amount of\ndirty memory falls below the configured dirty_ratio.\n\nThis exposes the possibility that one task could be stuck in there for\narbitrary periods of time due to page dirtying activity by other tasks.\n\nThe patch changes the logic so that tasks will break out of the loop if they\nhave written enough pages, regardless of the current dirty memory limits.\n\nHere \"enough\" pages is 1.5x the number of pages which they just dirtied.\n\nIf the amount of dirty memory in the machine happens to still exceed\ndirty_ratio (say, due to MAP_SHARED activity) then the task will again\nthrottle after dirtying a single page.  But there is now an upper limit on\nthe time for which a single task will be captured in balance_dirty_pages().",
        "modified_files_count": 1,
        "modified_files": [
            "mm/page-writeback.c"
        ],
        "github_commit_url": "https://github.com/intel/mOS/commit/9655215689729527c501184f5dd1ae8e1e100f99",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "balance_dirty_pages"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy limits the time a task can be stuck in the `balance_dirty_pages()` loop by breaking out after writing a sufficient number of pages, regardless of the dirty memory limits.",
            "The optimization strategy limits the time a task can be stuck in the `balance_dirty_pages()` loop by breaking out after writing a sufficient number of pages, regardless of the dirty memory limits.",
            "The optimization strategy limits the time a task can be stuck in the `balance_dirty_pages()` loop by breaking out after writing a sufficient number of pages, regardless of the dirty memory ratio.",
            "The optimization strategy limits the time a task can be stuck in the `balance_dirty_pages()` loop by breaking out after writing enough pages, even if the dirty memory ratio is still above the threshold.",
            "The optimization strategy limits the time a task can be stuck in the `balance_dirty_pages()` loop by breaking out after writing a sufficient number of pages, regardless of the dirty memory ratio."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy limits the time a task can be stuck in the `balance_dirty_pages()` loop by breaking out after writing a sufficient number of pages, regardless of the dirty memory ratio.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Hercules",
        "hash": "8caedfe81e0f03423fe46f05274b3590e2bb9416",
        "author": "shennetsind",
        "date": "2012-04-11T10:34:34+00:00",
        "message": "minor performance improvement for users with battle_config.ksprotection disabled.\n\ngit-svn-id: https://rathena.svn.sourceforge.net/svnroot/rathena/trunk@15855 54d463be-8e91-2dee-dedb-b68131a5f0ec",
        "modified_files_count": 1,
        "modified_files": [
            "src/map/battle.c"
        ],
        "github_commit_url": "https://github.com/HerculesWS/Hercules/commit/8caedfe81e0f03423fe46f05274b3590e2bb9416",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "battle_calc_damage"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary calculations when a specific configuration flag is disabled, reducing computational overhead.",
            "The optimization avoids unnecessary calculations by checking a configuration flag before performing certain operations.",
            "The optimization avoids unnecessary calculations by checking a configuration flag before performing certain operations.",
            "The optimization avoids unnecessary calculations by checking a configuration flag before performing certain operations.",
            "The optimization avoids unnecessary calculations by checking a configuration flag before performing certain operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary calculations by checking a configuration flag before performing certain operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "relic",
        "hash": "d56ce03a409825e09dff0bfdfeee79c8a5002b16",
        "author": "Diego F. Aranha",
        "date": "2018-07-26T13:02:08+02:00",
        "message": "Make BLS signature verification faster.",
        "modified_files_count": 1,
        "modified_files": [
            "src/cp/relic_cp_bls.c"
        ],
        "github_commit_url": "https://github.com/relic-toolkit/relic/commit/d56ce03a409825e09dff0bfdfeee79c8a5002b16",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cp_bls_ver"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the BLS signature verification process to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved reducing redundant computations in the BLS signature verification process by caching intermediate results.",
            "The optimization strategy involved reducing redundant computations in the BLS signature verification process by caching intermediate results.",
            "The optimization strategy involved restructuring the BLS signature verification process to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the BLS signature verification process to reduce redundant computations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the BLS signature verification process to reduce redundant computations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "hhvm",
        "hash": "d021074c0dc7ddfe7a7a814430f39b6746ca4132",
        "author": "Giuseppe Ottaviano",
        "date": "2023-05-30T10:41:36-07:00",
        "message": "nullptr fast path in AtomicCoreCachedSharedPtr::get()\n\nSummary: If the storage is `nullptr`, we don't need to protect it.\n\nReviewed By: Gownta\n\nDifferential Revision: D46228019\n\nfbshipit-source-id: dfc9515f8f01fd02b37337ef08446159e17482bc",
        "modified_files_count": 1,
        "modified_files": [
            "third-party/folly/src/folly/concurrency/CoreCachedSharedPtr.h"
        ],
        "github_commit_url": "https://github.com/facebook/hhvm/commit/d021074c0dc7ddfe7a7a814430f39b6746ca4132",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "reset"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization introduces a fast path to avoid unnecessary protection when the storage is `nullptr`.",
            "The optimization introduces a fast path for `nullptr` checks in `AtomicCoreCachedSharedPtr::get()` to avoid unnecessary protection logic when the storage is null.",
            "The optimization introduces a fast path for `nullptr` checks in `AtomicCoreCachedSharedPtr::get()` to avoid unnecessary protection logic when the storage is empty.",
            "The optimization introduces a fast path for `nullptr` checks in `AtomicCoreCachedSharedPtr::get()` to avoid unnecessary protection logic when the storage is empty.",
            "The optimization introduces a fast path for `nullptr` checks in `AtomicCoreCachedSharedPtr::get()` to avoid unnecessary protection logic when the storage is empty."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization introduces a fast path for `nullptr` checks in `AtomicCoreCachedSharedPtr::get()` to avoid unnecessary protection logic when the storage is empty.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "183c062c51c7e7663752b94ac399c830e4cb3c44",
        "author": "Waiman Long",
        "date": "2014-10-09T12:18:42-07:00",
        "message": "mm, thp: move invariant bug check out of loop in __split_huge_page_map\n\ncommit f8303c2582b889351e261ff18c4d8eb197a77db2 upstream.\n\nIn __split_huge_page_map(), the check for page_mapcount(page) is\ninvariant within the for loop.  Because of the fact that the macro is\nimplemented using atomic_read(), the redundant check cannot be optimized\naway by the compiler leading to unnecessary read to the page structure.\n\nThis patch moves the invariant bug check out of the loop so that it will\nbe done only once.  On a 3.16-rc1 based kernel, the execution time of a\nmicrobenchmark that broke up 1000 transparent huge pages using munmap()\nhad an execution time of 38,245us and 38,548us with and without the\npatch respectively.  The performance gain is about 1%.\n\nSigned-off-by: Waiman Long <Waiman.Long@hp.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nCc: Andrea Arcangeli <aarcange@redhat.com>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Rik van Riel <riel@redhat.com>\nCc: Scott J Norton <scott.norton@hp.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/huge_memory.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/183c062c51c7e7663752b94ac399c830e4cb3c44",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__split_huge_page_map"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved moving an invariant bug check out of a loop to eliminate redundant atomic reads and improve performance.",
            "The optimization strategy moves an invariant bug check out of a loop to eliminate redundant atomic reads and improve performance.",
            "The optimization strategy moves an invariant bug check out of a loop to eliminate redundant atomic reads and improve performance.",
            "The optimization strategy moves an invariant bug check out of a loop to eliminate redundant atomic reads and improve performance.",
            "The optimization strategy involved moving an invariant bug check out of a loop to eliminate redundant atomic reads and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy moves an invariant bug check out of a loop to eliminate redundant atomic reads and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "PandA-bambu",
        "hash": "565d0b74e8bb66c0ff8aa42db225d6eb11258dac",
        "author": "Fabrizio Ferrandi",
        "date": "2018-04-24T12:46:12+02:00",
        "message": "* Improved multiplication by an unsigned constant.",
        "modified_files_count": 1,
        "modified_files": [
            "src/frontend_analysis/IR_analysis/IR_lowering.cpp"
        ],
        "github_commit_url": "https://github.com/ferrandi/PandA-bambu/commit/565d0b74e8bb66c0ff8aa42db225d6eb11258dac",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "IR_lowering::expand_MC"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the handling of multiplication by an unsigned constant, likely through more efficient code generation or transformation.",
            "The optimization strategy involved improving the handling of multiplication by an unsigned constant, likely by reducing unnecessary operations or improving the efficiency of the operation.",
            "The optimization strategy involved improving the handling of multiplication by an unsigned constant, likely through more efficient code generation or transformation.",
            "The optimization strategy involved improving multiplication by an unsigned constant, likely through more efficient code generation or transformation.",
            "The optimization strategy involved improving the handling of multiplication by an unsigned constant, likely by reducing unnecessary operations or improving the efficiency of the operation."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved improving the handling of multiplication by an unsigned constant, likely through more efficient code generation or transformation.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Floorp",
        "hash": "6aedff6f4eea0bdbf8714f08807833cfcab5a069",
        "author": "Jed Davis",
        "date": "2021-02-16T22:51:29+00:00",
        "message": "Bug 1692631 - Add only one sending start profiler marker per message on Windows. r=gerald\n\nCurrently, we add an `eSending`/`TransferStart` marker every time we\nsend data as part of a message, rather than only the first time.  The\nprofiler frontend appears to ignore the extra markers (the displayed time\nintervals look reasonable), but it's wasteful: on large messages it can\nconsume enough CPU time to appear in the profile itself.\n\nDifferential Revision: https://phabricator.services.mozilla.com/D105093",
        "modified_files_count": 1,
        "modified_files": [
            "ipc/chromium/src/chrome/common/ipc_channel_win.cc"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/6aedff6f4eea0bdbf8714f08807833cfcab5a069",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Channel::ChannelImpl::ProcessOutgoingMessages"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces redundant profiler marker additions by ensuring only one `eSending`/`TransferStart` marker is added per message, minimizing unnecessary CPU overhead.",
            "The optimization reduces redundant profiler marker additions by ensuring only one `eSending`/`TransferStart` marker is added per message, minimizing unnecessary CPU overhead.",
            "The optimization reduces redundant profiler marker additions by ensuring only one `eSending`/`TransferStart` marker is added per message, minimizing unnecessary CPU overhead.",
            "The optimization reduces redundant profiler marker additions by ensuring only one `eSending`/`TransferStart` marker is added per message, minimizing unnecessary CPU overhead.",
            "The optimization reduces redundant profiler marker additions by ensuring only one `eSending`/`TransferStart` marker is added per message, minimizing unnecessary CPU overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces redundant profiler marker additions by ensuring only one `eSending`/`TransferStart` marker is added per message, minimizing unnecessary CPU overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kram",
        "hash": "1bacbd615ec005b605bd208117b546992527ac07",
        "author": "Alec Miller",
        "date": "2024-11-03T22:14:23-08:00",
        "message": "kram - simd - faster decompose_scale",
        "modified_files_count": 1,
        "modified_files": [
            "libkram/vectormath/float234.h"
        ],
        "github_commit_url": "https://github.com/alecazam/kram/commit/1bacbd615ec005b605bd208117b546992527ac07",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "macroVector4TypesStorageRenames"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of the `decompose_scale` function by processing multiple data points in parallel.",
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of the `decompose_scale` function by processing multiple data points in parallel.",
            "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of the `decompose_scale` function by processing multiple data points in parallel.",
            "The optimization strategy involved restructuring the `decompose_scale` function to leverage SIMD (Single Instruction, Multiple Data) operations for improved performance.",
            "The optimization strategy involved restructuring the `decompose_scale` function to leverage SIMD (Single Instruction, Multiple Data) operations for improved performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used SIMD (Single Instruction, Multiple Data) instructions to improve the performance of the `decompose_scale` function by processing multiple data points in parallel.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "644e334eeec01a25138b62ebd576b3a798183c7c",
        "author": "Pablo Neira Ayuso",
        "date": "2017-11-07T01:00:30+01:00",
        "message": "netfilter: nf_tables: performance set policy skips size description in selection\n\nUse the complexity and space notations if policy is performance, this\nresults in placing the bitmap set representation over the hashtable for\nkey <= 16 for better performance as we discussed during the last NFWS in\nFaro, Portugal.\n\nSigned-off-by: Pablo Neira Ayuso <pablo@netfilter.org>",
        "modified_files_count": 1,
        "modified_files": [
            "net/netfilter/nf_tables_api.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/644e334eeec01a25138b62ebd576b3a798183c7c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nft_select_set_ops"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves selecting a more efficient data structure (bitmap over hashtable) for small key sizes to improve performance in the netfilter subsystem.",
            "The optimization strategy involves selecting a more efficient data structure (bitmap over hashtable) for small key sizes to improve performance in the netfilter subsystem.",
            "The optimization strategy involves selecting a more efficient data structure (bitmap over hashtable) for small key sizes to improve performance in set policy operations.",
            "The optimization strategy involves selecting a more efficient data structure (bitmap over hashtable) for small key sizes to improve performance in the netfilter subsystem.",
            "The optimization strategy involves selecting a more efficient data structure (bitmap over hashtable) for small key sizes to improve performance in the netfilter subsystem."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves selecting a more efficient data structure (bitmap over hashtable) for small key sizes to improve performance in the netfilter subsystem.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow-directml",
        "hash": "3ecbdf133e8be1d94b24dcdcef3fdc7313f49507",
        "author": "Artem Belevich",
        "date": "2019-05-21T16:03:47-07:00",
        "message": "Work around ptxas bug which affects unoptimized builds compiled with clang for Pascal GPUs.\n\nManually unrolling the loops avoids triggering the issue.\n\nPiperOrigin-RevId: 249342998",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/core/lib/random/random_distributions.h"
        ],
        "github_commit_url": "https://github.com/microsoft/tensorflow-directml/commit/3ecbdf133e8be1d94b24dcdcef3fdc7313f49507",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "operator"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved manually unrolling loops to avoid triggering a ptxas bug in unoptimized builds for Pascal GPUs.",
            "The optimization strategy involved manually unrolling loops to avoid a compiler bug affecting unoptimized builds on Pascal GPUs.",
            "The optimization strategy involved manually unrolling loops to work around a ptxas bug affecting unoptimized builds compiled with clang for Pascal GPUs.",
            "The optimization strategy involved manually unrolling loops to work around a ptxas bug affecting unoptimized builds for Pascal GPUs.",
            "The optimization strategy involved manually unrolling loops to work around a ptxas bug affecting unoptimized builds on Pascal GPUs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved manually unrolling loops to work around a ptxas bug affecting unoptimized builds for Pascal GPUs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "NyuziProcessor",
        "hash": "e1b978b4c783b105e860ee19f32a558dd73c77ed",
        "author": "Jeff Bush",
        "date": "2015-01-05T22:08:58-08:00",
        "message": "It's actually faster than that...",
        "modified_files_count": 1,
        "modified_files": [
            "software/librender/SliceArray.h"
        ],
        "github_commit_url": "https://github.com/jbush001/NyuziProcessor/commit/e1b978b4c783b105e860ee19f32a558dd73c77ed",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sort"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a less efficient sorting algorithm with a more efficient one, likely reducing time complexity.",
            "The optimization strategy involved replacing a less efficient sorting algorithm with a more efficient one, likely reducing time complexity.",
            "The optimization strategy involved replacing a general-purpose sorting algorithm with a more efficient, specialized sorting implementation tailored for the specific data structure.",
            "The optimization strategy involved replacing a less efficient sorting algorithm with a more efficient one, likely reducing time complexity.",
            "The optimization strategy involved replacing a less efficient sorting algorithm with a more efficient one, likely reducing time complexity."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a less efficient sorting algorithm with a more efficient one, likely reducing time complexity.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "library-checker-problems",
        "hash": "482cc8f336e56fc563a960e97247a33e646838cd",
        "author": "antma",
        "date": "2021-07-16T12:52:08+03:00",
        "message": "general_weighted_matching: tiny verifier optimization for stresses",
        "modified_files_count": 1,
        "modified_files": [
            "graph/general_weighted_matching/verifier.cpp"
        ],
        "github_commit_url": "https://github.com/yosupo06/library-checker-problems/commit/482cc8f336e56fc563a960e97247a33e646838cd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the number of iterations in a stress-testing loop to improve performance during verification.",
            "The optimization strategy involved reducing the number of iterations in a stress-testing loop to improve performance during verification.",
            "The optimization strategy involved reducing the number of iterations in a stress-testing loop to improve performance during verification.",
            "The optimization strategy involved reducing the number of iterations in a stress-testing loop to improve performance during verification.",
            "The optimization strategy involved reducing unnecessary iterations or computations in the verifier to improve performance under stress testing conditions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the number of iterations in a stress-testing loop to improve performance during verification.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dolphin",
        "hash": "dbb8f588c7ac5c6c4586804c072c87de730ef00c",
        "author": "Bram Speeckaert",
        "date": "2022-11-01T11:27:45+01:00",
        "message": "JitArm64: cmpl - Optimize a == 0 case\n\nBy explicitly handling this, we can avoid materializing zero in a\nregister.\n\nBefore:\n0x52800019   mov    w25, #0x0\n0xb94087b6   ldr    w22, [x29, #0x84]\n0xcb16033b   sub    x27, x25, x22\n\nAfter:\n0xb94087b9   ldr    w25, [x29, #0x84]\n0xcb1903fb   neg    x27, x25",
        "modified_files_count": 1,
        "modified_files": [
            "Source/Core/Core/PowerPC/JitArm64/JitArm64_Integer.cpp"
        ],
        "github_commit_url": "https://github.com/dolphin-emu/dolphin/commit/dbb8f588c7ac5c6c4586804c072c87de730ef00c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "JitArm64::cmpl"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids materializing zero in a register by directly using the `neg` instruction for the `a == 0` case, reducing unnecessary operations.",
            "The optimization avoids materializing zero in a register by directly using a negation operation for the `a == 0` case.",
            "The optimization avoids materializing zero in a register by directly using a negation operation for the `a == 0` case.",
            "The optimization avoids materializing zero in a register by directly using the `neg` instruction for the `a == 0` case, reducing unnecessary operations.",
            "The optimization avoids materializing zero in a register by directly using the `neg` instruction for the `a == 0` case, reducing unnecessary operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids materializing zero in a register by directly using the `neg` instruction for the `a == 0` case, reducing unnecessary operations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "2353a510afecd50393f528ce0b53da13b8df7a56",
        "author": "Frerich Raabe",
        "date": "2010-09-29T15:46:17+02:00",
        "message": "Optimized EntryItemModel::queryForEntries()\n\nFor my 350k entries, counting the number of entries just needs 1.1s and 19MB\nRAM instead of 10.8s and 412MB RAM now. The trick is to let SQLite do the\ncounting.",
        "modified_files_count": 1,
        "modified_files": [
            "gui/entryitemmodel.cpp"
        ],
        "github_commit_url": "https://github.com/froglogic/tracetool/commit/2353a510afecd50393f528ce0b53da13b8df7a56",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "EntryItemModel::queryForEntries"
        ],
        "is_opt_qwen_plus": "true",
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "tracetool",
        "optimization_summary": [
            "The optimization strategy involved offloading the counting operation to SQLite instead of performing it in memory, reducing both time and memory usage.",
            "The optimization strategy involved offloading the counting operation to SQLite instead of performing it in memory, reducing both time and memory usage.",
            "The optimization strategy involved offloading the counting operation to SQLite instead of performing it in memory, reducing both time and memory usage.",
            "The optimization strategy involved offloading the counting operation to SQLite instead of performing it in memory, reducing both time and memory usage.",
            "The optimization strategy involved offloading the counting operation to SQLite instead of performing it in memory, reducing both time and memory usage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved offloading the counting operation to SQLite instead of performing it in memory, reducing both time and memory usage.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "petsc",
        "hash": "c124e916cc25c60b59020116a74464d5b14ef271",
        "author": "Hong Zhang",
        "date": "2004-06-23T09:26:55-06:00",
        "message": "bk-changeset-1.2299.1.11\nhzhang@harley.mcs.anl.gov|ChangeSet|20040623152655|64232\nChangeSet\n  1.2299.1.11 04/06/23 10:26:55 hzhang@harley.mcs.anl.gov +1 -0\n  optimize MatMatMultNumeric_SeqAIJ_SeqAIJ():\n  remove temp array of size C->n (large and sparse)\n  combine two loops into one.\n\n  src/mat/impls/aij/seq/matmatmult.c\n    1.81 04/06/23 10:26:54 hzhang@harley.mcs.anl.gov +12 -18\n    optimize MatMatMultNumeric_SeqAIJ_SeqAIJ():\n    remove temp array of size C->n (large and sparse)\n    combine two loops into one.\n\n\nHg-commit: 09a03d9f2d04d219982e6d1ec4720b601d1a81c4",
        "modified_files_count": 1,
        "modified_files": [
            "src/mat/impls/aij/seq/matmatmult.c"
        ],
        "github_commit_url": "https://github.com/petsc/petsc/commit/c124e916cc25c60b59020116a74464d5b14ef271",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MatMatMultNumeric_SeqAIJ_SeqAIJ"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes a large temporary array and merges two loops into one to reduce memory usage and improve cache efficiency.",
            "The optimization strategy involved removing a large temporary array and merging two loops into one to reduce memory usage and improve cache efficiency.",
            "The optimization strategy involved removing a large temporary array and merging two loops into one to reduce memory usage and improve cache efficiency.",
            "The optimization strategy involved removing a large temporary array and combining two loops into one to reduce memory usage and improve cache efficiency.",
            "The optimization strategy involved removing a large temporary array and merging two loops into one to reduce memory usage and improve cache efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved removing a large temporary array and merging two loops into one to reduce memory usage and improve cache efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sycl",
        "hash": "bb6119eb77fe5818985d375cef415f9fbc0b4757",
        "author": "Mehdi Amini",
        "date": "2022-01-30T19:49:22+00:00",
        "message": "Apply clang-tidy fixes for performance-for-range-copy in SCFInterfaceImpl.cpp (NFC)",
        "modified_files_count": 1,
        "modified_files": [
            "mlir/lib/Dialect/SCF/Transforms/BufferizableOpInterfaceImpl.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/bb6119eb77fe5818985d375cef415f9fbc0b4757",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bufferize"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing range-based loops that copied objects with ones that use references to avoid unnecessary copy overhead.",
            "The optimization strategy involved replacing range-based loops that copied objects with ones that use references to avoid unnecessary copy overhead.",
            "The optimization strategy involved replacing range-based loops that copied objects with ones that use references to avoid unnecessary copy overhead.",
            "The optimization strategy involved replacing range-based loops that copied objects with ones that used references to avoid unnecessary copy overhead.",
            "The optimization strategy involved replacing range-based loops that copied objects with ones that used references to avoid unnecessary copy overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing range-based loops that copied objects with ones that use references to avoid unnecessary copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "MyScaleDB",
        "hash": "ccecb55b9572bd9aa5ee99ac25b94052317e6b05",
        "author": "Alexey Arno",
        "date": "2014-12-17T16:29:37+03:00",
        "message": "Add performance and memory optimization. [#METR-14099]",
        "modified_files_count": 1,
        "modified_files": [
            "dbms/src/Interpreters/InterpreterSelectQuery.cpp"
        ],
        "github_commit_url": "https://github.com/myscale/MyScaleDB/commit/ccecb55b9572bd9aa5ee99ac25b94052317e6b05",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary memory allocations and improving cache locality by reusing pre-allocated buffers.",
            "The optimization strategy involved reducing unnecessary memory allocations and improving cache locality by reusing pre-allocated buffers.",
            "The optimization strategy involved reducing unnecessary memory allocations and improving cache locality by reusing pre-allocated buffers.",
            "The optimization strategy involved reducing unnecessary memory allocations and improving cache locality by reusing pre-allocated buffers.",
            "The optimization strategy involved reducing unnecessary memory allocations and improving cache locality by reusing pre-allocated buffers."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary memory allocations and improving cache locality by reusing pre-allocated buffers.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "2d1c4fd72b40adbc8ddd691c863fbffa0d5be4bb",
        "author": "Alexander Larsson",
        "date": "2017-12-14T08:37:23+00:00",
        "message": "build-export: scan repo for hardlinks on commit\n\nThis is a no-op on regular (archive) repos, but on bare repos it is\nan optimization if the source is a checkout from the repo. This\nhappens in flatpak-builder (https://github.com/flatpak/flatpak-builder/pull/81)\nwhen it commits the build to the cache during --install without --repo.\n\nCloses: #1249\nApproved by: alexlarsson",
        "modified_files_count": 1,
        "modified_files": [
            "app/flatpak-builtins-build-export.c"
        ],
        "github_commit_url": "https://github.com/flatpak/flatpak/commit/2d1c4fd72b40adbc8ddd691c863fbffa0d5be4bb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "flatpak_builtin_build_export"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "flatpak",
        "optimization_summary": [
            "The optimization strategy involves scanning the repository for hardlinks during commit to reduce redundant operations in specific repository types (bare repos).",
            "The optimization strategy involves scanning the repository for hardlinks during commit to reduce redundant operations in specific repository types (bare repos).",
            "The optimization strategy involves scanning the repository for hardlinks during commit to reduce redundant operations in specific repository types (bare repos).",
            "The optimization strategy involves scanning the repository for hardlinks during commit to reduce redundant operations in specific repository types (bare repos).",
            "The optimization strategy involves scanning the repository for hardlinks during commit to reduce redundant operations in specific repository types (bare repos)."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves scanning the repository for hardlinks during commit to reduce redundant operations in specific repository types (bare repos).",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "192542ce384d0c99866b4b95414117429a215c5b",
        "author": "Nick Lewycky",
        "date": "2013-02-05T06:20:31+00:00",
        "message": "Test for virtual instead of pure here. It has the exact same effect, and John\nclaims it will improve performance.\n\nllvm-svn: 174341",
        "modified_files_count": 1,
        "modified_files": [
            "clang/lib/Sema/SemaExpr.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/192542ce384d0c99866b4b95414117429a215c5b",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a test for \"pure\" with a test for \"virtual\" to achieve the same functionality with claimed performance improvements.",
            "The optimization strategy involved replacing a test for \"pure\" with a test for \"virtual\" to achieve the same effect but with claimed performance improvements.",
            "The optimization strategy involved replacing a test for \"pure\" with a test for \"virtual\" to achieve the same effect while claiming improved performance.",
            "The optimization strategy involved replacing a test for \"pure\" with a test for \"virtual,\" which is claimed to have the same effect but improves performance.",
            "The optimization strategy involved replacing a test for \"pure\" with a test for \"virtual,\" which is claimed to have the same effect but improves performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a test for \"pure\" with a test for \"virtual\" to achieve the same effect but with claimed performance improvements.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "velox",
        "hash": "790d6bda3902b3dd65173333eb94c00bac361e58",
        "author": "Kevin Wilfong",
        "date": "2024-02-01T10:08:18-08:00",
        "message": "Make MultiFragmentTest.partitionedOutputWithLargeInput run faster (#8610)\n\nSummary:\nPull Request resolved: https://github.com/facebookincubator/velox/pull/8610\n\nMultiFragmentTest.partitionedOutputWithLargeInput sometimes runs for a very long time, more than 10 minutes.\n\nFortunately the test is documented with a comment, and it looks like we can get the same coverage on a smaller input\ndataset, which reduces the test time proportionatly.\n\nReviewed By: pedroerp\n\nDifferential Revision: D53242660\n\nfbshipit-source-id: 8b17f731bceebcc886847244746a6b93629b21d8",
        "modified_files_count": 1,
        "modified_files": [
            "velox/exec/tests/MultiFragmentTest.cpp"
        ],
        "github_commit_url": "https://github.com/facebookincubator/velox/commit/790d6bda3902b3dd65173333eb94c00bac361e58",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduced the size of the input dataset for a test to decrease its runtime while maintaining coverage.",
            "The optimization strategy involved reducing the size of the input dataset for a test to decrease its runtime while maintaining coverage.",
            "The optimization strategy involved reducing the size of the input dataset for a test to decrease its runtime while maintaining coverage.",
            "The optimization strategy reduced the size of the input dataset for a test to decrease its runtime while maintaining coverage.",
            "The optimization strategy reduced the size of the input dataset for a test to decrease its runtime while maintaining coverage."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduced the size of the input dataset for a test to decrease its runtime while maintaining coverage.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "proxmark3",
        "hash": "bd3e8db852186d4ab9d5dda890d1cd52389b1254",
        "author": "Philippe Teuwen",
        "date": "2024-07-29T22:24:09+02:00",
        "message": "Faster validate_prng_nonce",
        "modified_files_count": 1,
        "modified_files": [
            "common/crapto1/crapto1.c"
        ],
        "github_commit_url": "https://github.com/RfidResearchGroup/proxmark3/commit/bd3e8db852186d4ab9d5dda890d1cd52389b1254",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "validate_prng_nonce"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to reduce the number of iterations in a loop by skipping unnecessary computations based on a condition.",
            "The optimization strategy used is to reduce the number of iterations in a loop by breaking early when a condition is met, thus avoiding unnecessary computations.",
            "The optimization strategy used is to reduce the number of iterations in a loop by skipping unnecessary computations based on a condition that filters out irrelevant cases early.",
            "The optimization strategy used is to reduce redundant calculations by caching intermediate results within the function.",
            "The optimization strategy used is to reduce the number of iterations in a loop by skipping unnecessary computations based on a condition."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is to reduce the number of iterations in a loop by skipping unnecessary computations based on a condition.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "platform_system_core",
        "hash": "379eee0fbdebacafc06bd374a403fd1c1773bbac",
        "author": "Treehugger Robot",
        "date": "2022-06-28T06:53:45+00:00",
        "message": "Merge \"first_stage_init: Optimize redundant vector copy\" am: 13faa1b394 am: a2d6bd56b1 am: b028b19f27\n\nOriginal change: https://android-review.googlesource.com/c/platform/system/core/+/2136933\n\nChange-Id: I664b84094d79dd19f08fe8844e75955b8dafcfbd\nSigned-off-by: Automerger Merge Worker <android-build-automerger-merge-worker@system.gserviceaccount.com>",
        "modified_files_count": 1,
        "modified_files": [
            "init/first_stage_mount.cpp"
        ],
        "github_commit_url": "https://github.com/aosp-mirror/platform_system_core/commit/379eee0fbdebacafc06bd374a403fd1c1773bbac",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FirstStageMount::UseDsuIfPresent"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved eliminating a redundant vector copy to improve performance by directly using the original vector.",
            "The optimization strategy involved eliminating a redundant vector copy to improve performance by directly using the original vector.",
            "The optimization strategy involved eliminating a redundant vector copy to improve performance by directly using the original vector.",
            "The optimization strategy involved eliminating a redundant vector copy to improve performance by directly using the original vector.",
            "The optimization strategy involved eliminating a redundant vector copy to improve performance by directly using the original vector."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved eliminating a redundant vector copy to improve performance by directly using the original vector.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "6aeff241fe6c4561a842b344c1ca14a700ec8441",
        "author": "Yang Shi",
        "date": "2020-04-07T10:43:38-07:00",
        "message": "mm/migrate.c: migrate PG_readahead flag\n\nCurrently the migration code doesn't migrate PG_readahead flag.\nTheoretically this would incur slight performance loss as the application\nmight have to ramp its readahead back up again.  Even though such problem\nhappens, it might be hidden by something else since migration is typically\ntriggered by compaction and NUMA balancing, any of which should be more\nnoticeable.\n\nMigrate the flag after end_page_writeback() since it may clear PG_reclaim\nflag, which is the same bit as PG_readahead, for the new page.\n\n[akpm@linux-foundation.org: tweak comment]\nSigned-off-by: Yang Shi <yang.shi@linux.alibaba.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Matthew Wilcox <willy@infradead.org>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Mel Gorman <mgorman@techsingularity.net>\nLink: http://lkml.kernel.org/r/1581640185-95731-1-git-send-email-yang.shi@linux.alibaba.com\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/migrate.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/6aeff241fe6c4561a842b344c1ca14a700ec8441",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "migrate_page_states"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization migrates the PG_readahead flag during page migration to avoid performance loss caused by resetting readahead state.",
            "The optimization migrates the PG_readahead flag during page migration to avoid performance loss caused by resetting readahead state.",
            "The optimization migrates the PG_readahead flag during page migration to avoid potential performance loss caused by resetting readahead state.",
            "The optimization migrates the PG_readahead flag during page migration to avoid performance loss caused by resetting readahead state.",
            "The optimization migrates the PG_readahead flag during page migration to avoid potential performance loss caused by resetting readahead state."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization migrates the PG_readahead flag during page migration to avoid performance loss caused by resetting readahead state.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SPMC",
        "hash": "0464e115aea5d09f95c7d63b48876a22b565230d",
        "author": "Max Kellermann",
        "date": "2016-04-02T17:56:38+02:00",
        "message": "VideoPlayer/VideoPlayerVideo: use std::list::emplace_back()\n\nReduce overhead.",
        "modified_files_count": 1,
        "modified_files": [
            "xbmc/cores/VideoPlayer/VideoPlayerVideo.cpp"
        ],
        "github_commit_url": "https://github.com/koying/SPMC/commit/0464e115aea5d09f95c7d63b48876a22b565230d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a push_back operation with emplace_back to reduce overhead by constructing elements in-place.",
            "The optimization strategy involved replacing a push_back operation with emplace_back to reduce overhead by constructing elements in-place within a std::list.",
            "The optimization strategy involved replacing a push_back operation with emplace_back to reduce overhead by constructing elements in-place.",
            "The optimization strategy involved replacing a push_back operation with emplace_back to reduce overhead by constructing elements in-place within a std::list.",
            "The optimization strategy involved replacing a push_back operation with emplace_back to reduce overhead by constructing elements in-place."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a push_back operation with emplace_back to reduce overhead by constructing elements in-place.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ladybird",
        "hash": "e7b8f6fe48b10c7ed1cc493002d45b064cba780d",
        "author": "Andreas Kling",
        "date": "2021-07-06T12:24:51+02:00",
        "message": "LibGfx: Make Painter::fill_rect_with_checkerboard() faster\n\nWe now divide each scanline into prologue, aligned run, and epilogue.\nBasically, we draw enough pixels one-by-one until we reach a grid\nintersection. Then we draw full grid cell slices using fast memory\nfills. Finally we go back to one-by-one for the epilogue.\n\nThis is roughly 2.5x faster in a microbenchmark and no longer dominates\nthe ImageViewer and PixelPaint resizing profiles.",
        "modified_files_count": 1,
        "modified_files": [
            "Userland/Libraries/LibGfx/Painter.cpp"
        ],
        "github_commit_url": "https://github.com/LadybirdBrowser/ladybird/commit/e7b8f6fe48b10c7ed1cc493002d45b064cba780d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Painter::fill_rect_with_checkerboard"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy divides each scanline into prologue, aligned run, and epilogue to reduce the number of one-by-one pixel operations by leveraging faster memory fills for aligned grid cells.",
            "The optimization strategy divides each scanline into prologue, aligned run, and epilogue to minimize pixel-by-pixel drawing and maximize the use of fast memory fills for grid cell slices.",
            "The optimization strategy divides each scanline into prologue, aligned run, and epilogue to minimize pixel-by-pixel drawing and maximize the use of fast memory fills for grid cell slices.",
            "The optimization strategy divides each scanline into prologue, aligned run, and epilogue to reduce the number of one-by-one pixel operations by leveraging faster memory fills for grid cell slices.",
            "The optimization strategy divides each scanline into prologue, aligned run, and epilogue to reduce the number of one-by-one pixel operations by leveraging faster memory fills for grid cell slices."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy divides each scanline into prologue, aligned run, and epilogue to reduce the number of one-by-one pixel operations by leveraging faster memory fills for grid cell slices.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "oneDNN",
        "hash": "7570fb07272aae0fc3e7bf03173c59a8baff0e03",
        "author": "Wierschem, Keola",
        "date": "2021-01-19T10:01:49-08:00",
        "message": "cpu: x64: fix performance regression for depthwise convolution on avx512_core+",
        "modified_files_count": 1,
        "modified_files": [
            "src/cpu/x64/jit_brgemm_conv_utils.cpp"
        ],
        "github_commit_url": "https://github.com/oneapi-src/oneDNN/commit/7570fb07272aae0fc3e7bf03173c59a8baff0e03",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "init_jcp"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the initialization logic in `init_jcp` to improve performance for depthwise convolution on AVX512_CORE+ architectures.",
            "The optimization strategy involved restructuring the initialization logic in the `init_jcp` function to improve performance for depthwise convolution on AVX512_CORE+ architectures.",
            "The optimization strategy involved restructuring the initialization logic in `init_jcp` to improve performance for depthwise convolution on AVX512_CORE+ architectures.",
            "The optimization strategy involved restructuring the initialization logic in `init_jcp` to improve performance for depthwise convolution on AVX512_CORE+ architectures.",
            "The optimization strategy involved restructuring the initialization logic in the `init_jcp` function to improve performance for depthwise convolution on AVX512_CORE+ architectures."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the initialization logic in `init_jcp` to improve performance for depthwise convolution on AVX512_CORE+ architectures.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cryptominisat",
        "hash": "9846dfa821eaba98556192ab9c32be4011846568",
        "author": "Mate Soos",
        "date": "2010-12-28T22:17:10+01:00",
        "message": "It's unreasonable to turn off all optimisation for sub-problems\n\nSo only turning off sub-problem finding and forcing a faster start-up\nthrough library-type startup",
        "modified_files_count": 1,
        "modified_files": [
            "Solver/PartHandler.cpp"
        ],
        "github_commit_url": "https://github.com/msoos/cryptominisat/commit/9846dfa821eaba98556192ab9c32be4011846568",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PartHandler::configureNewSolver"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves selectively disabling sub-problem finding and enabling a faster library-type startup to improve solver initialization performance.",
            "The optimization strategy involves selectively disabling sub-problem finding and enabling faster startup for library-type usage without turning off all optimizations.",
            "The optimization strategy involves selectively disabling sub-problem finding and enabling a faster library-type startup to improve solver initialization performance.",
            "The optimization strategy involves selectively disabling sub-problem finding and enabling faster startup configurations for library-type usage without turning off all optimizations.",
            "The optimization strategy involves selectively disabling sub-problem finding and enabling a faster library-type startup to improve solver initialization performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves selectively disabling sub-problem finding and enabling a faster library-type startup to improve solver initialization performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Prima",
        "hash": "85030421afea5e81f71bb2cc2c9dfeeac9e411d1",
        "author": "dk",
        "date": "2003-03-07T13:47:21+00:00",
        "message": "- minor optimizations in the growMode handler routine, - additional\n  checks to eliminate void calls.",
        "modified_files_count": 1,
        "modified_files": [
            "Widget.c"
        ],
        "github_commit_url": "https://github.com/dk/Prima/commit/85030421afea5e81f71bb2cc2c9dfeeac9e411d1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "size_notify"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved refining the growMode handler by adding early exit conditions and eliminating unnecessary function calls to improve efficiency.",
            "The optimization strategy involved refining the growMode handler to reduce unnecessary function calls and improve conditional checks for better performance.",
            "The optimization strategy involved refining the growMode handler to reduce unnecessary function calls and improve conditional checks for better performance.",
            "The optimization strategy involved refining the growMode handler routine by adding early exit checks and eliminating unnecessary function calls.",
            "The optimization strategy involved refining the growMode handler routine by eliminating unnecessary function calls and adding checks to improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved refining the growMode handler routine by eliminating unnecessary function calls and adding checks to improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kate",
        "hash": "c59393a2610b103d79f3d7059a9748128f858917",
        "author": "Sven Brauch",
        "date": "2012-10-30T00:16:18+01:00",
        "message": "minimap: Draw line modification markers in the minimap if len(document) < 50k.\n\nThis works in an extra step, and will thus always display markers even\nif there's an unfortunate lineksip.\nThe length of the document is limited to 50k for performance reaons,\nsince every line must be queried.",
        "modified_files_count": 1,
        "modified_files": [
            "part/view/kateviewhelpers.cpp"
        ],
        "github_commit_url": "https://github.com/KDE/kate/commit/c59393a2610b103d79f3d7059a9748128f858917",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "KateScrollBar::updatePixmap"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy limits the processing of line modification markers to documents with fewer than 50k lines to reduce performance overhead.",
            "The optimization strategy limits the processing of line modification markers to documents with fewer than 50k lines to reduce performance overhead.",
            "The optimization strategy limits the processing of line modification markers to documents with fewer than 50k lines to reduce performance overhead.",
            "The optimization strategy limits the processing of line modification markers to documents with fewer than 50k lines to reduce performance overhead.",
            "The optimization strategy limits the processing of line modification markers to documents with fewer than 50k lines to reduce performance overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy limits the processing of line modification markers to documents with fewer than 50k lines to reduce performance overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cachegrand",
        "hash": "6c24b26f91a792627a7fc1383004aae22b76fbd8",
        "author": "Daniele Salvatore Albano",
        "date": "2022-07-01T20:21:54+02:00",
        "message": "Refactor the redis get command to improve how the small data are sent back to the client (to avoid useless fiber context switch)",
        "modified_files_count": 1,
        "modified_files": [
            "src/network/protocol/redis/command/network_protocol_redis_command_get.c"
        ],
        "github_commit_url": "https://github.com/danielealbano/cachegrand/commit/6c24b26f91a792627a7fc1383004aae22b76fbd8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "NETWORK_PROTOCOL_REDIS_COMMAND_FUNCPTR_COMMAND_END"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy refactors the Redis GET command to send small data directly to the client, avoiding unnecessary fiber context switches.",
            "The optimization strategy avoids unnecessary fiber context switches when sending small data back to the client in the Redis GET command.",
            "The optimization strategy refactors the Redis GET command to avoid unnecessary fiber context switches when sending small data back to the client.",
            "The optimization strategy refactors the Redis GET command to reduce unnecessary fiber context switches when sending small data to clients.",
            "The optimization strategy refactors the Redis GET command to send small data directly to the client, avoiding unnecessary fiber context switches."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy refactors the Redis GET command to avoid unnecessary fiber context switches when sending small data back to the client.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "SWIFT",
        "hash": "6be06310230872c7bfa991c668cc9481ea112af8",
        "author": "Matthieu Schaller",
        "date": "2018-11-15T22:25:22+01:00",
        "message": "Do not use the threadpool parallelization for the waiting and unpacking of cell proxies.",
        "modified_files_count": 1,
        "modified_files": [
            "src/proxy.c"
        ],
        "github_commit_url": "https://github.com/SWIFTSIM/SWIFT/commit/6be06310230872c7bfa991c668cc9481ea112af8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "proxy_cells_exchange"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids using threadpool parallelization for waiting and unpacking cell proxies to reduce overhead.",
            "The optimization strategy avoids using threadpool parallelization for waiting and unpacking cell proxies to reduce overhead.",
            "The optimization strategy avoids using threadpool parallelization for waiting and unpacking cell proxies to reduce overhead.",
            "The optimization strategy avoids using threadpool parallelization for waiting and unpacking cell proxies to reduce overhead.",
            "The optimization strategy avoids using threadpool parallelization for waiting and unpacking cell proxies to reduce overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids using threadpool parallelization for waiting and unpacking cell proxies to reduce overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "81cf1ade0bb3a42023dd1694ed080c4adb7dafd3",
        "author": "David S. Miller",
        "date": "2023-05-17T08:38:42+01:00",
        "message": "Merge branch 'tcp-io_uring-zc-opts'\n\nMerge branch 'tcp-io_uring-zc-opts'\n\nPavel Begunkov says:\n\n====================\nminor tcp io_uring zc optimisations\n\nPatch 1 is a simple cleanup, patch 2 gives removes 2 atomics from the\nio_uring zc TCP submission path, which yielded extra 0.5% for my\nthroughput CPU bound tests based on liburing/examples/send-zerocopy.c\n====================\n\nReviewed-by: David Ahern <dsahern@kernel.org>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "net/ipv4/tcp.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/81cf1ade0bb3a42023dd1694ed080c4adb7dafd3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tcp_sendmsg_locked"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing two atomic operations from the io_uring zero-copy TCP submission path to improve throughput in CPU-bound scenarios.",
            "The optimization strategy involved removing two atomic operations from the io_uring zero-copy TCP submission path to improve throughput in CPU-bound scenarios.",
            "The optimization strategy involved removing two atomic operations from the io_uring zero-copy TCP submission path to improve throughput in CPU-bound scenarios.",
            "The optimization strategy involved removing two atomic operations from the io_uring zero-copy TCP submission path to improve throughput in CPU-bound scenarios.",
            "The optimization strategy involved removing two atomic operations from the io_uring zero-copy TCP submission path to improve throughput in CPU-bound scenarios."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing two atomic operations from the io_uring zero-copy TCP submission path to improve throughput in CPU-bound scenarios.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "primecount",
        "hash": "1f519a643dbc65c21543c87754bdbfd232ca8c4c",
        "author": "kimwalisch",
        "date": "2021-02-22T22:04:08+01:00",
        "message": "Speed up tiny computations",
        "modified_files_count": 1,
        "modified_files": [
            "src/phi.cpp"
        ],
        "github_commit_url": "https://github.com/kimwalisch/primecount/commit/1f519a643dbc65c21543c87754bdbfd232ca8c4c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PhiCache"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations in small cases by caching and reusing results.",
            "The optimization strategy involved reducing unnecessary computations in small input cases by adding early exit conditions.",
            "The optimization strategy involved reducing unnecessary computations in small input cases by adding early exit conditions.",
            "The optimization strategy involved reducing unnecessary computations in small cases by caching and reusing results.",
            "The optimization strategy involved reducing unnecessary computations in small cases by caching and reusing previously computed values."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations in small cases by caching and reusing results.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "b306320322c9cfaa465bc2c7367acf6072b1ac0e",
        "author": "Nicolas Saenz Julienne",
        "date": "2021-02-12T12:41:59+00:00",
        "message": "spi: Skip zero-length transfers in spi_transfer_one_message()\n\nWith the introduction of 26751de25d25 (\"spi: bcm2835: Micro-optimise\nFIFO loops\") it has become apparent that some users might initiate\nzero-length SPI transfers. A fact the micro-optimization omitted, and\nwhich turned out to cause crashes[1].\n\nInstead of changing the micro-optimization itself, use a bigger hammer\nand skip zero-length transfers altogether for drivers using the default\ntransfer_one_message() implementation.\n\nReported-by: Phil Elwell <phil@raspberrypi.com>\nFixes: 26751de25d25 (\"spi: bcm2835: Micro-optimise FIFO loops\")\nSigned-off-by: Nicolas Saenz Julienne <nsaenzjulienne@suse.de>\n\n[1] https://github.com/raspberrypi/linux/issues/4100\nLink: https://lore.kernel.org/r/20210211180820.25757-1-nsaenzjulienne@suse.de\n\nSigned-off-by: Mark Brown <broonie@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/spi/spi.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/b306320322c9cfaa465bc2c7367acf6072b1ac0e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "transfer_one_message"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips zero-length SPI transfers in the default `transfer_one_message()` implementation to avoid unnecessary processing and potential crashes.",
            "The optimization strategy skips zero-length SPI transfers in the default `transfer_one_message()` implementation to avoid unnecessary processing and potential crashes.",
            "The optimization strategy skips zero-length SPI transfers in the default `transfer_one_message()` implementation to prevent crashes caused by unsupported zero-length operations.",
            "The optimization strategy skips zero-length SPI transfers in the default `transfer_one_message()` implementation to prevent crashes and improve performance by avoiding unnecessary operations.",
            "The optimization strategy skips zero-length SPI transfers in the default `transfer_one_message()` implementation to avoid unnecessary processing and potential crashes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips zero-length SPI transfers in the default `transfer_one_message()` implementation to avoid unnecessary processing and potential crashes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "openldap",
        "hash": "bf61a1ca9d10afd4ae0fb9779b45ec81a9f839cc",
        "author": "Howard Chu",
        "date": "2001-12-15T23:21:37+00:00",
        "message": "Use DB_HASH instead of DB_BTREE for index databases. Since index keys are\nmainly 4-byte hashes already, there is no locality-of-reference to exploit\nas a Btree. About a 7% performance gain.",
        "modified_files_count": 1,
        "modified_files": [
            "servers/slapd/back-bdb/dbcache.c"
        ],
        "github_commit_url": "https://github.com/openldap/openldap/commit/bf61a1ca9d10afd4ae0fb9779b45ec81a9f839cc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bdb_db_cache"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved switching from DB_BTREE to DB_HASH for index databases, leveraging the fact that index keys are already 4-byte hashes with no locality-of-reference benefits for BTREE.",
            "The optimization strategy involved switching from DB_BTREE to DB_HASH for index databases, leveraging the fact that index keys are already 4-byte hashes to achieve a 7% performance gain.",
            "The optimization strategy replaced DB_BTREE with DB_HASH for index databases to better suit the 4-byte hash keys and eliminate unnecessary locality-of-reference exploitation.",
            "The optimization strategy involved switching from DB_BTREE to DB_HASH for index databases, leveraging the fact that index keys are already 4-byte hashes and thus do not benefit from B-tree's locality-of-reference.",
            "The optimization strategy involved switching from DB_BTREE to DB_HASH for index databases to better suit the 4-byte hash keys and eliminate unnecessary locality-of-reference exploitation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved switching from DB_BTREE to DB_HASH for index databases, leveraging the fact that index keys are already 4-byte hashes with no locality-of-reference benefits for BTREE.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "valgrind-macos",
        "hash": "e5f66a2aa00fa88ba3e0fb004510f0a630881ef1",
        "author": "Julian Seward",
        "date": "2021-07-13T09:07:45+02:00",
        "message": "Reimplement h_generic_calc_GetMSBs8x16 to be more efficient.\n\nh_generic_calc_GetMSBs8x16 concatenates the top bit of each 8-bit lane in a\n128-bit value, producing a 16-bit scalar value.  (It is PMOVMSKB, really).\nThe existing implementation is excessively inefficient and shows up sometimes\nin 'perf' profiles of V.  This commit replaces it with a logarithmic (4-stage)\nalgorithm which is hopefully much faster.",
        "modified_files_count": 1,
        "modified_files": [
            "VEX/priv/host_generic_simd128.c"
        ],
        "github_commit_url": "https://github.com/LouisBrunner/valgrind-macos/commit/e5f66a2aa00fa88ba3e0fb004510f0a630881ef1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "h_generic_calc_GetMSBs8x16"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced an inefficient linear algorithm with a logarithmic (4-stage) approach to improve the performance of extracting the most significant bits from a 128-bit value.",
            "The optimization strategy replaced an inefficient linear algorithm with a logarithmic (4-stage) approach to improve the performance of extracting the most significant bits from a 128-bit value.",
            "The optimization strategy replaced an inefficient linear algorithm with a logarithmic (4-stage) approach to improve the performance of extracting the most significant bits from a 128-bit value.",
            "The optimization strategy replaced an inefficient linear algorithm with a logarithmic (4-stage) approach to improve the performance of extracting the most significant bits from a 128-bit value.",
            "The optimization strategy replaced an inefficient linear algorithm with a logarithmic (4-stage) approach to improve the performance of extracting the most significant bits from a 128-bit value."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced an inefficient linear algorithm with a logarithmic (4-stage) approach to improve the performance of extracting the most significant bits from a 128-bit value.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "25c456719d40272e5da224021cdddc76bdc48840",
        "author": "Liang Chen",
        "date": "2024-02-21T10:19:27+08:00",
        "message": "clk: rockchip: rv1106: optimize calibrate step for cru pvtpll\n\nThe frequency of pvtpll may unstable when calibrate, if the step\nis too small, it will stride a too big length and adjust back\nagain, that is bad.\n\nSigned-off-by: Liang Chen <cl@rock-chips.com>\nChange-Id: I96227b37cde45ae86df68777da8f32467f8926e6",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/clk/rockchip/clk-rv1106.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/25c456719d40272e5da224021cdddc76bdc48840",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_cru_pvtpll_calibrate"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization adjusts the calibration step size for a clock controller to prevent instability caused by overly small steps leading to oscillations.",
            "The optimization strategy involved adjusting the calibration step size for the CRU PVTPLL to prevent instability caused by overly small steps leading to excessive adjustments.",
            "The optimization adjusts the calibration step size for the CRU PVTPLL to improve stability by avoiding excessive oscillations during frequency adjustments.",
            "The optimization strategy involved adjusting the calibration step size for the CRU PVTPLL to prevent instability caused by overly small steps leading to excessive adjustments.",
            "The optimization adjusts the calibration step size for the CRU PVTPLL to improve stability by avoiding excessive adjustments."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization adjusts the calibration step size for the CRU PVTPLL to improve stability by avoiding excessive adjustments.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "6ceb712e2699a493da544b1755f6f73d62930f9b",
        "author": "Richard Biener",
        "date": "2021-03-10T13:13:51+01:00",
        "message": "tree-optimization/99510 - fix type reuse of build_aligned_type\n\nThe fix for PR94775 added more strict checking for type reuse\nto check_aligned_type, specifically matching TYPE_USER_ALIGN.\nBut then build_aligned_type sets TYPE_USER_ALIGN on the built\nvariant so if the type we build an aligned variant for does not\nhave TYPE_USER_ALIGN we'll never re-use the newly created aligned\nvariant.  This results in ~35000 identical variants being created\nfor polyhedron doduc.\n\nThe following instead checks that the candidate has TYPE_USER_ALIGN set.\n\n2021-03-10  Richard Biener  <rguenther@suse.de>\n\n\tPR tree-optimization/99510\n\t* tree.c (check_aligned_type): Check that the candidate\n\thas TYPE_USER_ALIGN set instead of matching with the\n\toriginal type.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/tree.c"
        ],
        "github_commit_url": "https://github.com/Rust-GCC/gccrs/commit/6ceb712e2699a493da544b1755f6f73d62930f9b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "way"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "gccrs",
        "optimization_summary": [
            "The optimization strategy avoids redundant creation of identical type variants by refining the condition for reusing aligned types based on the TYPE_USER_ALIGN flag.",
            "The optimization strategy avoids redundant creation of identical aligned type variants by refining the reuse condition to check for TYPE_USER_ALIGN on candidates.",
            "The optimization strategy avoids redundant creation of identical aligned type variants by refining the reuse condition to check for TYPE_USER_ALIGN on candidates.",
            "The optimization strategy avoids redundant creation of identical type variants by refining the reuse condition for aligned types based on the TYPE_USER_ALIGN flag.",
            "The optimization strategy avoids redundant creation of identical type variants by refining the reuse condition for aligned types based on the TYPE_USER_ALIGN flag."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids redundant creation of identical type variants by refining the reuse condition for aligned types based on the TYPE_USER_ALIGN flag.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "notcurses",
        "hash": "449455cf4b2038fb5385946e8e6d2006d9480fb5",
        "author": "nick black",
        "date": "2020-12-30T01:59:58-05:00",
        "message": "microoptimize channels_blend() top half #1262",
        "modified_files_count": 1,
        "modified_files": [
            "src/lib/internal.h"
        ],
        "github_commit_url": "https://github.com/dankamongmen/notcurses/commit/449455cf4b2038fb5385946e8e6d2006d9480fb5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "channels_blend"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the logic in the `channels_blend` function to reduce unnecessary computations and improve performance.",
            "The optimization strategy involved simplifying the logic in the `channels_blend` function to reduce unnecessary operations and improve execution speed.",
            "The optimization strategy involved simplifying the logic in the `channels_blend` function to reduce unnecessary operations and improve execution speed.",
            "The optimization strategy involved simplifying the logic in the `channels_blend` function to reduce unnecessary operations and improve execution speed.",
            "The optimization strategy involved simplifying the logic in the `channels_blend` function to reduce unnecessary computations and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the logic in the `channels_blend` function to reduce unnecessary operations and improve execution speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ffmpeg",
        "hash": "cd460f4da04c05d6ba93ccbbe294e948768f0937",
        "author": "Michael Niedermayer",
        "date": "2019-08-12T08:45:07+02:00",
        "message": "avcodec/hnm4video: Optimize postprocess_current_frame()\n\nImproves: Timeout (220sec -> 108sec)\nImproves: 15570/clusterfuzz-testcase-minimized-ffmpeg_AV_CODEC_ID_HNM4_VIDEO_fuzzer-5085482213441536\n\nFound-by: continuous fuzzing process https://github.com/google/oss-fuzz/tree/master/projects/ffmpeg\nReviewed-by: Tomas Härdin <tjoppen@acc.umu.se>\nSigned-off-by: Michael Niedermayer <michael@niedermayer.cc>",
        "modified_files_count": 1,
        "modified_files": [
            "libavcodec/hnm4video.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/cd460f4da04c05d6ba93ccbbe294e948768f0937",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "postprocess_current_frame"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations and memory accesses within the `postprocess_current_frame` function by restructuring loops and minimizing unnecessary operations.",
            "The optimization strategy involved replacing a pixel-by-pixel processing loop with a more efficient block-based memory copy operation to reduce computational overhead.",
            "The optimization strategy involved reducing redundant computations and memory accesses within the postprocess_current_frame() function by restructuring loops and minimizing unnecessary operations.",
            "The optimization strategy involved reducing redundant computations within the postprocessing loop by caching and reusing previously computed values.",
            "The optimization strategy involved reducing redundant computations within the postprocessing loop by caching and reusing previously computed values."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations and memory accesses within the `postprocess_current_frame` function by restructuring loops and minimizing unnecessary operations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "1bc36b6426ae49139e9f56491db76b95921454d7",
        "author": "Jan Kara",
        "date": "2011-12-18T14:20:18+08:00",
        "message": "writeback: Include all dirty inodes in background writeback\n\nCurrent livelock avoidance code makes background work to include only inodes\nthat were dirtied before background writeback has started. However background\nwriteback can be running for a long time and thus excluding newly dirtied\ninodes can eventually exclude significant portion of dirty inodes making\nbackground writeback inefficient. Since background writeback avoids livelocking\nthe flusher thread by yielding to any other work, there is no real reason why\nbackground work should not include all dirty inodes so change the logic in\nwb_writeback().\n\nSigned-off-by: Jan Kara <jack@suse.cz>\nSigned-off-by: Wu Fengguang <fengguang.wu@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "fs/fs-writeback.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/1bc36b6426ae49139e9f56491db76b95921454d7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "wb_writeback"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy expands the scope of background writeback to include all dirty inodes, improving efficiency by avoiding the exclusion of newly dirtied inodes during long-running operations.",
            "The optimization strategy expands the scope of background writeback to include all dirty inodes, improving efficiency by avoiding the exclusion of newly dirtied inodes during prolonged operations.",
            "The optimization strategy broadens the scope of background writeback to include all dirty inodes, improving efficiency by avoiding the exclusion of newly dirtied inodes.",
            "The optimization strategy expands the scope of background writeback to include all dirty inodes, improving efficiency by avoiding the exclusion of newly dirtied inodes during prolonged operations.",
            "The optimization strategy expands the scope of background writeback to include all dirty inodes, improving efficiency by avoiding the exclusion of newly dirtied inodes during prolonged operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy expands the scope of background writeback to include all dirty inodes, improving efficiency by avoiding the exclusion of newly dirtied inodes during prolonged operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "scummvm",
        "hash": "a8e1340c45dcad45415a9699a153881c79f78cd9",
        "author": "Max Horn",
        "date": "2003-10-14T20:52:27+00:00",
        "message": "improved timer resolution -> this helps iMuse *a lot* on my system when there is load\n\nsvn-id: r10804",
        "modified_files_count": 1,
        "modified_files": [
            "common/timer.cpp"
        ],
        "github_commit_url": "https://github.com/scummvm/scummvm/commit/a8e1340c45dcad45415a9699a153881c79f78cd9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Timer::handler"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the timer resolution to reduce latency and enhance performance under load.",
            "The optimization strategy involved improving the timer resolution to enhance performance under load conditions.",
            "The optimization strategy involved improving the timer resolution to reduce latency and enhance performance under load.",
            "The optimization strategy involved improving the timer resolution to reduce latency and enhance performance under load.",
            "The optimization strategy involved improving the timer resolution to reduce latency and enhance performance under load."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the timer resolution to reduce latency and enhance performance under load.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "TheXTech",
        "hash": "630a2e6d19fc0163e06d90c6257cc2f2412b6072",
        "author": "ds-sloth",
        "date": "2024-12-20T14:57:23-05:00",
        "message": "blocks.cpp: PSwitch - make iBlock handling more efficient",
        "modified_files_count": 1,
        "modified_files": [
            "src/blocks.cpp"
        ],
        "github_commit_url": "https://github.com/TheXTech/TheXTech/commit/630a2e6d19fc0163e06d90c6257cc2f2412b6072",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PSwitch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop and condition checks to minimize redundant operations and improve the efficiency of `iBlock` handling.",
            "The optimization strategy involved restructuring the loop and condition checks to minimize redundant computations and improve the efficiency of `iBlock` handling.",
            "The optimization strategy involved restructuring the loop and condition checks to minimize redundant operations and improve the efficiency of `iBlock` handling.",
            "The optimization strategy involved restructuring the loop and condition checks to minimize redundant computations and improve the efficiency of `iBlock` handling.",
            "The optimization strategy involved restructuring the loop and condition checks to minimize redundant operations and improve the efficiency of `iBlock` handling."
        ],
        "is_generic_optimization": [
            false,
            true,
            true,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop and condition checks to minimize redundant operations and improve the efficiency of `iBlock` handling.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pulseaudio",
        "hash": "298bd0b0c674206f2ba7071943164c2cf699cbf3",
        "author": "Lennart Poettering",
        "date": "2009-04-07T00:47:55+02:00",
        "message": "adjust max_rewind/max_request whenever the latency changes",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/module-null-sink.c"
        ],
        "github_commit_url": "https://github.com/pulseaudio/pulseaudio/commit/298bd0b0c674206f2ba7071943164c2cf699cbf3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sink_update_requested_latency_cb"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves dynamically adjusting the max_rewind and max_request values in response to latency changes to improve resource allocation efficiency.",
            "The optimization strategy involves dynamically adjusting the `max_rewind` and `max_request` values in response to latency changes to improve resource allocation efficiency.",
            "The optimization strategy involves dynamically adjusting the max_rewind and max_request values in response to latency changes to improve resource allocation efficiency.",
            "The optimization strategy involves dynamically adjusting the max_rewind and max_request values in response to latency changes to improve resource allocation efficiency.",
            "The optimization strategy involves dynamically adjusting the max_rewind and max_request values in response to latency changes to improve resource allocation efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves dynamically adjusting the max_rewind and max_request values in response to latency changes to improve resource allocation efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "7878f98355cd88e6161875c98331c6d12bbefab3",
        "author": "Ming Lei",
        "date": "2022-11-16T14:48:59+00:00",
        "message": "UPSTREAM: blk-mq: don't touch ->tagset in blk_mq_get_sq_hctx\n\nblk_mq_run_hw_queues() could be run when there isn't queued request and\nafter queue is cleaned up, at that time tagset is freed, because tagset\nlifetime is covered by driver, and often freed after blk_cleanup_queue()\nreturns.\n\nSo don't touch ->tagset for figuring out current default hctx by the mapping\nbuilt in request queue, so use-after-free on tagset can be avoided. Meantime\nthis way should be fast than retrieving mapping from tagset.\n\nBug: 254441685\nCc: \"yukuai (C)\" <yukuai3@huawei.com>\nCc: Jan Kara <jack@suse.cz>\nFixes: b6e68ee82585 (\"blk-mq: Improve performance of non-mq IO schedulers with multiple HW queues\")\nSigned-off-by: Ming Lei <ming.lei@redhat.com>\nReviewed-by: Jan Kara <jack@suse.cz>\nLink: https://lore.kernel.org/r/20220522122350.743103-1-ming.lei@redhat.com\nSigned-off-by: Jens Axboe <axboe@kernel.dk>\n(cherry picked from commit 5d05426e2d5fd7df8afc866b78c36b37b00188b7)\nSigned-off-by: Lee Jones <joneslee@google.com>\nChange-Id: Ifebb3d15ddfab0b41d8f30b556969ac68058ca8b",
        "modified_files_count": 1,
        "modified_files": [
            "block/blk-mq.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/7878f98355cd88e6161875c98331c6d12bbefab3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "from"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids a potential use-after-free error by retrieving the mapping from the request queue instead of accessing the tagset, which also improves performance.",
            "The optimization avoids accessing freed memory by using an alternative mapping to determine the default hardware context, which also improves performance.",
            "The optimization avoids accessing freed memory by using an alternative mapping to determine the default hardware context, which also improves performance.",
            "The optimization avoids accessing the potentially freed `->tagset` by using the mapping built in the request queue, which prevents use-after-free errors and improves performance.",
            "The optimization avoids accessing a potentially freed `tagset` by using an alternative mapping built in the request queue, which also improves performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids accessing a potentially freed `tagset` by using an alternative mapping built in the request queue, which also improves performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "c4ad247b7aa09f2fd9c90c92a23eeebe5c72f256",
        "author": "Andrew Gallatin",
        "date": "2020-03-30T23:29:53+00:00",
        "message": "KTLS: Coalesce adjacent TLS trailers & headers to improve PCIe bus efficiency\n\nKTLS uses the embedded header and trailer fields of unmapped\nmbufs. This can lead to \"silly\" buffer lengths, where we have an\nmbuf chain that will create a scatter/gather lists with a\nregular pattern of 13 bytes followed by 16 bytes between each\nadjacent TLS record.\n\nFor software ktls we typically wind up with a pattern where we\nhave several TLS records encrypted, and made ready at once. When\nthese records are made ready, we can coalesce these silly buffers\nin sbready_compress by copying 13b TLS header of the next record\ninto the 16b TLS trailer of the current record. After doing so,\nwe now have a small 29 byte chunk between each TLS record.\n\nThis marginally increases PCIe bus efficiency. We've seen an\nalmost 1Gb/s increase in peak throughput on Broadwell based Xeons\nrunning a 100% software TLS workload with Mellanox ConnectX-4\nNICs.\n\nNote that this change is ifdef'ed for KTLS, as KTLS is currently\nthe only user of the hdr/trailer feature of unmapped mbufs, and\npeeking into them is expensive, since the ext_pgs struct lives in\nseparately allocated memory, and may be cold in cache.\n\nThis optimization is not applicable to HW (\"NIC\") TLS, as that\ndepends on having the entire TLS record described by a single\nunmapped mbuf, so we cannot shift parts of the record between\nmbufs for HW TLS.\n\nReviewed by:\tjhb, hselasky, scottl\nSponsored by:\tNetflix\nDifferential Revision:\thttps://reviews.freebsd.org/D24204",
        "modified_files_count": 1,
        "modified_files": [
            "sys/kern/uipc_sockbuf.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/c4ad247b7aa09f2fd9c90c92a23eeebe5c72f256",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sbcompress"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy coalesces adjacent TLS headers and trailers in mbuf chains to reduce scatter/gather list fragmentation, improving PCIe bus efficiency.",
            "The optimization coalesces adjacent TLS headers and trailers in mbuf chains to reduce scatter/gather list fragmentation, improving PCIe bus efficiency.",
            "The optimization coalesces adjacent TLS headers and trailers in mbuf chains to reduce scatter/gather list fragmentation, improving PCIe bus efficiency.",
            "The optimization strategy coalesces adjacent TLS headers and trailers in mbuf chains to reduce scatter/gather list fragmentation, improving PCIe bus efficiency.",
            "The optimization strategy coalesces adjacent TLS headers and trailers in mbuf chains to reduce scatter/gather list fragmentation, improving PCIe bus efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy coalesces adjacent TLS headers and trailers in mbuf chains to reduce scatter/gather list fragmentation, improving PCIe bus efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "f989d315a85f7abc510a5497234984c8a6d0e9de",
        "author": "Jeff Muizelaar",
        "date": "2012-11-08T16:57:49-05:00",
        "message": "Bug 801437. Reimplement ensure_copy. r=ehsan\n\nThe previous implementation would copy the entire file into memory which\nwould cause a huge amount of memory usage on when copying large files.\nThis version copies a block at a time to avoid this.",
        "modified_files_count": 1,
        "modified_files": [
            "toolkit/mozapps/update/updater/updater.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/f989d315a85f7abc510a5497234984c8a6d0e9de",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ensure_copy"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved changing the file copying mechanism from loading the entire file into memory to copying it in smaller blocks to reduce memory usage.",
            "The optimization strategy involved changing the file copying mechanism from loading the entire file into memory to copying it in smaller blocks to reduce memory usage.",
            "The optimization strategy involved changing the file copying mechanism from loading the entire file into memory to copying it in smaller blocks to reduce memory usage.",
            "The optimization strategy involved changing the file copying mechanism from loading the entire file into memory to processing it in smaller blocks to reduce memory usage.",
            "The optimization strategy involved changing the file copying mechanism from loading the entire file into memory to processing it in smaller blocks to reduce memory usage."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved changing the file copying mechanism from loading the entire file into memory to copying it in smaller blocks to reduce memory usage.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "9125969086bfa1bf804b246ea574a2329b06d2c5",
        "author": "Richard Biener",
        "date": "2023-11-06T15:27:47+01:00",
        "message": "tree-optimization/112405 - SIMD clone calls with (loop) mask\n\nThe following fixes the mask argument generation for SIMD clone\ncalls under either loop masking or when the actual call is not\nmasked but only a inbranch simd clone is available.  The issue\nwas that we tried to directly convert the vector mask to the\ncall argument type but SIMD clone masks require 1 or 0 (which\ncould be even float) values for mask elements so we have to\nresort to a VEC_COND_EXPR to generate them just like we do for\nregular passing of the mask.\n\n\tPR tree-optimization/112405\n\t* tree-vect-stmts.cc (vectorizable_simd_clone_call):\n\tProperly handle invariant and/or loop mask passing.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/tree-vect-stmts.cc"
        ],
        "github_commit_url": "https://github.com/Rust-GCC/gccrs/commit/9125969086bfa1bf804b246ea574a2329b06d2c5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vectorizable_simd_clone_call"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "gccrs",
        "optimization_summary": [
            "The optimization ensures proper handling of mask arguments for SIMD clone calls by using a VEC_COND_EXPR to generate valid mask values instead of directly converting the vector mask.",
            "The optimization ensures proper handling of mask arguments for SIMD clone calls by using a VEC_COND_EXPR to generate valid mask values instead of directly converting the vector mask.",
            "The optimization ensures proper handling of mask arguments for SIMD clone calls by using a VEC_COND_EXPR to generate valid mask values instead of directly converting the vector mask.",
            "The optimization ensures proper handling of mask arguments for SIMD clone calls by using a VEC_COND_EXPR to generate valid mask values instead of directly converting the vector mask.",
            "The optimization ensures proper handling of mask arguments for SIMD clone calls by using a VEC_COND_EXPR to generate valid mask values instead of directly converting the vector mask."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures proper handling of mask arguments for SIMD clone calls by using a VEC_COND_EXPR to generate valid mask values instead of directly converting the vector mask.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "86af5952a8470f96b53830372c64469cb7ce780c",
        "author": "Ming Lei",
        "date": "2019-02-15T08:40:11-07:00",
        "message": "block: loop: pass multi-page bvec to iov_iter\n\niov_iter is implemented on bvec itererator helpers, so it is safe to pass\nmulti-page bvec to it, and this way is much more efficient than passing one\npage in each bvec.\n\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Omar Sandoval <osandov@fb.com>\nSigned-off-by: Ming Lei <ming.lei@redhat.com>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/block/loop.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/86af5952a8470f96b53830372c64469cb7ce780c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "lo_rw_aio"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves passing multi-page bvecs to iov_iter instead of single-page bvecs to improve efficiency by reducing the number of iterations.",
            "The optimization strategy involves passing multi-page bvecs to iov_iter instead of single-page bvecs to reduce overhead and improve efficiency.",
            "The optimization strategy involves passing multi-page bvecs to iov_iter instead of single-page bvecs to reduce overhead and improve efficiency.",
            "The optimization strategy involves passing multi-page bvecs to iov_iter instead of single-page bvecs to improve efficiency by reducing the number of iterations.",
            "The optimization strategy involves passing multi-page bvecs to iov_iter instead of single-page bvecs to reduce overhead and improve efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves passing multi-page bvecs to iov_iter instead of single-page bvecs to reduce overhead and improve efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "seqan3",
        "hash": "1ac7b8a996fea356e43352a196638c068dbf69de",
        "author": "Svenja Mehringer",
        "date": "2022-11-28T14:49:23+01:00",
        "message": "Merge pull request #3104 from smehringer/io_performance\n\n[FEATURE] Minor increase in FASTA performance.",
        "modified_files_count": 1,
        "modified_files": [
            "include/seqan3/io/sequence_file/format_fasta.hpp"
        ],
        "github_commit_url": "https://github.com/seqan/seqan3/commit/1ac7b8a996fea356e43352a196638c068dbf69de",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving FASTA parsing performance by reducing unnecessary memory operations or iterations within the sequence file handling logic.",
            "The optimization strategy involved improving the efficiency of reading and writing FASTA files by reducing unnecessary operations or streamlining existing ones.",
            "The optimization strategy involved improving FASTA parsing performance by reducing unnecessary memory operations or iterations within the sequence file handling logic.",
            "The optimization strategy involved improving the efficiency of reading and writing FASTA files by reducing unnecessary operations or streamlining existing logic in the code.",
            "The optimization strategy involved improving FASTA parsing performance by reducing unnecessary memory operations or iterations within the sequence file handling logic."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving FASTA parsing performance by reducing unnecessary memory operations or iterations within the sequence file handling logic.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gstreamer",
        "hash": "09952ddc4b29e384ca06fbe5c4e58a1012cc6395",
        "author": "Haihua Hu",
        "date": "2017-12-09T19:32:25+00:00",
        "message": "gl/effects: use non-PBO GLMemory for internal textures\n\nmiddle textures in gleffects do not need to use GstGLMemoryPBO as they\naren't transfering data to/from the GPU. This will cost too much DMA\nmemory and cause performance issue. Change the allocator to use non-PBO\nGstGLMemory.\n\nhttps://bugzilla.gnome.org/show_bug.cgi?id=776072",
        "modified_files_count": 1,
        "modified_files": [
            "ext/gl/gstgleffects.c"
        ],
        "github_commit_url": "https://github.com/GStreamer/gstreamer/commit/09952ddc4b29e384ca06fbe5c4e58a1012cc6395",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gst_gl_effects_gl_start"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids using PBO-backed GLMemory for internal textures to reduce unnecessary DMA memory usage and improve performance.",
            "The optimization avoids using PBO (Pixel Buffer Object) memory for internal textures in GL effects to reduce unnecessary DMA memory usage and improve performance.",
            "The optimization avoids using PBO (Pixel Buffer Object) memory for internal textures in GL effects to reduce unnecessary DMA memory usage and improve performance.",
            "The optimization avoids using PBO (Pixel Buffer Object) memory for internal textures in GL effects to reduce DMA memory overhead and improve performance.",
            "The optimization avoids using PBO-based GLMemory for internal textures to reduce unnecessary DMA memory overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids using PBO (Pixel Buffer Object) memory for internal textures in GL effects to reduce DMA memory overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "perfetto",
        "hash": "9d10749af73dd56350fc35ee2eb0e0d3db2a170b",
        "author": "Lalit Maganti",
        "date": "2022-05-23T22:25:16+00:00",
        "message": "Merge \"tp: speed up multi-step clock resolution by 10x\" am: 3aded8458e am: 88d8b4c255 am: 270726f7e2 am: 1fe1931610\n\nOriginal change: https://android-review.googlesource.com/c/platform/external/perfetto/+/2102685\n\nChange-Id: I6d5b74b7cf1e29fc68df9b47da292ec367a04a25\nSigned-off-by: Automerger Merge Worker <android-build-automerger-merge-worker@system.gserviceaccount.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/trace_processor/importers/common/clock_tracker.cc"
        ],
        "github_commit_url": "https://github.com/google/perfetto/commit/9d10749af73dd56350fc35ee2eb0e0d3db2a170b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ClockTracker::FindPath"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of multi-step clock resolution by restructuring the pathfinding logic to reduce computational overhead.",
            "The optimization strategy involved improving the efficiency of multi-step clock resolution by restructuring the path-finding logic to reduce computational overhead.",
            "The optimization strategy involved improving the efficiency of multi-step clock resolution by restructuring the path-finding algorithm to reduce computational overhead.",
            "The optimization strategy involved improving the efficiency of multi-step clock resolution by restructuring the path-finding logic to reduce computational overhead.",
            "The optimization strategy involved improving the efficiency of multi-step clock resolution by restructuring the path-finding logic to reduce computational overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of multi-step clock resolution by restructuring the path-finding logic to reduce computational overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "KnobKraft-orm",
        "hash": "1555fe4af060b1cfc8265fe8dff50d6f59d68040",
        "author": "Christof Ruch",
        "date": "2023-10-14T15:09:10+02:00",
        "message": "[fix] Trying to accelerate the glow effect on Mac by setting buffered image to true. No idea if that works.",
        "modified_files_count": 1,
        "modified_files": [
            "The-Orm/PatchHolderButton.cpp"
        ],
        "github_commit_url": "https://github.com/christofmuc/KnobKraft-orm/commit/1555fe4af060b1cfc8265fe8dff50d6f59d68040",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PatchHolderButton::setGlow"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization attempts to improve rendering performance by enabling buffered image rendering for a glow effect.",
            "The optimization strategy involved enabling buffering for an image to potentially improve rendering performance of the glow effect on Mac.",
            "The optimization strategy involved enabling buffering for an image to potentially improve rendering performance of the glow effect on Mac.",
            "The optimization strategy involved enabling buffering for an image to potentially improve rendering performance of the glow effect on Mac.",
            "The optimization strategy involved enabling buffered image rendering to potentially improve the performance of the glow effect on Mac."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved enabling buffering for an image to potentially improve rendering performance of the glow effect on Mac.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "tensorflow",
        "hash": "41cc606be8dbdc2555236e069711d4c91f00efb9",
        "author": "A. Unique TensorFlower",
        "date": "2019-04-18T04:00:41-07:00",
        "message": "Improve performance of HloValue::SetPositionsAndComputeUses\n\nPreviously it called HloInstruction::OperandIndices what constructed a\nstd::vector with the indices what was unnecessary as we can iterate over\nthe list of operands directly instead.\nPiperOrigin-RevId: 244161260",
        "modified_files_count": 1,
        "modified_files": [
            "tensorflow/compiler/xla/service/hlo_value.cc"
        ],
        "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/41cc606be8dbdc2555236e069711d4c91f00efb9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HloValue::SetPositionsAndComputeUses"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing the construction of an unnecessary std::vector with direct iteration over the list of operands to reduce overhead.",
            "The optimization strategy involved replacing the construction of an unnecessary std::vector with direct iteration over the list of operands to reduce overhead.",
            "The optimization strategy involved replacing the construction of an unnecessary std::vector with direct iteration over the list of operands to reduce overhead.",
            "The optimization avoids unnecessary construction of a std::vector by directly iterating over the list of operands.",
            "The optimization strategy involved replacing the construction of an unnecessary std::vector with direct iteration over the list of operands to reduce overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing the construction of an unnecessary std::vector with direct iteration over the list of operands to reduce overhead.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "bitcoin",
        "hash": "4fbae77929e6344bc49ab60af10a9c5ff21d2cdf",
        "author": "Marcos Mayorga",
        "date": "2017-04-28T09:33:34+01:00",
        "message": "Improved efficiency in COutPoint constructors",
        "modified_files_count": 1,
        "modified_files": [
            "src/primitives/transaction.h"
        ],
        "github_commit_url": "https://github.com/bitcoin/bitcoin/commit/4fbae77929e6344bc49ab60af10a9c5ff21d2cdf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "COutPoint"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved modifying the `COutPoint` constructors to reduce unnecessary initializations and improve construction efficiency.",
            "The optimization strategy involved modifying the `COutPoint` constructors to reduce unnecessary initializations and improve construction efficiency.",
            "The optimization strategy involved modifying the COutPoint constructors to reduce unnecessary initializations and improve construction efficiency.",
            "The optimization strategy involved modifying the `COutPoint` constructors to reduce unnecessary initializations and improve construction efficiency.",
            "The optimization strategy involved modifying the `COutPoint` constructors to reduce unnecessary initializations and improve construction efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved modifying the `COutPoint` constructors to reduce unnecessary initializations and improve construction efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FEX",
        "hash": "d3ed9766e8e73e3445bacc6636eefa3c8678a96f",
        "author": "Ryan Houdek",
        "date": "2023-08-22T17:33:34-07:00",
        "message": "X86Tables: Optimize MOVLPD stores\n\nJust use the full register size and store the lower bits.",
        "modified_files_count": 1,
        "modified_files": [
            "FEXCore/Source/Interface/Core/X86Tables/SecondaryTables.cpp"
        ],
        "github_commit_url": "https://github.com/FEX-Emu/FEX/commit/d3ed9766e8e73e3445bacc6636eefa3c8678a96f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "InitializeSecondaryTables"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves using the full register size for MOVLPD stores and only storing the lower bits, reducing unnecessary memory operations.",
            "The optimization strategy involves using the full register size for MOVLPD stores and only storing the lower bits to improve performance.",
            "The optimization strategy involves using the full register size for MOVLPD stores and only storing the lower bits, reducing unnecessary memory operations.",
            "The optimization strategy involved modifying the MOVLPD instruction handling to use the full register size and store only the lower bits, reducing unnecessary data processing.",
            "The optimization strategy involves using the full register size and storing only the lower bits to improve MOVLPD store operations."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves using the full register size for MOVLPD stores and only storing the lower bits, reducing unnecessary memory operations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "novacoin",
        "hash": "544c4cb58b22d25f92f2ea5e77f29fee44845ca6",
        "author": "CryptoManiac",
        "date": "2015-04-01T23:31:57+03:00",
        "message": "Another kernel scanning optimization\n\nThere is no sense of continuous hashing of full 28 bytes sequence because first 24 bytes of kernel are static. Pre-calculate midstate from first 24 bytes instead to avoid unnecessary operations.\n\n~33% performance boost",
        "modified_files_count": 1,
        "modified_files": [
            "src/kernel.cpp"
        ],
        "github_commit_url": "https://github.com/novacoin-project/novacoin/commit/544c4cb58b22d25f92f2ea5e77f29fee44845ca6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ScanInputForStakeKernelHash"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy pre-calculates the midstate of the first 24 static bytes to avoid redundant hashing operations on the full 28-byte sequence.",
            "The optimization strategy pre-calculates the midstate of the first 24 static bytes to avoid redundant hashing operations on the full 28-byte sequence.",
            "The optimization strategy pre-calculates the midstate of the first 24 static bytes to avoid redundant hashing operations on the full 28-byte sequence.",
            "The optimization strategy pre-calculates the midstate of the first 24 static bytes to avoid redundant hashing operations on the full 28-byte sequence.",
            "The optimization strategy pre-calculates the midstate of the first 24 static bytes to avoid redundant hashing operations on the full 28-byte sequence."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy pre-calculates the midstate of the first 24 static bytes to avoid redundant hashing operations on the full 28-byte sequence.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "open_evse",
        "hash": "c6ddbe1ed526a010fa9537f0e531976686078ccb",
        "author": "William McBrine",
        "date": "2015-10-17T15:00:51-04:00",
        "message": "Improved square root function -- much, much faster; same results; and it\nsaves 196 bytes of compiled program space, despite longer source code.",
        "modified_files_count": 1,
        "modified_files": [
            "J1772EvseController.cpp"
        ],
        "github_commit_url": "https://github.com/lincomatic/open_evse/commit/c6ddbe1ed526a010fa9537f0e531976686078ccb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ulong_sqrt"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved rewriting the square root function to use a more efficient algorithm, reducing both execution time and compiled program size.",
            "The optimization strategy involved replacing a potentially iterative or naive square root implementation with a more efficient algorithm, reducing both execution time and compiled code size.",
            "The optimization strategy involved replacing a standard square root implementation with a more efficient algorithm that reduces both execution time and compiled code size while maintaining correctness.",
            "The optimization strategy involved rewriting the square root function to use a more efficient algorithm, reducing both execution time and compiled code size.",
            "The optimization strategy involved replacing a potentially iterative or naive square root implementation with a more efficient algorithm, reducing both execution time and compiled code size."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a standard square root implementation with a more efficient algorithm that reduces both execution time and compiled code size while maintaining correctness.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "circt",
        "hash": "ffd49ba28c6f9938c2c6c71509e6dd5ce3574279",
        "author": "Andrew Young",
        "date": "2021-03-29T16:26:08-07:00",
        "message": "[FIRRTL] Nest CSE+Canon passes to run on FModuleOp\n\nThe compiler can parallelize pass which are running on distinct\nIsolatedFromAbove operations. Moving these passes to run on the\nFModuleOp will increase the ability of the compiler to parallelize their\nexecution. Since there are no operations under the CircuitOp other than\nFExtModule and FModule, this does should not change what gets CSE'd and\nCanonicalized.",
        "modified_files_count": 1,
        "modified_files": [
            "tools/firtool/firtool.cpp"
        ],
        "github_commit_url": "https://github.com/llvm/circt/commit/ffd49ba28c6f9938c2c6c71509e6dd5ce3574279",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "processBuffer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves restructuring the pass execution to improve parallelization by targeting FModuleOp instead of CircuitOp.",
            "The optimization strategy involves restructuring the execution of CSE and Canonicalization passes to operate on FModuleOp, enabling better parallelization by leveraging the compiler's ability to process distinct IsolatedFromAbove operations concurrently.",
            "The optimization strategy involves restructuring the execution of CSE and Canonicalization passes to operate on FModuleOp, enabling better parallelization by leveraging the compiler's ability to process distinct IsolatedFromAbove operations concurrently.",
            "The optimization strategy involves restructuring the execution of CSE and Canonicalization passes to operate on FModuleOp, enabling better parallelization by leveraging the compiler's ability to process distinct IsolatedFromAbove operations concurrently.",
            "The optimization strategy involves restructuring the execution of CSE and Canonicalization passes to operate on FModuleOp, enabling better parallelization by leveraging the compiler's ability to process distinct IsolatedFromAbove operations concurrently."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves restructuring the execution of CSE and Canonicalization passes to operate on FModuleOp, enabling better parallelization by leveraging the compiler's ability to process distinct IsolatedFromAbove operations concurrently.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "f3530f26f8e9869e6e8c3370cf6f61330774fe2b",
        "author": "Patrice Chotard",
        "date": "2021-04-19T14:18:43+01:00",
        "message": "spi: stm32-qspi: Trigger DMA only if more than 4 bytes to transfer\n\nIn order to optimize accesses to spi flashes, trigger a DMA only\nif more than 4 bytes has to be transferred.\n\nDMA transfer preparation's cost becomes negligible above 4 bytes to\ntransfer. Below this threshold, indirect transfer give more throughput.\n\nmtd_speedtest shows that page write throughtput increases :\n  - from 779 to 853 KiB/s (~9.5%) with s25fl512s SPI-NOR.\n  - from 5283 to 5666 KiB/s (~7.25%) with Micron SPI-NAND.\n\nSigned-off-by: Christophe Kerello <christophe.kerello@foss.st.com>\nSigned-off-by: Patrice Chotard <patrice.chotard@foss.st.com>\nLink: https://lore.kernel.org/r/20210419121541.11617-3-patrice.chotard@foss.st.com\nSigned-off-by: Mark Brown <broonie@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/spi/spi-stm32-qspi.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/f3530f26f8e9869e6e8c3370cf6f61330774fe2b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "stm32_qspi_tx"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids triggering DMA for small data transfers (≤4 bytes) to reduce overhead and improve throughput.",
            "The optimization strategy involves conditionally triggering DMA transfers only when the data size exceeds a 4-byte threshold to reduce overhead for smaller transfers.",
            "The optimization strategy involves triggering DMA only for transfers exceeding 4 bytes to reduce overhead and improve throughput for smaller transfers.",
            "The optimization strategy avoids triggering DMA for transfers of 4 bytes or less, leveraging indirect transfers for smaller data sizes to improve throughput.",
            "The optimization strategy involves conditionally triggering DMA transfers only when the data size exceeds a threshold (4 bytes), reducing overhead for smaller transfers."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves conditionally triggering DMA transfers only when the data size exceeds a threshold (4 bytes), reducing overhead for smaller transfers.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "embox",
        "hash": "5478c5fcd4bcc74c5da64238f86d3132c3dc755e",
        "author": "Denis Deryugin",
        "date": "2016-01-18T18:02:35+03:00",
        "message": "DumbFS: Speed up formatting\n\nNow write raw data to flash w/o buffer, now it's much faster",
        "modified_files_count": 1,
        "modified_files": [
            "src/fs/driver/dfs/dfs.c"
        ],
        "github_commit_url": "https://github.com/embox/embox/commit/5478c5fcd4bcc74c5da64238f86d3132c3dc755e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dfs_format"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved writing raw data directly to flash memory without using a buffer, reducing overhead and improving speed.",
            "The optimization strategy involved writing raw data directly to flash memory without using a buffer, reducing overhead and improving speed.",
            "The optimization strategy involved writing raw data directly to flash memory without using a buffer, reducing overhead and improving speed.",
            "The optimization strategy involved writing raw data directly to flash memory without using a buffer, reducing overhead and improving speed.",
            "The optimization strategy involved writing raw data directly to flash memory without using a buffer, reducing overhead and improving speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved writing raw data directly to flash memory without using a buffer, reducing overhead and improving speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "dolphin",
        "hash": "530475dce8d3c4e94e0737be0dc48757a78bc475",
        "author": "Sintendo",
        "date": "2021-03-07T18:29:12+01:00",
        "message": "Jit64: divwx - Micro-optimize certain divisors\n\nWhen the multiplier is positive (which is the most common case), we can\ngenerate slightly better code.\n\n- Division by 30307\nBefore:\n49 63 C5             movsxd      rax,r13d\n48 69 C0 65 6B 32 45 imul        rax,rax,45326B65h\n4C 8B C0             mov         r8,rax\n48 C1 E8 3F          shr         rax,3Fh\n49 C1 F8 2D          sar         r8,2Dh\n44 03 C0             add         r8d,eax\n\nAfter:\n49 63 C5             movsxd      rax,r13d\n4C 69 C0 65 6B 32 45 imul        r8,rax,45326B65h\nC1 E8 1F             shr         eax,1Fh\n49 C1 F8 2D          sar         r8,2Dh\n44 03 C0             add         r8d,eax",
        "modified_files_count": 1,
        "modified_files": [
            "Source/Core/Core/PowerPC/Jit64/Jit_Integer.cpp"
        ],
        "github_commit_url": "https://github.com/dolphin-emu/dolphin/commit/530475dce8d3c4e94e0737be0dc48757a78bc475",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Jit64::divwx"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to improve division operations by generating more efficient assembly code for specific divisors when the multiplier is positive.",
            "The optimization strategy used is to generate more efficient assembly code for division operations by positive multipliers, reducing instruction count and improving performance.",
            "The optimization strategy used is to generate more efficient assembly code for division operations by positive multipliers, reducing instruction count and improving performance.",
            "The optimization strategy used is to generate more efficient assembly code for division operations by positive multipliers, reducing instruction count and improving performance.",
            "The optimization strategy used is to generate more efficient assembly code for division operations by positive multipliers, reducing unnecessary instructions and improving performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is to generate more efficient assembly code for division operations by positive multipliers, reducing instruction count and improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "beetle-psx-libretro",
        "hash": "266fe63f417564a5626810e94b9285a283174a16",
        "author": "Alberto Fustinoni",
        "date": "2017-07-26T15:27:32+09:00",
        "message": "WinRT compilation, using performance counter to calculate time deltas, which should be more efficient",
        "modified_files_count": 1,
        "modified_files": [
            "libretro-common/rthreads/rthreads.c"
        ],
        "github_commit_url": "https://github.com/libretro/beetle-psx-libretro/commit/266fe63f417564a5626810e94b9285a283174a16",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_scond_wait_win32"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a less efficient time calculation method with a performance counter for more efficient time delta calculations.",
            "The optimization strategy involved replacing a less efficient time calculation method with a performance counter for more efficient time delta calculations.",
            "The optimization strategy involved replacing a less efficient time calculation method with a performance counter for more efficient time delta calculations.",
            "The optimization strategy involved replacing a less efficient time calculation method with a performance counter for more efficient time delta calculations.",
            "The optimization strategy involved replacing a less efficient time calculation method with a performance counter for more efficient time delta calculations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a less efficient time calculation method with a performance counter for more efficient time delta calculations.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "2949440afaedbf424c3c2f55b93674046731a70c",
        "author": "TheRealMoeder",
        "date": "2017-02-26T22:08:59+01:00",
        "message": "Improve timing of timer voice alerts",
        "modified_files_count": 1,
        "modified_files": [
            "src/timer.c"
        ],
        "github_commit_url": "https://github.com/DeviationTX/deviation/commit/2949440afaedbf424c3c2f55b93674046731a70c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TIMER_Update"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "deviation",
        "optimization_summary": [
            "The optimization strategy involved restructuring the timing logic for voice alerts to reduce redundant checks and improve execution efficiency.",
            "The optimization strategy involved restructuring the timing logic for voice alerts to reduce unnecessary computations and improve responsiveness.",
            "The optimization strategy involved restructuring the timing logic for voice alerts to reduce unnecessary computations and improve responsiveness.",
            "The optimization strategy involved restructuring the timing logic for timer voice alerts to reduce unnecessary computations and improve responsiveness.",
            "The optimization strategy involved restructuring the timing logic for voice alerts to reduce redundant checks and improve execution efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the timing logic for voice alerts to reduce unnecessary computations and improve responsiveness.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "server",
        "hash": "5fbd019220d4c46e4f8ad68f69daabccb87f3abe",
        "author": "osku",
        "date": "2006-05-23T11:35:58+00:00",
        "message": "Optimize BLOB selects by using prebuilt->blob_heap directly instead of first\nreading BLOB data to a temporary heap and then copying it to\nprebuilt->blob_heap.",
        "modified_files_count": 1,
        "modified_files": [
            "row/row0sel.c"
        ],
        "github_commit_url": "https://github.com/MariaDB/server/commit/5fbd019220d4c46e4f8ad68f69daabccb87f3abe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rec_get_offsets"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary data copying by directly using the prebuilt->blob_heap for BLOB selects instead of utilizing an intermediate temporary heap.",
            "The optimization avoids unnecessary data copying by directly using the prebuilt->blob_heap for BLOB selects instead of utilizing an intermediate temporary heap.",
            "The optimization avoids unnecessary data copying by directly using the prebuilt->blob_heap for BLOB selects instead of utilizing an intermediate temporary heap.",
            "The optimization avoids unnecessary data copying by directly using the prebuilt->blob_heap for BLOB selects instead of utilizing an intermediate temporary heap.",
            "The optimization avoids unnecessary data copying by directly using the prebuilt->blob_heap for BLOB selects instead of utilizing an intermediate temporary heap."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary data copying by directly using the prebuilt->blob_heap for BLOB selects instead of utilizing an intermediate temporary heap.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "3DWorld",
        "hash": "786b2603db86141c624703335a93a2aa1b60a858",
        "author": "Frank E. Gennari",
        "date": "2011-09-26T08:11:38+00:00",
        "message": "Moved the model3d texture load after the polygon addition to reduce the peak memory usage when loading large models. -FG",
        "modified_files_count": 1,
        "modified_files": [
            "src/object_file_reader.cpp"
        ],
        "github_commit_url": "https://github.com/fegennari/3DWorld/commit/786b2603db86141c624703335a93a2aa1b60a858",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "read"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reordering the texture loading operation to occur after polygon addition, reducing peak memory usage during model loading.",
            "The optimization strategy involved reordering the texture load operation to occur after polygon addition to reduce peak memory usage during model loading.",
            "The optimization strategy involved reordering the texture load operation to occur after polygon addition to reduce peak memory usage during model loading.",
            "The optimization strategy involved reordering the texture load operation to occur after polygon addition, reducing peak memory usage during model loading.",
            "The optimization strategy involved reordering the texture load operation to occur after polygon addition, reducing peak memory usage during model loading."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reordering the texture load operation to occur after polygon addition, reducing peak memory usage during model loading.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pachi",
        "hash": "bffd7bea76f7ce98bd69bc468fa0d93b93d6c431",
        "author": "lemonsqueeze",
        "date": "2023-09-10T16:39:09+02:00",
        "message": "board_group_find_extra_libs(): speedup\n\nfaster with move queue instead of bitmap,\nfixed logic so can shortcircuit.",
        "modified_files_count": 1,
        "modified_files": [
            "board_play.h"
        ],
        "github_commit_url": "https://github.com/pasky/pachi/commit/bffd7bea76f7ce98bd69bc468fa0d93b93d6c431",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "board_group_find_extra_libs"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a bitmap with a move queue to improve speed and enabled short-circuiting logic for faster execution.",
            "The optimization replaces a bitmap with a move queue and introduces short-circuit logic to improve the speed of the `board_group_find_extra_libs` function.",
            "The optimization strategy replaced a bitmap with a move queue and introduced short-circuit logic to improve the speed of the `board_group_find_extra_libs` function.",
            "The optimization strategy replaced a bitmap with a move queue and introduced short-circuiting logic to improve the performance of the `board_group_find_extra_libs` function.",
            "The optimization replaces a bitmap with a move queue and introduces short-circuit logic to improve the efficiency of finding extra liberties for a board group."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a bitmap with a move queue and introduced short-circuit logic to improve the speed of the `board_group_find_extra_libs` function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ceph",
        "hash": "bf20b661cb6a6a33d9e93fb44ad1470f9f8245d2",
        "author": "Zac Medico",
        "date": "2017-08-24T09:47:23-07:00",
        "message": "PGPool::update: avoid expensive union_of\n\nAchieve the same result using a swap (constant complexity),\nand an assignment (linear complexity).\n\nSigned-off-by: Zac Medico <zmedico@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/osd/PG.cc"
        ],
        "github_commit_url": "https://github.com/ceph/ceph/commit/bf20b661cb6a6a33d9e93fb44ad1470f9f8245d2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PGPool::update"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces an expensive union operation with a swap and assignment to reduce complexity.",
            "The optimization strategy replaces an expensive union operation with a swap and assignment to reduce complexity.",
            "The optimization replaces an expensive union operation with a swap and assignment to reduce complexity.",
            "The optimization strategy replaces an expensive union operation with a swap and assignment to reduce computational complexity.",
            "The optimization strategy replaces an expensive union operation with a swap and assignment to reduce complexity."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces an expensive union operation with a swap and assignment to reduce complexity.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "solvespace",
        "hash": "0a061b6f9ea8ea10414e04a6a87c14c6b12ad04b",
        "author": "phkahler",
        "date": "2020-09-22T16:30:03-04:00",
        "message": "NFC: Performance. For step-and-repeat groups, create the copies first (in parallel) and then combine them using unions of equal size shells to reduce the total time spent on booleans.",
        "modified_files_count": 1,
        "modified_files": [
            "src/groupmesh.cpp"
        ],
        "github_commit_url": "https://github.com/solvespace/solvespace/commit/0a061b6f9ea8ea10414e04a6a87c14c6b12ad04b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Group::GenerateForStepAndRepeat"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy parallelizes the creation of copies in step-and-repeat groups and combines them using unions of equal-sized shells to reduce boolean operation time.",
            "The optimization strategy parallelizes the creation of copies in step-and-repeat groups and combines them using unions of equal-sized shells to reduce boolean operation time.",
            "The optimization strategy parallelizes the creation of copies in step-and-repeat groups and combines them using unions of equal-sized shells to reduce boolean operation time.",
            "The optimization strategy parallelizes the creation of copies in step-and-repeat groups and combines them using unions of equal-sized shells to reduce boolean operation time.",
            "The optimization strategy parallelizes the creation of copies in step-and-repeat groups and combines them using unions of equal-sized shells to reduce boolean operation time."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy parallelizes the creation of copies in step-and-repeat groups and combines them using unions of equal-sized shells to reduce boolean operation time.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "cad845f4c0d63e21392191cbef32c9a860e86481",
        "author": "Jakob Stoklund Olesen",
        "date": "2011-07-28T20:48:23+00:00",
        "message": "Reverse order of RS_Split live ranges under -compact-regions.\n\nThere are two conflicting strategies in play:\n\n- Under high register pressure, we want to assign large live ranges\n  first. Smaller live ranges are easier to place afterwards.\n\n- Live range splitting is guided by interference, so splitting should be\n  deferred until interference is as realistic as possible.\n\nWith the recent changes to the live range stages, and with compact\nregions enabled, it is less traumatic to split a live range too early.\nIf some of the split products were too big, they can often be split\nagain.\n\nBy reversing the RS_Split order, we get this queue order:\n\n1. Normal live ranges, large to small.\n2. RS_Split live ranges, large to small.\n\nThe large-to-small order improves RAGreedy's puzzle solving skills under\nhigh register pressure. It may cause a bit more iterated splitting, but\nwe handle that better now.\n\nWith this change, -compact-regions is mostly an improvement on SPEC.\n\nllvm-svn: 136388",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/RegAllocGreedy.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/cad845f4c0d63e21392191cbef32c9a860e86481",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reverses the order of live range splitting to prioritize large-to-small processing, improving register allocation under high pressure while accommodating earlier splits.",
            "The optimization strategy reverses the order of live range splitting to prioritize large-to-small processing, improving register allocation under high pressure while accommodating earlier splits.",
            "The optimization strategy reverses the order of live range splitting to prioritize large-to-small processing, improving register allocation under high pressure while accommodating earlier splits.",
            "The optimization strategy reverses the order of live range splitting to prioritize large-to-small processing, improving register allocation under high pressure while accommodating earlier splits.",
            "The optimization strategy reverses the order of live range splitting to prioritize large-to-small processing, improving register allocation under high pressure while accommodating earlier splits."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reverses the order of live range splitting to prioritize large-to-small processing, improving register allocation under high pressure while accommodating earlier splits.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "vlc",
        "hash": "c23ae082099b52952db027123b047a09ab5d8744",
        "author": "Zhao Zhili",
        "date": "2018-02-07T22:08:00+01:00",
        "message": "demux: adaptive: buffering faster\n\nAssume a 60 FPS video, each call of demuxer->demux return one frame,\nthen the delay between each of demuxer->demux should not large than\n16.7ms. A 50ms delay makes the buffering level around i_min_buffering.\n\nSigned-off-by: Francois Cartegnie <fcvlcdev@free.fr>",
        "modified_files_count": 1,
        "modified_files": [
            "modules/demux/adaptive/PlaylistManager.cpp"
        ],
        "github_commit_url": "https://github.com/videolan/vlc/commit/c23ae082099b52952db027123b047a09ab5d8744",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PlaylistManager::Run"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces buffering delay by aligning the demuxer's frame processing time closer to the target frame interval for smoother playback.",
            "The optimization reduces buffering delay by aligning the demuxer's frame processing time with the target frame rate, ensuring timely delivery of frames.",
            "The optimization reduces buffering delay by aligning the demuxer's frame processing time closer to the target frame interval for smoother playback.",
            "The optimization reduces buffering delay by aligning the demuxer's frame processing time closer to the target frame interval for smoother playback.",
            "The optimization reduces buffering delay by aligning the demuxer's frame processing time closer to the target frame interval for smoother playback."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces buffering delay by aligning the demuxer's frame processing time closer to the target frame interval for smoother playback.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "media-driver",
        "hash": "55d1e8bceb0f8d3a4b1f128bb938a8506e5c5718",
        "author": "WalterBai",
        "date": "2024-01-26T15:51:19+08:00",
        "message": "[Encode] Improve effiiciency of Fast Dump usage\n\nImprove effiiciency of Fast Dump usage in 1D buffer dump.",
        "modified_files_count": 1,
        "modified_files": [
            "media_softlet/agnostic/common/codec/hal/codechal_debug.cpp"
        ],
        "github_commit_url": "https://github.com/intel/media-driver/commit/55d1e8bceb0f8d3a4b1f128bb938a8506e5c5718",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CodechalDebugInterface::CodechalDebugInterface"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant operations in the Fast Dump usage for 1D buffer dumps by improving the logic for handling buffer allocations and memory mappings.",
            "The optimization strategy involved reducing redundant operations or improving the efficiency of buffer handling during the 1D buffer dump process.",
            "The optimization strategy involved reducing redundant operations in the Fast Dump usage for 1D buffer dumps by improving the logic for handling buffer allocations and memory mappings.",
            "The optimization strategy involved reducing redundant operations in the Fast Dump usage for 1D buffer dumps by improving the logic for handling buffer allocations and memory writes.",
            "The optimization strategy involved reducing redundant operations in the Fast Dump usage for 1D buffer dumps by improving the logic for handling buffer allocations and memory mappings."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant operations in the Fast Dump usage for 1D buffer dumps by improving the logic for handling buffer allocations and memory mappings.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "177aa816abd6c737617a72ad86fc1734a2bae7b5",
        "author": "Jakub Onderka",
        "date": "2022-11-21T10:05:51+09:00",
        "message": "Remove checks if FAST_ZPP is supported as PHP7 supports them",
        "modified_files_count": 1,
        "modified_files": [
            "zstd.c"
        ],
        "github_commit_url": "https://github.com/kjdev/php-ext-zstd/commit/177aa816abd6c737617a72ad86fc1734a2bae7b5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ZEND_FUNCTION"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "php-ext-zstd",
        "optimization_summary": [
            "The optimization removes unnecessary checks for FAST_ZPP support since it is guaranteed to be supported in PHP7, reducing redundant conditional evaluations.",
            "The optimization removes unnecessary checks for FAST_ZPP support since PHP7 inherently supports it, reducing redundant condition evaluations.",
            "The optimization removes unnecessary checks for FAST_ZPP support since it is guaranteed to be supported in PHP7, reducing redundant conditional evaluations.",
            "The optimization removes unnecessary checks for FAST_ZPP support since PHP7 inherently supports it, reducing redundant condition evaluations.",
            "The optimization removes unnecessary checks for FAST_ZPP support since PHP7 inherently supports it, reducing redundant conditional evaluations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes unnecessary checks for FAST_ZPP support since PHP7 inherently supports it, reducing redundant conditional evaluations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "plasma-framework",
        "hash": "745eeeb79a615ad64488e1b9056f394af085b30f",
        "author": "Jacopo De Simoi",
        "date": "2009-04-22T22:53:48+00:00",
        "message": "Optimization:  don't bother running the performMatch if the context is already invalid.  \n\nsvn path=/trunk/KDE/kdelibs/; revision=957814",
        "modified_files_count": 1,
        "modified_files": [
            "private/runnerjobs.cpp"
        ],
        "github_commit_url": "https://github.com/KDE/plasma-framework/commit/745eeeb79a615ad64488e1b9056f394af085b30f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FindMatchesJob::run"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary execution of the `performMatch` function by checking if the context is already invalid before proceeding.",
            "The optimization strategy avoids unnecessary execution of the `performMatch` function by checking if the context is already invalid before proceeding.",
            "The optimization avoids unnecessary execution of the `performMatch` function by checking if the context is already invalid before proceeding.",
            "The optimization avoids unnecessary execution of the `performMatch` function by checking if the context is already invalid before proceeding.",
            "The optimization avoids unnecessary execution of the `performMatch` function by checking if the context is already invalid before proceeding."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary execution of the `performMatch` function by checking if the context is already invalid before proceeding.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "darktable",
        "hash": "68e3a70527436188826609568d6fb105bee20c1a",
        "author": "hanno@schwalm-bremen.de",
        "date": "2023-04-02T19:33:05+02:00",
        "message": "Subtle improvements for pixelpipe\n\n- avoid some clock reading\n- improved debugging output",
        "modified_files_count": 1,
        "modified_files": [
            "src/develop/pixelpipe_hb.c"
        ],
        "github_commit_url": "https://github.com/darktable-org/darktable/commit/68e3a70527436188826609568d6fb105bee20c1a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_dev_pixelpipe_process_rec"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing the frequency of clock readings and enhancing debugging output efficiency in the pixelpipe processing function.",
            "The optimization strategy avoids redundant clock readings and improves debugging output efficiency in the pixelpipe processing function.",
            "The optimization strategy involved reducing the frequency of clock readings and enhancing debugging output for better performance.",
            "The optimization strategy involved reducing the frequency of clock readings and enhancing debugging output efficiency in the pixelpipe processing function.",
            "The optimization strategy involved reducing the frequency of clock readings and refining debugging output to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the frequency of clock readings and enhancing debugging output efficiency in the pixelpipe processing function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "3a6b5236550c60fee371dbeaff43b61931e208ad",
        "author": "Steven Johnson",
        "date": "2010-06-03T10:35:26-07:00",
        "message": "Bug 527512 - ExprFilter missing trivial optimizations for ugt, ult (r=edwsmith,nnethercote)",
        "modified_files_count": 1,
        "modified_files": [
            "js/src/nanojit/LIR.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/3a6b5236550c60fee371dbeaff43b61931e208ad",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ExprFilter::ins2"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying or removing unnecessary greater-than (ugt) and less-than (ult) comparisons in the ExprFilter to improve performance.",
            "The optimization strategy involved simplifying or removing unnecessary greater-than (ugt) and less-than (ult) comparisons in the ExprFilter to improve performance.",
            "The optimization strategy involved simplifying or removing unnecessary greater-than (ugt) and less-than (ult) comparisons in the ExprFilter to improve performance.",
            "The optimization strategy involved simplifying or removing unnecessary logic in the `ExprFilter::ins2` function to handle trivial cases of unsigned greater-than (ugt) and unsigned less-than (ult) comparisons more efficiently.",
            "The optimization strategy involved simplifying or removing unnecessary greater-than (ugt) and less-than (ult) comparisons in the ExprFilter to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying or removing unnecessary greater-than (ugt) and less-than (ult) comparisons in the ExprFilter to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "glsl-optimizer",
        "hash": "b27eb7cb4f5b49b9e7c24deb6c1fb52908f63703",
        "author": "Brian Paul",
        "date": "2009-01-11T15:11:00-07:00",
        "message": "cell: re-order the z/stencil fetch/extract/convert instructions for better perf\n\nThe new instruction order is 10 cycles faster.",
        "modified_files_count": 1,
        "modified_files": [
            "src/gallium/drivers/cell/ppu/cell_gen_fragment.c"
        ],
        "github_commit_url": "https://github.com/aras-p/glsl-optimizer/commit/b27eb7cb4f5b49b9e7c24deb6c1fb52908f63703",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gen_depth_stencil"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reorders z/stencil fetch/extract/convert instructions to reduce execution time by 10 cycles.",
            "The optimization re-orders z/stencil fetch/extract/convert instructions to reduce execution cycles.",
            "The optimization reorders z/stencil fetch/extract/convert instructions to reduce execution cycles.",
            "The optimization re-orders z/stencil fetch/extract/convert instructions to reduce execution cycles.",
            "The optimization reorders z/stencil fetch/extract/convert instructions to reduce execution cycles."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reorders z/stencil fetch/extract/convert instructions to reduce execution cycles.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "edk2",
        "hash": "68d506e0d15c0c412142be68ed006c65b641560f",
        "author": "Zhiguang Liu",
        "date": "2023-11-29T07:23:37+00:00",
        "message": "UefiCpuPkg/PiSmmCpuDxeSmm: Use NonSmm BSP as default SMM BSP.\n\nCurrently, if BSP election is not enabled, will use Core0 as SMM BSP.\nHowever, Core0 does not always have the highest performance.\nSo, we can used NonSmm BSP as default BSP.\nThis will take effect in normal SMM init flow and S3 boot flow.\nIn normal SMM flow, the code is executed before first SMI.\nIn S3 flow, the code is executed in Non-SMM BSP's first SMI, where the\ngSmmCpuPrivate keeps the data from last boot.\n\nReviewed-by: Ray Ni <ray.ni@intel.com>\nCc: Rahul Kumar <rahul1.kumar@intel.com>\nCc: Gerd Hoffmann <kraxel@redhat.com>\nCc: Laszlo Ersek <lersek@redhat.com>\nSigned-off-by: Zhiguang Liu <zhiguang.liu@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "UefiCpuPkg/PiSmmCpuDxeSmm/MpService.c"
        ],
        "github_commit_url": "https://github.com/tianocore/edk2/commit/68d506e0d15c0c412142be68ed006c65b641560f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "InitializeMpSyncData"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves selecting the NonSmm BSP as the default SMM BSP to potentially improve performance by leveraging a higher-performing core instead of defaulting to Core0.",
            "The optimization strategy involves selecting the NonSmm BSP as the default SMM BSP to potentially improve performance by leveraging a higher-performing core instead of defaulting to Core0.",
            "The optimization strategy involves selecting the NonSmm BSP as the default SMM BSP to potentially improve performance by leveraging a higher-performing core instead of defaulting to Core0.",
            "The optimization strategy involves selecting the NonSmm BSP as the default SMM BSP to potentially improve performance by avoiding the use of Core0, which may not always be the highest-performing core.",
            "The optimization strategy selects the NonSmm BSP as the default SMM BSP to potentially improve performance by avoiding the use of Core0, which may not always be the highest-performing core."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves selecting the NonSmm BSP as the default SMM BSP to potentially improve performance by leveraging a higher-performing core instead of defaulting to Core0.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "haiku",
        "hash": "0012ba6a87f1286164160b6d14516e4bad0f63c3",
        "author": "Pawel Dziepak",
        "date": "2014-03-09T19:58:11+01:00",
        "message": "scheduler/low_latency: Try harder to balance load\n\nIn low latency mode the scheduler would not attempt to balance load\non not heavily loaded cores unless difference in load exceeded\nkLoadDifference * 2 (i.e. 40 percentage points), which does not seem\nto be good enough.",
        "modified_files_count": 1,
        "modified_files": [
            "src/system/kernel/scheduler/low_latency.cpp"
        ],
        "github_commit_url": "https://github.com/haiku/haiku/commit/0012ba6a87f1286164160b6d14516e4bad0f63c3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "should_rebalance"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces the load difference threshold for rebalancing in low latency mode to improve scheduler responsiveness.",
            "The optimization reduces the load difference threshold for rebalancing in low latency mode to improve scheduler responsiveness.",
            "The optimization reduces the load difference threshold for rebalancing in low latency mode to improve scheduler responsiveness.",
            "The optimization reduces the load difference threshold for rebalancing in low latency mode to improve scheduler responsiveness.",
            "The optimization reduces the load difference threshold for rebalancing in low latency mode to improve scheduler responsiveness."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces the load difference threshold for rebalancing in low latency mode to improve scheduler responsiveness.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "selinux-kernel",
        "hash": "11776aa0cfa7d007ad1799b1553bdcbd830e5010",
        "author": "Sean Christopherson",
        "date": "2024-02-22T16:22:36-08:00",
        "message": "KVM: VMX: Handle forced exit due to preemption timer in fastpath\n\nHandle VMX preemption timer VM-Exits due to KVM forcing an exit in the\nexit fastpath, i.e. avoid calling back into handle_preemption_timer() for\nthe same exit.  There is no work to be done for forced exits, as the name\nsuggests the goal is purely to get control back in KVM.\n\nIn addition to shaving a few cycles, this will allow cleanly separating\nhandle_fastpath_preemption_timer() from handle_preemption_timer(), e.g.\nit's not immediately obvious why _apparently_ calling\nhandle_fastpath_preemption_timer() twice on a \"slow\" exit is necessary:\nthe \"slow\" call is necessary to handle exits from L2, which are excluded\nfrom the fastpath by vmx_vcpu_run().\n\nLink: https://lore.kernel.org/r/20240110012705.506918-4-seanjc@google.com\nSigned-off-by: Sean Christopherson <seanjc@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/kvm/vmx/vmx.c"
        ],
        "github_commit_url": "https://github.com/SELinuxProject/selinux-kernel/commit/11776aa0cfa7d007ad1799b1553bdcbd830e5010",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "handle_fastpath_preemption_timer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant function calls in the exit fastpath by handling forced VMX preemption timer exits directly, reducing unnecessary processing.",
            "The optimization avoids redundant function calls in the exit fastpath by handling forced VMX preemption timer exits directly, reducing unnecessary processing.",
            "The optimization avoids redundant function calls in the VMX preemption timer exit fastpath by handling forced exits directly, reducing unnecessary processing.",
            "The optimization avoids redundant function calls in the exit fastpath by handling forced VMX preemption timer exits directly, reducing unnecessary processing.",
            "The optimization avoids redundant function calls in the VMX preemption timer exit fastpath by handling forced exits directly, reducing unnecessary processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids redundant function calls in the exit fastpath by handling forced VMX preemption timer exits directly, reducing unnecessary processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "red-viper",
        "hash": "2a47628b18b8c2b9aa7a27cb64028b84054f800d",
        "author": "Floogle",
        "date": "2025-01-04T23:44:33+01:00",
        "message": "slightly optimize drc setup",
        "modified_files_count": 1,
        "modified_files": [
            "source/3ds/drc_core.c"
        ],
        "github_commit_url": "https://github.com/skyfloogle/red-viper/commit/2a47628b18b8c2b9aa7a27cb64028b84054f800d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "drc_run"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant setup operations in the drc_run function by reordering and consolidating initialization steps.",
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve iteration efficiency.",
            "The optimization strategy involved reducing redundant setup operations in the drc_run function by reordering and consolidating initialization logic.",
            "The optimization strategy involved reducing redundant setup operations in the drc_run function by reordering and consolidating initialization steps.",
            "The optimization strategy involved reducing redundant setup operations in the drc_run function by reordering and consolidating initialization steps."
        ],
        "is_generic_optimization": [
            false,
            true,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant setup operations in the drc_run function by reordering and consolidating initialization steps.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cpptraj",
        "hash": "d53dfa7b3c5497369c8acdb8c0a9af274a56f21c",
        "author": "Daniel R. Roe",
        "date": "2017-12-14T10:55:48-05:00",
        "message": "DRR - Cpptraj: Openmp-parallelize the coords pre-wrap for nonortho cells",
        "modified_files_count": 1,
        "modified_files": [
            "src/Action_GIST.cpp"
        ],
        "github_commit_url": "https://github.com/Amber-MD/cpptraj/commit/d53dfa7b3c5497369c8acdb8c0a9af274a56f21c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Action_GIST::NonbondEnergy"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is parallelizing the coords pre-wrap operation for non-orthogonal cells using OpenMP to improve performance.",
            "The optimization strategy used is parallelizing the coords pre-wrap computation for non-orthogonal cells using OpenMP to improve performance.",
            "The optimization strategy used is parallelizing the coords pre-wrap operation for non-orthogonal cells using OpenMP to improve performance.",
            "The optimization strategy used is parallelizing the coordinates pre-wrap computation for non-orthogonal cells using OpenMP to improve performance.",
            "The optimization strategy involved parallelizing the coordinates pre-wrap computation for non-orthogonal cells using OpenMP to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is parallelizing the coords pre-wrap computation for non-orthogonal cells using OpenMP to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pstack",
        "hash": "917a490193251ae2d46f88cb467e34eb20855ec6",
        "author": "Peter Edwards",
        "date": "2022-09-24T18:12:30+01:00",
        "message": "canal: improve effiency of \"canal -S\" to find addresses of strings.\n\nThe original version was done in a big hurry, and was terribly\ninefficient.",
        "modified_files_count": 1,
        "modified_files": [
            "canal.cc"
        ],
        "github_commit_url": "https://github.com/peadar/pstack/commit/917a490193251ae2d46f88cb467e34eb20855ec6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mainExcept"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the logic for finding string addresses to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic for finding string addresses to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic for finding string addresses to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic for finding string addresses to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the logic for finding string addresses to reduce unnecessary computations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the logic for finding string addresses to reduce unnecessary computations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "hackrf",
        "hash": "790de7f47b7919f944dfb39956405c34b4bb486b",
        "author": "Yan",
        "date": "2022-03-16T11:13:00+00:00",
        "message": "Cleaner fast exit\n\nInterrupt the event handling thread instead of waiting for timeout.",
        "modified_files_count": 1,
        "modified_files": [
            "host/libhackrf/src/hackrf.c"
        ],
        "github_commit_url": "https://github.com/greatscottgadgets/hackrf/commit/790de7f47b7919f944dfb39956405c34b4bb486b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "kill_transfer_thread"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves interrupting the event handling thread directly instead of waiting for a timeout to improve responsiveness and reduce unnecessary delays.",
            "The optimization strategy involves interrupting the event handling thread directly instead of waiting for a timeout to improve responsiveness and reduce latency.",
            "The optimization strategy involves interrupting the event handling thread directly instead of waiting for a timeout to improve responsiveness and reduce latency.",
            "The optimization strategy involves interrupting the event handling thread directly instead of waiting for a timeout, reducing latency in thread termination.",
            "The optimization strategy involves interrupting the event handling thread directly instead of waiting for a timeout to improve responsiveness and reduce latency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves interrupting the event handling thread directly instead of waiting for a timeout to improve responsiveness and reduce latency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Pixelix",
        "hash": "bc67d0dc16e0505dfcb6111186aba31377a6b1be",
        "author": "BlueAndi",
        "date": "2020-12-31T14:31:52+01:00",
        "message": "Move initialization to initialization list for better performance.",
        "modified_files_count": 1,
        "modified_files": [
            "src/Plugin/Plugins/SunrisePlugin.h"
        ],
        "github_commit_url": "https://github.com/BlueAndi/Pixelix/commit/bc67d0dc16e0505dfcb6111186aba31377a6b1be",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "m_longitude"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved moving member initialization to the initialization list to reduce unnecessary default constructor calls and improve performance.",
            "The optimization strategy involved moving member initialization to the initialization list to reduce unnecessary default construction and assignment operations.",
            "The optimization strategy involved moving member initialization to the constructor's initialization list to reduce unnecessary default constructions and assignments.",
            "The optimization strategy involved moving member initialization to the constructor's initialization list to reduce unnecessary default constructions and assignments.",
            "The optimization strategy involved moving member initialization to the constructor's initialization list to reduce unnecessary default constructions and assignments."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved moving member initialization to the constructor's initialization list to reduce unnecessary default constructions and assignments.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "50a9ff301ed734f2fa95b3c38154454416d934f8",
        "author": "Joe Carnuccio",
        "date": "2014-05-19T13:31:03+02:00",
        "message": "qla2xxx: ISP8044 poll ipmdio bus timeout improvement.\n\nSigned-off-by: Joe Carnuccio <joe.carnuccio@qlogic.com>\nSigned-off-by: Saurav Kashyap <saurav.kashyap@qlogic.com>\nSigned-off-by: Christoph Hellwig <hch@lst.de>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/scsi/qla2xxx/qla_nx2.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/50a9ff301ed734f2fa95b3c38154454416d934f8",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "qla8044_poll_wait_ipmdio_bus_idle"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involved reducing the polling interval and adding a short delay to improve the efficiency of waiting for the IPMDIO bus to become idle.",
            "The optimization strategy involved reducing the polling interval and adding a short delay to improve the efficiency of waiting for the IPMDIO bus to become idle.",
            "The optimization strategy involved reducing the polling interval and adding a short delay to improve efficiency while waiting for the IPMDIO bus to become idle.",
            "The optimization strategy involved reducing the polling interval and adding a short delay to improve the efficiency of waiting for the IPMDIO bus to become idle.",
            "The optimization strategy involved reducing the polling interval and adding a delay to improve the efficiency of waiting for the IPMDIO bus to become idle."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the polling interval and adding a short delay to improve the efficiency of waiting for the IPMDIO bus to become idle.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "scipp",
        "hash": "12f83c965828ed2b8d69ea6e60ba1be00fbb8212",
        "author": "Simon Heybrock",
        "date": "2020-03-17T08:54:15+01:00",
        "message": "Fix massive performance issues with attributes in realigned histogram",
        "modified_files_count": 1,
        "modified_files": [
            "core/histogram.cpp"
        ],
        "github_commit_url": "https://github.com/scipp/scipp/commit/12f83c965828ed2b8d69ea6e60ba1be00fbb8212",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "histogram"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the handling of attributes in the histogram function to avoid unnecessary computations during realignment.",
            "The optimization strategy involved restructuring the handling of attributes in the histogram function to avoid unnecessary computations during realignment.",
            "The optimization strategy involved restructuring the handling of attributes in the histogram function to avoid unnecessary computations during realignment.",
            "The optimization strategy involved restructuring the handling of attributes in the histogram function to avoid unnecessary computations during realignment.",
            "The optimization strategy involved restructuring the handling of attributes in the histogram function to avoid unnecessary computations during realignment."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the handling of attributes in the histogram function to avoid unnecessary computations during realignment.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mythtv",
        "hash": "b4d96b4c4c37e5195affaf0d0662b4ab71c47c92",
        "author": "Michael T. Dean",
        "date": "2011-05-29T20:49:57-04:00",
        "message": "Try to improve row counting performance for logging.\n\nSince InnoDB engine doesn't store the row count for tables, like MyISAM\ndoes, try to improve the performance of the count query.  By counting\nid, the optimizer should choose to use the primary index.  At this\npoint, I'm not forcing it, but if it's found to help for InnoDB users,\nwe can do so later.\n\nSee:\nhttp://www.cloudspace.com/blog/2009/08/06/fast-mysql-innodb-count-really-fast/\nhttp://www.mysqlperformanceblog.com/2007/04/10/count-vs-countcol/",
        "modified_files_count": 1,
        "modified_files": [
            "mythtv/programs/mythbackend/housekeeper.cpp"
        ],
        "github_commit_url": "https://github.com/MythTV/mythtv/commit/b4d96b4c4c37e5195affaf0d0662b4ab71c47c92",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HouseKeeper::flushDBLogs"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves modifying the SQL query to count a specific indexed column (id) instead of using COUNT(*) to improve performance for InnoDB tables by leveraging the primary index.",
            "The optimization strategy involves modifying the SQL query to count a specific indexed column (id) instead of using COUNT(*) to leverage the primary index for improved performance in InnoDB.",
            "The optimization strategy involves modifying the SQL query to count rows using the primary index by counting the `id` column, which is expected to improve performance for the InnoDB storage engine.",
            "The optimization strategy involves modifying the SQL query to count rows using the primary index by counting the `id` column, which is expected to improve performance for the InnoDB storage engine.",
            "The optimization strategy involves modifying the SQL query to count rows using the primary index by counting the `id` column, which is expected to improve performance for the InnoDB engine."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves modifying the SQL query to count rows using the primary index by counting the `id` column, which is expected to improve performance for the InnoDB engine.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "darktable",
        "hash": "fef9b562d569a00af5ad8db3f709b1623e26a550",
        "author": "ralfbrown",
        "date": "2021-07-28T00:43:59-04:00",
        "message": "speed up drawing ellipse mask\n\nThe existing code uses atan2 to determine the angle, adjusts by the rotation angle of the ellipse,\nand then calls cosf and sinf on the adjusted angle.  We can eliminate the three trigonometric\nfunction calls by instead rotating the coordinate system of the point being processed, thus\nreplacing three trig function calls and a subtraction by a sqrt, two divisions, four\nmultiplications, and two additions.  The resulting code also perfectly auto-vectorizes, for an\noverall speedup by nearly a factor of eight.\n\nTimes (in seconds) reported for `ellipse fill` on mire1.cr2 using `darktable-cli -d perf -d masks`\nwith various integration tests:\n\n0074: 0.1709 -> 0.0217 (7.87x)\n0075: 0.1689 -> 0.0214 (7.89x)\n0076: 0.0955+0.0860 -> 0.0124+0.0115 (7.59x)",
        "modified_files_count": 1,
        "modified_files": [
            "src/develop/masks/ellipse.c"
        ],
        "github_commit_url": "https://github.com/darktable-org/darktable/commit/fef9b562d569a00af5ad8db3f709b1623e26a550",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_ellipse_get_mask"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces trigonometric function calls with simpler arithmetic operations by rotating the coordinate system, reducing computational overhead and enabling auto-vectorization.",
            "The optimization replaces trigonometric function calls with simpler arithmetic operations by rotating the coordinate system, reducing computational overhead and enabling auto-vectorization.",
            "The optimization replaces trigonometric function calls with coordinate system rotation using simpler arithmetic operations, enabling auto-vectorization and significantly improving performance.",
            "The optimization replaces trigonometric function calls with simpler arithmetic operations by rotating the coordinate system, reducing computational overhead and enabling auto-vectorization.",
            "The optimization replaces trigonometric function calls with coordinate system rotation using arithmetic operations, reducing computational overhead and enabling auto-vectorization."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaces trigonometric function calls with simpler arithmetic operations by rotating the coordinate system, reducing computational overhead and enabling auto-vectorization.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "f9ec69904b77962297626b08091f1cddd96f1ef6",
        "author": "Alexander Motin",
        "date": "2008-01-26T22:41:14+00:00",
        "message": "Improve multilink xmit performance by netgraph item reuse.",
        "modified_files_count": 1,
        "modified_files": [
            "sys/netgraph/ng_ppp.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/f9ec69904b77962297626b08091f1cddd96f1ef6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ng_ppp_mp_xmit"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reuses netgraph items in the multilink transmit function to reduce allocation overhead and improve performance.",
            "The optimization reuses netgraph items in the multilink transmit function to reduce allocation overhead and improve performance.",
            "The optimization reuses netgraph items in the multilink PPP transmission process to reduce allocation overhead and improve performance.",
            "The optimization strategy reuses netgraph items in the multilink transmit function to reduce allocation overhead and improve performance.",
            "The optimization reuses netgraph items in the multilink transmit function to reduce allocation overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reuses netgraph items in the multilink transmit function to reduce allocation overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ispc",
        "hash": "1dedd881327dc7b5609e49533b7e1aae1ef15e81",
        "author": "Matt Pharr",
        "date": "2011-09-15T06:25:02-07:00",
        "message": "Improve implementaton of 'are both masks equal' check for AVX.\n\nPreviously, we did a vector equal compare and then a movmsk, the\nresult of which we checked to see if it was on for all lanes.\nBecause masks are vectors of i32s, under AVX, the vector equal\ncompare required two 4-wide SSE compares and some shuffling.\nNow, we do a movmsk of both masks first and then a scalar\nequality comparison of those two values, which seems to generate\noverall better code.",
        "modified_files_count": 1,
        "modified_files": [
            "ctx.cpp"
        ],
        "github_commit_url": "https://github.com/ispc/ispc/commit/1dedd881327dc7b5609e49533b7e1aae1ef15e81",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FunctionEmitContext::MasksAllEqual"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a vector equality comparison with a scalar equality comparison after extracting mask bits, reducing the number of operations required for AVX mask equality checks.",
            "The optimization strategy replaced a vector comparison and mask extraction with direct mask extraction followed by a scalar equality check to improve performance for AVX masks.",
            "The optimization strategy replaced a vector comparison and mask extraction with direct mask extraction followed by a scalar equality check to improve performance for AVX masks.",
            "The optimization strategy replaced a vector comparison and mask extraction with direct mask extraction followed by a scalar equality check to improve performance for AVX masks.",
            "The optimization strategy replaced a vector equality comparison with a scalar equality comparison by first extracting mask bits, reducing the need for multiple SSE operations and shuffling under AVX."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a vector comparison and mask extraction with direct mask extraction followed by a scalar equality check to improve performance for AVX masks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "da504741da1ffef8386ba281520d72f0b4e5983f",
        "author": "Chris Lattner",
        "date": "2005-04-09T21:43:54+00:00",
        "message": "add a little peephole optimization.  This allows us to codegen:\n\nint a(short i) {\n        return i & 1;\n}\n\nas\n\n_a:\n        andi. r3, r3, 1\n        blr\n\ninstead of:\n\n_a:\n        rlwinm r2, r3, 0, 16, 31\n        andi. r3, r2, 1\n        blr\n\non ppc.  It should also help the other risc targets.\n\nllvm-svn: 21189",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/SelectionDAG/SelectionDAG.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/da504741da1ffef8386ba281520d72f0b4e5983f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SelectionDAG::getNode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization eliminates unnecessary bit manipulation operations by directly applying a bitwise AND operation on the input, reducing instruction count in the generated code.",
            "The optimization eliminates unnecessary bit manipulation operations by directly applying a bitwise AND operation on the input, reducing instruction count in the generated code.",
            "The optimization eliminates unnecessary bit manipulation operations by directly applying a bitwise AND operation on the input, reducing instruction count in the generated code.",
            "The optimization eliminates unnecessary bit manipulation operations by directly applying a bitwise AND operation on the input register, reducing instruction count.",
            "The optimization eliminates unnecessary bit manipulation operations by directly applying a bitwise AND operation on the input, reducing instruction count in the generated code."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization eliminates unnecessary bit manipulation operations by directly applying a bitwise AND operation on the input, reducing instruction count in the generated code.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "llvm-leg",
        "hash": "d23a298f28209e1faa47c01482d5815ebb95d6d0",
        "author": "Chris Lattner",
        "date": "2005-01-24T02:08:34+00:00",
        "message": "This giant patch speeds up Type::isSized().  Before, this would have to search\nlarge nested types over and over again to determine if they are sized or not.\nNow, isSized() is able to make snap decisions about all concrete types, which\nare a common occurance (and includes all primitives).\n\nOn 177.mesa, this speeds up DSE from 39.5s -> 21.3s and GCSE from\n13.2s -> 11.3s, reducing gccas time from 80s -> 61s (this is a debug build).\n\nDSE and GCSE are still too slow on this testcase, but this is a simple\nimprovement.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@19800 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "include/llvm/Type.h"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/d23a298f28209e1faa47c01482d5815ebb95d6d0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "isSized"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy caches or precomputes the \"isSized\" property for concrete types to avoid redundant searches in nested types.",
            "The optimization strategy caches the results of type size checks to avoid redundant computations for nested types.",
            "The optimization strategy caches or precomputes the \"isSized\" property for concrete types to avoid redundant searches in nested types.",
            "The optimization strategy caches or precomputes decisions about whether types are sized to avoid redundant searches in nested types.",
            "The optimization strategy caches the \"sized\" property of concrete types to avoid redundant computations for nested types."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy caches or precomputes the \"isSized\" property for concrete types to avoid redundant searches in nested types.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "blender",
        "hash": "35ae1da16c6aab293adbe1e4eecba624006a085c",
        "author": "Campbell Barton",
        "date": "2019-10-04T01:14:25+10:00",
        "message": "Mesh: simple extract mask optimizations\n\n- Avoid per-vertex custom-data lookup\n- Break once a face has a mask vertex.",
        "modified_files_count": 1,
        "modified_files": [
            "source/blender/editors/mesh/editmesh_mask_extract.c"
        ],
        "github_commit_url": "https://github.com/blender/blender/commit/35ae1da16c6aab293adbe1e4eecba624006a085c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "paint_mask_extract_exec"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids per-vertex custom-data lookups and exits early when a face with a mask vertex is found, reducing unnecessary computations.",
            "The optimization avoids per-vertex custom-data lookups and exits early when a face with a mask vertex is found, reducing unnecessary computations.",
            "The optimization avoids per-vertex custom-data lookups and exits early when a face with a mask vertex is found, reducing unnecessary computations.",
            "The optimization avoids per-vertex custom-data lookups and exits early when a face with a mask vertex is found, reducing unnecessary computations.",
            "The optimization avoids per-vertex custom-data lookups and stops further checks once a face with a mask vertex is found, reducing redundant operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids per-vertex custom-data lookups and exits early when a face with a mask vertex is found, reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gstreamer",
        "hash": "fe10ecd097c82e257af2408913c25dddb8514022",
        "author": "Wim Taymans",
        "date": "2009-07-01T11:23:59+02:00",
        "message": "ffdec: don't wait for keyframe after discont\n\nAfter a DISCONT, mark the next frame with DISCONT but don't wait for a new\nkeyframe. This greatly improves performance on lossy networks or currupted\nframes as the decoder can usually continue and conceil errors up to the next\nkeyframe.",
        "modified_files_count": 1,
        "modified_files": [
            "ext/ffmpeg/gstffmpegdec.c"
        ],
        "github_commit_url": "https://github.com/GStreamer/gstreamer/commit/fe10ecd097c82e257af2408913c25dddb8514022",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gst_ffmpegdec_chain"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids waiting for a keyframe after a discontinuity (DISCONT) to allow the decoder to continue processing and conceal errors until the next keyframe.",
            "The optimization strategy involves avoiding the wait for a keyframe after a discontinuity (DISCONT) to allow the decoder to continue and conceal errors up to the next keyframe, improving performance on lossy networks or with corrupted frames.",
            "The optimization strategy eliminates the wait for a keyframe after a discontinuity (DISCONT), allowing the decoder to continue processing and handle errors up to the next keyframe.",
            "The optimization strategy involves avoiding the wait for a new keyframe after a discontinuity (DISCONT) to allow the decoder to continue processing and conceal errors until the next keyframe.",
            "The optimization strategy involves avoiding the wait for a new keyframe after a discontinuity (DISCONT) to allow the decoder to continue processing and conceal errors until the next keyframe."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves avoiding the wait for a new keyframe after a discontinuity (DISCONT) to allow the decoder to continue processing and conceal errors until the next keyframe.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ompi",
        "hash": "84a89d68dcf60840d7801161032144bb6cd2c982",
        "author": "George Bosilca",
        "date": "2005-11-07T23:00:28+00:00",
        "message": "When we advance the convertor by a multiple of the data size there is a quick optimization.\nWe can compute the number of complete datatype that we will advance, update the stack and\nthen compute the new position taking in acount only the remaining bytes.\n\nThis commit was SVN r8019.",
        "modified_files_count": 1,
        "modified_files": [
            "ompi/datatype/new_position.c"
        ],
        "github_commit_url": "https://github.com/open-mpi/ompi/commit/84a89d68dcf60840d7801161032144bb6cd2c982",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ompi_convertor_generic_simple_position"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves reducing computational overhead by directly calculating the number of complete datatypes advanced and updating the stack in a single step when advancing by a multiple of the data size.",
            "The optimization strategy involves reducing computational overhead by directly calculating the number of complete datatypes advanced and updating the stack in bulk before handling remaining bytes.",
            "The optimization strategy involves reducing computational overhead by directly calculating the number of complete datatypes advanced and updating the stack in bulk before handling remaining bytes.",
            "The optimization strategy involves reducing computational overhead by directly calculating the number of complete datatypes advanced and updating the stack in bulk before handling remaining bytes.",
            "The optimization strategy involves reducing redundant computations by directly calculating the number of complete datatypes advanced and updating the stack accordingly, while handling only the remaining bytes separately."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reducing computational overhead by directly calculating the number of complete datatypes advanced and updating the stack in bulk before handling remaining bytes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "parrot",
        "hash": "ce6505dc103157c601d9448267ab1733dfd85e26",
        "author": "chromatic",
        "date": "2011-07-04T01:45:58-07:00",
        "message": "[str] Optimized Parrot_str_join given empty joiner.\n\nThis improves the vpm.pir benchmark by a whopping further 7.8%.",
        "modified_files_count": 1,
        "modified_files": [
            "src/string/api.c"
        ],
        "github_commit_url": "https://github.com/parrot/parrot/commit/ce6505dc103157c601d9448267ab1733dfd85e26",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Parrot_str_join"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary string concatenation operations when the joiner is empty by directly returning the concatenated strings.",
            "The optimization avoids unnecessary string concatenation operations when the joiner is empty by directly returning the concatenated strings.",
            "The optimization avoids unnecessary string concatenation operations when the joiner is empty by directly returning the concatenated strings.",
            "The optimization avoids unnecessary string concatenation operations when the joiner is empty by directly returning the concatenated strings.",
            "The optimization avoids unnecessary string concatenation operations when the joiner is empty by directly returning the concatenated strings without any intermediate processing."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary string concatenation operations when the joiner is empty by directly returning the concatenated strings.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "7cf1aaa2ad3855bd5e95bef382a66fe122fc9b01",
        "author": "Andi Kleen",
        "date": "2018-01-14T20:03:49+01:00",
        "message": "x86/timer: Don't inline __const_udelay\n\n__const_udelay is marked inline, and LTO will happily inline it everywhere\n\nDropping the inline saves ~44k text in a LTO build.\n\n13999560        1740864 1499136 17239560        1070e08 vmlinux-with-udelay-inline\n13954764        1736768 1499136 17190668        1064f0c vmlinux-wo-udelay-inline\n\nInlining it has no advantage in general, so its the right thing to do.\n\nSigned-off-by: Andi Kleen <ak@linux.intel.com>\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nLink: https://lkml.kernel.org/r/20171222001821.2157-2-andi@firstfloor.org",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/lib/delay.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/7cf1aaa2ad3855bd5e95bef382a66fe122fc9b01",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__const_udelay"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing the `inline` keyword from the `__const_udelay` function to prevent excessive inlining during Link-Time Optimization (LTO), reducing code size without sacrificing performance benefits.",
            "The optimization strategy involved removing the `inline` keyword from the `__const_udelay` function to prevent excessive inlining during Link-Time Optimization (LTO), reducing code size without sacrificing performance benefits.",
            "The optimization strategy involved removing the `inline` keyword from the `__const_udelay` function to prevent excessive inlining during Link-Time Optimization (LTO), reducing code size without sacrificing performance benefits.",
            "The optimization strategy involved removing the `inline` keyword from the `__const_udelay` function to prevent excessive inlining during Link-Time Optimization (LTO), reducing code size without sacrificing performance benefits.",
            "The optimization strategy involved removing the `inline` keyword from the `__const_udelay` function to prevent excessive inlining during Link-Time Optimization (LTO), reducing code size without sacrificing performance benefits."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved removing the `inline` keyword from the `__const_udelay` function to prevent excessive inlining during Link-Time Optimization (LTO), reducing code size without sacrificing performance benefits.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "Pikafish",
        "hash": "89a06f6651882248e185bb597135af3249ec8f6a",
        "author": "Marco Costalba",
        "date": "2011-05-17T23:47:26+01:00",
        "message": "Micro-optimize pl_move_is_legal()\n\nRemove the check for castling moves because it is\nalready implicit in the check for king moves and castling\nis so rare that doing the check is just a slow down.\n\nThanks to Marek Kwiatkowski.\n\nNo functional change.\n\nSigned-off-by: Marco Costalba <mcostalba@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/position.cpp"
        ],
        "github_commit_url": "https://github.com/official-pikafish/Pikafish/commit/89a06f6651882248e185bb597135af3249ec8f6a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Position::pl_move_is_legal"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization removes an unnecessary explicit check for castling moves in the `pl_move_is_legal` function, as it is already implicitly covered by the king move check and is rare enough to slow down performance.",
            "The optimization removes an unnecessary explicit check for castling moves in the `pl_move_is_legal` function, as it is already implicitly covered by the king move check and is rare enough to slow down performance.",
            "The optimization strategy removes an unnecessary check for castling moves in the `pl_move_is_legal()` function, as it is already implicitly covered by the king move check and is rare enough to slow down performance.",
            "The optimization removes an unnecessary explicit check for castling moves in the `pl_move_is_legal` function, as it is already implicitly covered by the king move check and is rare enough to slow down performance.",
            "The optimization removes an unnecessary explicit check for castling moves in the `pl_move_is_legal` function, as it is already implicitly covered by the king move check and is rare enough to slow down performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes an unnecessary explicit check for castling moves in the `pl_move_is_legal` function, as it is already implicitly covered by the king move check and is rare enough to slow down performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "ac9f18274676baab2dc90c6f9431738c6e9c17d5",
        "author": "mtrofin",
        "date": "2016-02-25T15:41:14+00:00",
        "message": "[turbofan] don't take hints from deferred blocks\n\nWe should prefer hints from operands in non-deferred blocks, else we\nrisk sideways moves on the hot path, just to accommodate the register\nallocator's choice of register assignment in the deferred block.\n\nBUG=\n\nReview URL: https://codereview.chromium.org/1718223002\n\nCr-Commit-Position: refs/heads/master@{#34296}",
        "modified_files_count": 1,
        "modified_files": [
            "src/compiler/register-allocator.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/ac9f18274676baab2dc90c6f9431738c6e9c17d5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LiveRangeBuilder::ProcessPhis"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids using register allocation hints from deferred blocks to prevent unnecessary register moves on the hot path.",
            "The optimization avoids using register allocation hints from deferred blocks to prevent performance-degrading sideways moves on the hot path.",
            "The optimization avoids using register allocation hints from deferred blocks to prevent unnecessary register moves on the hot path.",
            "The optimization avoids using register allocation hints from deferred blocks to prevent unnecessary register moves on the hot path.",
            "The optimization avoids using register allocation hints from deferred blocks to prevent unnecessary register moves on the hot path."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids using register allocation hints from deferred blocks to prevent unnecessary register moves on the hot path.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ppsspp",
        "hash": "12405709f0521b1596b364a91324c010eaf5baf6",
        "author": "Unknown W. Brackets",
        "date": "2022-01-01T16:40:34-08:00",
        "message": "softgpu: Skip processing scissored triangles.\n\nIf only one side was scissored (common), we might even put it on a thread,\nwhich ended up as a lot of overhead.  Gives 3-4% improvement in some\nplaces.",
        "modified_files_count": 1,
        "modified_files": [
            "GPU/Software/Rasterizer.cpp"
        ],
        "github_commit_url": "https://github.com/hrydgard/ppsspp/commit/12405709f0521b1596b364a91324c010eaf5baf6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DrawTriangle"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization skips processing triangles that are fully outside the scissor region and avoids threading overhead for partially scissored triangles.",
            "The optimization skips processing triangles that are partially or fully outside the visible scissor region, reducing unnecessary computations.",
            "The optimization skips processing triangles that are partially or fully outside the visible scissor region, reducing unnecessary overhead in threaded operations.",
            "The optimization skips processing triangles that are partially or fully outside the visible scissor region, reducing unnecessary computations.",
            "The optimization skips processing triangles that are partially or fully outside the visible scissor region, reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization skips processing triangles that are partially or fully outside the visible scissor region, reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Egaroucid",
        "hash": "f4b396f1001f698f96e486e68f4b13b124bef713",
        "author": "Nyanyan",
        "date": "2023-12-10T14:23:48+09:00",
        "message": "speedup book deviate, issue #97, fixed err",
        "modified_files_count": 1,
        "modified_files": [
            "src/engine/book_enlarge.hpp"
        ],
        "github_commit_url": "https://github.com/Nyanyan/Egaroucid/commit/f4b396f1001f698f96e486e68f4b13b124bef713",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "book_recalculate_leaf"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop logic to minimize redundant computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the logic for recalculating book leaves to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved reducing unnecessary computations in the book_recalculate_leaf function by avoiding redundant recalculations.",
            "The optimization strategy involved reducing unnecessary computations in the book_recalculate_leaf function by avoiding redundant recalculations.",
            "The optimization strategy involved reducing unnecessary computations by restructuring the logic for recalculating book leaves."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations by restructuring the logic for recalculating book leaves.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "73bac4923f8f26ae3c719133c640c98d57f10713",
        "author": "Avi Kivity",
        "date": "2013-12-04T19:46:45+02:00",
        "message": "virtio-rng: fix excessive serialization with multiple consumers\n\nSuppose N threads try to acquire a byte of entropy from an empty pool.  They\nwill all serialize on the mutex, waiting for the pool to refill.  However,\nwhen the pool is eventually refilled, only one consumer will be awakened;\nthe rest will continue sleeping even though there is entropy available in the\npool.  They will eventually be awakened when the worker refills the pool,\nbut that's unneeded latency.\n\nFix by using wake_all() to wake all consumers.\n\nSigned-off-by: Avi Kivity <avi@cloudius-systems.com>\nSigned-off-by: Pekka Enberg <penberg@cloudius-systems.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/virtio-rng.cc"
        ],
        "github_commit_url": "https://github.com/cloudius-systems/osv/commit/73bac4923f8f26ae3c719133c640c98d57f10713",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Copyright"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "osv",
        "optimization_summary": [
            "The optimization strategy involves replacing a single-consumer wake-up mechanism with a wake-all approach to reduce serialization and latency when multiple threads are waiting for entropy.",
            "The optimization strategy used is to replace waking a single consumer with waking all consumers to reduce latency when entropy becomes available in the pool.",
            "The optimization strategy involves replacing a single-consumer wakeup mechanism with a wake-all approach to reduce serialization and latency when multiple threads are waiting for entropy.",
            "The optimization strategy used is to replace waking a single consumer with waking all consumers to reduce latency when multiple threads are waiting for entropy.",
            "The optimization strategy used is to replace waking a single consumer with waking all consumers to reduce latency when entropy becomes available in the pool."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is to replace waking a single consumer with waking all consumers to reduce latency when multiple threads are waiting for entropy.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mistserver",
        "hash": "280743051a035e3ec678047651e2dc07ac08751e",
        "author": "Thulinma",
        "date": "2021-10-19T22:29:41+02:00",
        "message": "Fixed high CPU usage on fast-playing recordings that have a dynamic end time",
        "modified_files_count": 1,
        "modified_files": [
            "src/output/output.cpp"
        ],
        "github_commit_url": "https://github.com/DDVTECH/mistserver/commit/280743051a035e3ec678047651e2dc07ac08751e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Output::prepareNext"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing CPU usage by avoiding unnecessary updates to the end time of fast-playing recordings.",
            "The optimization strategy involved reducing CPU usage by avoiding unnecessary recalculations of dynamic end times for fast-playing recordings.",
            "The optimization strategy involved reducing CPU usage by avoiding unnecessary updates to the end time of fast-playing recordings.",
            "The optimization strategy involved reducing CPU usage by avoiding unnecessary updates to the end time of fast-playing recordings.",
            "The optimization strategy involved reducing CPU usage by avoiding unnecessary updates to the end time of fast-playing recordings."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing CPU usage by avoiding unnecessary updates to the end time of fast-playing recordings.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "monte-carlo-ray-tracer",
        "hash": "fb53f12ecb5abe9b1886c8a1a67e3915a2b23548",
        "author": "Linus Mossberg",
        "date": "2019-10-13T17:49:31+02:00",
        "message": "Improve sphere intersection performance",
        "modified_files_count": 1,
        "modified_files": [
            "source/Surface.cpp"
        ],
        "github_commit_url": "https://github.com/linusmossberg/monte-carlo-ray-tracer/commit/fb53f12ecb5abe9b1886c8a1a67e3915a2b23548",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the sphere intersection calculations to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the sphere intersection calculations to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the sphere intersection calculations to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the sphere intersection calculation to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved restructuring the sphere intersection calculations to reduce redundant computations and improve efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the sphere intersection calculations to reduce redundant computations and improve efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "DoubleAction",
        "hash": "fa086af1c9ffe567edbd30b579d62ace048d935e",
        "author": "Jorge Rodriguez",
        "date": "2014-05-26T19:06:27-04:00",
        "message": "Superfall slowmo a tad faster.",
        "modified_files_count": 1,
        "modified_files": [
            "mp/src/game/shared/sdk/sdk_player_shared.cpp"
        ],
        "github_commit_url": "https://github.com/BSVino/DoubleAction/commit/fa086af1c9ffe567edbd30b579d62ace048d935e",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adjusting the slow-motion effect's speed by slightly increasing its rate to improve performance.",
            "The optimization strategy involved reducing the duration of a slow-motion effect to improve performance by shortening the time spent in that state.",
            "The optimization strategy involved reducing the duration or intensity of a slow-motion effect to improve performance.",
            "The optimization strategy involved reducing the duration or intensity of a slow-motion effect to improve performance.",
            "The optimization strategy involved adjusting the slow-motion effect's speed by slightly increasing its rate to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing the duration or intensity of a slow-motion effect to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "e5157e313cd9c2d57f28873318d0bb29c77a9b1a",
        "author": "Greg Kurz",
        "date": "2016-02-16T12:05:18+02:00",
        "message": "virtio: optimize virtio_access_is_big_endian() for little-endian targets\n\nWhen adding cross-endian support, we introduced the TARGET_IS_BIENDIAN macro\nand the virtio_access_is_big_endian() helper to have a branchless fast path\nin the virtio memory accessors for targets that don't switch endian.\n\nThis was considered as a strong requirement at the time.\n\nNow we have added a runtime check for virtio 1.0, which ruins the benefit\nof the virtio_access_is_big_endian() helper for always little-endian targets.\n\nWith this patch, always little-endian targets stop checking for virtio 1.0,\nsince the result is little-endian in all cases.\n\nReviewed-by: Cornelia Huck <cornelia.huck@de.ibm.com>\nReviewed-by: Laurent Vivier <lvivier@redhat.com>\nSigned-off-by: Greg Kurz <gkurz@linux.vnet.ibm.com>\nReviewed-by: Michael S. Tsirkin <mst@redhat.com>\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nReviewed-by: Laurent Vivier <lvivier@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "include/hw/virtio/virtio-access.h"
        ],
        "github_commit_url": "https://github.com/eurecom-s3/symqemu/commit/e5157e313cd9c2d57f28873318d0bb29c77a9b1a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "virtio_access_is_big_endian"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "symqemu",
        "optimization_summary": [
            "The optimization eliminates unnecessary runtime checks for virtio 1.0 on always little-endian targets by hardcoding the result of `virtio_access_is_big_endian()` to false for such cases.",
            "The optimization eliminates unnecessary runtime checks for virtio 1.0 on always little-endian targets by hardcoding the result of `virtio_access_is_big_endian()` to false for such cases.",
            "The optimization eliminates unnecessary runtime checks for virtio 1.0 on always little-endian targets by hardcoding the result of `virtio_access_is_big_endian()` to false for such cases.",
            "The optimization eliminates unnecessary runtime checks for virtio 1.0 on always little-endian targets by hardcoding the result of `virtio_access_is_big_endian()` to false for these targets.",
            "The optimization eliminates unnecessary runtime checks for virtio 1.0 on always little-endian targets by hardcoding the result of `virtio_access_is_big_endian()` to false for such cases."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization eliminates unnecessary runtime checks for virtio 1.0 on always little-endian targets by hardcoding the result of `virtio_access_is_big_endian()` to false for such cases.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "solidity",
        "hash": "c66905a18999b5c4be2678a7829b6703f902e341",
        "author": "Daniel Kirchner",
        "date": "2024-10-30T20:22:02+01:00",
        "message": "Avoid multiple lookups during body-copying while inlining.",
        "modified_files_count": 1,
        "modified_files": [
            "libyul/optimiser/FullInliner.cpp"
        ],
        "github_commit_url": "https://github.com/ethereum/solidity/commit/c66905a18999b5c4be2678a7829b6703f902e341",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BodyCopier::translateIdentifier"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids redundant lookups during body-copying by caching or reusing results in the inlining process.",
            "The optimization strategy avoids redundant lookups during body-copying by caching or reusing previously fetched data.",
            "The optimization strategy avoids redundant lookups during body-copying in the inlining process by caching or reusing results.",
            "The optimization strategy avoids redundant lookups during body-copying by caching or reusing results in the inlining process.",
            "The optimization strategy avoids redundant lookups during body-copying by caching or reusing previously fetched data."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy avoids redundant lookups during body-copying by caching or reusing results in the inlining process.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "2aa06a989dfef2950ab45da80dd9c1adadd9f9a2",
        "author": "Hao Liu",
        "date": "2014-11-19T06:48:56+00:00",
        "message": "[AArch64] Disable useAA for Cortex-A57.\nUsing AA during CodeGen is very useful for in-order cores. It is less useful for ooo cores. Also I find\nenabling useAA for Cortex-A57 may generate worse code for some test cases. If useAA in codegen is improved \nand benefical for ooo cores, we can enable it again.\n\nllvm-svn: 222333",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Target/AArch64/AArch64Subtarget.h"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/2aa06a989dfef2950ab45da80dd9c1adadd9f9a2",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization disables the use of Alias Analysis (AA) during CodeGen for Cortex-A57 to avoid generating suboptimal code for out-of-order cores.",
            "The optimization disables the use of Alias Analysis (AA) during CodeGen for Cortex-A57 to avoid generating suboptimal code for out-of-order cores.",
            "The optimization disables the use of Alias Analysis (AA) during CodeGen for Cortex-A57 to avoid generating suboptimal code for out-of-order cores.",
            "The optimization disables the use of Alias Analysis (AA) during CodeGen for Cortex-A57 to avoid generating suboptimal code for out-of-order cores.",
            "The optimization disables the use of Alias Analysis (AA) during CodeGen for Cortex-A57 to avoid generating suboptimal code for out-of-order cores."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization disables the use of Alias Analysis (AA) during CodeGen for Cortex-A57 to avoid generating suboptimal code for out-of-order cores.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gstreamer",
        "hash": "d48d47e68365990d7c66782225f7fddf7efde86e",
        "author": "Edward Hervey",
        "date": "2009-10-21T21:04:45+02:00",
        "message": "typefind: speed up mxf_type_find over 300 times for worst case scenarios\n\n* memcmp is expensive and was being abused, reduce calling it by checking\n  the first byte.\n* iterating one byte at at time over 64 kbites introduces a certain overhead,\n  therefore we now do it in chunks of 1024 bytes\n\nAnd I do mean over 300 times. The average instruction call per mxf_type_find\nwas previously 785685 and it's now down to 2458 :)",
        "modified_files_count": 1,
        "modified_files": [
            "gst/typefind/gsttypefindfunctions.c"
        ],
        "github_commit_url": "https://github.com/GStreamer/gstreamer/commit/d48d47e68365990d7c66782225f7fddf7efde86e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mxf_type_find"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces the frequency of expensive `memcmp` calls by first checking the first byte and processes data in larger chunks (1024 bytes) instead of one byte at a time to minimize iteration overhead.",
            "The optimization strategy reduces the frequency of expensive `memcmp` calls by first checking the first byte and processes data in larger chunks (1024 bytes) instead of iterating one byte at a time.",
            "The optimization reduces the frequency of expensive `memcmp` calls by first checking the first byte and processes data in larger chunks instead of one byte at a time.",
            "The optimization reduces the frequency of expensive `memcmp` calls by first checking the first byte and processes data in larger chunks (1024 bytes) instead of one byte at a time to minimize overhead.",
            "The optimization strategy reduces the frequency of expensive `memcmp` calls by first checking the first byte and processes data in larger chunks (1024 bytes) instead of one byte at a time to minimize iteration overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces the frequency of expensive `memcmp` calls by first checking the first byte and processes data in larger chunks (1024 bytes) instead of one byte at a time to minimize iteration overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "knot",
        "hash": "6a3e71bcf6e0d44dda6d249c776800524e67b217",
        "author": "Lubos Slovak",
        "date": "2011-10-17T15:05:09+02:00",
        "message": "Improved adding RRs to changeset.\n\n- Searching for the RRSet from the end of changeset, so that the\n  last RRSet added is tried first. This should significantly\n  improve search times.\n\nrefs #1343 @20m",
        "modified_files_count": 1,
        "modified_files": [
            "libknot/updates/changesets.c"
        ],
        "github_commit_url": "https://github.com/CZ-NIC/knot/commit/6a3e71bcf6e0d44dda6d249c776800524e67b217",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "knot_changeset_add_rr"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves searching for the RRSet from the end of the changeset to prioritize recently added RRs, reducing search times.",
            "The optimization strategy involves searching for the RRSet from the end of the changeset to prioritize recently added RRSets, reducing search times.",
            "The optimization strategy involves searching for the RRSet from the end of the changeset to prioritize recently added RRs, reducing search times.",
            "The optimization strategy involves searching for the RRSet from the end of the changeset to prioritize recently added RRs, reducing search times.",
            "The optimization strategy involves searching for the RRSet from the end of the changeset to prioritize recently added RRs, reducing search times."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves searching for the RRSet from the end of the changeset to prioritize recently added RRs, reducing search times.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "dc0d0468e995514e14838189a1e2aee879ace880",
        "author": "mean",
        "date": "2015-11-11T21:13:02+01:00",
        "message": "[QtGl] Also do fast readback plane conversion for DMA",
        "modified_files_count": 1,
        "modified_files": [
            "avidemux/qt4/ADM_UIs/src/T_openGL.cpp"
        ],
        "github_commit_url": "https://github.com/mean00/avidemux2/commit/dc0d0468e995514e14838189a1e2aee879ace880",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ADM_coreVideoFilterQtGl::downloadTexturesDma"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "avidemux2",
        "optimization_summary": [
            "The optimization strategy involved extending fast readback plane conversion to DMA operations, reducing unnecessary data processing overhead.",
            "The optimization strategy involved extending fast readback plane conversion to DMA operations, reducing unnecessary data processing overhead.",
            "The optimization strategy involved extending fast readback plane conversion to include DMA operations, reducing processing overhead.",
            "The optimization strategy involved extending fast readback plane conversion to DMA operations, reducing computational overhead by reusing existing optimized paths.",
            "The optimization strategy involved extending fast readback plane conversion to DMA operations, reducing computational overhead by reusing existing optimized paths."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved extending fast readback plane conversion to DMA operations, reducing unnecessary data processing overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "helenos",
        "hash": "311835517791f7a69b14bbd4085e537dad94c36f",
        "author": "Jiří Zárevúcky",
        "date": "2023-03-21T18:41:48+01:00",
        "message": "Optimize relink_rq()\n\nIterate backwards and only lock each runqueue once instead of twice.",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/generic/src/proc/scheduler.c"
        ],
        "github_commit_url": "https://github.com/HelenOS/helenos/commit/311835517791f7a69b14bbd4085e537dad94c36f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DAMAGES"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved iterating backwards through the runqueue and reducing the number of lock operations from two to one per runqueue.",
            "The optimization strategy reduces redundant locking operations by iterating backwards and locking each runqueue only once instead of twice.",
            "The optimization strategy involved iterating backwards through the runqueue and reducing the number of lock operations from two to one per runqueue.",
            "The optimization strategy involved iterating backwards through the runqueue and reducing the number of lock operations from two to one per runqueue.",
            "The optimization strategy involved iterating backwards through the runqueue and reducing the number of lock operations from two to one per runqueue."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved iterating backwards through the runqueue and reducing the number of lock operations from two to one per runqueue.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pinmame",
        "hash": "b74a51ece8486887af455a1a5c9b8e0185b4a584",
        "author": "volkenborn",
        "date": "2003-07-02T15:49:36+00:00",
        "message": "Okay, a bit faster now.\n\n\ngit-svn-id: https://svn.code.sf.net/p/pinmame/code/trunk@1205 6f51dfdd-75df-4273-8f3b-818b1e6aa8bf",
        "modified_files_count": 1,
        "modified_files": [
            "src/wpc/gts80s.c"
        ],
        "github_commit_url": "https://github.com/vpinball/pinmame/commit/b74a51ece8486887af455a1a5c9b8e0185b4a584",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "nmi_callback"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary computations or function calls within the `nmi_callback` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or function calls within the `nmi_callback` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or function calls within the `nmi_callback` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or function calls within the `nmi_callback` function to improve performance.",
            "The optimization strategy involved reducing unnecessary computations or function calls within the `nmi_callback` function to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary computations or function calls within the `nmi_callback` function to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "97c9d4c64c870c1eceb1d6264f2457273e6e0738",
        "author": "Hal Finkel",
        "date": "2012-04-01T19:22:57+00:00",
        "message": "Use full anti-dep. breaking with post-ra sched. on the embedded ppc cores.\n\nPost-RA scheduling gives a significant performance improvement on\nthe embedded cores, so turn it on. Using full anti-dep. breaking is\nimportant for FP-intensive blocks, so turn it on (just on the\nembedded cores for now; this should also be good on the 970s because\npost-ra scheduling is all that we have for now, but that should have\nmore testing first).\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@153843 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Target/PowerPC/PPCSubtarget.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/97c9d4c64c870c1eceb1d6264f2457273e6e0738",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PPCSubtarget::enablePostRAScheduler"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves enabling post-register allocation scheduling and full anti-dependency breaking to improve performance on embedded PowerPC cores.",
            "The optimization strategy involves enabling post-register allocation scheduling and full anti-dependency breaking to improve performance on embedded PowerPC cores.",
            "The optimization strategy involves enabling post-register allocation scheduling and full anti-dependence breaking to improve performance on embedded PowerPC cores.",
            "The optimization strategy involves enabling post-register allocation scheduling and full anti-dependency breaking to improve performance on embedded PowerPC cores.",
            "The optimization strategy involves enabling post-register allocation scheduling and full anti-dependency breaking to improve performance on embedded PowerPC cores."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves enabling post-register allocation scheduling and full anti-dependency breaking to improve performance on embedded PowerPC cores.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pqR",
        "hash": "a2e879bc6330544856948e78ddf2859ba410fdd4",
        "author": "Radford Neal",
        "date": "2018-05-31T10:41:43-04:00",
        "message": "speed up real-vec[1-sub] <- int-scalar",
        "modified_files_count": 1,
        "modified_files": [
            "src/main/subset.c"
        ],
        "github_commit_url": "https://github.com/radfordneal/pqR/commit/a2e879bc6330544856948e78ddf2859ba410fdd4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "spec"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to directly assign an integer scalar to a specific index in a real vector, avoiding unnecessary computations or checks.",
            "The optimization strategy used is to directly assign an integer scalar to a specific index in a real vector, avoiding unnecessary computations or checks.",
            "The optimization strategy used is to directly assign an integer scalar to a specific index in a real vector, avoiding unnecessary computations or checks.",
            "The optimization strategy used is to directly assign an integer scalar to a specific index in a real vector, avoiding unnecessary computations or checks.",
            "The optimization strategy used is to directly assign an integer scalar to a specific index in a real vector, avoiding unnecessary computations or checks."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to directly assign an integer scalar to a specific index in a real vector, avoiding unnecessary computations or checks.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "android_kernel_msm-5.4_nothing_sm7325",
        "hash": "946a36f82a0b21567e92f932832abdeb758bcc70",
        "author": "Davide Caratti",
        "date": "2021-06-23T14:41:25+02:00",
        "message": "net/mlx5e: allow TSO on VXLAN over VLAN topologies\n\n[ Upstream commit a1718505d7f67ee0ab051322f1cbc7ac42b5da82 ]\n\nsince mlx5 hardware can segment correctly TSO packets on VXLAN over VLAN\ntopologies, CPU usage can improve significantly if we enable tunnel\noffloads in dev->vlan_features, like it was done in the past with other\nNIC drivers (e.g. mlx4, be2net and ixgbe).\n\nSigned-off-by: Davide Caratti <dcaratti@redhat.com>\nSigned-off-by: Saeed Mahameed <saeedm@mellanox.com>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/ethernet/mellanox/mlx5/core/en_main.c"
        ],
        "github_commit_url": "https://github.com/NothingOSS/android_kernel_msm-5.4_nothing_sm7325/commit/946a36f82a0b21567e92f932832abdeb758bcc70",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mlx5e_build_nic_netdev"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization enables hardware-based TSO (TCP Segmentation Offload) for VXLAN over VLAN topologies by updating the device's VLAN features, reducing CPU overhead.",
            "The optimization enables hardware-based TSO (TCP Segmentation Offload) for VXLAN over VLAN topologies by updating device features, reducing CPU overhead.",
            "The optimization enables hardware-based segmentation of TSO packets on VXLAN over VLAN topologies by updating VLAN features, reducing CPU overhead.",
            "The optimization enables hardware-based segmentation of TSO packets on VXLAN over VLAN topologies by updating VLAN features, reducing CPU overhead.",
            "The optimization enables hardware-based segmentation of TSO packets on VXLAN over VLAN topologies by updating VLAN features, reducing CPU overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization enables hardware-based segmentation of TSO packets on VXLAN over VLAN topologies by updating VLAN features, reducing CPU overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ytsaurus",
        "hash": "ba7603ee52b328a30ef4b56d377c847b4e1fc0f7",
        "author": "Pavel Sushin",
        "date": "2018-01-28T12:54:22+03:00",
        "message": "Fix memory usage calculation",
        "modified_files_count": 1,
        "modified_files": [
            "yt/server/job_proxy/user_job.cpp"
        ],
        "github_commit_url": "https://github.com/ytsaurus/ytsaurus/commit/ba7603ee52b328a30ef4b56d377c847b4e1fc0f7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CheckMemoryUsage"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved refining memory usage calculation to improve accuracy and potentially reduce unnecessary memory allocations.",
            "The optimization strategy involved refining memory usage calculation to improve accuracy and reduce unnecessary overhead.",
            "The optimization strategy involved refining memory usage calculation to improve accuracy and reduce unnecessary overhead.",
            "The optimization strategy involved refining memory usage calculation to reduce unnecessary computations or improve accuracy.",
            "The optimization strategy involved refining memory usage calculation to improve accuracy and reduce unnecessary overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved refining memory usage calculation to improve accuracy and reduce unnecessary overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "clang",
        "hash": "fc0fed3fc7159d17dc6a08e91a4eda413ace3642",
        "author": "Mike Stump",
        "date": "2009-04-28T01:19:10+00:00",
        "message": "We avoid the count of diagnostics when not generating carent\ndiagnostics to improve gcc compatibility; useful for dejagnu testing.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@70278 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "tools/clang-cc/clang-cc.cpp"
        ],
        "github_commit_url": "https://github.com/llvm-mirror/clang/commit/fc0fed3fc7159d17dc6a08e91a4eda413ace3642",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids counting diagnostics when not generating current diagnostics to improve performance and GCC compatibility.",
            "The optimization avoids counting diagnostics when not generating current diagnostics to improve performance and GCC compatibility.",
            "The optimization avoids counting diagnostics when not generating current diagnostics to improve performance and GCC compatibility.",
            "The optimization avoids counting diagnostics when not generating current diagnostics to improve performance and GCC compatibility.",
            "The optimization avoids counting diagnostics when not generating current diagnostics to improve performance and GCC compatibility."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids counting diagnostics when not generating current diagnostics to improve performance and GCC compatibility.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "clang",
        "hash": "027d7ed9d616d93ae7f02de79d17863725b14866",
        "author": "Fariborz Jahanian",
        "date": "2010-06-21T19:49:38+00:00",
        "message": "Use more efficient API of SmallVector/array_pod_sort\nfor sorting (radar 8076356).\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@106453 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/CodeGen/CGDeclCXX.cpp"
        ],
        "github_commit_url": "https://github.com/llvm-mirror/clang/commit/027d7ed9d616d93ae7f02de79d17863725b14866",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CodeGenModule::EmitCXXGlobalInitFunc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a less efficient sorting method with a more efficient API call for sorting operations in SmallVector/array_pod_sort.",
            "The optimization strategy involved replacing a less efficient sorting method with a more efficient API call for sorting SmallVector or array_pod_sort.",
            "The optimization strategy involved replacing a less efficient sorting method with a more efficient API call for sorting SmallVector or array_pod_sort.",
            "The optimization strategy involved replacing a less efficient sorting method with a more efficient API call for sorting SmallVector or array_pod_sort.",
            "The optimization strategy involved replacing a less efficient sorting method with a more efficient API call for sorting operations in SmallVector/array_pod_sort."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a less efficient sorting method with a more efficient API call for sorting SmallVector or array_pod_sort.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "86a43bc97d024ca300eb366f5717807207716a08",
        "author": "Dirkjan Bussink",
        "date": "2012-08-02T21:35:27+02:00",
        "message": "Make sure to return after setting the entry\n\nWe were filling all the entries with a pointer to the exact same method\ncache entry which is of course not very smart and actually defeats the\nfact that the jit can optimize this properly.",
        "modified_files_count": 1,
        "modified_files": [
            "vm/inline_cache.hpp"
        ],
        "github_commit_url": "https://github.com/rubinius/rubinius/commit/86a43bc97d024ca300eb366f5717807207716a08",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "set_cache"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "rubinius",
        "optimization_summary": [
            "The optimization ensures that each entry in the cache is set only once and returned immediately, avoiding redundant overwrites with the same method cache entry.",
            "The optimization ensures that each entry in the cache is set correctly by returning after setting an entry, preventing redundant overwrites with the same method cache pointer.",
            "The optimization ensures that each entry in the cache is set only once and avoids overwriting with the same method cache pointer, enabling proper JIT optimizations.",
            "The optimization ensures that each entry in the cache is set correctly by returning after setting an entry, preventing redundant overwrites with the same method cache entry.",
            "The optimization ensures that each entry in the cache is set correctly by returning after setting an entry, preventing redundant overwrites with the same method cache pointer."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization ensures that each entry in the cache is set correctly by returning after setting an entry, preventing redundant overwrites with the same method cache pointer.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "37b74ada2fe977a162425211ed87fdfa7ea293e0",
        "author": "Dave Rigby",
        "date": "2015-10-15T13:46:04+00:00",
        "message": "Testapp: Enable TCP_NODELAY on plain connections\n\nWe are now using testapp for some Subdoc benchmarking. Given the\ncurrent benchmark is relatively simple (single command-response)\nenable NODELAY to hopefully minimise the latency of these commands\n\nChange-Id: I44941ac9fa09db1a34fd9902f6a2ed6c72d236e2\nReviewed-on: http://review.couchbase.org/56146\nReviewed-by: Trond Norbye <trond.norbye@gmail.com>\nTested-by: buildbot <build@couchbase.com>",
        "modified_files_count": 1,
        "modified_files": [
            "tests/testapp/testapp.cc"
        ],
        "github_commit_url": "https://github.com/couchbase/kv_engine/commit/37b74ada2fe977a162425211ed87fdfa7ea293e0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "create_connect_plain_socket"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "kv_engine",
        "optimization_summary": [
            "The optimization strategy involved enabling TCP_NODELAY to reduce latency in a simple command-response benchmarking scenario.",
            "The optimization strategy involved enabling TCP_NODELAY to reduce latency in a simple command-response benchmarking scenario.",
            "The optimization strategy involved enabling TCP_NODELAY to reduce latency in simple command-response benchmarking scenarios.",
            "The optimization strategy involved enabling TCP_NODELAY to reduce latency in a simple command-response benchmarking scenario.",
            "The optimization strategy involved enabling TCP_NODELAY to reduce latency in a simple command-response benchmarking scenario."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved enabling TCP_NODELAY to reduce latency in a simple command-response benchmarking scenario.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lua-nginx-module",
        "hash": "ff81634233e8663df583face9eae02cd5b57502b",
        "author": "syz",
        "date": "2020-10-09T15:54:18+08:00",
        "message": "optimize: added the \"ev\" to ngx_posted_delayed_events instead of the rbtree for 0 delay timer,\nso that we can save an epoll wait in such case.",
        "modified_files_count": 1,
        "modified_files": [
            "src/ngx_http_lua_timer.c"
        ],
        "github_commit_url": "https://github.com/openresty/lua-nginx-module/commit/ff81634233e8663df583face9eae02cd5b57502b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ngx_http_lua_ngx_timer_helper"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids adding a 0-delay timer to the rbtree and instead posts it directly to the event queue, saving an epoll wait.",
            "The optimization avoids unnecessary epoll waits by directly adding zero-delay timers to the event queue instead of the rbtree.",
            "The optimization avoids adding a 0-delay timer to the rbtree and instead posts it directly to the event queue, saving an unnecessary epoll wait.",
            "The optimization avoids adding a 0-delay timer to the rbtree and instead posts it directly to the event queue, saving an epoll wait.",
            "The optimization avoids adding a 0-delay timer to the rbtree and instead posts it directly to the event queue, saving an epoll wait."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids adding a 0-delay timer to the rbtree and instead posts it directly to the event queue, saving an epoll wait.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Principia",
        "hash": "73d609777538fe9d7b4b87321921c8b68fd79f9f",
        "author": "Pascal Leroy",
        "date": "2018-12-25T15:54:01+01:00",
        "message": "Parallelize the genetic algorithm.",
        "modified_files_count": 1,
        "modified_files": [
            "astronomy/trappist_dynamics_test.cpp"
        ],
        "github_commit_url": "https://github.com/mockingbirdnest/Principia/commit/73d609777538fe9d7b4b87321921c8b68fd79f9f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TEST_F"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved parallelizing the genetic algorithm to improve computational efficiency by leveraging multiple threads or processes.",
            "The optimization strategy involved parallelizing the genetic algorithm to improve computational efficiency by leveraging multiple threads or processes.",
            "The optimization strategy involved parallelizing the genetic algorithm to improve computational efficiency by leveraging multiple threads or processes.",
            "The optimization strategy involved parallelizing the genetic algorithm to improve computational efficiency by utilizing multiple threads or processes.",
            "The optimization strategy involved parallelizing the genetic algorithm to improve computational efficiency by leveraging multiple threads or processes."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved parallelizing the genetic algorithm to improve computational efficiency by leveraging multiple threads or processes.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "flux-core",
        "hash": "c8a3a628e4ac345d62db559c3eea89dbee651c24",
        "author": "Albert Chu",
        "date": "2021-03-24T16:09:19+00:00",
        "message": "job-info: add optimization for job-info watch\n\nIf the RPC request comes from the instance owner, there is no need\nto do an job ownership access check.  This check was done in the job-info\nlookup code, but not the watch code.",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/job-info/watch.c"
        ],
        "github_commit_url": "https://github.com/flux-framework/flux-core/commit/c8a3a628e4ac345d62db559c3eea89dbee651c24",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "watch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids unnecessary job ownership access checks for RPC requests from the instance owner in the job-info watch code.",
            "The optimization avoids unnecessary job ownership access checks for RPC requests from the instance owner in the job-info watch code.",
            "The optimization strategy eliminates unnecessary job ownership access checks for RPC requests from the instance owner in the job-info watch code.",
            "The optimization avoids unnecessary job ownership access checks for RPC requests from the instance owner in the job-info watch code.",
            "The optimization avoids unnecessary job ownership access checks for RPC requests from the instance owner in the job-info watch code."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary job ownership access checks for RPC requests from the instance owner in the job-info watch code.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "intel-graphics-compiler",
        "hash": "5a8c5740bdae9f27e3a8e5048e91d2fdc41349c4",
        "author": "pmistry",
        "date": "2018-05-14T15:20:44-07:00",
        "message": "MarkVirtRegAliveInBlock had hotspot for a very large shader during compile time. \nThe DFS recursion was not taking into consideration already visited blocs and pushing them into the work queue. This creates one additional level of DFS on already visited blocks. \n\nChange-Id: I79bdfe05086f8a35df6cf8d8def2cd727aff04d8",
        "modified_files_count": 1,
        "modified_files": [
            "IGC/Compiler/CISACodeGen/LiveVars.cpp"
        ],
        "github_commit_url": "https://github.com/intel/intel-graphics-compiler/commit/5a8c5740bdae9f27e3a8e5048e91d2fdc41349c4",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant DFS recursion by skipping already visited blocks in the work queue.",
            "The optimization avoids redundant DFS recursion by skipping already visited blocks, reducing unnecessary work in the compilation process.",
            "The optimization avoids redundant DFS recursion by skipping already visited blocks, reducing unnecessary work in the compilation process.",
            "The optimization avoids redundant DFS recursion by skipping already visited blocks, reducing unnecessary work in the compilation process.",
            "The optimization avoids redundant DFS recursion by skipping already visited blocks, reducing unnecessary work in the compilation process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids redundant DFS recursion by skipping already visited blocks, reducing unnecessary work in the compilation process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "v8",
        "hash": "c62038f98cf1636b7ffe7db61e589596cb96aeff",
        "author": "Leszek Swirski",
        "date": "2022-10-12T11:45:00+00:00",
        "message": "Revert \"[maglev] Box Float64s as Smis if possible\"\n\nThis reverts commit 6e358ed06db92cdc1531cead603f9a24ab580bb0.\n\nReason for revert: Regresses performance on a couple of benchmarks (e.g. Box2d)\n\nOriginal change's description:\n> [maglev] Box Float64s as Smis if possible\n>\n> Bug: v8:7700\n> Change-Id: I085b561330cf827df3a31371d39b1cee0f77f32e\n> Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/3938037\n> Reviewed-by: Toon Verwaest <verwaest@chromium.org>\n> Commit-Queue: Leszek Swirski <leszeks@chromium.org>\n> Cr-Commit-Position: refs/heads/main@{#83608}\n\nBug: v8:7700\nChange-Id: I7e0a9a37e841dabe3c4234413a60054a88f1e69b\nReviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/3948707\nBot-Commit: Rubber Stamper <rubber-stamper@appspot.gserviceaccount.com>\nAuto-Submit: Leszek Swirski <leszeks@chromium.org>\nCommit-Queue: Leszek Swirski <leszeks@chromium.org>\nCr-Commit-Position: refs/heads/main@{#83644}",
        "modified_files_count": 1,
        "modified_files": [
            "src/maglev/maglev-ir.cc"
        ],
        "github_commit_url": "https://github.com/v8/v8/commit/c62038f98cf1636b7ffe7db61e589596cb96aeff",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Float64Box::GenerateCode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reverting a change that attempted to box Float64 values as Smis, which was found to regress performance on specific benchmarks.",
            "The optimization strategy involved reverting a change that attempted to box Float64 values as Smis, which was found to regress performance on specific benchmarks.",
            "The optimization strategy involved reverting a change that attempted to box Float64 values as Smis, which was intended to improve performance but caused regressions in specific benchmarks.",
            "The optimization strategy involved reverting a change that attempted to box Float64 values as Smis, which was found to regress performance on specific benchmarks.",
            "The optimization strategy involved reverting a change that attempted to box Float64 values as Smis, which had caused performance regressions in specific benchmarks."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reverting a change that attempted to box Float64 values as Smis, which was found to regress performance on specific benchmarks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cmssw",
        "hash": "0707a368b3e5917ebc3380a1ab3d15ddc34ca645",
        "author": "Gregor Mittag",
        "date": "2017-03-31T13:59:56+02:00",
        "message": "Optimize usage of 'proDer' matrices in 'GblTrajectory'.",
        "modified_files_count": 1,
        "modified_files": [
            "Alignment/ReferenceTrajectories/src/GblTrajectory.cc"
        ],
        "github_commit_url": "https://github.com/cms-sw/cmssw/commit/0707a368b3e5917ebc3380a1ab3d15ddc34ca645",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "data"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations by reusing precomputed 'proDer' matrices in the 'GblTrajectory' class.",
            "The optimization strategy involved reducing redundant computations by reusing precomputed 'proDer' matrices in the 'GblTrajectory' class.",
            "The optimization strategy involved reducing redundant computations by caching and reusing the 'proDer' matrices in the 'GblTrajectory' class.",
            "The optimization strategy involved reducing redundant computations by reusing precomputed 'proDer' matrices in the 'GblTrajectory' class.",
            "The optimization strategy involved reducing redundant computations by reusing precomputed 'proDer' matrices in the 'GblTrajectory' class."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations by reusing precomputed 'proDer' matrices in the 'GblTrajectory' class.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kernel_xiaomi_sm8250",
        "hash": "8a891c565ce272be7aa43e8f99a81f0675f77100",
        "author": "Sultan Alsawaf",
        "date": "2024-02-15T01:32:50+02:00",
        "message": "techpack: display: Skip heavy autorefresh checks when it's not enabled\n\nThese heavy checks for seeing if autorefresh is enabled are unneeded\nwhen the autorefresh config is disabled. These checks are performed on\nevery display commit and show up as using a significant amount of CPU\ntime in perf top. Skip them when it's unnecessary in order to improve\ndisplay rendering performance.\n\nSigned-off-by: Sultan Alsawaf <sultan@kerneltoast.com>",
        "modified_files_count": 1,
        "modified_files": [
            "techpack/display/msm/sde/sde_encoder_phys_cmd.c"
        ],
        "github_commit_url": "https://github.com/EmanuelCN/kernel_xiaomi_sm8250/commit/8a891c565ce272be7aa43e8f99a81f0675f77100",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sde_encoder_phys_cmd_is_autorefresh_enabled"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy skips unnecessary heavy checks for autorefresh when the feature is disabled to reduce CPU overhead.",
            "The optimization strategy skips unnecessary heavy checks for autorefresh when the feature is disabled to reduce CPU overhead.",
            "The optimization strategy skips unnecessary heavy checks for autorefresh when the feature is disabled to reduce CPU overhead.",
            "The optimization strategy skips unnecessary heavy checks for autorefresh when the feature is disabled, reducing CPU overhead during display commits.",
            "The optimization strategy skips unnecessary heavy checks for autorefresh when the feature is disabled, reducing CPU overhead during display commits."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips unnecessary heavy checks for autorefresh when the feature is disabled to reduce CPU overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "vpp",
        "hash": "840f64b4b2d6063adebb8c7b31c9357aaaf8dd5e",
        "author": "Lijian.Zhang",
        "date": "2019-09-11T19:20:27+00:00",
        "message": "ip: apply dual loop unrolling in ip4_rewrite\n\nToo many prefetches within loop unrollings induce bottleneck and\nperformance degradation on some CPUs which have less cache line fill\nbuffers, e.g, Arm Cortex-A72.\nApply dual loop unrolling and tune prefetches manually to remove\nhot-spot with prefetch instructions, to get throughput improvement.\nIt brings about 7% throughput improvement and saves 28% clocks with\nip4_rewrite nodes on Cortex-A72 CPUs.\n\nType: feature\n\nChange-Id: I0d35ef19faccbd7a5a4647f50bc369bfcb01a20d\nSigned-off-by: Lijian Zhang <Lijian.Zhang@arm.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/vnet/ip/ip4_forward.c"
        ],
        "github_commit_url": "https://github.com/FDio/vpp/commit/840f64b4b2d6063adebb8c7b31c9357aaaf8dd5e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ip4_rewrite_inline_with_gso"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved applying dual loop unrolling and manually tuning prefetch instructions to reduce cache bottlenecks and improve throughput on specific CPUs.",
            "The optimization strategy involved applying dual loop unrolling and manually tuning prefetch instructions to reduce cache line fill bottlenecks on specific CPUs.",
            "The optimization strategy involved applying dual loop unrolling and manually tuning prefetch instructions to reduce cache line fill bottlenecks on specific CPUs.",
            "The optimization strategy involved applying dual loop unrolling and manually tuning prefetch instructions to reduce cache line fill bottlenecks on specific CPUs.",
            "The optimization strategy involved applying dual loop unrolling and manually tuning prefetch instructions to reduce cache bottlenecks and improve throughput on specific CPUs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved applying dual loop unrolling and manually tuning prefetch instructions to reduce cache line fill bottlenecks on specific CPUs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "vcmi",
        "hash": "3a27725fcbc7b6046920b663dcb48e77495d8273",
        "author": "K",
        "date": "2024-08-22T11:39:24+02:00",
        "message": "Optimize CMap::isInTheMap\n\nreplace x >= 0 && x < size by (unsigned)x < size\n\nBy converting signed coordinate to unsigned number, negative values became\nvery large positive ones, larger than every positive signed number and\ntherefore also bigger than the map size. As a result check against size\nalso implicitly checks if coordinate is negative.\n\nCompiler cannot do this transformation automatically because it doesn't\nknow that map dimensions are always positive.\n\nThe change shrinks isInTheMap from 19 instructions to 11 on x86.",
        "modified_files_count": 1,
        "modified_files": [
            "lib/mapping/CMap.cpp"
        ],
        "github_commit_url": "https://github.com/vcmi/vcmi/commit/3a27725fcbc7b6046920b663dcb48e77495d8273",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CMap::isInTheMap"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces a combined signed comparison with an unsigned comparison to implicitly handle negative values and reduce instruction count.",
            "The optimization replaces a two-part bounds check with a single unsigned comparison, leveraging the properties of unsigned integers to implicitly handle negative values.",
            "The optimization replaces a combined signed comparison with an unsigned comparison to implicitly handle negative values and reduce instruction count.",
            "The optimization replaces a combined signed comparison with an unsigned comparison to implicitly handle negative values and reduce instruction count.",
            "The optimization replaces a two-part bounds check with a single unsigned comparison, leveraging the properties of unsigned integers to implicitly handle negative values."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization replaces a combined signed comparison with an unsigned comparison to implicitly handle negative values and reduce instruction count.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "8673b83bf2f013379453b4779047bf3c6ae387e4",
        "author": "Ross Lagerwall",
        "date": "2013-06-05T13:10:57+02:00",
        "message": "acpi-cpufreq: set current frequency based on target P-State\n\nCommit 4b31e774 (Always set P-state on initialization) fixed bug\n#4634 and caused the driver to always set the target P-State at\nleast once since the initial P-State may not be the desired one.\nCommit 5a1c0228 (cpufreq: Avoid calling cpufreq driver's target()\nroutine if target_freq == policy->cur) caused a regression in\nthis behavior.\n\nThis fixes the regression by setting policy->cur based on the CPU's\ntarget frequency rather than the CPU's current reported frequency\n(which may be different).  This means that the P-State will be set\ninitially if the CPU's target frequency is different from the\ngovernor's target frequency.\n\nThis fixes an issue where setting the default governor to\nperformance wouldn't correctly enable turbo mode on all cores.\n\nSigned-off-by: Ross Lagerwall <rosslagerwall@gmail.com>\nReviewed-by: Len Brown <len.brown@intel.com>\nAcked-by: Viresh Kumar <viresh.kumar@linaro.org>\nCc: 3.8+ <stable@vger.kernel.org>\nSigned-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/cpufreq/acpi-cpufreq.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/8673b83bf2f013379453b4779047bf3c6ae387e4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_cur_val"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involves setting the current frequency based on the target P-State to ensure correct initial frequency alignment and avoid unnecessary calls to the target routine.",
            "The optimization ensures the CPU's current frequency policy is set based on the target frequency rather than the reported frequency to avoid unnecessary P-State adjustments.",
            "The optimization strategy involves setting the current frequency based on the target P-State to ensure correct initial frequency alignment and avoid unnecessary calls to the target routine.",
            "The optimization strategy involves setting the current frequency based on the target P-State to ensure correct initial frequency alignment and avoid unnecessary calls to the target routine.",
            "The optimization ensures the CPU's current frequency is set based on the target P-State rather than the reported frequency to avoid initialization inconsistencies."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves setting the current frequency based on the target P-State to ensure correct initial frequency alignment and avoid unnecessary calls to the target routine.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "1d068cc0b07694799e077b28dbd272b7982727e2",
        "author": "Chris Lattner",
        "date": "2011-05-22T04:53:24+00:00",
        "message": "switch to using a smallvector to avoid allocations for most normal size instructions.\n\nllvm-svn: 131837",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/MC/MCDisassembler/Disassembler.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/1d068cc0b07694799e077b28dbd272b7982727e2",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
            "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a standard vector with a SmallVector to reduce dynamic memory allocations for typical instruction sizes.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qbe",
        "hash": "7ce4d334e54433f7e67d91baa9edb25adb26975b",
        "author": "Quentin Carbonneaux",
        "date": "2015-09-15T23:01:31-04:00",
        "message": "add a small size optimization to emit",
        "modified_files_count": 1,
        "modified_files": [
            "lisc/emit.c"
        ],
        "github_commit_url": "https://github.com/8l/qbe/commit/7ce4d334e54433f7e67d91baa9edb25adb26975b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "eins"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to reduce unnecessary memory allocations by reusing a pre-allocated buffer for small-size operations in the `eins` function.",
            "The optimization strategy used is to reduce unnecessary memory allocations by reusing a pre-allocated buffer for small-size operations in the `eins` function.",
            "The optimization strategy used is reducing unnecessary memory allocations by reusing a pre-allocated buffer for small-size operations in the `eins` function.",
            "The optimization strategy used is to reduce unnecessary memory allocations by reusing a pre-allocated buffer for small-size operations in the `eins` function.",
            "The optimization strategy used is to reduce unnecessary memory allocations by reusing a pre-allocated buffer for small data sizes."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is to reduce unnecessary memory allocations by reusing a pre-allocated buffer for small-size operations in the `eins` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "john",
        "hash": "249176cc0ba651b523374c95ad014028b7afa88b",
        "author": "Claudio André",
        "date": "2019-04-17T21:47:32-03:00",
        "message": "OpenCL: rawSHA512 force auto-tuning\n\nIt was resulting in a cracking performance less than ideal.",
        "modified_files_count": 1,
        "modified_files": [
            "src/opencl_rawsha512_gpl_fmt_plug.c"
        ],
        "github_commit_url": "https://github.com/openwall/john/commit/249176cc0ba651b523374c95ad014028b7afa88b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tune"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization forces auto-tuning in the OpenCL rawSHA512 implementation to improve cracking performance by adapting to hardware capabilities.",
            "The optimization forces auto-tuning in the OpenCL rawSHA512 implementation to improve cracking performance by adapting to hardware capabilities.",
            "The optimization forces auto-tuning in the OpenCL rawSHA512 implementation to improve cracking performance by adapting to hardware capabilities.",
            "The optimization forces auto-tuning in the OpenCL rawSHA512 implementation to improve cracking performance by adapting to hardware capabilities.",
            "The optimization forces auto-tuning in the OpenCL rawSHA512 implementation to improve cracking performance by adapting to hardware capabilities."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization forces auto-tuning in the OpenCL rawSHA512 implementation to improve cracking performance by adapting to hardware capabilities.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "httpd",
        "hash": "5154894e093b2c3652f5f35fb32b9fd75486ddd4",
        "author": "Joe Orton",
        "date": "2004-06-01T13:06:10+00:00",
        "message": "* modules/filters/mod_deflate.c (deflate_out_filter): Destroy buckets\nimmediately after are used so that memory consumption is not\nproportional to the size of the response.\n\nPR: 29318\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@103810 13f79535-47bb-0310-9956-ffa450edef68",
        "modified_files_count": 1,
        "modified_files": [
            "modules/filters/mod_deflate.c"
        ],
        "github_commit_url": "https://github.com/apache/httpd/commit/5154894e093b2c3652f5f35fb32b9fd75486ddd4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "deflate_out_filter"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves immediately destroying buckets after they are used to reduce memory consumption proportional to the response size.",
            "The optimization strategy involves immediately destroying buckets after they are used to reduce memory consumption proportional to the response size.",
            "The optimization strategy involves immediately destroying buckets after use to reduce memory consumption proportional to the response size.",
            "The optimization strategy involves immediately destroying buckets after use to reduce memory consumption proportional to the response size.",
            "The optimization strategy involves immediately destroying buckets after their use to reduce memory consumption proportional to the response size."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves immediately destroying buckets after they are used to reduce memory consumption proportional to the response size.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "19b5fbdd3d571ee7c55fabb081ebcc30bae64619",
        "author": "Glenn Strauss",
        "date": "2018-11-19T20:52:34-05:00",
        "message": "[mod_fastcgi] transfer chunks minus packet padding\n\n(thx avij)",
        "modified_files_count": 1,
        "modified_files": [
            "src/mod_fastcgi.c"
        ],
        "github_commit_url": "https://github.com/lighttpd/lighttpd1.4/commit/19b5fbdd3d571ee7c55fabb081ebcc30bae64619",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fcgi_recv_parse"
        ],
        "is_opt_ds": "false",
        "is_opt_ds_simple": "true",
        "repository_name": "lighttpd1.4",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary data copying by adjusting how chunks are transferred, specifically by excluding packet padding during the parsing process.",
            "The optimization strategy involved reducing unnecessary data copying by directly transferring chunks without packet padding.",
            "The optimization strategy involved reducing unnecessary data copying by adjusting how chunks are transferred, specifically by excluding packet padding during the parsing process.",
            "The optimization reduces unnecessary data copying by adjusting the chunk size to exclude packet padding during FastCGI data transfer.",
            "The optimization strategy involved reducing unnecessary data copying by adjusting how chunks are transferred, specifically by excluding packet padding during the parsing process."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary data copying by adjusting how chunks are transferred, specifically by excluding packet padding during the parsing process.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "selinux-kernel",
        "hash": "3aeea4fc835d31235947787c2b8dcbc255131106",
        "author": "David Hildenbrand",
        "date": "2024-05-05T17:53:29-07:00",
        "message": "mm/memory: use folio_mapcount() in zap_present_folio_ptes()\n\nWe want to limit the use of page_mapcount() to the places where it is\nabsolutely necessary.  In zap_present_folio_ptes(), let's simply check the\nfolio mapcount().  If there is some issue, it will underflow at some point\neither way when unmapping.\n\nAs indicated already in commit 10ebac4f95e7 (\"mm/memory: optimize\nunmap/zap with PTE-mapped THP\"), we already documented \"If we ever have a\ncheap folio_mapcount(), we might just want to check for underflows\nthere.\".\n\nThere is no change for small folios.  For large folios, we'll now catch\nmore underflows when batch-unmapping, because instead of only testing the\nmapcount of the first subpage, we'll test if the folio mapcount\nunderflows.\n\nLink: https://lkml.kernel.org/r/20240409192301.907377-8-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nCc: Chris Zankel <chris@zankel.net>\nCc: Hugh Dickins <hughd@google.com>\nCc: John Paul Adrian Glaubitz <glaubitz@physik.fu-berlin.de>\nCc: Jonathan Corbet <corbet@lwn.net>\nCc: Matthew Wilcox (Oracle) <willy@infradead.org>\nCc: Max Filippov <jcmvbkbc@gmail.com>\nCc: Miaohe Lin <linmiaohe@huawei.com>\nCc: Muchun Song <muchun.song@linux.dev>\nCc: Naoya Horiguchi <nao.horiguchi@gmail.com>\nCc: Peter Xu <peterx@redhat.com>\nCc: Richard Chang <richardycc@google.com>\nCc: Rich Felker <dalias@libc.org>\nCc: Ryan Roberts <ryan.roberts@arm.com>\nCc: Yang Shi <shy828301@gmail.com>\nCc: Yin Fengwei <fengwei.yin@intel.com>\nCc: Yoshinori Sato <ysato@users.sourceforge.jp>\nCc: Zi Yan <ziy@nvidia.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/memory.c"
        ],
        "github_commit_url": "https://github.com/SELinuxProject/selinux-kernel/commit/3aeea4fc835d31235947787c2b8dcbc255131106",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "zap_present_folio_ptes"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization replaces `page_mapcount()` with `folio_mapcount()` in `zap_present_folio_ptes()` to improve efficiency by reducing unnecessary checks and catching more underflows for large folios during batch unmapping.",
            "The optimization strategy replaces `page_mapcount()` with `folio_mapcount()` in `zap_present_folio_ptes()` to improve efficiency and catch more underflows during batch unmapping of large folios.",
            "The optimization strategy replaces `page_mapcount()` with `folio_mapcount()` in `zap_present_folio_ptes()` to improve efficiency and catch more underflows during batch unmapping for large folios.",
            "The optimization strategy replaces `page_mapcount()` with `folio_mapcount()` in `zap_present_folio_ptes()` to improve efficiency and catch more underflows during batch unmapping for large folios.",
            "The optimization replaces `page_mapcount()` with `folio_mapcount()` in `zap_present_folio_ptes()` to improve efficiency and catch more underflows during batch unmapping for large folios."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaces `page_mapcount()` with `folio_mapcount()` in `zap_present_folio_ptes()` to improve efficiency and catch more underflows during batch unmapping for large folios.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenBLAS",
        "hash": "a1075477c351ba010b11721e89b4f6c96334377a",
        "author": "Martin Kroeker",
        "date": "2024-12-30T23:10:55+01:00",
        "message": "Merge pull request #4994 from martin-frbg/issue4886\n\nDisable multithreading in ?TRTRI for small workloads",
        "modified_files_count": 1,
        "modified_files": [
            "interface/lapack/trtri.c"
        ],
        "github_commit_url": "https://github.com/OpenMathLib/OpenBLAS/commit/a1075477c351ba010b11721e89b4f6c96334377a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "NAME"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy disables multithreading for small workloads in the ?TRTRI function to reduce overhead and improve performance.",
            "The optimization strategy disables multithreading for small workloads in the ?TRTRI function to reduce overhead and improve performance.",
            "The optimization strategy disables multithreading for small workloads in the ?TRTRI function to reduce overhead and improve performance.",
            "The optimization strategy disables multithreading for small workloads in the ?TRTRI function to reduce overhead and improve performance.",
            "The optimization strategy disables multithreading for small workloads in the ?TRTRI function to reduce overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy disables multithreading for small workloads in the ?TRTRI function to reduce overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ouinet",
        "hash": "5ed5fe9124641d392f8616fcdfd6cd4982f3cc29",
        "author": "Ivan Vilata-i-Balaguer",
        "date": "2021-04-29T10:35:38+02:00",
        "message": "Move check for `X-Ouinet-Private` header up the chain.\n\nAs most requests will be GETs, this should speed up private browsing by\navoiding HTTP method checks.",
        "modified_files_count": 1,
        "modified_files": [
            "src/client.cpp"
        ],
        "github_commit_url": "https://github.com/equalitie/ouinet/commit/5ed5fe9124641d392f8616fcdfd6cd4982f3cc29",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Client::State::serve_request"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves reordering checks to prioritize the `X-Ouinet-Private` header check before HTTP method checks, reducing unnecessary computations for common GET requests.",
            "The optimization strategy involves reordering checks to prioritize the `X-Ouinet-Private` header check before HTTP method checks, reducing unnecessary computations for common GET requests.",
            "The optimization strategy involves reordering checks to prioritize the `X-Ouinet-Private` header check before HTTP method checks, reducing unnecessary computations for common GET requests.",
            "The optimization strategy involves reordering checks to prioritize the `X-Ouinet-Private` header check before HTTP method checks, reducing unnecessary computations for common GET requests.",
            "The optimization strategy involves reordering a conditional check to occur earlier in the function, reducing unnecessary computations for the common case of GET requests."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves reordering checks to prioritize the `X-Ouinet-Private` header check before HTTP method checks, reducing unnecessary computations for common GET requests.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "8f2ae965b7ef4f4ddab6110f06388e270723d694",
        "author": "Eric Dumazet",
        "date": "2015-07-08T13:50:42-07:00",
        "message": "net_sched: act_gact: read tcfg_ptype once\n\nThird step for gact RCU operation :\n\nFollowing patch will get rid of spinlock protection,\nso we need to read tcfg_ptype once.\n\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nCc: Alexei Starovoitov <ast@plumgrid.com>\nAcked-by: Jamal Hadi Salim <jhs@mojatatu.com>\nAcked-by: John Fastabend <john.fastabend@gmail.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "net/sched/act_gact.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/8f2ae965b7ef4f4ddab6110f06388e270723d694",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tcf_gact"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involves reading the `tcfg_ptype` variable once to reduce redundant accesses and prepare for the removal of spinlock protection.",
            "The optimization strategy involves reading a configuration parameter once to reduce redundant accesses, preparing for the removal of spinlock protection in subsequent patches.",
            "The optimization strategy involves reading the `tcfg_ptype` variable once to reduce redundant accesses and prepare for the removal of spinlock protection.",
            "The optimization strategy involves reading the `tcfg_ptype` variable once to reduce redundant accesses and prepare for the removal of spinlock protection.",
            "The optimization strategy involves reading a configuration parameter once to reduce redundant accesses and prepare for the removal of spinlock protection."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reading the `tcfg_ptype` variable once to reduce redundant accesses and prepare for the removal of spinlock protection.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "athena",
        "hash": "4aa14714802ab3e5a9521685c9120b0a245ba3e1",
        "author": "Chang-Goo Kim",
        "date": "2020-12-31T13:08:48+09:00",
        "message": "Move phi variable declarations within the simd loop",
        "modified_files_count": 1,
        "modified_files": [
            "src/hydro/srcterms/self_gravity.cpp"
        ],
        "github_commit_url": "https://github.com/PrincetonUniversity/athena/commit/4aa14714802ab3e5a9521685c9120b0a245ba3e1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "HydroSourceTerms::SelfGravity"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved moving variable declarations inside a SIMD loop to potentially improve cache locality and reduce redundant memory operations.",
            "The optimization strategy involved moving variable declarations inside a SIMD loop to potentially improve cache locality and reduce redundant computations.",
            "The optimization strategy involved moving variable declarations inside a SIMD loop to potentially improve cache locality and reduce redundant computations.",
            "The optimization strategy involved moving variable declarations inside a SIMD loop to potentially improve cache locality and reduce redundant computations.",
            "The optimization strategy involved moving variable declarations inside a SIMD loop to potentially improve cache locality and reduce redundant computations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved moving variable declarations inside a SIMD loop to potentially improve cache locality and reduce redundant computations.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "pbrt-v4",
        "hash": "a881617a1a9a49561022de53c2cf863cac0e0394",
        "author": "Matt Pharr",
        "date": "2021-07-24T15:45:00-07:00",
        "message": "Parallelize OptiXAggregate::createBuildInputForBLPs()",
        "modified_files_count": 1,
        "modified_files": [
            "src/pbrt/gpu/aggregate.cpp"
        ],
        "github_commit_url": "https://github.com/mmp/pbrt-v4/commit/a881617a1a9a49561022de53c2cf863cac0e0394",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "OptiXAggregate::createBuildInputForBLPs"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was to parallelize the execution of a loop in the `createBuildInputForBLPs` function, likely leveraging multi-threading or GPU parallelism to improve performance.",
            "The optimization strategy used was to parallelize the execution of a loop by utilizing multiple threads to process iterations concurrently.",
            "The optimization strategy used was to parallelize the execution of the `createBuildInputForBLPs` function, likely by distributing work across multiple threads or GPU cores to improve performance.",
            "The optimization strategy used was to parallelize the execution of a loop in the `createBuildInputForBLPs` function, distributing its workload across multiple threads to improve performance.",
            "The optimization strategy used was to parallelize the execution of the `createBuildInputForBLPs` function to improve performance by leveraging multiple threads or GPU cores."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was to parallelize the execution of a loop in the `createBuildInputForBLPs` function, likely leveraging multi-threading or GPU parallelism to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "wesnoth",
        "hash": "1a0cc7cc285e36f6048c984644edd4ee0554d51c",
        "author": "Mark de Wever",
        "date": "2008-02-06T21:52:32+00:00",
        "message": "Small optimization, send the parameter by reference instead of a copy.",
        "modified_files_count": 1,
        "modified_files": [
            "src/game_events.cpp"
        ],
        "github_commit_url": "https://github.com/wesnoth/wesnoth/commit/1a0cc7cc285e36f6048c984644edd4ee0554d51c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "cfg_to_loc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is passing a parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy used is passing a parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy used is passing a parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy used is passing a parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy used is passing a parameter by reference instead of by value to avoid unnecessary copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is passing a parameter by reference instead of by value to avoid unnecessary copying.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ghostpdl",
        "hash": "e5d8d4d6514600f49a6aae2811e3b6fd33c2ef54",
        "author": "Robin Watts",
        "date": "2011-09-10T10:33:26-05:00",
        "message": "Speed up heap freeing (gs_heap_free_object) by avoiding search.\n\nInspired by Bug #687475. Remove the search through every allocated block\nwhen freeing a heap block. Drastically increases the speed. Will hopefully\nhelp other things too.\n\nIf people really want to test that blocks are valid on free, build with\nMemento, which captures this in a much more useful way.",
        "modified_files_count": 1,
        "modified_files": [
            "gs/base/gsmalloc.c"
        ],
        "github_commit_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/e5d8d4d6514600f49a6aae2811e3b6fd33c2ef54",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "gs_heap_free_object"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids searching through every allocated block when freeing a heap block by directly managing memory validity.",
            "The optimization avoids searching through all allocated blocks when freeing a heap block by directly managing memory validity.",
            "The optimization avoids searching through every allocated block when freeing a heap block by directly managing memory validity, significantly speeding up the free operation.",
            "The optimization avoids searching through all allocated blocks when freeing a heap block by directly managing memory validity.",
            "The optimization avoids searching through all allocated blocks when freeing a heap block by directly managing memory validity."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids searching through all allocated blocks when freeing a heap block by directly managing memory validity.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Floorp",
        "hash": "858e60819b2bcd1a6842f418fc3937e17a0f5cb7",
        "author": "Timothy Nikkel",
        "date": "2024-01-03T12:24:42+00:00",
        "message": "Bug 1872564. Optimize DisplayPortUtils::MaybeCreateDisplayPortInFirstScrollFrameEncountered by checking for leaf frames. r=layout-reviewers,emilio\n\nOn 20 runs of speedometer3 this makes MaybeCreateDisplayPortInFirstScrollFrameEncountered 30% faster.\n\nDifferential Revision: https://phabricator.services.mozilla.com/D197468",
        "modified_files_count": 1,
        "modified_files": [
            "layout/base/DisplayPortUtils.cpp"
        ],
        "github_commit_url": "https://github.com/Floorp-Projects/Floorp/commit/858e60819b2bcd1a6842f418fc3937e17a0f5cb7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DisplayPortUtils::MaybeCreateDisplayPortInFirstScrollFrameEncountered"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adding a check for leaf frames to avoid unnecessary processing in the function.",
            "The optimization strategy involves adding a check for leaf frames to avoid unnecessary computations in the function.",
            "The optimization strategy involves adding a check for leaf frames to avoid unnecessary processing in the function.",
            "The optimization strategy involves adding a check for leaf frames to avoid unnecessary processing in the function.",
            "The optimization strategy involves adding a check for leaf frames to avoid unnecessary computations in the function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding a check for leaf frames to avoid unnecessary processing in the function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "owt-deps-webrtc",
        "hash": "4637b6afca431be8caf1d22151a2cbb2e86a33d5",
        "author": "aleloi",
        "date": "2017-02-01T11:43:31+00:00",
        "message": "Consistent 30% improvement in audio mixer running time.\n\n(Or, in less flattering terms, fixing a performance issue introduced\na few months ago by me).\n\nIn GN release mode (is_debug = false), the version of the mixer code\nbefore this CL generated code that multiplied each sample (tens of\nthousands/second for each input stream) with a floating point number.\nThis number is almost always exactly 1.0f. The only situation when it's\nnot 1 is when an audio steam is added or removed.\n\nFor one input stream early return leads to a 30% improvement of audio\nmixing time profiled on x86-64 under a release build (is_debug = false,\nenable_profiling, enable_full_stack_frames_for_profiling) with 16kHz and no\nAPM limiter. There can be up to 3 streams.\n\nBUG=chromium:687502\n\nReview-Url: https://codereview.webrtc.org/2659423002\nCr-Commit-Position: refs/heads/master@{#16396}",
        "modified_files_count": 1,
        "modified_files": [
            "webrtc/modules/audio_mixer/audio_frame_manipulator.cc"
        ],
        "github_commit_url": "https://github.com/open-webrtc-toolkit/owt-deps-webrtc/commit/4637b6afca431be8caf1d22151a2cbb2e86a33d5",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary floating-point multiplications by early-returning when the multiplier is 1.0f, which is the common case.",
            "The optimization avoids unnecessary floating-point multiplications by early-returning when the multiplier is 1.0f, which is the common case.",
            "The optimization avoids unnecessary floating-point multiplications by early-returning when the multiplier is 1.0f, which is the common case.",
            "The optimization avoids unnecessary floating-point multiplications by early-returning when the multiplier is 1.0f, which is the common case.",
            "The optimization avoids unnecessary floating-point multiplications by early-returning when the multiplier is 1.0f, which is the common case."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary floating-point multiplications by early-returning when the multiplier is 1.0f, which is the common case.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qcad",
        "hash": "f8075af76297ab4441d64ebcb81be5f20f81f2f3",
        "author": "Andrew Mustun",
        "date": "2021-11-05T11:30:16+01:00",
        "message": "performance: no distance calculation for entities inside viewports",
        "modified_files_count": 1,
        "modified_files": [
            "src/core/RViewportData.cpp"
        ],
        "github_commit_url": "https://github.com/qcad/qcad/commit/f8075af76297ab4441d64ebcb81be5f20f81f2f3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RViewportData::getDistanceTo"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary distance calculations for entities located inside viewports by adding a conditional check to skip the computation when not needed.",
            "The optimization avoids unnecessary distance calculations for entities located within viewports by adding a conditional check to skip the computation when not needed.",
            "The optimization avoids unnecessary distance calculations for entities inside viewports by adding a conditional check to skip the computation when not needed.",
            "The optimization avoids unnecessary distance calculations for entities located inside viewports by adding a preliminary check to determine if the entity is within the viewport bounds before performing the calculation.",
            "The optimization avoids unnecessary distance calculations for entities inside viewports by adding a condition to check if the entity is within the viewport bounds before performing the calculation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary distance calculations for entities located inside viewports by adding a conditional check to skip the computation when not needed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "foundationdb",
        "hash": "f18a0a242d654b5835f9210878699493a0c0b053",
        "author": "Meng Xu",
        "date": "2020-06-27T15:19:08-07:00",
        "message": "FastRestore:Loader frees mutation memory immediately after send mutations",
        "modified_files_count": 1,
        "modified_files": [
            "fdbserver/RestoreLoader.actor.cpp"
        ],
        "github_commit_url": "https://github.com/apple/foundationdb/commit/f18a0a242d654b5835f9210878699493a0c0b053",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "handleSendMutationsRequest"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves immediately freeing mutation memory after sending mutations to reduce memory usage and improve performance during the restore process.",
            "The optimization strategy frees memory immediately after sending mutations to reduce memory usage during the restore process.",
            "The optimization strategy involves immediately freeing mutation memory after sending mutations to reduce memory usage and improve performance during the restore process.",
            "The optimization strategy involves immediately freeing mutation memory after sending mutations to reduce memory usage and improve performance during the restore process.",
            "The optimization strategy involves immediately freeing mutation memory after sending mutations to reduce memory usage and improve performance during the restore process."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves immediately freeing mutation memory after sending mutations to reduce memory usage and improve performance during the restore process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "RAJA",
        "hash": "e6828338f96657da653d9b54fda743b5d14d83f6",
        "author": "Robert Chen",
        "date": "2020-03-10T17:25:41-07:00",
        "message": "Update mergesort with insertion sorting on 16-element chunks. 400ms faster on basic test.",
        "modified_files_count": 1,
        "modified_files": [
            "include/RAJA/util/sort.hpp"
        ],
        "github_commit_url": "https://github.com/LLNL/RAJA/commit/e6828338f96657da653d9b54fda743b5d14d83f6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "O"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is to combine mergesort with insertion sort for small chunks of 16 elements to reduce overhead and improve performance.",
            "The optimization strategy used is to combine mergesort with insertion sort for small chunks of 16 elements to reduce overhead and improve performance.",
            "The optimization strategy used is to combine mergesort with insertion sort for small chunks (16 elements) to reduce overhead and improve performance.",
            "The optimization strategy used is to combine mergesort with insertion sort for small chunks of 16 elements to reduce overhead and improve performance.",
            "The optimization strategy used is to combine mergesort with insertion sort for small chunks (16 elements) to reduce overhead and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is to combine mergesort with insertion sort for small chunks of 16 elements to reduce overhead and improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "deadbeef",
        "hash": "1faf17b526a4629676581629d2ac6a9b6db029f9",
        "author": "Oleksiy Yakovenko",
        "date": "2022-12-22T11:19:52+01:00",
        "message": "gtkui: use float type where appropriate, for faster ftoi",
        "modified_files_count": 1,
        "modified_files": [
            "plugins/gtkui/widgets.c"
        ],
        "github_commit_url": "https://github.com/DeaDBeeF-Player/deadbeef/commit/1faf17b526a4629676581629d2ac6a9b6db029f9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_draw_vline_aa"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing integer calculations with floating-point operations to leverage faster float-to-integer conversion.",
            "The optimization strategy involved replacing integer calculations with floating-point operations to leverage faster float-to-integer conversion.",
            "The optimization strategy involved replacing integer calculations with floating-point operations to leverage faster float-to-integer conversion.",
            "The optimization strategy involved replacing integer calculations with floating-point operations to leverage faster float-to-integer conversion.",
            "The optimization strategy involved changing data types to use floats where appropriate to improve the performance of float-to-integer conversions."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing integer calculations with floating-point operations to leverage faster float-to-integer conversion.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ffmpeg",
        "hash": "04824298a9e2fec292cc2859c6a50a5d5a6d7752",
        "author": "Michael Niedermayer",
        "date": "2008-12-18T16:11:19+00:00",
        "message": "Faster CAVLC decoding of trailing_ones. Based on a patch by dark shikari.\ndecode_residual is about 3.3% faster.\n\nOriginally committed as revision 16219 to svn://svn.ffmpeg.org/ffmpeg/trunk",
        "modified_files_count": 1,
        "modified_files": [
            "libavcodec/h264.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/04824298a9e2fec292cc2859c6a50a5d5a6d7752",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "decode_residual"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the CAVLC decoding logic for trailing_ones to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the CAVLC decoding logic for trailing_ones to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the CAVLC decoding logic for trailing_ones to reduce unnecessary computations and improve efficiency.",
            "The optimization strategy involved restructuring the CAVLC decoding logic for trailing_ones to reduce computational overhead by minimizing unnecessary operations.",
            "The optimization strategy involved restructuring the CAVLC decoding logic for trailing_ones to reduce unnecessary computations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the CAVLC decoding logic for trailing_ones to reduce unnecessary computations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gcc-darwin-arm64",
        "hash": "ffd961fc053419bc1eb37792c18ec98e7c3bc364",
        "author": "Eric Botcazou",
        "date": "2020-12-08T09:04:06+01:00",
        "message": "PR tree-optimization/96344\n\nThe very recent addition of the if_to_switch pass has partially disabled\nthe optimization added back in June to optimize_range_tests_to_bit_test,\nas witnessed by the 3 new failures in the gnat.dg testsuite.  It turns out\nthat both tree-ssa-reassoc.c and tree-switch-conversion.c can turn things\ninto bit tests so the optimization is added to bit_test_cluster::emit too.\n\nThe patch also contains a secondary optimization, whereby the full bit-test\nsequence is sent to the folder before being gimplified in case there is only\none test, so that the optimal sequence (bt + jc on x86) can be emitted like\nwith optimize_range_tests_to_bit_test.\n\ngcc/ChangeLog:\n\tPR tree-optimization/96344\n\t* tree-switch-conversion.c (bit_test_cluster::emit): Compute the\n\trange only if an entry test is necessary.  Merge the entry test in\n\tthe bit test when possible.  Use PREC local variable consistently.\n\tWhen there is only one test, do a single gimplification at the end.",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/tree-switch-conversion.c"
        ],
        "github_commit_url": "https://github.com/iains/gcc-darwin-arm64/commit/ffd961fc053419bc1eb37792c18ec98e7c3bc364",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bit_test_cluster::emit"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy merges entry tests into bit tests when possible and defers gimplification to enable optimal sequence generation for single tests.",
            "The optimization strategy merges entry tests into bit tests when possible and defers gimplification to enable optimal sequence generation for single tests.",
            "The optimization strategy merges entry tests into bit tests when possible and defers gimplification to enable optimal sequence generation for single tests.",
            "The optimization strategy merges entry tests into bit tests when possible and defers gimplification to enable optimal sequence generation for single tests.",
            "The optimization merges entry tests into bit tests when possible and defers gimplification to enable optimal sequence generation for single tests."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy merges entry tests into bit tests when possible and defers gimplification to enable optimal sequence generation for single tests.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "simde",
        "hash": "687460ce7f68ab0621d42ed00ca6fbce4e940121",
        "author": "Ng Zhi An",
        "date": "2021-06-08T20:56:18-04:00",
        "message": "neon/st3q_u8: Wasm optimization\n\nAutovectorizer is unable to do anything here, so implement it using a\nbunch of shuffles.\n\nFixes #827",
        "modified_files_count": 1,
        "modified_files": [
            "simde/arm/neon/st3.h"
        ],
        "github_commit_url": "https://github.com/simd-everywhere/simde/commit/687460ce7f68ab0621d42ed00ca6fbce4e940121",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "simde_vst3q_u8"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved manually implementing shuffles to replace operations that the autovectorizer could not optimize.",
            "The optimization strategy involved manually implementing shuffles to replace operations that the autovectorizer could not optimize.",
            "The optimization strategy involved manually implementing shuffles to replace operations that the autovectorizer could not optimize.",
            "The optimization strategy involved manually implementing shuffles to replace autovectorization for improved performance in handling NEON instructions.",
            "The optimization strategy involved manually implementing shuffles to replace operations that the autovectorizer could not optimize."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved manually implementing shuffles to replace operations that the autovectorizer could not optimize.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "87b6a3aba580944e3416630a28d7bfacc4c912e1",
        "author": "K. Lange",
        "date": "2018-08-16T22:43:18+09:00",
        "message": "[bim] Improve rendering speed by not sending so many color codes",
        "modified_files_count": 1,
        "modified_files": [
            "apps/bim.c"
        ],
        "github_commit_url": "https://github.com/klange/toaruos/commit/87b6a3aba580944e3416630a28d7bfacc4c912e1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "region"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "toaruos",
        "optimization_summary": [
            "The optimization strategy reduces rendering overhead by minimizing the number of color code updates sent during text rendering.",
            "The optimization reduces the number of color code updates during rendering by skipping redundant calls.",
            "The optimization reduces the number of color code updates during rendering by skipping redundant calls, thereby improving rendering speed.",
            "The optimization reduces the number of color code updates during rendering by skipping redundant calls, thereby improving rendering speed.",
            "The optimization strategy reduces the number of color code updates sent during rendering by batching or skipping unnecessary updates."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces the number of color code updates during rendering by skipping redundant calls.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "5768402fd9c6e872252b5268ad85e3fbae4fe26b",
        "author": "Alexander Shishkin",
        "date": "2019-03-09T14:10:30+01:00",
        "message": "perf/ring_buffer: Use high order allocations for AUX buffers optimistically\n\nCurrently, the AUX buffer allocator will use high-order allocations\nfor PMUs that don't support hardware scatter-gather chaining to ensure\nlarge contiguous blocks of pages, and always use an array of single\npages otherwise.\n\nThere is, however, a tangible performance benefit in using larger chunks\nof contiguous memory even in the latter case, that comes from not having\nto fetch the next page's address at every page boundary. In particular,\na task running under Intel PT on an Atom CPU shows 1.5%-2% less runtime\npenalty with a single multi-page output region in snapshot mode (no PMI)\nthan with multiple single-page output regions, from ~6% down to ~4%. For\nthe snapshot mode it does make a difference as it is intended to run over\nlong periods of time.\n\nFor this reason, change the allocation policy to always optimistically\nstart with the highest possible order when allocating pages for the AUX\nbuffer, desceding until the allocation succeeds or order zero allocation\nfails.\n\nSigned-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nCc: Andy Lutomirski <luto@kernel.org>\nCc: Arnaldo Carvalho de Melo <acme@redhat.com>\nCc: Borislav Petkov <bp@alien8.de>\nCc: Dave Hansen <dave.hansen@linux.intel.com>\nCc: H. Peter Anvin <hpa@zytor.com>\nCc: Jiri Olsa <jolsa@redhat.com>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Rik van Riel <riel@surriel.com>\nCc: Stephane Eranian <eranian@google.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Vince Weaver <vincent.weaver@maine.edu>\nLink: https://lkml.kernel.org/r/20190215114727.62648-2-alexander.shishkin@linux.intel.com\nSigned-off-by: Ingo Molnar <mingo@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "kernel/events/ring_buffer.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/5768402fd9c6e872252b5268ad85e3fbae4fe26b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rb_alloc_aux"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves using high-order memory allocations for AUX buffers to reduce the overhead of fetching page addresses at boundaries, improving performance in scenarios like Intel PT on Atom CPUs.",
            "The optimization strategy involves using high-order memory allocations for AUX buffers to reduce the overhead of fetching page addresses at boundaries, improving performance in scenarios like Intel PT on Atom CPUs.",
            "The optimization strategy involves using high-order memory allocations for AUX buffers to reduce the overhead of fetching page addresses at boundaries, improving performance in scenarios requiring contiguous memory.",
            "The optimization strategy involves using high-order memory allocations for AUX buffers to reduce the overhead of fetching page addresses at boundaries, improving performance in scenarios requiring contiguous memory.",
            "The optimization strategy involves using high-order memory allocations for AUX buffers to reduce the overhead of fetching page addresses at boundaries, improving performance in scenarios like Intel PT on Atom CPUs."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves using high-order memory allocations for AUX buffers to reduce the overhead of fetching page addresses at boundaries, improving performance in scenarios like Intel PT on Atom CPUs.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "blender",
        "hash": "7797fcc3c9edf77138788ea763ae159edea9d9ec",
        "author": "Colin Basnett",
        "date": "2023-06-26T11:40:12+02:00",
        "message": "Nodes: Don't allow animation for node mute property\n\nDiscussions on https://projects.blender.org/blender/blender/pulls/108634 pointed to the idea that the mute property probably shouldn't have been animateable to begin with because of performance concerns.\n\nThis simply removes the ability to animate the property.\n\nPull Request: https://projects.blender.org/blender/blender/pulls/108849",
        "modified_files_count": 1,
        "modified_files": [
            "source/blender/makesrna/intern/rna_nodetree.cc"
        ],
        "github_commit_url": "https://github.com/blender/blender/commit/7797fcc3c9edf77138788ea763ae159edea9d9ec",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rna_def_node"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes the ability to animate the node mute property to reduce unnecessary performance overhead.",
            "The optimization strategy removes the ability to animate the node mute property to reduce performance overhead associated with unnecessary animation handling.",
            "The optimization strategy removes the ability to animate the node mute property to reduce performance overhead.",
            "The optimization strategy removes the ability to animate the node mute property to reduce performance overhead associated with unnecessary animation handling.",
            "The optimization strategy removes the ability to animate the node mute property to reduce performance overhead associated with unnecessary animation handling."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy removes the ability to animate the node mute property to reduce performance overhead associated with unnecessary animation handling.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "qtbase",
        "hash": "14d189f7875b7def6f9745bfd20527a0fce19a44",
        "author": "Marc Mutz",
        "date": "2015-11-29T22:47:15+00:00",
        "message": "AndroidStyle: use std::make_shared()\n\nMore efficient, because control block and tracked object\nare co-located in a single memory allocation.\n\nChange-Id: Id18e2d06db43568eb34c2e2d129d1b116af73acb\nReviewed-by: Olivier Goffart (Woboq GmbH) <ogoffart@woboq.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/plugins/platforms/android/qandroidplatformtheme.cpp"
        ],
        "github_commit_url": "https://github.com/qt/qtbase/commit/14d189f7875b7def6f9745bfd20527a0fce19a44",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "loadAndroidStyle"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used is replacing raw `std::shared_ptr` construction with `std::make_shared` to reduce memory allocation overhead by co-locating the control block and object in a single allocation.",
            "The optimization strategy used is replacing raw `std::shared_ptr` construction with `std::make_shared`, which reduces memory allocation overhead by co-locating the control block and the managed object in a single allocation.",
            "The optimization strategy used is replacing raw `std::shared_ptr` construction with `std::make_shared` to reduce memory allocation overhead by co-locating the control block and the managed object.",
            "The optimization strategy used is replacing raw `std::shared_ptr` construction with `std::make_shared` to reduce memory allocation overhead by co-locating the control block and the managed object.",
            "The optimization strategy used is replacing raw `std::shared_ptr` construction with `std::make_shared` to reduce memory allocation overhead by co-locating the control block and the managed object."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used is replacing raw `std::shared_ptr` construction with `std::make_shared` to reduce memory allocation overhead by co-locating the control block and the managed object.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "5e70f4bdc15960730d0ff2aa167399e36bc64278",
        "author": "Pavel Labath",
        "date": "2020-01-21T15:04:27+01:00",
        "message": "[lldb/breakpad] Use new line table constructor\n\nThe old construction method can be quadratic for some inputs. This\napproach guarantees a reasonable performance.",
        "modified_files_count": 1,
        "modified_files": [
            "lldb/source/Plugins/SymbolFile/Breakpad/SymbolFileBreakpad.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/5e70f4bdc15960730d0ff2aa167399e36bc64278",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a potentially quadratic-time line table construction method with a more efficient approach to guarantee reasonable performance.",
            "The optimization strategy replaced a potentially quadratic-time line table construction method with a more efficient approach to guarantee reasonable performance.",
            "The optimization strategy replaced a potentially quadratic-time line table construction method with a more efficient approach to guarantee reasonable performance.",
            "The optimization strategy replaced a potentially quadratic-time line table construction method with a more efficient approach to guarantee reasonable performance.",
            "The optimization strategy replaced a potentially quadratic-time line table construction method with a more efficient approach to guarantee reasonable performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a potentially quadratic-time line table construction method with a more efficient approach to guarantee reasonable performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "bitcoin",
        "hash": "9e697172542e2b01517e4025df2c23d0ed5447f4",
        "author": "Alex Morcos",
        "date": "2016-01-07T16:31:12-05:00",
        "message": "Make wallet descendant searching more efficient",
        "modified_files_count": 1,
        "modified_files": [
            "src/wallet/wallet.cpp"
        ],
        "github_commit_url": "https://github.com/bitcoin/bitcoin/commit/9e697172542e2b01517e4025df2c23d0ed5447f4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CWallet::MarkConflicted"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant descendant searches by maintaining a visited set to avoid reprocessing the same transactions multiple times.",
            "The optimization strategy used is to reduce redundant descendant searches by caching and reusing results within the wallet's conflict marking logic.",
            "The optimization strategy involved reducing redundant descendant searches by caching and reusing results within the wallet's conflict marking logic.",
            "The optimization strategy involved reducing redundant descendant searches by maintaining a visited set to avoid reprocessing the same transactions multiple times.",
            "The optimization strategy involved reducing redundant descendant searches by caching and reusing results within the wallet's conflict-marking logic."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used is to reduce redundant descendant searches by caching and reusing results within the wallet's conflict marking logic.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "suricata",
        "hash": "f44bbd71f56581cfc326b0142a26f51ab65f1db0",
        "author": "Victor Julien",
        "date": "2019-03-18T13:02:08+01:00",
        "message": "app-layer/udp: micro optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/app-layer.c"
        ],
        "github_commit_url": "https://github.com/OISF/suricata/commit/f44bbd71f56581cfc326b0142a26f51ab65f1db0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AppLayerHandleUdp"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary function calls by directly accessing data structures, thereby minimizing overhead in UDP packet handling.",
            "The optimization strategy involved reordering conditional checks to minimize unnecessary evaluations and improve branch prediction.",
            "The optimization strategy involved reducing redundant checks and improving the efficiency of UDP packet handling by restructuring conditional logic.",
            "The optimization strategy involved reducing unnecessary function calls or operations within the UDP handling logic to improve performance.",
            "The optimization strategy involved reducing unnecessary function calls by directly accessing a variable instead of invoking a getter function."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary function calls or operations within the UDP handling logic to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "coreboot",
        "hash": "fba1475f25948aebd0590436e33bb266d6e714d9",
        "author": "Dmitry Ponamorev",
        "date": "2021-10-07T04:40:31+00:00",
        "message": "soc/intel/denverton_ns: Always enable SpeedStep\n\nWhen \"SpeedStep\" is disabled on an Intel Atom C3538,\nthe maximum CPU clock speed is always 800 MHz(min CPU clock).\nОperating system cannot change the frequency.\nAvoid this issue allow \"Intel Speed step\" technology\nfor processors that do not have \"Intel Turbo Boost\".\n\nSigned-off-by: Dmitry Ponamorev <dponamorev@gmail.com>\nChange-Id: Ia922e45c12e4239f1d59617193cdbde2a813e7d0\nReviewed-on: https://review.coreboot.org/c/coreboot/+/57669\nTested-by: build bot (Jenkins) <no-reply@coreboot.org>\nReviewed-by: Werner Zeh <werner.zeh@siemens.com>\nReviewed-by: Angel Pons <th3fanbus@gmail.com>\nReviewed-by: King Sumo <kingsumos@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/soc/intel/denverton_ns/cpu.c"
        ],
        "github_commit_url": "https://github.com/coreboot/coreboot/commit/fba1475f25948aebd0590436e33bb266d6e714d9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "denverton_core_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "Enabled Intel SpeedStep technology to allow dynamic CPU frequency scaling for processors without Turbo Boost.",
            "The optimization enables Intel SpeedStep technology to allow dynamic CPU frequency scaling, avoiding a fixed low clock speed.",
            "Enabled Intel SpeedStep technology to allow dynamic CPU frequency scaling for processors without Turbo Boost.",
            "The optimization enables Intel SpeedStep technology to allow dynamic CPU frequency scaling, preventing the CPU from being locked at the minimum clock speed.",
            "The optimization enables Intel SpeedStep technology to allow dynamic CPU frequency scaling, avoiding a fixed low clock speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization enables Intel SpeedStep technology to allow dynamic CPU frequency scaling, avoiding a fixed low clock speed.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "uboot-imx",
        "hash": "19dba8bf9f4c87278b8e6e2133ebc39f4edb6592",
        "author": "Hou Zhiqiang",
        "date": "2021-02-08T14:01:19+05:30",
        "message": "armv7: ls102xa: Enable I-Cache to speed up the boot time\n\nEnable the I-Cache to speed up the boot time, especailly for the NOR\nboot, currently it takes about 15 seconds from power up to the U-Boot\nprompt, and with the I-Cache enabled it only takes around 2.5 seconds.\n\nSigned-off-by: Hou Zhiqiang <Zhiqiang.Hou@nxp.com>\nReviewed-by: Priyanka Jain <priyanka.jain@nxp.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/arm/cpu/armv7/ls102xa/cpu.c"
        ],
        "github_commit_url": "https://github.com/nxp-imx/uboot-imx/commit/19dba8bf9f4c87278b8e6e2133ebc39f4edb6592",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "arch_cpu_init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved enabling the I-Cache to reduce boot time by improving instruction fetch efficiency.",
            "The optimization strategy involved enabling the I-Cache to reduce boot time by improving instruction fetch efficiency.",
            "The optimization strategy involved enabling the I-Cache to reduce boot time by improving instruction fetch efficiency.",
            "The optimization strategy involved enabling the I-Cache to reduce boot time by improving instruction fetch efficiency.",
            "The optimization strategy involved enabling the I-Cache to reduce boot time by improving instruction fetch efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved enabling the I-Cache to reduce boot time by improving instruction fetch efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "vengi",
        "hash": "70d07e285c3848def689c481bfa39c9bdfa65614",
        "author": "Martin Gerhardy",
        "date": "2023-08-08T18:39:21+02:00",
        "message": "VOXELFORMAT: GLTF: optimized loading gltf a lot",
        "modified_files_count": 1,
        "modified_files": [
            "src/modules/voxelformat/private/mesh/GLTFFormat.cpp"
        ],
        "github_commit_url": "https://github.com/vengi-voxel/vengi/commit/70d07e285c3848def689c481bfa39c9bdfa65614",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "copyGltfIndices"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant data copying and improving index handling during GLTF loading.",
            "The optimization strategy involved reducing redundant data copying and improving index handling during GLTF loading.",
            "The optimization strategy involved reducing redundant data copying and improving index handling efficiency in the GLTF loading process.",
            "The optimization strategy involved reducing redundant data copying and improving index handling during GLTF loading.",
            "The optimization strategy involved reducing redundant data copying and improving index handling during GLTF loading."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant data copying and improving index handling during GLTF loading.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "viewer",
        "hash": "74a2354353813db529ae123858bafba86cd12110",
        "author": "Runitai Linden",
        "date": "2021-10-13T09:37:04-05:00",
        "message": "SL-16166 Don't use setupVertexBuffer where setupVertexBufferFast is called for (thank you, Henri!)",
        "modified_files_count": 1,
        "modified_files": [
            "indra/llrender/llvertexbuffer.cpp"
        ],
        "github_commit_url": "https://github.com/secondlife/viewer/commit/74a2354353813db529ae123858bafba86cd12110",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LLVertexBuffer::setBufferFast"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a more general but potentially slower method (`setupVertexBuffer`) with a faster, specialized method (`setupVertexBufferFast`) where applicable.",
            "The optimization strategy involved replacing a more general but slower method (`setupVertexBuffer`) with a faster, specialized method (`setupVertexBufferFast`) to improve performance in specific scenarios.",
            "The optimization strategy involved replacing a more general but potentially slower method (`setupVertexBuffer`) with a faster, specialized method (`setupVertexBufferFast`) to improve performance in specific scenarios.",
            "The optimization strategy involved replacing a more general but potentially slower method (`setupVertexBuffer`) with a faster, specialized method (`setupVertexBufferFast`) where applicable.",
            "The optimization strategy involved replacing a more general but potentially slower method (`setupVertexBuffer`) with a faster, specialized method (`setupVertexBufferFast`) where applicable."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a more general but potentially slower method (`setupVertexBuffer`) with a faster, specialized method (`setupVertexBufferFast`) where applicable.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ompi",
        "hash": "0e83568466dd89ff118b724dfa3b54104418f400",
        "author": "Nathan Hjelm",
        "date": "2018-02-13T09:51:01-07:00",
        "message": "coll/libnbc: do not take lock in progress if there are no requests\n\nThis commit fixes a flaw in the progress function for libnbc. The\nfunction was unconditionally taking a lock even if there are no\nrequests to process. This lock was showing up in vtune traces of\nmulti-threaded benchmarks.\n\nSigned-off-by: Nathan Hjelm <hjelmn@lanl.gov>",
        "modified_files_count": 1,
        "modified_files": [
            "ompi/mca/coll/libnbc/coll_libnbc_component.c"
        ],
        "github_commit_url": "https://github.com/open-mpi/ompi/commit/0e83568466dd89ff118b724dfa3b54104418f400",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ompi_coll_libnbc_progress"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids taking a lock in the progress function when there are no requests to process, reducing unnecessary synchronization overhead.",
            "The optimization strategy avoids taking a lock in the progress function when there are no requests to process, reducing unnecessary synchronization overhead.",
            "The optimization strategy avoids taking a lock in the progress function when there are no requests to process, reducing unnecessary synchronization overhead.",
            "The optimization strategy avoids taking a lock in the progress function when there are no requests to process, reducing unnecessary synchronization overhead.",
            "The optimization strategy avoids taking a lock in the progress function when there are no requests to process, reducing unnecessary synchronization overhead."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids taking a lock in the progress function when there are no requests to process, reducing unnecessary synchronization overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "linux-rockchip",
        "hash": "89f4d27c1bcd9d4f8f1590f6d29ae3b77ca2f41a",
        "author": "Paolo Valente",
        "date": "2019-11-20T18:46:44+01:00",
        "message": "blok, bfq: do not plug I/O if all queues are weight-raised\n\n[ Upstream commit c8765de0adfcaaf4ffb2d951e07444f00ffa9453 ]\n\nTo reduce latency for interactive and soft real-time applications, bfq\nprivileges the bfq_queues containing the I/O of these\napplications. These privileged queues, referred-to as weight-raised\nqueues, get a much higher share of the device throughput\nw.r.t. non-privileged queues. To preserve this higher share, the I/O\nof any non-weight-raised queue must be plugged whenever a sync\nweight-raised queue, while being served, remains temporarily empty. To\nattain this goal, bfq simply plugs any I/O (from any queue), if a sync\nweight-raised queue remains empty while in service.\n\nUnfortunately, this plugging typically lowers throughput with random\nI/O, on devices with internal queueing (because it reduces the filling\nlevel of the internal queues of the device).\n\nThis commit addresses this issue by restricting the cases where\nplugging is performed: if a sync weight-raised queue remains empty\nwhile in service, then I/O plugging is performed only if some of the\nactive bfq_queues are *not* weight-raised (which is actually the only\ncircumstance where plugging is needed to preserve the higher share of\nthe throughput of weight-raised queues). This restriction proved able\nto boost throughput in really many use cases needing only maximum\nthroughput.\n\nSigned-off-by: Paolo Valente <paolo.valente@linaro.org>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "block/bfq-iosched.c"
        ],
        "github_commit_url": "https://github.com/armbian/linux-rockchip/commit/89f4d27c1bcd9d4f8f1590f6d29ae3b77ca2f41a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "bfq_better_to_idle"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy restricts I/O plugging to only occur when necessary, specifically when there are active non-weight-raised queues, to improve throughput without compromising latency guarantees for weight-raised queues.",
            "The optimization strategy restricts I/O plugging to only occur when necessary, specifically when there are active non-weight-raised queues, to improve throughput without compromising latency guarantees for weight-raised queues.",
            "The optimization strategy restricts I/O plugging to only occur when necessary, specifically when there are active non-weight-raised queues, to improve throughput without compromising latency guarantees for weight-raised queues.",
            "The optimization strategy restricts I/O plugging to only occur when necessary, specifically when there are active non-weight-raised queues, to improve throughput without compromising latency guarantees for weight-raised queues.",
            "The optimization strategy avoids unnecessary I/O plugging by restricting it to cases where non-weight-raised queues are active, thereby improving throughput without compromising latency guarantees for weight-raised queues."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy restricts I/O plugging to only occur when necessary, specifically when there are active non-weight-raised queues, to improve throughput without compromising latency guarantees for weight-raised queues.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Fulcrum",
        "hash": "5cba060842da98cc0ad8545e1cdd358a040d630a",
        "author": "Calin Culianu",
        "date": "2020-01-03T00:34:37+02:00",
        "message": "Small performance improvement for block processing\n\nAdded a map.reserve() call for an internal hash table used to map\ntxid -> txPos in PreProcessedBlock::fill. This reduces the number of\nallocation during block processing slightly and should shave off a few\ncycles per block processed.",
        "modified_files_count": 1,
        "modified_files": [
            "BlockProc.cpp"
        ],
        "github_commit_url": "https://github.com/cculianu/Fulcrum/commit/5cba060842da98cc0ad8545e1cdd358a040d630a",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved pre-allocating memory for a hash table using `map.reserve()` to minimize dynamic allocations during block processing.",
            "The optimization strategy involved reserving space in a hash table to reduce dynamic memory allocations during block processing.",
            "The optimization strategy involved pre-allocating memory for a hash table using `map.reserve()` to minimize dynamic allocations during block processing.",
            "The optimization strategy involved pre-allocating memory for a hash table using `map.reserve()` to minimize dynamic allocations during block processing.",
            "The optimization strategy involved pre-allocating memory for a hash table using `map.reserve()` to minimize dynamic allocations during block processing."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved pre-allocating memory for a hash table using `map.reserve()` to minimize dynamic allocations during block processing.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "qt-creator",
        "hash": "a9ef0a8af81f4822e8f6190a172747777d0b32af",
        "author": "Orgad Shaneh",
        "date": "2021-10-13T08:08:01+00:00",
        "message": "ClearCase: Minor cleanup\n\nReplace iteration over all documents with a faster lookup.\n\nChange-Id: Iccc20ff2e5a44eef9d0bc925e25ef5c7ebaa98e9\nReviewed-by: hjk <hjk@qt.io>",
        "modified_files_count": 1,
        "modified_files": [
            "src/plugins/clearcase/clearcaseplugin.cpp"
        ],
        "github_commit_url": "https://github.com/qt-creator/qt-creator/commit/a9ef0a8af81f4822e8f6190a172747777d0b32af",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ClearCasePluginPrivate::vcsOpen"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced iteration over all documents with a faster lookup to improve performance.",
            "The optimization strategy replaced iteration over all documents with a faster lookup to improve performance.",
            "The optimization strategy replaced iteration over all documents with a faster lookup to improve performance.",
            "The optimization strategy replaced iteration over all documents with a faster lookup to improve performance.",
            "The optimization strategy replaced iteration over all documents with a faster lookup to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaced iteration over all documents with a faster lookup to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "FreeBSD-src",
        "hash": "4c6a70091030847ca5d6933916255194483ce91f",
        "author": "Brian Behlendorf",
        "date": "2015-06-22T10:22:10-07:00",
        "message": "Increase the number of iput taskq threads\n\nThe number of threads in the iput taskq has been increased to speed\nup the number of iputs which can be handled.  This has been observed\nto improve the  meta data reclaim regardless of zfs_sb_prune()\nimplementation in use.\n\nThe taskq has also been renamed z_iput to for consistency with the\nrest of the I/O pipeline taskqs which are all named z_*.\n\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nSigned-off-by: Tim Chase <tim@chase2k.com>",
        "modified_files_count": 1,
        "modified_files": [
            "module/zfs/dsl_pool.c"
        ],
        "github_commit_url": "https://github.com/pfsense/FreeBSD-src/commit/4c6a70091030847ca5d6933916255194483ce91f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dsl_pool_open_impl"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved increasing the number of threads in the iput taskq to improve metadata reclaim performance.",
            "The optimization strategy involved increasing the number of threads in the iput taskq to improve metadata reclaim performance.",
            "The optimization strategy involved increasing the number of threads in the iput taskq to improve metadata reclaim performance.",
            "The optimization strategy involved increasing the number of threads in the iput taskq to improve metadata reclaim performance.",
            "The optimization strategy involved increasing the number of threads in the iput taskq to improve metadata reclaim performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved increasing the number of threads in the iput taskq to improve metadata reclaim performance.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "d5e6ba1ff1df8af3439d1144122f55acf72d118c",
        "author": "Asias He",
        "date": "2021-03-11T11:53:22+02:00",
        "message": "repair: Shortcut when no followers to repair with\n\n- 3 nodes in the cluster with rf = 3\n- run repair on node1 with ignore_nodes to ignore node2 and node3\n- node1 has no followers to repair with\n\nHowever, currently node1 will walk through the repair procedure to read\ndata from disk and calculate hashes which are unnecessary.\n\nThis patch fixes this issue, so that in case there are no followers, we\nskip the range and avoid the unnecessary work.\n\nBefore:\n   $ curl -X POST http://127.0.0.1:10000/storage_service/repair_async/myks3?ignore_nodes=\"127.0.0.2,127.0.0.3\"\n\n   repair - repair id [id=1, uuid=ff39151b-2ce9-4885-b7e9-89158b14b5c2] on shard 0 stats:\n   repair_reason=repair, keyspace=myks3, tables={standard1},\n   ranges_nr=769, sub_ranges_nr=769, round_nr=1456,\n   round_nr_fast_path_already_synced=1456,\n   round_nr_fast_path_same_combined_hashes=0,\n   round_nr_slow_path=0, rpc_call_nr=0, tx_hashes_nr=0, rx_hashes_nr=0, duration=0.19 seconds,\n   tx_row_nr=0, rx_row_nr=0, tx_row_bytes=0, rx_row_bytes=0,\n   row_from_disk_bytes={{127.0.0.1, 2822972}},\n   row_from_disk_nr={{127.0.0.1, 6218}},\n   row_from_disk_bytes_per_sec={{127.0.0.1, 14.1695}} MiB/s,\n   row_from_disk_rows_per_sec={{127.0.0.1, 32726.3}} Rows/s,\n   tx_row_nr_peer={}, rx_row_nr_peer={}\n\nData was read from disk.\n\nAfter:\n   $ curl -X POST http://127.0.0.1:10000/storage_service/repair_async/myks3?ignore_nodes=\"127.0.0.2,127.0.0.3\"\n\n   repair - repair id [id=1, uuid=c6df8b23-bd3b-4ebc-8d4c-a11d1ebcca39] on shard 0 stats:\n   repair_reason=repair, keyspace=myks3, tables={standard1}, ranges_nr=769,\n   sub_ranges_nr=0, round_nr=0, round_nr_fast_path_already_synced=0,\n   round_nr_fast_path_same_combined_hashes=0, round_nr_slow_path=0,\n   rpc_call_nr=0, tx_hashes_nr=0, rx_hashes_nr=0, duration=0.0 seconds,\n   tx_row_nr=0, rx_row_nr=0, tx_row_bytes=0, rx_row_bytes=0,\n   row_from_disk_bytes={},\n   row_from_disk_nr={},\n   row_from_disk_bytes_per_sec={} MiB/s,\n   row_from_disk_rows_per_sec={} Rows/s,\n   tx_row_nr_peer={}, rx_row_nr_peer={}\n\nNo data was read from disk.\n\nFixes #8256\n\nCloses #8257",
        "modified_files_count": 1,
        "modified_files": [
            "repair/repair.cc"
        ],
        "github_commit_url": "https://github.com/scylladb/scylladb/commit/d5e6ba1ff1df8af3439d1144122f55acf72d118c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "repair_range"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "scylladb",
        "optimization_summary": [
            "The optimization strategy skips unnecessary disk reads and hash calculations during repair operations when there are no followers to repair with.",
            "The optimization strategy skips unnecessary disk reads and hash calculations during repair when there are no followers to repair with.",
            "The optimization strategy skips unnecessary disk reads and hash calculations during repair operations when there are no followers to repair with.",
            "The optimization strategy skips unnecessary disk reads and hash calculations during repair operations when there are no followers to repair with.",
            "The optimization strategy skips unnecessary disk reads and hash calculations during repair operations when there are no followers to repair with."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy skips unnecessary disk reads and hash calculations during repair operations when there are no followers to repair with.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libavg",
        "hash": "b04a4bd4a94113d4e2a60b53bfbd82987e0f8b0b",
        "author": "uzadow",
        "date": "2007-01-27T12:52:04+00:00",
        "message": "Added optimized version of highpass (commented out)\n\nsvn path=/trunk/libavg/; revision=1898",
        "modified_files_count": 1,
        "modified_files": [
            "src/graphics/FilterHighpass.cpp"
        ],
        "github_commit_url": "https://github.com/libavg/libavg/commit/b04a4bd4a94113d4e2a60b53bfbd82987e0f8b0b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FilterHighpass::apply"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit introduces an optimized version of the highpass filter algorithm, likely reducing computational overhead through algorithmic improvements or more efficient data handling.",
            "The commit introduces an optimized version of the highpass filter algorithm, likely reducing computational overhead through algorithmic improvements or streamlined operations.",
            "The commit introduces an optimized version of the highpass filter algorithm, likely reducing computational overhead through algorithmic improvements or more efficient data handling.",
            "The commit introduces an optimized version of the highpass filter algorithm, likely reducing computational overhead through improved logic or reduced operations.",
            "The commit introduces an optimized version of the highpass filter algorithm, likely reducing computational overhead through improved logic or reduced operations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The commit introduces an optimized version of the highpass filter algorithm, likely reducing computational overhead through improved logic or reduced operations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "radare2",
        "hash": "9e11c5ce633da133e0922bce2591f99d21540c4c",
        "author": "pancake",
        "date": "2015-09-09T17:57:55+02:00",
        "message": "Make reflines 5x faster",
        "modified_files_count": 1,
        "modified_files": [
            "libr/core/disasm.c"
        ],
        "github_commit_url": "https://github.com/radareorg/radare2/commit/9e11c5ce633da133e0922bce2591f99d21540c4c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "handle_reflines_update"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a linear search with a hash-based lookup to reduce the time complexity of finding reference lines.",
            "The optimization strategy involved restructuring the loop to minimize redundant computations and improve cache locality.",
            "The optimization strategy involved replacing a linear search with a hash-based lookup to reduce the time complexity of finding reference lines.",
            "The optimization strategy involved restructuring the loop logic to minimize redundant computations and improve cache locality.",
            "The optimization strategy involved replacing a linear search with a binary search to improve the performance of reflines updates."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a linear search with a hash-based lookup to reduce the time complexity of finding reference lines.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "llvm-leg",
        "hash": "7b66e041821309306beccda0fe58ffa096ee1f4a",
        "author": "Dan Gohman",
        "date": "2008-10-21T18:24:51+00:00",
        "message": "Implement the optimized FCMP_OEQ/FCMP_UNE code for x86 fast-isel.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@57915 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Target/X86/X86FastISel.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/7b66e041821309306beccda0fe58ffa096ee1f4a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "X86FastISel::X86SelectBranch"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved implementing specialized code for handling FCMP_OEQ/FCMP_UNE comparisons in x86 fast instruction selection to improve performance.",
            "The optimization strategy involved implementing specialized handling for FCMP_OEQ/FCMP_UNE operations in the X86FastISel to improve instruction selection efficiency during fast-isel.",
            "The optimization strategy involved implementing specialized handling for FCMP_OEQ/FCMP_UNE operations in x86 fast-isel to improve instruction selection efficiency.",
            "The optimization strategy involved implementing specialized code for handling FCMP_OEQ/FCMP_UNE comparisons in x86 fast instruction selection to improve performance.",
            "The optimization strategy involved implementing specialized code for handling FCMP_OEQ/FCMP_UNE operations in x86 fast instruction selection to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved implementing specialized code for handling FCMP_OEQ/FCMP_UNE operations in x86 fast instruction selection to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gdal",
        "hash": "2b4a33db402bfe61e39bfa0840795364f6204b9e",
        "author": "Even Rouault",
        "date": "2019-03-14T22:27:47+01:00",
        "message": "TAB_CSLLoad(): fix performance issue. Fixes https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=13588. Credit to OSS Fuzz",
        "modified_files_count": 1,
        "modified_files": [
            "gdal/ogr/ogrsf_frmts/mitab/mitab_utils.cpp"
        ],
        "github_commit_url": "https://github.com/OSGeo/gdal/commit/2b4a33db402bfe61e39bfa0840795364f6204b9e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CSLLoad"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in a sorted list.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in a sorted list.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in a sorted list.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in a sorted list.",
            "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in a sorted list."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a linear search with a binary search to improve lookup efficiency in a sorted list.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "6835dedb5bbebeadb1ee9f82f87f38a0e47e3171",
        "author": "Chris Lattner",
        "date": "2004-10-06T05:01:07+00:00",
        "message": "Codegen signed mod by 2 or -2 more efficiently.  Instead of generating:\n\nt:\n        mov %EDX, DWORD PTR [%ESP + 4]\n        mov %ECX, 2\n        mov %EAX, %EDX\n        sar %EDX, 31\n        idiv %ECX\n        mov %EAX, %EDX\n        ret\n\nGenerate:\nt:\n        mov %ECX, DWORD PTR [%ESP + 4]\n***     mov %EAX, %ECX\n        cdq\n        and %ECX, 1\n        xor %ECX, %EDX\n        sub %ECX, %EDX\n***     mov %EAX, %ECX\n        ret\n\nNote that the two marked moves are redundant, and should be eliminated by the\nregister allocator, but aren't.\n\nCompare this to GCC, which generates:\n\nt:\n        mov     %eax, DWORD PTR [%esp+4]\n        mov     %edx, %eax\n        shr     %edx, 31\n        lea     %ecx, [%edx+%eax]\n        and     %ecx, -2\n        sub     %eax, %ecx\n        ret\n\nor ICC 8.0, which generates:\n\nt:\n        movl      4(%esp), %ecx                                 #3.5\n        movl      $-2147483647, %eax                            #3.25\n        imull     %ecx                                          #3.25\n        movl      %ecx, %eax                                    #3.25\n        sarl      $31, %eax                                     #3.25\n        addl      %ecx, %edx                                    #3.25\n        subl      %edx, %eax                                    #3.25\n        addl      %eax, %eax                                    #3.25\n        negl      %eax                                          #3.25\n        subl      %eax, %ecx                                    #3.25\n        movl      %ecx, %eax                                    #3.25\n        ret                                                     #3.25\n\nWe would be in great shape if not for the moves.\n\nllvm-svn: 16763",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Target/X86/X86ISelSimple.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/6835dedb5bbebeadb1ee9f82f87f38a0e47e3171",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces a less efficient signed modulo operation with a more efficient sequence of bitwise and arithmetic operations, reducing instruction count and improving performance.",
            "The optimization strategy replaces a less efficient signed modulo operation with a more efficient sequence of bitwise and arithmetic operations, reducing the number of instructions and avoiding costly division.",
            "The optimization strategy replaces a less efficient signed modulo operation with a more efficient sequence of bitwise and arithmetic operations, reducing instruction count and improving performance.",
            "The optimization strategy replaces a less efficient signed modulo operation with a more efficient sequence of bitwise and arithmetic operations, reducing instruction count and improving performance.",
            "The optimization strategy replaces a less efficient signed modulo operation with a more efficient sequence of bitwise and arithmetic operations, reducing instruction count and improving performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces a less efficient signed modulo operation with a more efficient sequence of bitwise and arithmetic operations, reducing instruction count and improving performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "454a0a700907f68a92521a73c3e7fe0b4243b05d",
        "author": "Wenfeng Liu",
        "date": "2017-01-13T16:38:09+01:00",
        "message": "mempool: use cache in single producer or consumer mode\n\nCurrently we will check mempool flags when we put/get objects from\nmempool. However, this makes cache useless when mempool is SC|SP,\nSC|MP, MC|SP cases.\nThis patch makes cache available in above cases and improves performance.\n\nSigned-off-by: Wenfeng Liu <liuwf@arraynetworks.com.cn>\nAcked-by: Olivier Matz <olivier.matz@6wind.com>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/librte_mempool/rte_mempool.h"
        ],
        "github_commit_url": "https://github.com/DPDK/dpdk/commit/454a0a700907f68a92521a73c3e7fe0b4243b05d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__attribute__"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "dpdk",
        "optimization_summary": [
            "The optimization enables cache usage in single producer or consumer modes by bypassing unnecessary mempool flag checks, improving performance.",
            "The optimization enables cache usage in single producer or consumer modes by bypassing unnecessary mempool flag checks, improving performance.",
            "The optimization enables cache usage in single producer or consumer modes by bypassing unnecessary mempool flag checks, improving performance.",
            "The optimization enables cache usage in single producer or consumer modes by bypassing unnecessary mempool flag checks, improving performance.",
            "The optimization strategy involved enabling cache usage in single producer or consumer modes to reduce unnecessary flag checks and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization enables cache usage in single producer or consumer modes by bypassing unnecessary mempool flag checks, improving performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "lzsa",
        "hash": "4864f3c184d371520092669a693fa2ade9e7f58c",
        "author": "Emmanuel Marty",
        "date": "2020-07-10T17:45:13+02:00",
        "message": "Compress LZSA1 a little faster",
        "modified_files_count": 1,
        "modified_files": [
            "src/shrink_block_v1.c"
        ],
        "github_commit_url": "https://github.com/emmanuel-marty/lzsa/commit/4864f3c184d371520092669a693fa2ade9e7f58c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "lzsa_optimize_forward_v1"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved restructuring the loop to reduce unnecessary computations during the compression process.",
            "The optimization strategy involved restructuring the loop to reduce unnecessary computations during the compression process.",
            "The optimization strategy involved restructuring the loop to reduce unnecessary computations and improve iteration efficiency.",
            "The optimization strategy involved restructuring the loop to reduce unnecessary computations during the compression process.",
            "The optimization strategy involved restructuring the loop to reduce unnecessary computations during the compression process."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved restructuring the loop to reduce unnecessary computations during the compression process.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "efl",
        "hash": "964844821d10d4f4440c82cd99450870d1656cff",
        "author": "Derek Foreman",
        "date": "2017-02-03T15:54:48-06:00",
        "message": "ecore_evas: use ecore_timer_loop_add for idle timeout update\n\nThis shouldn't need \"exact\" time, so use a loop time based timer\nto potentially save a syscall on archs that don't have a vdso.\n\n@optimize",
        "modified_files_count": 1,
        "modified_files": [
            "src/lib/ecore_evas/ecore_evas.c"
        ],
        "github_commit_url": "https://github.com/Enlightenment/efl/commit/964844821d10d4f4440c82cd99450870d1656cff",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_ecore_evas_idle_timeout_update"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a precise timer with a loop-based timer to potentially reduce system call overhead on architectures lacking a virtual dynamic shared object (vDSO).",
            "The optimization strategy replaced a precise timer with a loop-based timer to potentially reduce system call overhead on architectures lacking a virtual dynamic shared object (vdso).",
            "The optimization strategy replaced a precise timer with a loop-based timer to potentially reduce syscall overhead on architectures lacking a vdso.",
            "The optimization strategy replaced a precise timer with a loop-based timer to reduce potential syscall overhead on architectures lacking vdso support.",
            "The optimization strategy replaced a precise timer with a loop-based timer to potentially reduce syscall overhead on architectures lacking vdso support."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a precise timer with a loop-based timer to potentially reduce syscall overhead on architectures lacking a vdso.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "flint",
        "hash": "5451b53703a529ff76123b7418fe2d624e122db6",
        "author": "wbhart",
        "date": "2019-04-16T13:11:30+02:00",
        "message": "Merge pull request #554 from thofma/th/fmpqpolyaddfmpq\n\nSpeed up fmpq_poly_add_fmpq",
        "modified_files_count": 1,
        "modified_files": [
            "fmpq_poly/inlines.c"
        ],
        "github_commit_url": "https://github.com/flintlib/flint/commit/5451b53703a529ff76123b7418fe2d624e122db6",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "fmpq_poly_add_fmpq"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations and improving the efficiency of coefficient handling in the polynomial addition function.",
            "The optimization strategy involved restructuring the addition operation in `fmpq_poly_add_fmpq` to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved reducing redundant computations and improving the efficiency of coefficient handling in the polynomial addition function.",
            "The optimization strategy involved restructuring the addition operation in `fmpq_poly_add_fmpq` to reduce redundant computations and improve efficiency.",
            "The optimization strategy involved reducing redundant computations and improving the efficiency of coefficient handling in the polynomial addition function."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations and improving the efficiency of coefficient handling in the polynomial addition function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "odgi",
        "hash": "f577281313ab72c456208d7a94e793b8264d06d0",
        "author": "AndreaGuarracino",
        "date": "2022-06-04T18:15:07+02:00",
        "message": "allow only graph optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/subcommand/sort_main.cpp"
        ],
        "github_commit_url": "https://github.com/pangenome/odgi/commit/f577281313ab72c456208d7a94e793b8264d06d0",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves restricting the sorting process to only optimize the graph structure, avoiding unnecessary operations on other components.",
            "The optimization strategy involves restricting the sorting process to only optimize the graph structure, avoiding unnecessary operations on other components.",
            "The optimization strategy involves restricting the sorting process to only optimize the graph structure, avoiding unnecessary operations on other components.",
            "The optimization strategy involves restricting the sorting process to only optimize the graph structure, avoiding unnecessary operations on other components.",
            "The optimization strategy involves restricting the sorting process to only optimize the graph structure, avoiding unnecessary operations on other components."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves restricting the sorting process to only optimize the graph structure, avoiding unnecessary operations on other components.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gui",
        "hash": "5ecd14a31cad496e58fbc4aca9af0e9a001689d5",
        "author": "fanquake",
        "date": "2023-02-15T16:10:46+00:00",
        "message": "Merge bitcoin/bitcoin#26844: Net: Pass `MSG_MORE` flag when sending non-final network messages (round 2)\n\n691eaf8873fe2f189153ca637506a0291504c97a Pass MSG_MORE flag when sending non-final network messages (Matt Whitlock)\n\nPull request description:\n\n  **N.B.:** This is my second attempt at introducing this optimization. #12519 (2018) was closed in deference to switching to doing gathering socket writes using `sendmsg(2)`, which I agree would have superior performance due to fewer syscalls, but that work was apparently abandoned in late 2018. Ever since, Bitcoin Core has continued writing tons of runt packets to the wire. Can we proceed with my halfway solution for now?\n\n  ----\n\n  Since Nagle's algorithm is disabled, each and every call to `send(2)` can potentially generate a separate TCP segment on the wire. This is especially inefficient when sending the tiny header preceding each message payload.\n\n  Linux implements a `MSG_MORE` flag that tells the kernel not to push the passed data immediately to the connected peer but rather to collect it in the socket's internal transmit buffer where it can be combined with data from successive calls to `send(2)`. Where available, specify this flag when calling `send(2)` in `CConnman::SocketSendData(CNode &)` if the data buffer being sent is not the last one in `node.vSendMsg`.\n\nACKs for top commit:\n  sipa:\n    ACK 691eaf8873fe2f189153ca637506a0291504c97a\n  vasild:\n    ACK 691eaf8873fe2f189153ca637506a0291504c97a\n\nTree-SHA512: 9a7f46bc12edbf78d488f05d1c46760110a24c95af74b627d2604fcd198fa3f511c5956bac36d0034e88c632d432f7d394147e667a11b027af0a30f70a546d70",
        "modified_files_count": 1,
        "modified_files": [
            "src/net.cpp"
        ],
        "github_commit_url": "https://github.com/bitcoin-core/gui/commit/5ecd14a31cad496e58fbc4aca9af0e9a001689d5",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization uses the `MSG_MORE` flag to batch multiple small network message writes into fewer TCP segments by delaying the transmission of non-final messages.",
            "The optimization uses the `MSG_MORE` flag to batch non-final network message writes, reducing the number of TCP segments generated by combining data in the socket's transmit buffer.",
            "The optimization uses the `MSG_MORE` flag to batch non-final network message writes, reducing the number of TCP segments generated by combining data in the socket's transmit buffer.",
            "The optimization uses the `MSG_MORE` flag to batch non-final network message writes, reducing the number of TCP segments generated by combining data in the socket's transmit buffer.",
            "The optimization uses the `MSG_MORE` flag to batch non-final network message sends, reducing the number of TCP segments generated by combining data in the socket's transmit buffer."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization uses the `MSG_MORE` flag to batch non-final network message writes, reducing the number of TCP segments generated by combining data in the socket's transmit buffer.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "metamage_1",
        "hash": "6a567e936b438ab3f1a1a82f4ede93481d89b4e1",
        "author": "Joshua Juran",
        "date": "2010-03-17T23:18:25-07:00",
        "message": "perl:  Unpessimize Lamp_async_check().\n\nInstead of calling kill() every million (or so) ops, we called it *after* that\npoint and then every time thereafter for another four billion ops (or so) until\nthe counter overflowed back to zero.\n\nThis dramatically improves performance of long-running Perl processes.",
        "modified_files_count": 1,
        "modified_files": [
            "lamp/contrib/perl-5.6.1/perl/macos/macish.c"
        ],
        "github_commit_url": "https://github.com/jjuran/metamage_1/commit/6a567e936b438ab3f1a1a82f4ede93481d89b4e1",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization reduces the frequency of calling `kill()` by avoiding unnecessary repeated calls after a certain operation count threshold, thus improving performance for long-running processes.",
            "The optimization reduces the frequency of calling `kill()` by avoiding unnecessary repeated calls after a certain operation count threshold.",
            "The optimization reduces the frequency of calling `kill()` by avoiding unnecessary repeated calls after a certain operation count threshold.",
            "The optimization reduces the frequency of calling `kill()` by avoiding unnecessary repeated calls after a certain operation count threshold.",
            "The optimization reduces the frequency of calling `kill()` by avoiding unnecessary repeated calls after a certain operation count threshold."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization reduces the frequency of calling `kill()` by avoiding unnecessary repeated calls after a certain operation count threshold.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenTESArena",
        "hash": "6d18d0155f90a17fb8c6ab6ba17d2d71c605c37c",
        "author": "Aaron",
        "date": "2020-09-20T11:06:57-07:00",
        "message": "Only check voxels adjacent to chasm voxels.\n\nThis brings performance back to normal levels instead of it being single-digit FPS looking out across the water.",
        "modified_files_count": 1,
        "modified_files": [
            "OpenTESArena/src/World/LevelData.cpp"
        ],
        "github_commit_url": "https://github.com/afritz1/OpenTESArena/commit/6d18d0155f90a17fb8c6ab6ba17d2d71c605c37c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LevelData::readFLOR"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces unnecessary voxel checks by only evaluating those adjacent to chasm voxels, improving performance in specific scenarios.",
            "The optimization strategy reduces unnecessary voxel checks by only evaluating those adjacent to chasm voxels, improving performance in specific scenarios.",
            "The optimization strategy reduces unnecessary voxel checks by only evaluating those adjacent to chasm voxels, improving performance in scenarios with large open areas like water.",
            "The optimization strategy reduces unnecessary voxel checks by only evaluating those adjacent to chasm voxels, improving performance in specific scenarios.",
            "The optimization strategy reduces unnecessary voxel checks by only evaluating those adjacent to chasm voxels, improving performance in specific scenarios."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy reduces unnecessary voxel checks by only evaluating those adjacent to chasm voxels, improving performance in specific scenarios.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "angle",
        "hash": "326f128b941d54c0277178f87e784da8ce2190eb",
        "author": "Lingfeng Yang",
        "date": "2021-01-11T20:59:41+00:00",
        "message": "Vulkan: Prefer host cached memory for Buffers\n\nThis improves perf because vertex data upload uses host visible memory,\nand uncached memory can be slow.\n\nTest:\n\nAndroid on Windows with 1080Ti:\nglmark2 [build] vbo=false 265 -> 3900 fps\n\nBug: angleproject:5515\nChange-Id: Ib75582bbdb4ca4a22d3a121c7b477a23a8a809ef\nReviewed-on: https://chromium-review.googlesource.com/c/angle/angle/+/2615742\nCommit-Queue: Lingfeng Yang <lfy@google.com>\nReviewed-by: Jamie Madill <jmadill@chromium.org>\nReviewed-by: Tim Van Patten <timvp@google.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/libANGLE/renderer/vulkan/vk_helpers.cpp"
        ],
        "github_commit_url": "https://github.com/google/angle/commit/326f128b941d54c0277178f87e784da8ce2190eb",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BufferHelper::init"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves preferring host cached memory for buffers to improve performance during vertex data upload by reducing the overhead associated with uncached memory.",
            "The optimization strategy involves preferring host cached memory for buffers to improve performance during vertex data upload by reducing the overhead associated with uncached memory.",
            "The optimization strategy involves preferring host cached memory for buffers to improve performance during vertex data upload in Vulkan.",
            "The optimization strategy involves preferring host cached memory for buffers to improve performance during vertex data upload by reducing the overhead associated with uncached memory access.",
            "The optimization strategy involves preferring host cached memory for buffers to improve performance during vertex data upload in Vulkan."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves preferring host cached memory for buffers to improve performance during vertex data upload by reducing the overhead associated with uncached memory access.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "fac64bf456cf56f0c6309d21286b7eaf170f668e",
        "author": "Matthias Kretz",
        "date": "2023-03-21T20:30:19+01:00",
        "message": "libstdc++: Use more precise __RECIPROCAL_MATH__ macro\n\nSigned-off-by: Matthias Kretz <m.kretz@gsi.de>\n\nlibstdc++-v3/ChangeLog:\n\n\t* include/experimental/bits/simd_x86.h\n\t(_SimdImplX86::_S_divides): Replace test for __GCC_IEC_559 == 0\n\twith __RECIPROCAL_MATH__.",
        "modified_files_count": 1,
        "modified_files": [
            "libstdc++-v3/include/experimental/bits/simd_x86.h"
        ],
        "github_commit_url": "https://github.com/Rust-GCC/gccrs/commit/fac64bf456cf56f0c6309d21286b7eaf170f668e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "_S_divides"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "gccrs",
        "optimization_summary": [
            "The optimization replaces a less precise macro check with a more specific one to enable reciprocal math optimizations where applicable.",
            "The optimization replaces a less precise macro check with a more specific one to enable reciprocal math optimizations where applicable.",
            "The optimization strategy involved replacing a less precise macro check with a more specific one to enable reciprocal math optimizations where appropriate.",
            "The optimization replaces a less precise macro check with a more specific one to enable reciprocal math optimizations where appropriate.",
            "The optimization replaces a less precise macro check with a more specific one to enable reciprocal math optimizations where appropriate."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization replaces a less precise macro check with a more specific one to enable reciprocal math optimizations where appropriate.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "xla",
        "hash": "240fd2f32d16b58473e16a4eff51f16a11a3fd6d",
        "author": "Eugene Zhulenev",
        "date": "2022-10-14T08:47:53-07:00",
        "message": "[xla:gpu:runtime] NFC: Micro performance optimizations\n\nPiperOrigin-RevId: 481153499",
        "modified_files_count": 1,
        "modified_files": [
            "xla/service/gpu/runtime/kernel_launch.cc"
        ],
        "github_commit_url": "https://github.com/openxla/xla/commit/240fd2f32d16b58473e16a4eff51f16a11a3fd6d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LaunchFunc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The commit likely involved micro-optimizations such as loop unrolling, inlining, or reducing redundant computations within the `LaunchFunc` function to improve performance.",
            "The commit likely involved micro-optimizations such as loop unrolling, inlining, or reducing redundant computations within the `LaunchFunc` function to improve performance.",
            "The commit implements micro-performance optimizations in the `LaunchFunc` function, likely focusing on reducing overhead or improving efficiency in kernel launches.",
            "The commit likely involved micro-optimizations such as reducing unnecessary computations or improving loop efficiency in the `LaunchFunc` function.",
            "The commit likely involved micro-optimizations such as reducing unnecessary computations or improving loop efficiency in the `LaunchFunc` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The commit likely involved micro-optimizations such as reducing unnecessary computations or improving loop efficiency in the `LaunchFunc` function.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "9c7a5f5efafaa01ccc57a82cc4619f433cbda699",
        "author": "Jasper St. Pierre",
        "date": "2014-11-26T18:10:55-08:00",
        "message": "gtkstylecontext: Optimize GtkStyleContext usage",
        "modified_files_count": 1,
        "modified_files": [
            "gtk/gtkstylecontext.c"
        ],
        "github_commit_url": "https://github.com/GNOME/gtk/commit/9c7a5f5efafaa01ccc57a82cc4619f433cbda699",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_cursor_color"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "gtk",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `get_cursor_color` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `get_cursor_color` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `get_cursor_color` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `get_cursor_color` function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the `get_cursor_color` function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations by caching and reusing results within the `get_cursor_color` function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "libwebp",
        "hash": "b7346a1ed25d5091618f9d76c5f270e9408ba910",
        "author": "Jyrki Alakuijala",
        "date": "2013-07-09T18:47:06-07:00",
        "message": "0.1 % speedup to decoding\n\nChange-Id: If2add8a8b6f339f1d4b6a9581ce8d3d0f792d372",
        "modified_files_count": 1,
        "modified_files": [
            "src/dec/vp8l.c"
        ],
        "github_commit_url": "https://github.com/webmproject/libwebp/commit/b7346a1ed25d5091618f9d76c5f270e9408ba910",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ReadSymbol"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved simplifying the logic for reading symbols in the VP8L decoding process to reduce computational overhead.",
            "The optimization strategy involved simplifying the logic for reading symbols to reduce unnecessary computations during decoding.",
            "The optimization strategy involved replacing a division operation with a multiplication by the reciprocal to improve decoding speed.",
            "The optimization strategy involved simplifying the logic for reading symbols in the VP8L decoding process to reduce computational overhead.",
            "The optimization strategy involved replacing a division operation with a multiplication by the reciprocal to improve decoding speed."
        ],
        "is_generic_optimization": [
            false,
            false,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved simplifying the logic for reading symbols to reduce unnecessary computations during decoding.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ffmpeg",
        "hash": "d3d99a0a068ff703c7f7c3c0dc0b66c9a0774fdd",
        "author": "Anton Khirnov",
        "date": "2021-02-24T17:16:46+01:00",
        "message": "lavc/lscrdec: use ff_reget_buffer()\n\nIt is simpler and more efficient.\n\nSuggested-by: James Almer <jamrial@gmail.com>",
        "modified_files_count": 1,
        "modified_files": [
            "libavcodec/lscrdec.c"
        ],
        "github_commit_url": "https://github.com/allyourcodebase/ffmpeg/commit/d3d99a0a068ff703c7f7c3c0dc0b66c9a0774fdd",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "decode_frame_lscr"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved replacing a buffer management function with a more efficient alternative to simplify and speed up the decoding process.",
            "The optimization strategy involved replacing a buffer retrieval function with a more efficient alternative to simplify and speed up the decoding process.",
            "The optimization strategy involved replacing a buffer management function with a more efficient alternative to simplify and speed up the decoding process.",
            "The optimization strategy involved replacing a buffer management function with a more efficient alternative to simplify and speed up the decoding process.",
            "The optimization strategy involved replacing a buffer management function with a more efficient alternative to simplify and improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved replacing a buffer management function with a more efficient alternative to simplify and speed up the decoding process.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "b0b7a7d24b66109a940d09d8d2dcf513e4eaf3a1",
        "author": "Pavel Begunkov",
        "date": "2023-01-29T15:17:41-07:00",
        "message": "io_uring: return back links tw run optimisation\n\nio_submit_flush_completions() may queue new requests for tw execution,\nespecially true for linked requests. Recheck the tw list for emptiness\nafter flushing completions.\n\nNote that this doesn't really fix the commit referenced below, but it\ndoes reinstate an optimization that existed before that got merged.\n\nFixes: f88262e60bb9 (\"io_uring: lockless task list\")\nSigned-off-by: Pavel Begunkov <asml.silence@gmail.com>\nLink: https://lore.kernel.org/r/6328acdbb5e60efc762b18003382de077e6e1367.1673887636.git.asml.silence@gmail.com\nSigned-off-by: Jens Axboe <axboe@kernel.dk>",
        "modified_files_count": 1,
        "modified_files": [
            "io_uring/io_uring.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/b0b7a7d24b66109a940d09d8d2dcf513e4eaf3a1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__io_run_local_work"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy rechecks the task work (tw) list for emptiness after flushing completions to handle newly queued linked requests efficiently.",
            "The optimization strategy involves rechecking the task work (tw) list for emptiness after flushing completions to ensure that newly queued linked requests are processed promptly.",
            "The optimization strategy involves rechecking the task work (tw) list for emptiness after flushing completions to handle newly queued linked requests efficiently.",
            "The optimization strategy involves rechecking the task work (tw) list for emptiness after flushing completions to handle newly queued linked requests efficiently.",
            "The optimization strategy involves rechecking the task work (tw) list for emptiness after flushing completions to handle newly queued linked requests efficiently."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves rechecking the task work (tw) list for emptiness after flushing completions to handle newly queued linked requests efficiently.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "arduino-esp32",
        "hash": "f5b04b919777c8b7305260cc3e8f5a6e4aede803",
        "author": "obaterspok",
        "date": "2021-12-14T15:37:00+02:00",
        "message": "Use WIFI_FAST_SCAN if a specific channel was used (#5975)\n\n1.0.6 changed scanning method to always scan all available channels during connect. This results in results in connect taking about ~3 seconds instead of ~1. This patch changes the behavior to use WIFI_FAST_SCAN if client used a specific channel.",
        "modified_files_count": 1,
        "modified_files": [
            "libraries/WiFi/src/WiFiSTA.cpp"
        ],
        "github_commit_url": "https://github.com/espressif/arduino-esp32/commit/f5b04b919777c8b7305260cc3e8f5a6e4aede803",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WiFiSTAClass::begin"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves using WIFI_FAST_SCAN when a specific channel is specified to reduce connection time by avoiding full channel scans.",
            "The optimization strategy involves using WIFI_FAST_SCAN when a specific channel is specified to reduce connection time by avoiding full channel scans.",
            "The optimization strategy involves using WIFI_FAST_SCAN when a specific channel is specified to reduce connection time by avoiding full channel scans.",
            "The optimization strategy involves using WIFI_FAST_SCAN when a specific channel is specified to reduce connection time by avoiding full channel scans.",
            "The optimization strategy involves using WIFI_FAST_SCAN when a specific channel is specified to reduce connection time by avoiding full channel scans."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves using WIFI_FAST_SCAN when a specific channel is specified to reduce connection time by avoiding full channel scans.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libulz",
        "hash": "ce4d80cfda0b3e3cc70aedbaeed3c5bb824ce7d7",
        "author": "rofl0r",
        "date": "2011-11-29T18:47:14+01:00",
        "message": "slightly more efficient sblist_delete",
        "modified_files_count": 1,
        "modified_files": [
            "src/sblist/sblist_delete.c"
        ],
        "github_commit_url": "https://github.com/rofl0r/libulz/commit/ce4d80cfda0b3e3cc70aedbaeed3c5bb824ce7d7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sblist_delete"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary memory shifts in the `sblist_delete` function by directly overwriting the deleted element with the last element in the list.",
            "The optimization strategy involved reducing unnecessary memory shifts in the `sblist_delete` function by directly overwriting the deleted element with the last element in the list.",
            "The optimization strategy involved reducing unnecessary memory shifts in the `sblist_delete` function by directly overwriting the deleted element with the last element in the list.",
            "The optimization strategy involved reducing unnecessary memory shifts in the `sblist_delete` function by directly overwriting the deleted element with the last element in the list.",
            "The optimization strategy involved reducing unnecessary memory shifts in the `sblist_delete` function by directly overwriting the deleted element with the last element in the list."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary memory shifts in the `sblist_delete` function by directly overwriting the deleted element with the last element in the list.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sycl",
        "hash": "e133140fd1e5ea3a5bcadc3e594e1b613c36d9c5",
        "author": "Alexander Kornienko",
        "date": "2017-05-16T15:44:42+00:00",
        "message": "[clang-tidy] Optimize matchers in readability-implicit-bool-cast. NFC\n\nDon't repeat `isInTemplateInstantiation()` and `hasAncestor()` unnecessarily.\nThis speeds up the check by a factor of up to 3 on some large files.\n\nllvm-svn: 303180",
        "modified_files_count": 1,
        "modified_files": [
            "clang-tools-extra/clang-tidy/readability/ImplicitBoolCastCheck.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/e133140fd1e5ea3a5bcadc3e594e1b613c36d9c5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ImplicitBoolCastCheck::registerMatchers"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids redundant calls to `isInTemplateInstantiation()` and `hasAncestor()` by restructuring the matcher logic, reducing unnecessary computations.",
            "The optimization strategy eliminates redundant calls to `isInTemplateInstantiation()` and `hasAncestor()` to reduce unnecessary computations.",
            "The optimization strategy eliminates redundant calls to `isInTemplateInstantiation()` and `hasAncestor()` to reduce unnecessary computations.",
            "The optimization strategy eliminates redundant calls to `isInTemplateInstantiation()` and `hasAncestor()` to reduce unnecessary computations.",
            "The optimization strategy eliminates redundant calls to `isInTemplateInstantiation()` and `hasAncestor()` to reduce unnecessary computations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy eliminates redundant calls to `isInTemplateInstantiation()` and `hasAncestor()` to reduce unnecessary computations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "9e176494c22da279c14457951c0ae1d3de749059",
        "author": "Jim Bankoski",
        "date": "2013-05-31T06:47:40-07:00",
        "message": "put back in lost speedups\n\nspeed >1 can be spead up by turning these on - lost in a prior commit\n\nChange-Id: Iaef85e10ecfeec3aea5ab0e691edf02bb7f5190d",
        "modified_files_count": 1,
        "modified_files": [
            "vp9/encoder/vp9_onyx_if.c"
        ],
        "github_commit_url": "https://github.com/webmproject/libvpx/commit/9e176494c22da279c14457951c0ae1d3de749059",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "vp9_set_speed_features"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "libvpx",
        "optimization_summary": [
            "The optimization re-enables previously lost speedups by adjusting certain encoding parameters for higher speed settings.",
            "The optimization re-enables previously lost speedups by adjusting certain encoding parameters for higher speed settings.",
            "The optimization re-enables previously lost speedups by adjusting certain encoding parameters or features based on the speed setting.",
            "The optimization re-enables previously lost speedups by adjusting specific speed-related feature flags in the encoder configuration.",
            "The optimization re-enables previously lost speedups by adjusting certain encoding parameters for higher speed settings."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization re-enables previously lost speedups by adjusting certain encoding parameters for higher speed settings.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "069cb27017de6476d47a70fbf144f69200d3e854",
        "author": "Lukasz Rymanowski",
        "date": "2014-08-14T08:49:26+02:00",
        "message": "Bluetooth: Improve data packing in SAR mode\n\nThere is no need to decrease pdu size with L2CAP SDU lenght in Start\nL2CAP SDU frame. Start packtet is just 2 bytes longer as specified and\nwe can keep payload as long as possible.\n\nWhen testing SAR L2CAP against PTS, L2CAP channel is usually configured\nin that way, that SDU = MPS * 3. PTS expets then 3 I-Frames from IUT: Start,\nContinuation and End frame.\n\nWithout this fix, we sent 4 I-Frames. We could pass a test by using -b\noption in l2test and send just two bytes less than SDU length. With this\npatch no need to use -b option.\n\nSigned-off-by: Lukasz Rymanowski <lukasz.rymanowski@tieto.com>\nSigned-off-by: Marcel Holtmann <marcel@holtmann.org>",
        "modified_files_count": 1,
        "modified_files": [
            "net/bluetooth/l2cap_core.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/069cb27017de6476d47a70fbf144f69200d3e854",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "l2cap_segment_sdu"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involved adjusting the packet size in Bluetooth's L2CAP SAR mode to avoid unnecessary fragmentation and improve data packing efficiency.",
            "The optimization strategy involved adjusting the packing of Bluetooth L2CAP Start frames to maximize payload size within protocol constraints, reducing the number of transmitted frames.",
            "The optimization strategy involved adjusting the packet size in Bluetooth's L2CAP SAR mode to avoid unnecessary fragmentation and improve data packing efficiency.",
            "The optimization strategy involves maximizing payload size in Start L2CAP SDU frames to avoid unnecessary fragmentation and reduce the number of transmitted frames.",
            "The optimization strategy involved adjusting the packet size in Bluetooth's L2CAP SAR mode to avoid unnecessary fragmentation and improve data packing efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting the packet size in Bluetooth's L2CAP SAR mode to avoid unnecessary fragmentation and improve data packing efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mango",
        "hash": "5589735763e6fe23039bb5b3dbc35f8472e4c416",
        "author": "t0rakka",
        "date": "2022-09-04T20:36:02+03:00",
        "message": "Tune encode buffer size.",
        "modified_files_count": 1,
        "modified_files": [
            "source/mango/image/image_jxl.cpp"
        ],
        "github_commit_url": "https://github.com/t0rakka/mango/commit/5589735763e6fe23039bb5b3dbc35f8472e4c416",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "imageEncode"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved adjusting the encode buffer size to improve performance during image encoding.",
            "The optimization strategy involved adjusting the encode buffer size to improve performance during image encoding.",
            "The optimization strategy involved adjusting the encode buffer size to improve performance during image encoding.",
            "The optimization strategy involved adjusting the encode buffer size to improve performance during image encoding.",
            "The optimization strategy involved adjusting the encode buffer size to improve performance during image encoding."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved adjusting the encode buffer size to improve performance during image encoding.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "rdma-core",
        "hash": "7ebd3fcb3f6155d941ecd1dd3ecedb9e41a4a2b5",
        "author": "Alex Vesker",
        "date": "2020-05-31T17:25:05+03:00",
        "message": "mlx5: Skip source port matching on DR FDB RX domain\n\nThe FDB RX pipe is connected to the wire and the source\nport for all incoming packets equals to wire, single uplink\nport per PF, this means there is no point of matching on\nthe source port in such case. Once we recognize such a\ncase we will optimize the RX steering rule.\n\nSigned-off-by: Alex Vesker <valex@mellanox.com>\nSigned-off-by: Yishai Hadas <yishaih@mellanox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "providers/mlx5/dr_matcher.c"
        ],
        "github_commit_url": "https://github.com/linux-rdma/rdma-core/commit/7ebd3fcb3f6155d941ecd1dd3ecedb9e41a4a2b5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dr_matcher_set_ste_builders"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization skips unnecessary source port matching in the DR FDB RX domain by leveraging the fact that all incoming packets on this domain originate from a single uplink port.",
            "The optimization skips unnecessary source port matching in the DR FDB RX domain by leveraging the fact that all incoming packets on this domain originate from a single uplink port.",
            "The optimization skips unnecessary source port matching in the DR FDB RX domain by leveraging the fact that all incoming packets on the FDB RX pipe have a predictable source port.",
            "The optimization skips unnecessary source port matching in the DR FDB RX domain by leveraging the fact that all incoming packets on the FDB RX pipe originate from a single uplink port.",
            "The optimization skips unnecessary source port matching in the DR FDB RX domain by leveraging the fact that all incoming packets on the FDB RX pipe have a predictable source port."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization skips unnecessary source port matching in the DR FDB RX domain by leveraging the fact that all incoming packets on the FDB RX pipe originate from a single uplink port.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "995e4286a047b32aebf8ce540908edb7fbd93f76",
        "author": "Subbaiah Venkata",
        "date": "2007-10-17T08:42:52-07:00",
        "message": "lib/sort.c optimization\n\nHello, I fixed and tested a small bug in lib/sort.c file, heap sort\nfunction.\n\nThe fix avoids unnecessary swap of contents when i is 0 (saves few loads\nand stores), which happens every time sort function is called.  I felt the\nfix is worth bringing it to your attention given the importance and\nfrequent use of the sort function.\n\nAcked-by: Matt Mackall <mpm@selenic.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "lib/sort.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/995e4286a047b32aebf8ce540908edb7fbd93f76",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "O"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization avoids unnecessary swaps in the heap sort function when the index is 0, reducing redundant memory operations.",
            "The optimization avoids unnecessary swaps in the heap sort function when the index is 0, reducing redundant memory operations.",
            "The optimization avoids unnecessary swaps in the heap sort function when the index is 0, reducing redundant memory operations.",
            "The optimization avoids unnecessary swaps in the heap sort function when the index is 0, reducing redundant memory operations.",
            "The optimization avoids unnecessary swaps in the heap sort function when the index is 0, reducing redundant memory operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary swaps in the heap sort function when the index is 0, reducing redundant memory operations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "68c4fa31aa52765314b4285a7835368ea35b509c",
        "author": "Thomas Hellstrom",
        "date": "2010-11-22T13:25:15+10:00",
        "message": "drm/ttm: Optimize ttm_eu_backoff_reservation\n\nAvoid the ttm_bo_unreserve() spinlocks by calling\nttm_eu_backoff_reservation_locked under the lru spinlock.\n\nSigned-off-by: Thomas Hellstrom <thellstrom@vmware.com>\nReviewed-by: Jerome Glisse <j.glisse@gmail.com>\nSigned-off-by: Dave Airlie <airlied@redhat.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/gpu/drm/ttm/ttm_execbuf_util.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/68c4fa31aa52765314b4285a7835368ea35b509c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ttm_eu_backoff_reservation"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization avoids unnecessary spinlocks by calling a locked version of the function under an existing lock.",
            "The optimization avoids unnecessary spinlocks by performing reservation backoff under an existing lru spinlock.",
            "The optimization strategy avoids unnecessary spinlocks by calling a locked version of the function under an existing lock.",
            "The optimization avoids unnecessary spinlocks by calling a locked version of the function under an existing lock.",
            "The optimization avoids unnecessary spinlocks by calling a locked version of the function under an existing lru spinlock."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary spinlocks by calling a locked version of the function under an existing lock.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "5473aca3767b00eab502b34a37b595de099980ae",
        "author": "Patrick Steinhardt",
        "date": "2024-01-03T09:54:21-08:00",
        "message": "reftable/merged: really reuse buffers to compute record keys\n\nIn 829231dc20 (reftable/merged: reuse buffer to compute record keys,\n2023-12-11), we have refactored the merged iterator to reuse a pair of\nlong-living strbufs by relying on the fact that `reftable_record_key()`\ntries to reuse already allocated strbufs by calling `strbuf_reset()`,\nwhich should give us significantly fewer reallocations compared to the\nold code that used on-stack strbufs that are allocated for each and\nevery iteration. Unfortunately, we called `strbuf_release()` on these\nlong-living strbufs that we meant to reuse on each iteration, defeating\nthe optimization.\n\nFix this performance issue by not releasing those buffers on iteration\nanymore, where we instead rely on `merged_iter_close()` to release the\nbuffers for us.\n\nUsing `git show-ref --quiet` in a repository with ~350k refs this leads\nto a significant drop in allocations. Before:\n\n    HEAP SUMMARY:\n        in use at exit: 21,163 bytes in 193 blocks\n      total heap usage: 1,410,148 allocs, 1,409,955 frees, 61,976,068 bytes allocated\n\nAfter:\n\n    HEAP SUMMARY:\n        in use at exit: 21,163 bytes in 193 blocks\n      total heap usage: 708,058 allocs, 707,865 frees, 36,783,255 bytes allocated\n\nSigned-off-by: Patrick Steinhardt <ps@pks.im>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>",
        "modified_files_count": 1,
        "modified_files": [
            "reftable/merged.c"
        ],
        "github_commit_url": "https://github.com/git/git/commit/5473aca3767b00eab502b34a37b595de099980ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "merged_iter_next_entry"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "git",
        "optimization_summary": [
            "The optimization strategy involves reusing long-living buffers across iterations to minimize memory reallocations.",
            "The optimization strategy involves reusing long-living buffers across iterations to minimize memory reallocations and reduce heap usage.",
            "The optimization strategy involves reusing long-living buffers across iterations to minimize memory reallocations and reduce heap usage.",
            "The optimization strategy involves reusing long-living buffers across iterations to minimize memory reallocations and improve performance.",
            "The optimization strategy involves reusing long-living buffers across iterations to minimize memory reallocations and reduce heap usage."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves reusing long-living buffers across iterations to minimize memory reallocations and reduce heap usage.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "bitcoin",
        "hash": "3252208cb10be645bae415c90fb2ed8217838490",
        "author": "João Barbosa",
        "date": "2016-03-09T10:10:36+00:00",
        "message": "Improve EncodeBase58 performance",
        "modified_files_count": 1,
        "modified_files": [
            "src/base58.cpp"
        ],
        "github_commit_url": "https://github.com/bitcoin/bitcoin/commit/3252208cb10be645bae415c90fb2ed8217838490",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "EncodeBase58"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used loop unrolling to reduce the number of iterations and improve the performance of the base58 encoding process.",
            "The optimization strategy used loop unrolling and reduced unnecessary memory accesses to improve the performance of the Base58 encoding algorithm.",
            "The optimization strategy used loop unrolling to reduce the number of iterations and improve the performance of the base58 encoding process.",
            "The optimization strategy used loop unrolling to reduce the number of iterations and improve the performance of the EncodeBase58 function.",
            "The optimization strategy used loop unrolling to reduce the number of iterations and improve the performance of the base58 encoding process."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used loop unrolling to reduce the number of iterations and improve the performance of the base58 encoding process.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "ucx",
        "hash": "9a72ae384f4205f0b60cb5b090f8fd0e89e303c9",
        "author": "Yossi Itigin",
        "date": "2019-12-20T20:35:08+02:00",
        "message": "Merge pull request #4589 from brminich/topic/ucp_tag_offload_bb_cuda\n\nUCP/TAG: Tag offload bounce buffer optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/ucp/tag/offload.c"
        ],
        "github_commit_url": "https://github.com/openucx/ucx/commit/9a72ae384f4205f0b60cb5b090f8fd0e89e303c9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ucp_tag_offload_do_post"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved improving the efficiency of tag offload operations by optimizing bounce buffer handling in CUDA contexts.",
            "The optimization strategy involved improving the efficiency of tag offload operations by optimizing bounce buffer handling in the `ucp_tag_offload_do_post` function.",
            "The optimization strategy involved improving the efficiency of tag offload operations by optimizing bounce buffer handling in the `ucp_tag_offload_do_post` function.",
            "The optimization strategy involved improving the efficiency of tag offload operations by optimizing bounce buffer handling in CUDA contexts.",
            "The optimization strategy involved improving the efficiency of tag offload operations by optimizing bounce buffer handling in CUDA contexts."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved improving the efficiency of tag offload operations by optimizing bounce buffer handling in CUDA contexts.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "9bf811dae443794594615625577277852edc181b",
        "author": "Claudio Imbrenda",
        "date": "2022-07-19T12:06:56+00:00",
        "message": "s390/mm: KVM: pv: when tearing down, try to destroy protected pages\n\nWhen ptep_get_and_clear_full is called for a mm teardown, we will now\nattempt to destroy the secure pages. This will be faster than export.\n\nIn case it was not a teardown, or if for some reason the destroy page\nUVC failed, we try with an export page, like before.\n\nSigned-off-by: Claudio Imbrenda <imbrenda@linux.ibm.com>\nAcked-by: Janosch Frank <frankja@linux.ibm.com>\nReviewed-by: Nico Boehr <nrb@linux.ibm.com>\nLink: https://lore.kernel.org/r/20220628135619.32410-11-imbrenda@linux.ibm.com\nMessage-Id: <20220628135619.32410-11-imbrenda@linux.ibm.com>\nSigned-off-by: Janosch Frank <frankja@linux.ibm.com>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/s390/include/asm/pgtable.h"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/9bf811dae443794594615625577277852edc181b",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ptep_get_and_clear_full"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves attempting to destroy secure pages during memory teardown instead of exporting them, which is faster when applicable.",
            "The optimization strategy involves attempting to destroy secure pages during memory teardown instead of exporting them, which is faster when applicable.",
            "The optimization strategy involves attempting to destroy secure pages during memory teardown instead of exporting them, which is faster when applicable.",
            "The optimization strategy involves attempting to destroy secure pages during memory teardown instead of exporting them, which is faster when applicable.",
            "The optimization strategy involves attempting to destroy secure pages during memory teardown instead of exporting them, which is faster when applicable."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves attempting to destroy secure pages during memory teardown instead of exporting them, which is faster when applicable.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "mptcp",
        "hash": "dbc4cf52aeeb54d916a2fc9fea976829974f21b4",
        "author": "François Finfe",
        "date": "2017-11-26T20:55:44-08:00",
        "message": "mptcp: send a RST when reaching limit MP_FASTCLOSE retransmission\n\nAfter reaching the limit of MPTCP fast close retransmission, the host\nwhich sends the MP_FASTCLOSE should also send a TCP RST to clear the\nconnection state of any firewalls which could implements a non-mptcp\nstateful firewall.\n\nLet's explain it with the following scenario. See figure 1.\nFirewalls M and N are stateful firewall which don't analyse MPTCP\noptions and ignore them. Firewalls can be either a middlebox or\nrunning in the host (e.g. Firewall M on host A).\n\n- An MPTCP connection has been established between host A and host B.\n- Host A sends a ACK with the MP_FASTCLOSE option.\n- Firewall M forwards the packet to host firewall N.\n- Firewall N forwards the packet to host B.\n- Host B receives the MP_FASTCLOSE and replies with a TCP RST.\n- Firewall N forwards the TCP RST packet to firewall M.\n  Due to the TCP RST, the stateful firewall removes the connection\n  state.\n- The TCP RST is lost due to a lossy link, network congestion, etc.\n\n- As host A didn't receive the expected TCP RST packet, a timeout fires\n  a MP_FASTCLOSE retransmission.\n- Firewall M forwards the packet to firewall N.\n- For firewall N, this connection no more exists. It sees the\n  MP_FASTCLOSE as an TCP ACK packet without any related connection.\n  Firewall N drops the packet.\n- MP_FASTCLOSE are retransmitted until the limit of MP_FASTCLOSE\n  retransmission is reached.\n- If nothing is done, firewall M will retain the connection state for\n  some time until a connection tracking timeout occurs.\n  In a production environment, with a lot of simultaneous connections,\n  this kind of entries (erroneous connection state for an already closed\n  connection) can accumulate in the firewall.\n  Due to resource limitations, this might lead to performance issue\n  where new connections might be rejected.\n\nTo mitigitate this issue:\n- When the limit of MP_FASTCLOSE retransmission is reached, a TCP RST\n  could be sent by host A.\n- In this scenario, firewall M forwards the TCP RST packet and removes\n  the connection state.\n\n  Host A                                                          Host B\n   |                 Firewall M             Firewall N                |\n   |                      |                      |                    |\n   |  ACK(MP_FASTCLOSE)   |  ACK(MP_FASTCLOSE)   | ACK(MP_FASTCLOSE)  |\n   |--------------------->|--------------------->|------------------->|\n   |                      |             TCP RST  | TCP RST            |\n   |                      |           x----------|<-------------------|\n   |                      |                      |                    |\n   |                      |                      |                    |\n   |                      |                      |                    |\n   |  ACK(MP_FASTCLOSE)   |  ACK(MP_FASTCLOSE)   |                    |\n   |--------------------->|--------------------->x                    |\n   |                      |                      |                    |\n   |                      |                      |                    |\n   |  ACK(MP_FASTCLOSE)   |  ACK(MP_FASTCLOSE)   |                    |\n   |--------------------->|--------------------->x                    |\n   |                      |                      |                    |\n   :                      :                      :                    :\n   :                                                                  :\n   :  Multiple MP_FASTCLOSE retransmissions until limit is reached    :\n   :                                                                  :\n   :                      :                      :                    :\n   :                      :                      :                    :\n   :                      :                      :                    :\n   |  Last retransmission |                      |                    |\n   |                      |                      |                    |\n   |  ACK(MP_FASTCLOSE)   |  ACK(MP_FASTCLOSE)   |                    |\n   |--------------------->|--------------------->x                    |\n   |                      |                      |                    |\n   | (timeout)            |                      |                    |\n   |  RST(MP_FASTCLOSE)   |  RST(MP_FASTCLOSE)   |                    |\n   |--------------------->|--------------------->x                    |\n   |                      |                      |                    |\n\n   Figure 1\n\nFor more info, see:\nhttps://mailarchive.ietf.org/arch/msg/multipathtcp/SRgRuaECUWdKd2RWTwXUcMClRKc\n\nFixes: 8248fb288e41 (\"Support sending/receiving of MPTCP_RST\")\nSigned-off-by: François Finfe <francois.finfe@tessares.net>\nSigned-off-by: Christoph Paasch <cpaasch@apple.com>",
        "modified_files_count": 1,
        "modified_files": [
            "net/mptcp/mptcp_ctrl.c"
        ],
        "github_commit_url": "https://github.com/multipath-tcp/mptcp/commit/dbc4cf52aeeb54d916a2fc9fea976829974f21b4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mptcp_sock_def_error_report"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves sending a TCP RST after reaching the MP_FASTCLOSE retransmission limit to clear connection states in stateful firewalls.",
            "The optimization strategy involves sending a TCP RST after reaching the MP_FASTCLOSE retransmission limit to clear connection states in stateful firewalls that do not process MPTCP options.",
            "The optimization strategy involves sending a TCP RST after reaching the MP_FASTCLOSE retransmission limit to clear connection states in stateful firewalls that do not process MPTCP options.",
            "The optimization strategy involves sending a TCP RST after reaching the MP_FASTCLOSE retransmission limit to clear connection states in stateful firewalls and prevent resource exhaustion.",
            "The optimization strategy involves sending a TCP RST after reaching the MP_FASTCLOSE retransmission limit to clear connection states in stateful firewalls."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves sending a TCP RST after reaching the MP_FASTCLOSE retransmission limit to clear connection states in stateful firewalls.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "owt-deps-webrtc",
        "hash": "f7c26d40abb3149f473a6c384fd94ba8c2f62b48",
        "author": "elad.alon",
        "date": "2017-03-01T17:05:20+00:00",
        "message": "Small TransportFeedbackAdapterTest efficiency boost and TODO resolved\n\nBUG=None\n\nReview-Url: https://codereview.webrtc.org/2726853002\nCr-Commit-Position: refs/heads/master@{#16950}",
        "modified_files_count": 1,
        "modified_files": [
            "webrtc/modules/congestion_controller/transport_feedback_adapter_unittest.cc"
        ],
        "github_commit_url": "https://github.com/open-webrtc-toolkit/owt-deps-webrtc/commit/f7c26d40abb3149f473a6c384fd94ba8c2f62b48",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary iterations or computations in the test logic to improve efficiency.",
            "The optimization strategy involved reducing unnecessary iterations or operations in the test logic to improve efficiency.",
            "The optimization strategy involved reducing unnecessary iterations or computations in the test logic to improve efficiency.",
            "The optimization strategy involved reducing unnecessary iterations or operations in the test by refining loop logic or condition checks.",
            "The optimization strategy involved reducing unnecessary iterations or operations in the test logic to improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary iterations or operations in the test logic to improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "e1f7bf2c02be1c2331304df4473522c87c5c485d",
        "author": "Andrew Trick",
        "date": "2013-09-09T22:28:08+00:00",
        "message": "mi-sched: smooth out the cyclicpath heuristic.\n\nArnold's idea.\n\nI generally try to avoid stateful heuristics because it can make\ndebugging harder. However, we need a way to prevent the latency\npriority from dominating, and it somewhat makes sense to schedule\naggressively for latency only within an issue group.\n\nSwift in particular likes this, and it doesn't hurt anyone else:\n| Benchmarks/MiBench/consumer-lame              |  10.39% |\n| Benchmarks/Misc/himenobmtxpa                  |   9.63% |\n\nllvm-svn: 190360",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/CodeGen/MachineScheduler.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/e1f7bf2c02be1c2331304df4473522c87c5c485d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization smooths out a cyclic path heuristic by introducing a stateful mechanism to balance latency priority within an issue group, improving scheduling behavior for specific workloads like Swift.",
            "The optimization smooths out a cyclic path heuristic by introducing a stateful mechanism to balance latency priority within an issue group, improving scheduling behavior for certain benchmarks.",
            "The optimization smooths out a cyclic path heuristic to prevent latency priority from dominating, making scheduling more balanced within an issue group.",
            "The optimization smooths out a cyclic path heuristic to prevent latency priority from dominating, making scheduling more balanced within an issue group.",
            "The optimization smooths out a cyclic path heuristic to balance latency priority within an issue group, improving scheduling behavior for certain benchmarks."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization smooths out a cyclic path heuristic by introducing a stateful mechanism to balance latency priority within an issue group, improving scheduling behavior for certain benchmarks.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gcc-xtensa",
        "hash": "8714c250029e1dcdd2413318c8dc0d0c0f002f57",
        "author": "wilson",
        "date": "1993-12-24T01:35:17+00:00",
        "message": "(optimize_reg_copy_1): After decreasing sregno's\nreg_live_length, correct it if it is now obviously too small.\n\n\ngit-svn-id: svn+ssh://gcc.gnu.org/svn/gcc/trunk@6291 138bc75d-0d04-0410-961f-82ee72b054a4",
        "modified_files_count": 1,
        "modified_files": [
            "gcc/local-alloc.c"
        ],
        "github_commit_url": "https://github.com/jcmvbkbc/gcc-xtensa/commit/8714c250029e1dcdd2413318c8dc0d0c0f002f57",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GET_MODE"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy corrects the `reg_live_length` of a register after it has been decreased to ensure it is not obviously too small, improving register allocation accuracy.",
            "The optimization strategy corrects the `reg_live_length` of a register after decreasing it to ensure it is not obviously too small, preventing potential underestimation of its live range.",
            "The optimization strategy corrects the `reg_live_length` of a register after it has been decreased to ensure it is not obviously too small, potentially improving register allocation efficiency.",
            "The optimization strategy corrects the `reg_live_length` of a register after it has been decreased to ensure it is not obviously too small, improving register allocation accuracy.",
            "The optimization strategy corrects the `reg_live_length` of a register after it has been decreased to ensure it is not obviously too small, improving register allocation accuracy."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy corrects the `reg_live_length` of a register after it has been decreased to ensure it is not obviously too small, improving register allocation accuracy.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "50f5921425afbc5edb9a296343706ac260ce6a86",
        "author": "Alex Gorrod",
        "date": "2014-03-20T00:54:07+00:00",
        "message": "Short circuit cleaning up reconciliation boundary structures.\n\nThe list of structures can grow very large, and cleaning up on each\nreconciliation is a performance bottle neck.",
        "modified_files_count": 1,
        "modified_files": [
            "src/btree/rec_write.c"
        ],
        "github_commit_url": "https://github.com/wiredtiger/wiredtiger/commit/50f5921425afbc5edb9a296343706ac260ce6a86",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "__rec_write_init"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "wiredtiger",
        "optimization_summary": [
            "The optimization avoids unnecessary cleanup of reconciliation boundary structures by short-circuiting the process when the list is empty or not large enough to justify the operation.",
            "The optimization avoids unnecessary cleanup of reconciliation boundary structures by short-circuiting the operation when the list is empty or not large enough to justify the cost.",
            "The optimization avoids unnecessary cleanup of reconciliation boundary structures by short-circuiting the process when the list is empty or not large enough to justify the operation.",
            "The optimization avoids unnecessary cleanup of reconciliation boundary structures by short-circuiting the process when the list is empty or not large enough to justify the operation.",
            "The optimization avoids unnecessary cleanup of reconciliation boundary structures by short-circuiting the process when the list is empty or not large enough to justify the operation."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary cleanup of reconciliation boundary structures by short-circuiting the process when the list is empty or not large enough to justify the operation.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "gem5-aladdin",
        "hash": "be62a142cf0513bfa69f4837565889dcb447fae0",
        "author": "Ani Udipi",
        "date": "2013-11-01T11:56:17-04:00",
        "message": "mem: Schedule time for DRAM event taking tRAS into account\n\nThis patch changes the time the controller is woken up to take the\nnext scheduling decisions. tRAS is now handled in estimateLatency and\ndoDRAMAccess and we do not need to worry about it at scheduling\ntime. The earliest we need to wake up is to do a pre-charge, row\naccess and column access before the bus becomes free for use.",
        "modified_files_count": 1,
        "modified_files": [
            "src/mem/simple_dram.cc"
        ],
        "github_commit_url": "https://github.com/harvard-acc/gem5-aladdin/commit/be62a142cf0513bfa69f4837565889dcb447fae0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SimpleDRAM::doDRAMAccess"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves adjusting the scheduling logic to account for tRAS latency more efficiently by integrating it into `estimateLatency` and `doDRAMAccess`, reducing unnecessary wake-ups.",
            "The optimization strategy involves deferring the handling of tRAS latency to specific functions (`estimateLatency` and `doDRAMAccess`) to reduce unnecessary wake-ups of the DRAM controller during scheduling.",
            "The optimization strategy involves adjusting the scheduling logic to account for tRAS latency more efficiently by integrating it into `estimateLatency` and `doDRAMAccess`, reducing unnecessary wake-ups.",
            "The optimization strategy involves adjusting the scheduling logic to account for tRAS latency more efficiently by integrating it into `estimateLatency` and `doDRAMAccess`, reducing unnecessary wake-ups.",
            "The optimization strategy involves adjusting the scheduling logic to account for tRAS latency more efficiently by integrating it into `estimateLatency` and `doDRAMAccess`, reducing unnecessary wake-ups."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adjusting the scheduling logic to account for tRAS latency more efficiently by integrating it into `estimateLatency` and `doDRAMAccess`, reducing unnecessary wake-ups.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "revng",
        "hash": "68fca82f46bea2688259f87a2691fea27da5f882",
        "author": "Pietro Fezzardi",
        "date": "2023-10-09T10:34:41+02:00",
        "message": "RestructureCFG: call updateNodes more efficiently\n\nBefore this commit it was called on all metaregions, now only on parent\nmetaregions.",
        "modified_files_count": 1,
        "modified_files": [
            "lib/RestructureCFG/RestructureCFG.cpp"
        ],
        "github_commit_url": "https://github.com/revng/revng/commit/68fca82f46bea2688259f87a2691fea27da5f882",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "restructureCFG"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves reducing the number of calls to `updateNodes` by invoking it only on parent metaregions instead of all metaregions.",
            "The optimization strategy involved reducing the number of calls to `updateNodes` by invoking it only on parent metaregions instead of all metaregions.",
            "The optimization strategy involves reducing the number of calls to `updateNodes` by invoking it only on parent metaregions instead of all metaregions.",
            "The optimization strategy involves reducing the number of calls to `updateNodes` by invoking it only on parent metaregions instead of all metaregions.",
            "The optimization strategy involves reducing the number of calls to `updateNodes` by invoking it only on parent metaregions instead of all metaregions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves reducing the number of calls to `updateNodes` by invoking it only on parent metaregions instead of all metaregions.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "f68e14805085972b4e0b0ab684af37f713b9c262",
        "author": "Michael S. Tsirkin",
        "date": "2009-09-22T07:17:42-07:00",
        "message": "mm: reduce atomic use on use_mm fast path\n\nWhen the mm being switched to matches the active mm, we don't need to\nincrement and then drop the mm count.  In a simple benchmark this happens\nin about 50% of time.  Making that conditional reduces contention on that\ncacheline on SMP systems.\n\nAcked-by: Andrea Arcangeli <aarcange@redhat.com>\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "modified_files_count": 1,
        "modified_files": [
            "mm/mmu_context.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/f68e14805085972b4e0b0ab684af37f713b9c262",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "use_mm"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization avoids unnecessary atomic operations by conditionally incrementing and dropping the mm count only when the mm being switched to differs from the active mm, reducing cacheline contention on SMP systems.",
            "The optimization strategy conditionally avoids incrementing and dropping the mm count when the mm being switched to matches the active mm, reducing cacheline contention on SMP systems.",
            "The optimization reduces atomic operations by conditionally skipping unnecessary mm count increments when the active mm matches the target mm.",
            "The optimization strategy conditionally avoids incrementing and dropping the mm count when the mm being switched to matches the active mm, reducing cacheline contention on SMP systems.",
            "The optimization strategy conditionally avoids incrementing and dropping the mm count when the mm being switched to matches the active mm, reducing contention on the cacheline in SMP systems."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy conditionally avoids incrementing and dropping the mm count when the mm being switched to matches the active mm, reducing cacheline contention on SMP systems.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ceph",
        "hash": "fcff420a580d7f24cdd81aebf6c3b01c5f8785f7",
        "author": "lightmelodies",
        "date": "2023-11-26T06:07:27+00:00",
        "message": "rgw: optimize gc chain size calculation\n\nReduce time complexity of gc chain size calculation from O(n^2) to O(n).\n\nSigned-off-by: Wei Wang <lightmelodies@outlook.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/rgw/driver/rados/rgw_gc.cc"
        ],
        "github_commit_url": "https://github.com/ceph/ceph/commit/fcff420a580d7f24cdd81aebf6c3b01c5f8785f7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "RGWGC::send_split_chain"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used was to reduce the time complexity of the gc chain size calculation from O(n^2) to O(n) by improving the algorithm's efficiency.",
            "The optimization strategy used was to reduce the time complexity of the gc chain size calculation from O(n^2) to O(n) by improving the algorithm's efficiency.",
            "The optimization strategy reduced the time complexity of the gc chain size calculation by replacing a nested loop structure with a single loop and using a more efficient data structure for lookups.",
            "The optimization strategy used was to reduce the time complexity of the gc chain size calculation from O(n^2) to O(n) by improving the algorithm's efficiency.",
            "The optimization strategy used was to reduce the time complexity of the gc chain size calculation from O(n^2) to O(n) by improving the algorithm's efficiency."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was to reduce the time complexity of the gc chain size calculation from O(n^2) to O(n) by improving the algorithm's efficiency.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "supercollider",
        "hash": "f0484bdd723a29917b7f19ec8e2715f397d76f81",
        "author": "Tim Blechmann",
        "date": "2010-11-28T14:12:17+01:00",
        "message": "sc plugin interface: increase speed of buffer_alloc_read_channels\n\nreading multiple frames at once from libsndfile seems to be way more\nefficient than reading one by one. quick benchmarks suggest a speedup of\nmore than 10\n\nSigned-off-by: Tim Blechmann <tim@klingt.org>",
        "modified_files_count": 1,
        "modified_files": [
            "source/sc/sc_plugin_interface.cpp"
        ],
        "github_commit_url": "https://github.com/supercollider/supercollider/commit/f0484bdd723a29917b7f19ec8e2715f397d76f81",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sc_plugin_interface::buffer_alloc_read_channels"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reading multiple frames at once from libsndfile instead of one by one to significantly improve efficiency.",
            "The optimization strategy involved reading multiple frames at once from libsndfile instead of one by one to significantly improve efficiency.",
            "The optimization strategy involved reading multiple frames at once from libsndfile instead of one frame at a time to significantly reduce overhead and improve efficiency.",
            "The optimization strategy involved reading multiple frames at once from libsndfile instead of one by one to significantly reduce overhead and improve efficiency.",
            "The optimization strategy involved reading multiple frames at once from libsndfile instead of one by one to significantly reduce overhead and improve efficiency."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reading multiple frames at once from libsndfile instead of one by one to significantly reduce overhead and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ompi",
        "hash": "d5d16c21623c97a561ae818eb9c9db4a0c3eaf05",
        "author": "George Bosilca",
        "date": "2006-01-19T23:57:03+00:00",
        "message": "A slighy faster version. The if outside the for not inside.\n\nThis commit was SVN r8761.",
        "modified_files_count": 1,
        "modified_files": [
            "ompi/class/ompi_free_list.c"
        ],
        "github_commit_url": "https://github.com/open-mpi/ompi/commit/d5d16c21623c97a561ae818eb9c9db4a0c3eaf05",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ompi_free_list_grow"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved moving a conditional check outside of a loop to avoid redundant evaluations during each iteration.",
            "The optimization strategy involved moving a conditional check outside of a loop to reduce redundant evaluations.",
            "The optimization strategy involved moving a conditional check outside of a loop to avoid redundant evaluations during each iteration.",
            "The optimization strategy involved moving a conditional check outside of a loop to avoid redundant evaluations during each iteration.",
            "The optimization strategy involved moving a conditional check outside of a loop to avoid redundant evaluations during each iteration."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved moving a conditional check outside of a loop to avoid redundant evaluations during each iteration.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "mongoose-os",
        "hash": "12c07edc9a4d32bd71b3dc263ac9e6810f1ab25e",
        "author": "Deomid Ryabkov",
        "date": "2019-10-29T22:00:41+00:00",
        "message": "Do not render UDP log message if UDP logging is not enabled\n\nMinor perf optimization\n\nCL: Do not render UDP log message if UDP logging is not enabled; minor perf optimization",
        "modified_files_count": 1,
        "modified_files": [
            "src/mgos_debug.c"
        ],
        "github_commit_url": "https://github.com/cesanta/mongoose-os/commit/12c07edc9a4d32bd71b3dc263ac9e6810f1ab25e",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "mgos_debug_write"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids rendering UDP log messages when UDP logging is not enabled, reducing unnecessary computation.",
            "The optimization avoids rendering UDP log messages when UDP logging is not enabled, reducing unnecessary computation.",
            "The optimization avoids unnecessary rendering of UDP log messages by checking if UDP logging is enabled before processing.",
            "The optimization avoids unnecessary rendering of UDP log messages by checking if UDP logging is enabled before proceeding.",
            "The optimization avoids unnecessary rendering of UDP log messages by checking if UDP logging is enabled before processing."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary rendering of UDP log messages by checking if UDP logging is enabled before processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "Halide",
        "hash": "fca8d9606145d0c42caac1954c37d86fa291fea0",
        "author": "Marcos Slomp",
        "date": "2023-07-28T09:55:19-07:00",
        "message": "Making Metal code-gen a bit faster (#7720)\n\nremoving redundant print_expr() call",
        "modified_files_count": 1,
        "modified_files": [
            "src/CodeGen_Metal_Dev.cpp"
        ],
        "github_commit_url": "https://github.com/halide/Halide/commit/fca8d9606145d0c42caac1954c37d86fa291fea0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CodeGen_Metal_Dev::CodeGen_Metal_C::visit"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing a redundant function call to improve performance by eliminating unnecessary computations.",
            "The optimization strategy involved removing a redundant function call to improve performance by eliminating unnecessary computations.",
            "The optimization strategy involved removing a redundant function call to improve performance by eliminating unnecessary computations.",
            "The optimization strategy involved removing a redundant function call to improve performance by eliminating unnecessary computation.",
            "The optimization strategy involved removing a redundant function call to improve performance by eliminating unnecessary computations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved removing a redundant function call to improve performance by eliminating unnecessary computations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "4a278393bda27e62e2e08fb4d000350c0ce83578",
        "author": "Michael Cahill",
        "date": "2016-04-14T13:31:48+10:00",
        "message": "WT-2546 Default to \"fast\" statistics in wtperf.",
        "modified_files_count": 1,
        "modified_files": [
            "bench/wtperf/wtperf.c"
        ],
        "github_commit_url": "https://github.com/wiredtiger/wiredtiger/commit/4a278393bda27e62e2e08fb4d000350c0ce83578",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "main"
        ],
        "is_opt_ds": "false",
        "is_opt_ds_simple": "true",
        "repository_name": "wiredtiger",
        "optimization_summary": [
            "The optimization strategy involved changing the default statistics configuration to \"fast\" mode in wtperf to reduce overhead.",
            "The optimization strategy involved changing the default statistics configuration to \"fast\" mode in wtperf to reduce overhead.",
            "The optimization strategy involved changing the default statistics configuration to \"fast\" mode in wtperf to reduce overhead and improve performance during benchmarking.",
            "The optimization strategy involved changing the default statistics configuration to \"fast\" mode in wtperf to reduce overhead.",
            "The optimization strategy involved changing the default statistics configuration to \"fast\" mode in wtperf to reduce overhead and improve performance during benchmarking."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved changing the default statistics configuration to \"fast\" mode in wtperf to reduce overhead.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "pango",
        "hash": "7721b0bed57038b342655220ad9bc32f4599f174",
        "author": "Timm Bäder",
        "date": "2017-10-27T16:29:14-04:00",
        "message": "PangoLayout: Optimize pango_layout_get_baseline\n\nThe baseline is the baseline of the first line of text in the layout, so\nwe can simply _get_extents_internal and use the extents of the first\nline we get from that.\n\nThis is not a perfect solution (e.g. gtk+ calls pango_layout_get_extents\nbefore a pango_layout_get_baseline call and the former calls\nget_extents_internal anyway, so we compute the extents twice...) but it\nimproves the situation pointed out by the comment in\npango_layout_get_baseline.\n\nhttps://bugzilla.gnome.org/show_bug.cgi?id=788643",
        "modified_files_count": 1,
        "modified_files": [
            "pango/pango-layout.c"
        ],
        "github_commit_url": "https://github.com/GNOME/pango/commit/7721b0bed57038b342655220ad9bc32f4599f174",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "pango_layout_get_baseline"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy avoids redundant computation by directly using the extents of the first line from `_get_extents_internal` instead of recalculating the baseline.",
            "The optimization strategy avoids redundant computation by directly using the extents of the first line from `_get_extents_internal` instead of recalculating the baseline separately.",
            "The optimization strategy avoids redundant computation by directly using the extents of the first line from `_get_extents_internal` instead of recalculating the baseline separately.",
            "The optimization strategy avoids redundant computation by directly using the extents of the first line from `_get_extents_internal` instead of recalculating the baseline separately.",
            "The optimization strategy used is to directly retrieve the baseline from the first line's extents instead of recalculating it, reducing redundant computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy avoids redundant computation by directly using the extents of the first line from `_get_extents_internal` instead of recalculating the baseline separately.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "4dcf078f094d436866ef793aa25c96fba85ac8d0",
        "author": "Richard Henderson",
        "date": "2020-02-03T11:33:11+11:00",
        "message": "target/ppc: Use probe_write for DCBZ\n\nUsing probe_write instead of tlb_vaddr_to_host means that we\nprocess watchpoints and notdirty pages more efficiently.\n\nSigned-off-by: Richard Henderson <richard.henderson@linaro.org>\nMessage-Id: <20200129235040.24022-5-richard.henderson@linaro.org>\nTested-by: Howard Spoelstra <hsp.cat7@gmail.com>\nSigned-off-by: David Gibson <david@gibson.dropbear.id.au>",
        "modified_files_count": 1,
        "modified_files": [
            "target/ppc/mem_helper.c"
        ],
        "github_commit_url": "https://github.com/eurecom-s3/symqemu/commit/4dcf078f094d436866ef793aa25c96fba85ac8d0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dcbz_common"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "symqemu",
        "optimization_summary": [
            "The optimization strategy replaces `tlb_vaddr_to_host` with `probe_write` to improve the efficiency of handling watchpoints and notdirty pages in the PowerPC target.",
            "The optimization strategy replaces a function call with a more efficient alternative to handle watchpoints and notdirty pages.",
            "The optimization strategy replaces `tlb_vaddr_to_host` with `probe_write` to improve the efficiency of handling watchpoints and notdirty pages in the `dcbz_common` function.",
            "The optimization strategy replaces `tlb_vaddr_to_host` with `probe_write` to improve the efficiency of handling watchpoints and notdirty pages in the `dcbz_common` function.",
            "The optimization strategy replaced a function call with a more efficient alternative to improve handling of watchpoints and notdirty pages."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaces `tlb_vaddr_to_host` with `probe_write` to improve the efficiency of handling watchpoints and notdirty pages in the `dcbz_common` function.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ImageMagick6",
        "hash": "0132164f33ea82daf732f3923c2fb141cb834dcc",
        "author": "Cristy",
        "date": "2021-07-25T20:32:32-04:00",
        "message": "reduce memory moves",
        "modified_files_count": 1,
        "modified_files": [
            "magick/histogram.c"
        ],
        "github_commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/0132164f33ea82daf732f3923c2fb141cb834dcc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CheckImageColors"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing memory moves by directly manipulating image data in place rather than creating intermediate copies.",
            "The optimization strategy reduces memory moves by reorganizing how pixel data is accessed and processed in the histogram computation.",
            "The optimization strategy involved reducing memory moves by restructuring how pixel data is accessed and processed in the CheckImageColors function.",
            "The optimization strategy involved restructuring the code to minimize unnecessary memory operations by directly accessing data in place.",
            "The optimization strategy reduces memory moves by reordering operations to minimize data copying."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing memory moves by directly manipulating image data in place rather than creating intermediate copies.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "omr",
        "hash": "7198a5c9ad23a63b924752089034375a8a24a04d",
        "author": "Nicholas Coughlin",
        "date": "2017-11-07T12:05:07-05:00",
        "message": "Disable recomp in MimicInterpreterFrameShape\n\nFull speed debug compilations, implemented\nusing MimicInterpreterFrameShape, must use\nthe no-opt optimization level. Therefore,\nthey do not support recompilations.\n\nThis change disables recompilations for\nany methods compiled in such a configuration.\n\nSigned-off-by: Nicholas Coughlin <cnic@ca.ibm.com>",
        "modified_files_count": 1,
        "modified_files": [
            "compiler/control/OMROptions.cpp"
        ],
        "github_commit_url": "https://github.com/eclipse-omr/omr/commit/7198a5c9ad23a63b924752089034375a8a24a04d",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy disables recompilations for methods compiled with the no-opt optimization level in MimicInterpreterFrameShape to improve performance in full-speed debug compilations.",
            "The optimization strategy disables recompilations for methods compiled with the no-opt optimization level in MimicInterpreterFrameShape to improve performance in full-speed debug compilations.",
            "The optimization strategy disables recompilations for methods compiled with the no-opt optimization level in MimicInterpreterFrameShape to improve performance in full-speed debug compilations.",
            "The optimization strategy disables recompilations for methods compiled with the no-opt optimization level in MimicInterpreterFrameShape to improve performance in full-speed debug compilations.",
            "The optimization strategy disables recompilations for methods compiled with the no-opt optimization level in MimicInterpreterFrameShape to improve performance in full-speed debug compilations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy disables recompilations for methods compiled with the no-opt optimization level in MimicInterpreterFrameShape to improve performance in full-speed debug compilations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "simple_lmk",
        "hash": "7d06955b377b9098416f847426543d644c8fafae",
        "author": "Sultan Alsawaf",
        "date": "2023-05-05T16:46:22-07:00",
        "message": "mm: Adjust tsk_is_oom_victim() for Simple LMK\n\nThe page allocator uses tsk_is_oom_victim() to determine when to\nfast-path memory allocations in order to get an allocating process out\nof the page allocator and into do_exit() quickly. Unfortunately,\ntsk_is_oom_victim()'s check to see if a process is killed for OOM\npurposes is to look for the presence of an OOM reaper artifact that only\nthe OOM killer sets. This means that for processes killed by Simple LMK,\nthere is no fast-pathing done in the page allocator to get them to die\nfaster.\n\nRemedy this by changing tsk_is_oom_victim() to look for the existence of\nthe TIF_MEMDIE flag, which Simple LMK sets for its victims.\n\nSigned-off-by: Sultan Alsawaf <sultan@kerneltoast.com>",
        "modified_files_count": 1,
        "modified_files": [
            "include/linux/oom.h"
        ],
        "github_commit_url": "https://github.com/kerneltoast/simple_lmk/commit/7d06955b377b9098416f847426543d644c8fafae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tsk_is_oom_victim"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy modifies the condition in `tsk_is_oom_victim()` to check for the `TIF_MEMDIE` flag instead of an OOM reaper artifact, enabling faster termination of processes killed by Simple LMK.",
            "The optimization strategy involves modifying the `tsk_is_oom_victim()` function to check for the `TIF_MEMDIE` flag instead of relying solely on an OOM reaper artifact, enabling faster termination of processes killed by Simple LMK.",
            "The optimization strategy involves modifying the condition in `tsk_is_oom_victim()` to check for the `TIF_MEMDIE` flag instead of an OOM reaper artifact, enabling faster termination of processes killed by Simple LMK.",
            "The optimization strategy modifies the condition in `tsk_is_oom_victim()` to check for the `TIF_MEMDIE` flag instead of an OOM reaper artifact, enabling faster termination of processes killed by Simple LMK.",
            "The optimization strategy modifies the condition in `tsk_is_oom_victim()` to check for the `TIF_MEMDIE` flag instead of an OOM reaper artifact, enabling faster termination of processes killed by Simple LMK."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy modifies the condition in `tsk_is_oom_victim()` to check for the `TIF_MEMDIE` flag instead of an OOM reaper artifact, enabling faster termination of processes killed by Simple LMK.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ustore",
        "hash": "452ae7907007b99f006c7f21d9579617ef4ae685",
        "author": "Ashot Vardanian",
        "date": "2022-12-22T19:35:03+04:00",
        "message": "Refactor: Reusing transaction state for efficiency",
        "modified_files_count": 1,
        "modified_files": [
            "tests/stress_serializable_transactions.cpp"
        ],
        "github_commit_url": "https://github.com/unum-cloud/ustore/commit/452ae7907007b99f006c7f21d9579617ef4ae685",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "serializable_writes"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reusing transaction states to minimize redundant initializations and improve efficiency.",
            "The optimization strategy involved reusing transaction states to minimize redundant initializations and improve efficiency.",
            "The optimization strategy involved reusing transaction states to minimize redundant initializations and improve efficiency.",
            "The optimization strategy involved reusing transaction states to minimize redundant initializations and improve efficiency.",
            "The optimization strategy involved reusing transaction states to minimize redundant initializations and improve efficiency."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reusing transaction states to minimize redundant initializations and improve efficiency.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "ClickHouse",
        "hash": "7eacea4c518a46664f6f388143bcd74c9c0c9e71",
        "author": "Nikolai Kochetov",
        "date": "2023-11-08T17:28:57+01:00",
        "message": "Update src/Processors/QueryPlan/Optimizations/useDataParallelAggregation.cpp\n\nCo-authored-by: Nikita Taranov <nikita.taranov@clickhouse.com>",
        "modified_files_count": 1,
        "modified_files": [
            "src/Processors/QueryPlan/Optimizations/useDataParallelAggregation.cpp"
        ],
        "github_commit_url": "https://github.com/ClickHouse/ClickHouse/commit/7eacea4c518a46664f6f388143bcd74c9c0c9e71",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "isPartitionKeySuitsGroupByKey"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves refining the logic for determining whether a partition key suits a group-by key to avoid unnecessary computations.",
            "The optimization strategy involves refining the logic for determining whether a partition key suits a group-by key to avoid unnecessary computations.",
            "The optimization strategy involves refining the logic for determining whether a partition key suits a group-by key to improve decision-making efficiency.",
            "The optimization strategy involves refining the logic for determining if a partition key suits a group-by key to reduce unnecessary computations.",
            "The optimization strategy involves refining the logic for determining if a partition key suits a group-by key to reduce unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves refining the logic for determining if a partition key suits a group-by key to reduce unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "atomspace",
        "hash": "d19b646bca8cc48e0a614f2ff5d152fc78013e90",
        "author": "Linas Vepstas",
        "date": "2020-02-12T13:57:02-06:00",
        "message": "Optimize searches for parent/child type relationships.\n\nThe partial order is always strict...",
        "modified_files_count": 1,
        "modified_files": [
            "opencog/atoms/atom_types/NameServer.h"
        ],
        "github_commit_url": "https://github.com/opencog/atomspace/commit/d19b646bca8cc48e0a614f2ff5d152fc78013e90",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "protoatom"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves restructuring the search logic for parent/child type relationships to leverage strict partial order properties, reducing unnecessary comparisons.",
            "The optimization strategy involves restructuring the search logic for parent/child type relationships to leverage strict partial order properties, reducing unnecessary checks.",
            "The optimization strategy involves improving the efficiency of searches for parent/child type relationships by leveraging the strictness of the partial order.",
            "The optimization strategy involves restructuring the search logic for parent/child type relationships to leverage strict partial order properties, reducing unnecessary checks.",
            "The optimization strategy involves restructuring the search logic for parent/child type relationships to leverage strict partial order properties, reducing unnecessary comparisons."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves restructuring the search logic for parent/child type relationships to leverage strict partial order properties, reducing unnecessary comparisons.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "silifuzz",
        "hash": "5875d5deab8d2f0419a376628a66782959546ea1",
        "author": "Doug Kwan",
        "date": "2024-03-28T10:49:18-07:00",
        "message": "#silifuzz Fix a minor performance issue in crc32c computation.\n\nWe should not do byte-wise CRC update at the end of input if remaining input size is a multiple of sizeof(uint64_t).\n\nPiperOrigin-RevId: 619989373",
        "modified_files_count": 1,
        "modified_files": [
            "util/crc32c.cc"
        ],
        "github_commit_url": "https://github.com/google/silifuzz/commit/5875d5deab8d2f0419a376628a66782959546ea1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "crc32c_accelerated_impl"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary byte-wise CRC updates by checking if the remaining input size is a multiple of sizeof(uint64_t).",
            "The optimization avoids unnecessary byte-wise CRC updates by checking if the remaining input size is a multiple of `sizeof(uint64_t)` before proceeding.",
            "The optimization avoids byte-wise CRC updates at the end of input when the remaining size is a multiple of sizeof(uint64_t), improving efficiency by leveraging aligned data processing.",
            "The optimization avoids unnecessary byte-wise CRC updates by checking if the remaining input size is a multiple of sizeof(uint64_t).",
            "The optimization avoids unnecessary byte-wise CRC updates by checking if the remaining input size is a multiple of sizeof(uint64_t)."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization avoids unnecessary byte-wise CRC updates by checking if the remaining input size is a multiple of sizeof(uint64_t).",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "duckstation",
        "hash": "4e802e90caa14d95ea56a68faabcd95d2c7702f1",
        "author": "Connor McLaughlin",
        "date": "2021-01-20T12:32:37+10:00",
        "message": "SPU: Move voice key off/on outside sample loop\n\nShould be a very tiny performance boost with no difference in behaviour.",
        "modified_files_count": 1,
        "modified_files": [
            "src/core/spu.cpp"
        ],
        "github_commit_url": "https://github.com/stenzek/duckstation/commit/4e802e90caa14d95ea56a68faabcd95d2c7702f1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SPU::Execute"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization moves the voice key off/on operations outside of the sample loop to reduce redundant checks and improve performance.",
            "The optimization moves the voice key off/on operations outside of the sample loop to reduce redundant checks and improve performance.",
            "The optimization moves the voice key off/on operations outside of the sample loop to reduce redundant checks and improve performance.",
            "The optimization strategy moves the voice key off/on operations outside of the sample loop to reduce redundant checks and improve performance.",
            "The optimization strategy moves the voice key off/on operations outside of the sample loop to reduce redundant checks and improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization moves the voice key off/on operations outside of the sample loop to reduce redundant checks and improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "47c0846231b7548dfba49dddddf1639751b871b4",
        "author": "James Harrison",
        "date": "2021-04-12T14:03:56+00:00",
        "message": "MB-45236: Only re-check eviction thresholds if they may have changed\n\nIf a StoredValue it not eligible for eviction, it will not be tracked\nby the MFU or age histograms. If the histograms have not been changed,\nthe MFU and age thresholds definitely do not need recalculating.\n\nThis reduces time wasted iterating histograms. This would be most\nnotable in large value eviction buckets where many ineligible (e.g.,\nnon-resident) items may be visited before `learningPopulation` SVs have\nbeen visited.\n\nLocal profiling on Mid-2016 MacBook Pro (8 X 2500 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x4)\n  L1 Instruction 32 KiB (x4)\n  L2 Unified 256 KiB (x4)\n  L3 Unified 6144 KiB (x1)\n\nUnder set-only workload from pillowfight, recorded for two minutes after first\npager run.\n\nBefore:\n1.79 min  100.0%\t6.00 ms\t \tPagingVisitor::visitBucket(std::__1::shared_ptr<VBucket> const&)\n1.62 min   90.6%\t60.00 ms\t \t     ItemEviction::getThresholds(double, double) const\n\nAfter:\n1.75 min  100.0%\t40.00 ms\t \tPagingVisitor::visitBucket(std::__1::shared_ptr<VBucket> const&)\n4.40 s    4.1%\t3.00 ms\t \t     ItemEviction::getThresholds(double, double) const\n\nA much smaller proportion of the time spent in visitBucket is spent\nrecalculating thresholds. This difference is repeatable.\nThe peak rate of evictions/s over this period increased from (roughly)\n25k to 35k.\n\nAdditionally, while far more indirect, the restore throughput test\n\ntools_restore_400M_rift.test\n\nImproves from ~72 MB/s to ~150 MB/s with this patch.\n\nThis perf test is a good representation of a heavy bulk load.\n\nChange-Id: Ibc1210a0ebb682dd1119fd37de621492e6c65078\nReviewed-on: http://review.couchbase.org/c/kv_engine/+/150734\nReviewed-by: Dave Rigby <daver@couchbase.com>\nReviewed-by: Richard de Mellow <richard.demellow@couchbase.com>\nTested-by: Build Bot <build@couchbase.com>",
        "modified_files_count": 1,
        "modified_files": [
            "engines/ep/src/paging_visitor.cc"
        ],
        "github_commit_url": "https://github.com/couchbase/kv_engine/commit/47c0846231b7548dfba49dddddf1639751b871b4",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "PagingVisitor::visit"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "kv_engine",
        "optimization_summary": [
            "The optimization avoids recalculating eviction thresholds unless the underlying histograms have changed, reducing unnecessary computations.",
            "The optimization avoids recalculating eviction thresholds unless the underlying histograms have changed, reducing unnecessary computations.",
            "The optimization avoids recalculating eviction thresholds unless the underlying histograms have changed, reducing unnecessary computations.",
            "The optimization avoids recalculating eviction thresholds unless the underlying histograms have changed, reducing unnecessary computations.",
            "The optimization avoids recalculating eviction thresholds unless the underlying histograms have changed, reducing unnecessary computations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids recalculating eviction thresholds unless the underlying histograms have changed, reducing unnecessary computations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "fastbasic",
        "hash": "721036c954f346c71fef730230e273301ec6ac54",
        "author": "Daniel Serpell",
        "date": "2018-03-01T22:53:45-03:00",
        "message": "Adds an optimizer pass to replace A <= x with A < x+1.",
        "modified_files_count": 1,
        "modified_files": [
            "src/compiler/peephole.cc"
        ],
        "github_commit_url": "https://github.com/dmsc/fastbasic/commit/721036c954f346c71fef730230e273301ec6ac54",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "peephole"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaces comparisons of the form \"A <= x\" with \"A < x+1\" to potentially improve performance by simplifying or aligning better with low-level instruction handling.",
            "The optimization strategy replaces comparisons of the form \"A <= x\" with \"A < x+1\" to potentially improve performance by simplifying or aligning better with low-level instruction handling.",
            "The optimization strategy replaces comparisons of the form \"A <= x\" with \"A < x+1\" to potentially improve performance by simplifying or aligning better with low-level instruction handling.",
            "The optimization strategy replaces comparisons of the form \"A <= x\" with \"A < x+1\" to potentially improve performance by simplifying or aligning better with low-level instruction handling.",
            "The optimization strategy replaces comparisons of the form \"A <= x\" with \"A < x+1\" to potentially improve performance by simplifying or aligning better with low-level instruction handling."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces comparisons of the form \"A <= x\" with \"A < x+1\" to potentially improve performance by simplifying or aligning better with low-level instruction handling.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "sycl",
        "hash": "2738ede6b2e8de6b09afadc7f09d75b18491a629",
        "author": "Matt Arsenault",
        "date": "2017-08-02T17:15:01+00:00",
        "message": "AMDGPU: Restore using MRI to find highest used regs\n\nIf there are no calls, this is a faster path than\nsearching the entire program for calls.\n\nThis was supposed to be left in r309781.\nFixes unused variable warning.\n\nllvm-svn: 309832",
        "modified_files_count": 1,
        "modified_files": [
            "llvm/lib/Target/AMDGPU/AMDGPUAsmPrinter.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/2738ede6b2e8de6b09afadc7f09d75b18491a629",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AMDGPUAsmPrinter::analyzeResourceUsage"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves using MRI (Machine Register Information) to find the highest used registers, which is faster than searching the entire program for calls when there are no calls present.",
            "The optimization strategy involves using MRI (Machine Register Information) to find the highest used registers, which is faster than searching the entire program for calls when there are no calls present.",
            "The optimization strategy involves using MRI (Machine Register Information) to find the highest used registers, which is faster than searching the entire program for calls when there are no calls present.",
            "The optimization strategy involves using MRI (Machine Register Information) to find the highest used registers, which is faster than searching the entire program for calls when there are no calls present.",
            "The optimization strategy involves using MRI to find the highest used registers, which is faster than searching the entire program for calls when there are no calls."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves using MRI (Machine Register Information) to find the highest used registers, which is faster than searching the entire program for calls when there are no calls present.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sparselizard",
        "hash": "280d40b3e06d8bb8ec4af35823802f1823511ad5",
        "author": "Alexandre Halbach",
        "date": "2021-03-08T08:57:42+02:00",
        "message": "minor speedup defineinneroverlapinterfaces",
        "modified_files_count": 1,
        "modified_files": [
            "src/mesh/dtracker.cpp"
        ],
        "github_commit_url": "https://github.com/halbux/sparselizard/commit/280d40b3e06d8bb8ec4af35823802f1823511ad5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dtracker::defineinneroverlapinterfaces"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the function.",
            "The optimization strategy involved replacing a nested loop structure with a more efficient single loop to reduce redundant computations.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the function.",
            "The optimization strategy involved reducing redundant computations by caching and reusing results within the function."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations by caching and reusing results within the function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "BsodSurvivor",
        "hash": "f54bb7743a5e0a0242b3d577a997cab4100c5137",
        "author": "Tobias Grosser",
        "date": "2015-06-26T12:09:28+00:00",
        "message": "Drop divs before adding array-out-of-bounds assumptions\n\nIn case we have modulo operations in the access function (supported since\nr240518), the assumptions generated to ensure array accesses remain within\nbounds can contain existentially quantified dimensions which results in more\ncomplex and more difficult to handle integer sets. As a result LNT's linpack\nbenchmark started to fail due to excessive compile time.\n\nWe now just drop the existentially quantified dimensions. This should be\ngenerally save, but may result in less precise assumptions which may\nconsequently make us fall back to the original (unoptimized) code more often. In\npractice, these cases probably do not appear to often.\n\nI had difficulties to extract a good test case, but fortunately our LNT bots\ncover this one well.\n\nllvm-svn: 240775",
        "modified_files_count": 1,
        "modified_files": [
            "polly/lib/Analysis/ScopInfo.cpp"
        ],
        "github_commit_url": "https://github.com/ykfre/BsodSurvivor/commit/f54bb7743a5e0a0242b3d577a997cab4100c5137",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes existentially quantified dimensions from array-out-of-bounds assumptions to reduce compile-time complexity caused by modulo operations in access functions.",
            "The optimization strategy involves simplifying array-bound assumptions by removing existentially quantified dimensions to reduce compile-time complexity.",
            "The optimization strategy involves simplifying array-out-of-bounds assumptions by dropping existentially quantified dimensions to reduce compile-time complexity.",
            "The optimization strategy removes existentially quantified dimensions from array-out-of-bounds assumptions to reduce compile-time complexity.",
            "The optimization strategy involves simplifying array-out-of-bounds assumptions by dropping existentially quantified dimensions to reduce compile-time complexity."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves simplifying array-out-of-bounds assumptions by dropping existentially quantified dimensions to reduce compile-time complexity.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "e9895752a396c4acb8c2b4ba525c13329d4e9fab",
        "author": "Nikias Bassen",
        "date": "2017-02-01T18:50:00+01:00",
        "message": "bplist: Avoid heap buffer allocation when parsing array/dict/string/data node sizes > 14\n\nThe sizes where effectively parsed by calling parse_uint_node() which\nallocates a node_t (along with plist_data_t) that is immediately freed\nafter retrieving the integer value it holds.\nThis commit changes the code to directly operate on the binary stream\nto 'just' read the size instead, reducing the memory footprint further.",
        "modified_files_count": 1,
        "modified_files": [
            "src/bplist.c"
        ],
        "github_commit_url": "https://github.com/libimobiledevice/libplist/commit/e9895752a396c4acb8c2b4ba525c13329d4e9fab",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "parse_bin_node"
        ],
        "is_opt_ds": "true",
        "is_opt_ds_simple": "true",
        "repository_name": "libplist",
        "optimization_summary": [
            "The optimization avoids unnecessary heap allocation by directly reading the size from the binary stream instead of creating and freeing a temporary node.",
            "The optimization avoids unnecessary heap allocation by directly reading the size from the binary stream instead of creating and freeing an intermediate node.",
            "The optimization avoids unnecessary heap allocation by directly reading the size from the binary stream instead of creating and freeing a temporary node.",
            "The optimization avoids unnecessary heap allocation by directly reading integer values from the binary stream instead of creating and freeing intermediate node structures.",
            "The optimization avoids unnecessary heap allocation by directly reading the size from the binary stream instead of creating and freeing an intermediate node."
        ],
        "is_generic_optimization": [
            true,
            false,
            false,
            true,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary heap allocation by directly reading the size from the binary stream instead of creating and freeing an intermediate node.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cppcheck",
        "hash": "7908421e0e02ddc79258864ec2c22d2541c500df",
        "author": "Daniel Marjamäki",
        "date": "2007-05-26T06:44:28+00:00",
        "message": "Tokenize: Improved the tokenizer. Calculations are done in the tokenizer. sizeof is replaced with numbers.",
        "modified_files_count": 1,
        "modified_files": [
            "tokenize.cpp"
        ],
        "github_commit_url": "https://github.com/danmar/cppcheck/commit/7908421e0e02ddc79258864ec2c22d2541c500df",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Tokenize"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved precomputing `sizeof` values during tokenization to replace them with concrete numbers, reducing runtime calculations.",
            "The optimization strategy involved precomputing `sizeof` values during tokenization to replace them with concrete numbers, reducing runtime calculations.",
            "The optimization strategy involved precomputing `sizeof` values during tokenization to replace them with concrete numbers, reducing runtime calculations.",
            "The optimization strategy involved precomputing `sizeof` values during tokenization to replace them with concrete numbers, reducing runtime calculations.",
            "The optimization strategy involved precomputing `sizeof` values during tokenization to replace them with concrete numbers, reducing runtime calculations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved precomputing `sizeof` values during tokenization to replace them with concrete numbers, reducing runtime calculations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "cmssw",
        "hash": "4011ab4f1fbef2d2025605535408d81f60d0d504",
        "author": "Arnaud",
        "date": "2014-10-17T14:51:42+02:00",
        "message": "MultiThreading without DQMStrore",
        "modified_files_count": 1,
        "modified_files": [
            "DQMOffline/EGamma/src/ElectronDqmAnalyzerBase.cc"
        ],
        "github_commit_url": "https://github.com/cms-sw/cmssw/commit/4011ab4f1fbef2d2025605535408d81f60d0d504",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ElectronDqmAnalyzerBase::endRun"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved removing the dependency on DQMStore in a multi-threaded context to improve performance.",
            "The optimization strategy involved removing the dependency on DQMStore for multi-threading, thereby reducing potential bottlenecks related to thread synchronization.",
            "The optimization strategy involved removing the dependency on DQMStore for multi-threading, thereby reducing potential bottlenecks related to thread synchronization.",
            "The optimization strategy involved removing the dependency on DQMStore for multi-threading, thereby reducing potential bottlenecks related to thread synchronization.",
            "The optimization strategy involved removing the dependency on DQMStore for multi-threading, thereby reducing potential bottlenecks related to thread synchronization."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved removing the dependency on DQMStore for multi-threading, thereby reducing potential bottlenecks related to thread synchronization.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "5e040d4b1a440b832c7b4cf8116eebcdff91909c",
        "author": "Edward Cree",
        "date": "2019-08-08T18:22:29-07:00",
        "message": "sfc: don't score irq moderation points for GRO\n\nWe already scored points when handling the RX event, no-one else does this,\n and looking at the history it appears this was originally meant to only\n score on merges, not on GRO_NORMAL.  Moreover, it gets in the way of\n changing GRO to not immediately pass GRO_NORMAL skbs to the stack.\nPerformance testing with four TCP streams received on a single CPU (where\n throughput was line rate of 9.4Gbps in all tests) showed a 13.7% reduction\n in RX CPU usage (n=6, p=0.03).\n\nSigned-off-by: Edward Cree <ecree@solarflare.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/ethernet/sfc/rx.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/5e040d4b1a440b832c7b4cf8116eebcdff91909c",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "efx_rx_packet_gro"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization avoids unnecessary scoring of IRQ moderation points for GRO_NORMAL packets, reducing CPU overhead in the RX path.",
            "The optimization removes unnecessary scoring of IRQ moderation points for GRO_NORMAL packets, reducing redundant operations during RX event handling.",
            "The optimization removes unnecessary scoring of IRQ moderation points for GRO_NORMAL packets, reducing CPU overhead during RX processing.",
            "The optimization removes unnecessary scoring of IRQ moderation points for GRO_NORMAL packets, reducing redundant operations during RX event handling.",
            "The optimization avoids unnecessary scoring of IRQ moderation points for GRO_NORMAL packets, reducing CPU overhead in the RX path."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization removes unnecessary scoring of IRQ moderation points for GRO_NORMAL packets, reducing CPU overhead during RX processing.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "e6331a321aafcc291a60ceedf4d6b0051a6117ca",
        "author": "Paul Burton",
        "date": "2019-03-25T14:02:12-07:00",
        "message": "MIPS: KVM: Use prandom_u32_max() to generate tlbwr index\n\nEmulation of the tlbwr instruction, which writes a TLB entry to a random\nindex in the TLB, currently uses get_random_bytes() to generate a 4 byte\nrandom number which we then mask to form the index. This is overkill in\na couple of ways:\n\n  - We don't need 4 bytes here since we mask the value to form a 6 bit\n    number anyway, so we waste /dev/random entropy generating 3 random\n    bytes that are unused.\n\n  - We don't need crypto-grade randomness here - the architecture spec\n    allows implementations to use any algorithm & merely encourages that\n    some pseudo-randomness be used rather than a simple counter. The\n    fast prandom_u32() function fits that criteria well.\n\nSo rather than using get_random_bytes() & consuming /dev/random entropy,\nswitch to using the faster prandom_u32_max() which provides what we need\nhere whilst also performing the masking/modulo for us.\n\nSigned-off-by: Paul Burton <paul.burton@mips.com>\nReported-by: George Spelvin <lkml@sdf.org>\nCc: James Hogan <jhogan@kernel.org>\nCc: linux-mips@vger.kernel.org",
        "modified_files_count": 1,
        "modified_files": [
            "arch/mips/kvm/emulate.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/e6331a321aafcc291a60ceedf4d6b0051a6117ca",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "kvm_mips_emul_tlbwr"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy replaced a cryptographically secure random number generator with a faster pseudo-random number generator to reduce overhead and entropy consumption while maintaining sufficient randomness for the use case.",
            "The optimization replaces a cryptographically strong random number generator with a faster pseudo-random generator to reduce overhead in generating random indices.",
            "The optimization strategy replaced a cryptographically secure random number generator with a faster pseudo-random number generator to reduce overhead and entropy consumption.",
            "The optimization strategy replaced a cryptographically secure random number generator with a faster pseudo-random number generator to reduce overhead and entropy consumption.",
            "The optimization replaces a high-entropy random number generator with a faster pseudo-random function to reduce overhead and unnecessary entropy consumption."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaced a cryptographically secure random number generator with a faster pseudo-random number generator to reduce overhead and entropy consumption.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "sycl",
        "hash": "fff033c6536dadb1dbcdd59aa6e563e045874f98",
        "author": "smaslov-intel",
        "date": "2022-05-18T04:36:30-07:00",
        "message": "[SYCL][L0] Optimize the LastCommandEvent of the synchronized queue (#6159)\n\nSigned-off-by: Sergey V Maslov <sergey.v.maslov@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "sycl/plugins/level_zero/pi_level_zero.cpp"
        ],
        "github_commit_url": "https://github.com/triSYCL/sycl/commit/fff033c6536dadb1dbcdd59aa6e563e045874f98",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "piQueueFinish"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant operations by caching and reusing the last command event in a synchronized queue.",
            "The optimization strategy involved restructuring the handling of the last command event in a synchronized queue to reduce unnecessary overhead.",
            "The optimization strategy involved reducing redundant operations by caching and reusing the last command event in a synchronized queue to minimize overhead.",
            "The optimization strategy involved restructuring the handling of the last command event in a synchronized queue to reduce redundant operations and improve efficiency.",
            "The optimization strategy involved reducing redundant operations by caching and reusing the last command event in a synchronized queue."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant operations by caching and reusing the last command event in a synchronized queue.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "133eb8e38b02c6c63a039523fca12737009a6686",
        "author": "Robin Gong",
        "date": "2018-10-12T18:54:02+02:00",
        "message": "spi: imx: use PIO mode if size is small\n\nUse PIO mode instead if size is smaller than fifo size, since\ndma may be less efficient.\n\nSigned-off-by: Robin Gong <yibin.gong@nxp.com>\nSigned-off-by: Mark Brown <broonie@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/spi/spi-imx.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/133eb8e38b02c6c63a039523fca12737009a6686",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "spi_imx_can_dma"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves switching to PIO mode for small data transfers to avoid the overhead of DMA when it is less efficient.",
            "The optimization strategy involves switching to PIO mode for small data transfers instead of using DMA, as DMA may be less efficient for sizes smaller than the FIFO size.",
            "The optimization strategy involves switching to PIO mode for small data transfers to avoid the overhead of DMA when it is less efficient.",
            "The optimization strategy involves switching to PIO mode for small data transfers instead of using DMA, as DMA may be less efficient for sizes smaller than the FIFO size.",
            "The optimization strategy involves switching to PIO mode for small data transfers to improve efficiency over DMA."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves switching to PIO mode for small data transfers to avoid the overhead of DMA when it is less efficient.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "MediaInfoLib",
        "hash": "a20f0935cf31bdeec1527852e8973c7e137115f3",
        "author": "JeromeMartinez",
        "date": "2014-03-01T19:32:26+00:00",
        "message": "+ File reading: Speed improvement of big files, especially for full parsing, with the help of a dedicated reading thread, crash with some MOV files\n\n\ngit-svn-id: svn://svn.code.sf.net/p/mediainfo/code/MediaInfoLib/trunk@6124 45c5ae6f-87cc-4fd0-92ee-e4f023fd80da",
        "modified_files_count": 1,
        "modified_files": [
            "Source/MediaInfo/Multiple/File_Mpeg4_Elements.cpp"
        ],
        "github_commit_url": "https://github.com/MediaArea/MediaInfoLib/commit/a20f0935cf31bdeec1527852e8973c7e137115f3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "File_Mpeg4::mdat_xxxx"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved introducing a dedicated reading thread to improve the speed of reading large files, particularly during full parsing, while addressing crashes with certain MOV files.",
            "The optimization strategy involved introducing a dedicated reading thread to improve the speed of reading large files, particularly during full parsing.",
            "The optimization strategy involved introducing a dedicated reading thread to improve the speed of reading large files, particularly during full parsing, while addressing crashes with certain MOV files.",
            "The optimization strategy involved introducing a dedicated reading thread to improve the speed of reading large files, particularly during full parsing, while addressing crashes with certain MOV files.",
            "The optimization strategy involved introducing a dedicated reading thread to improve the speed of reading large files, particularly during full parsing, while addressing crashes with certain MOV files."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved introducing a dedicated reading thread to improve the speed of reading large files, particularly during full parsing, while addressing crashes with certain MOV files.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "3d7d72a34e05b23e21bafc8bfb861e73c86b31f3",
        "author": "Jack Wang",
        "date": "2023-09-06T23:55:09+02:00",
        "message": "x86/sgx: Break up long non-preemptible delays in sgx_vepc_release()\n\nOn large enclaves we hit the softlockup warning with following call trace:\n\n\txa_erase()\n\tsgx_vepc_release()\n\t__fput()\n\ttask_work_run()\n\tdo_exit()\n\nThe latency issue is similar to the one fixed in:\n\n  8795359e35bc (\"x86/sgx: Silence softlockup detection when releasing large enclaves\")\n\nThe test system has 64GB of enclave memory, and all is assigned to a single VM.\nRelease of 'vepc' takes a longer time and causes long latencies, which triggers\nthe softlockup warning.\n\nAdd cond_resched() to give other tasks a chance to run and reduce\nlatencies, which also avoids the softlockup detector.\n\n[ mingo: Rewrote the changelog. ]\n\nFixes: 540745ddbc70 (\"x86/sgx: Introduce virtual EPC for use by KVM guests\")\nReported-by: Yu Zhang <yu.zhang@ionos.com>\nSigned-off-by: Jack Wang <jinpu.wang@ionos.com>\nSigned-off-by: Ingo Molnar <mingo@kernel.org>\nTested-by: Yu Zhang <yu.zhang@ionos.com>\nReviewed-by: Jarkko Sakkinen <jarkko@kernel.org>\nReviewed-by: Kai Huang <kai.huang@intel.com>\nAcked-by: Haitao Huang <haitao.huang@linux.intel.com>\nCc: stable@vger.kernel.org",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/kernel/cpu/sgx/virt.c"
        ],
        "github_commit_url": "https://github.com/altera-opensource/linux-socfpga/commit/3d7d72a34e05b23e21bafc8bfb861e73c86b31f3",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "sgx_vepc_release"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "linux-socfpga",
        "optimization_summary": [
            "The optimization strategy involves adding `cond_resched()` calls to break up long non-preemptible delays and allow other tasks to run, thereby reducing latencies and avoiding softlockup warnings.",
            "The optimization strategy involves adding `cond_resched()` calls to preemptively yield the CPU during long-running operations, reducing latencies and avoiding softlockup warnings.",
            "The optimization strategy involves adding `cond_resched()` calls to preemptively yield the CPU during long-running operations, reducing latencies and avoiding softlockup warnings.",
            "The optimization strategy involves adding `cond_resched()` calls to reduce latencies and avoid softlockup warnings by allowing other tasks to run during the release of large enclaves.",
            "The optimization strategy involves adding `cond_resched()` calls to break up long non-preemptible delays and allow other tasks to run, reducing latencies and avoiding softlockup warnings."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves adding `cond_resched()` calls to break up long non-preemptible delays and allow other tasks to run, thereby reducing latencies and avoiding softlockup warnings.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "f32c",
        "hash": "738662dbedd55690cff26e171689ce9e40720e47",
        "author": "marko",
        "date": "2011-08-03T00:32:58+00:00",
        "message": "Do a binary search on half words, and then bytes, in word-aligned path\nof strcmp(), for performance increase from 1.34 to 1.37 DMIPS/MHz.\n\n\n\ngit-svn-id: svn+ssh://login.nxlab.fer.hr/fpgasvn/f32c@490 6164e1d0-f123-df11-80f4-0019d13f85ef",
        "modified_files_count": 1,
        "modified_files": [
            "src/include/string.h"
        ],
        "github_commit_url": "https://github.com/f32c/f32c/commit/738662dbedd55690cff26e171689ce9e40720e47",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "strcmp"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy used a binary search on half words and bytes in the word-aligned path of strcmp() to improve performance.",
            "The optimization strategy used a binary search on half words and bytes in the word-aligned path of strcmp() to improve performance.",
            "The optimization strategy used a binary search on half words and then bytes in the word-aligned path of strcmp() to improve performance.",
            "The optimization strategy used a binary search on half words and then bytes in the word-aligned path of strcmp() to improve performance.",
            "The optimization strategy used a binary search on half words and bytes in the word-aligned path of strcmp() to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy used a binary search on half words and bytes in the word-aligned path of strcmp() to improve performance.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_brcm_rpi",
        "hash": "3fe6a63b5dbdc0864f01d3171046af03d34ee747",
        "author": "Dmitry Vyukov",
        "date": "2022-01-05T12:42:32+01:00",
        "message": "tomoyo: Check exceeded quota early in tomoyo_domain_quota_is_ok().\n\n[ Upstream commit 04e57a2d952bbd34bc45744e72be3eecdc344294 ]\n\nIf tomoyo is used in a testing/fuzzing environment in learning mode,\nfor lots of domains the quota will be exceeded and stay exceeded\nfor prolonged periods of time. In such cases it's pointless (and slow)\nto walk the whole acl list again and again just to rediscover that\nthe quota is exceeded. We already have the TOMOYO_DIF_QUOTA_WARNED flag\nthat notes the overflow condition. Check it early to avoid the slowdown.\n\n[penguin-kernel]\nThis patch causes a user visible change that the learning mode will not be\nautomatically resumed after the quota is increased. To resume the learning\nmode, administrator will need to explicitly clear TOMOYO_DIF_QUOTA_WARNED\nflag after increasing the quota. But I think that this change is generally\npreferable, for administrator likely wants to optimize the acl list for\nthat domain before increasing the quota, or that domain likely hits the\nquota again. Therefore, don't try to care to clear TOMOYO_DIF_QUOTA_WARNED\nflag automatically when the quota for that domain changed.\n\nSigned-off-by: Dmitry Vyukov <dvyukov@google.com>\nSigned-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>\nSigned-off-by: Sasha Levin <sashal@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "security/tomoyo/util.c"
        ],
        "github_commit_url": "https://github.com/lineage-rpi/android_kernel_brcm_rpi/commit/3fe6a63b5dbdc0864f01d3171046af03d34ee747",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "tomoyo_read_lock"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves checking the quota exceeded flag early to avoid unnecessary processing of the ACL list when the quota is already known to be exceeded.",
            "The optimization strategy involves checking the quota exceeded flag early to avoid unnecessary ACL list traversal in a testing/fuzzing environment.",
            "The optimization strategy involves checking the quota exceeded flag early to avoid unnecessary processing of the ACL list when the quota is already known to be exceeded.",
            "The optimization strategy involves checking the quota exceeded flag early to avoid unnecessary ACL list traversal in a testing/fuzzing environment.",
            "The optimization strategy involves checking the quota exceeded flag early to avoid unnecessary ACL list traversal in a testing/fuzzing environment."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves checking the quota exceeded flag early to avoid unnecessary ACL list traversal in a testing/fuzzing environment.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libfabric",
        "hash": "92b3dc1cbffdb8e3d6370e6de7584980e3192253",
        "author": "Wei Zhang",
        "date": "2021-05-18T18:16:25+00:00",
        "message": "prov/efa: do not use delivery complete for inject\n\nIf application called fi_inject, it will not receive a completion\nentry for the message, which means we do not need to enable\ndelivery complete for this message either.\n\nThis patch makes the change that delviery complete is disabled\nfor inject, which helps improve performance.\n\nSigned-off-by: Wei Zhang <wzam@amazon.com>",
        "modified_files_count": 1,
        "modified_files": [
            "prov/efa/src/rxr/rxr_msg.c"
        ],
        "github_commit_url": "https://github.com/ofiwg/libfabric/commit/92b3dc1cbffdb8e3d6370e6de7584980e3192253",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "rxr_msg_post_rtm"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization disables the delivery complete feature for inject operations to avoid unnecessary overhead since completions are not required for such messages.",
            "The optimization disables the delivery complete feature for inject operations to avoid unnecessary overhead since completions are not required for such messages.",
            "The optimization disables the delivery complete feature for inject operations to avoid unnecessary overhead since completions are not required for such messages.",
            "The optimization disables the delivery complete feature for inject operations to avoid unnecessary overhead since completions are not required for such messages.",
            "The optimization disables the delivery complete feature for inject operations to avoid unnecessary overhead since completions are not required for such messages."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization disables the delivery complete feature for inject operations to avoid unnecessary overhead since completions are not required for such messages.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "libosmscout",
        "hash": "6b64aa5b7e180cace70d47b837a53265e648b2f4",
        "author": "Lukáš Karas",
        "date": "2018-11-29T07:57:25+01:00",
        "message": "allow to change cache sizes by argument of PerformanceTest",
        "modified_files_count": 1,
        "modified_files": [
            "Demos/src/PerformanceTest.cpp"
        ],
        "github_commit_url": "https://github.com/Framstag/libosmscout/commit/6b64aa5b7e180cace70d47b837a53265e648b2f4",
        "contains_optimization_keyword": true,
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy allows dynamic adjustment of cache sizes via function arguments to improve performance testing flexibility.",
            "The optimization strategy allows dynamic adjustment of cache sizes via arguments to improve performance testing flexibility.",
            "The optimization strategy allows dynamic adjustment of cache sizes via function arguments to improve performance testing flexibility.",
            "The optimization strategy allows dynamic adjustment of cache sizes via function arguments to improve performance testing flexibility.",
            "The optimization strategy allows dynamic adjustment of cache sizes via arguments to improve performance testing flexibility."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy allows dynamic adjustment of cache sizes via function arguments to improve performance testing flexibility.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "llvm-leg",
        "hash": "7c8a26030faad65d49ecd06a4e51344368b79d8d",
        "author": "Nadav Rotem",
        "date": "2013-07-16T22:51:07+00:00",
        "message": "SLPVectorizer: Improve the compile time of isConsecutive by adding a simple constant-gep check before using SCEV.\nThis check does not always work because not all of the GEPs use a constant offset, but it happens often enough to reduce the number of times we use SCEV.\n\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@186465 91177308-0d34-0410-b5e6-96231b3b80d8",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Transforms/Vectorize/SLPVectorizer.cpp"
        ],
        "github_commit_url": "https://github.com/frasercrmck/llvm-leg/commit/7c8a26030faad65d49ecd06a4e51344368b79d8d",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BoUpSLP::isConsecutiveAccess"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy adds a constant GEP check before using SCEV to reduce unnecessary computations in the `isConsecutiveAccess` function, improving compile time.",
            "The optimization strategy adds a constant GEP offset check before using SCEV to reduce unnecessary computations in the `isConsecutiveAccess` function, improving compile time.",
            "The optimization strategy adds a constant-offset GEP check before invoking SCEV to reduce unnecessary computations in the `isConsecutiveAccess` function, improving compile-time performance.",
            "The optimization strategy adds a constant-gep check before using SCEV to reduce the frequency of computationally expensive SCEV calls in the `isConsecutiveAccess` function.",
            "The optimization strategy adds a constant GEP check before using SCEV to reduce unnecessary computations in the `isConsecutiveAccess` function, improving compile time."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy adds a constant GEP check before using SCEV to reduce unnecessary computations in the `isConsecutiveAccess` function, improving compile time.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "OpenOCD",
        "hash": "f4b9a2fc8bbc682e957276a0012199a606c919b0",
        "author": "Rodrigo L. Rosa",
        "date": "2011-06-12T11:18:27+02:00",
        "message": "flash speed improved",
        "modified_files_count": 1,
        "modified_files": [
            "src/target/dsp5680xx.c"
        ],
        "github_commit_url": "https://github.com/arduino/OpenOCD/commit/f4b9a2fc8bbc682e957276a0012199a606c919b0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "dsp5680xx_f_wr"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant memory accesses by caching frequently used data in local variables.",
            "The optimization strategy involved reducing redundant memory accesses by caching frequently used data in local variables.",
            "The optimization strategy involved reducing redundant memory accesses by caching frequently used data in local variables.",
            "The optimization strategy involved reducing redundant memory accesses by caching frequently used data in local variables.",
            "The optimization strategy involved reducing redundant memory accesses by caching frequently used data in local variables."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant memory accesses by caching frequently used data in local variables.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "xbmc",
        "hash": "c3746317e21702a6fc53b13689df69fe78b74d34",
        "author": "Tobias Markus",
        "date": "2024-09-01T11:47:44+02:00",
        "message": "xbmc base: cppcheck performance fixes",
        "modified_files_count": 1,
        "modified_files": [
            "xbmc/Util.cpp"
        ],
        "github_commit_url": "https://github.com/xbmc/xbmc/commit/c3746317e21702a6fc53b13689df69fe78b74d34",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "GetHomePath"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing unnecessary string operations and improving loop efficiency in the `GetHomePath` function.",
            "The optimization strategy involved reducing unnecessary string operations and improving memory handling within the GetHomePath function.",
            "The optimization strategy involved replacing a local variable with a direct return statement to eliminate unnecessary intermediate storage.",
            "The optimization strategy involved reducing unnecessary string operations and improving memory handling within the `GetHomePath` function.",
            "The optimization strategy involved replacing a string concatenation operation with a more efficient direct assignment to reduce unnecessary memory allocations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved reducing unnecessary string operations and improving memory handling within the GetHomePath function.",
        "is_generic_optimization_final": true
    },
    {
        "repository_name": "kmsan",
        "hash": "bb52073645a618ab4d93c8d932fb8faf114c55bc",
        "author": "Magnus Karlsson",
        "date": "2021-03-15T12:04:51-07:00",
        "message": "ice: optimize for XDP_REDIRECT in xsk path\n\nOptimize ice_run_xdp_zc() for the XDP program verdict being\nXDP_REDIRECT in the xsk zero-copy path. This path is only used when\nhaving AF_XDP zero-copy on and in that case most packets will be\ndirected to user space. This provides a little over 100k extra packets\nin throughput on my server when running l2fwd in xdpsock.\n\nSigned-off-by: Magnus Karlsson <magnus.karlsson@intel.com>\nTested-by: George Kuruvinakunnel <george.kuruvinakunnel@intel.com>\nSigned-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/ethernet/intel/ice/ice_xsk.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/bb52073645a618ab4d93c8d932fb8faf114c55bc",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ice_run_xdp_zc"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involves specializing the handling of the XDP_REDIRECT verdict in the AF_XDP zero-copy path to improve throughput for packets directed to user space.",
            "The optimization strategy involves specializing the handling of the XDP_REDIRECT verdict in the AF_XDP zero-copy path to improve throughput for packets directed to user space.",
            "The optimization strategy involves specializing the handling of the XDP_REDIRECT verdict in the AF_XDP zero-copy path to improve throughput for packets directed to user space.",
            "The optimization strategy involves specializing the handling of the XDP_REDIRECT verdict in the AF_XDP zero-copy path to improve throughput for packets directed to user space.",
            "The optimization strategy involves specializing the handling of the XDP_REDIRECT verdict in the AF_XDP zero-copy path to improve throughput for packets directed to user space."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves specializing the handling of the XDP_REDIRECT verdict in the AF_XDP zero-copy path to improve throughput for packets directed to user space.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "kmsan",
        "hash": "fe66483156050f4eb63c4a1988f3b439e6c9ff2a",
        "author": "Davidlohr Bueso",
        "date": "2020-01-29T19:50:44+01:00",
        "message": "Bluetooth: optimize barrier usage for Rmw atomics\n\nUse smp_mb__before_atomic() instead of smp_mb() and avoid the\nunnecessary barrier for non LL/SC architectures, such as x86.\n\nSigned-off-by: Davidlohr Bueso <dbueso@suse.de>\nSigned-off-by: Marcel Holtmann <marcel@holtmann.org>",
        "modified_files_count": 1,
        "modified_files": [
            "net/bluetooth/hidp/core.c"
        ],
        "github_commit_url": "https://github.com/google/kmsan/commit/fe66483156050f4eb63c4a1988f3b439e6c9ff2a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hidp_session_run"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy reduces unnecessary memory barriers by using architecture-specific atomic operations and avoiding redundant barriers on non-LL/SC architectures like x86.",
            "The optimization strategy involves replacing a general memory barrier with a more specific one tailored for atomic operations and eliminating unnecessary barriers on certain architectures.",
            "The optimization strategy replaces a general memory barrier with a more specific one tailored for atomic operations and eliminates unnecessary barriers on certain architectures.",
            "The optimization strategy reduces unnecessary memory barriers by using architecture-specific atomic operations and avoiding redundant barriers on non-LL/SC architectures like x86.",
            "The optimization strategy involves replacing a general memory barrier with a more specific one and eliminating unnecessary barriers for certain architectures to improve performance."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy replaces a general memory barrier with a more specific one tailored for atomic operations and eliminates unnecessary barriers on certain architectures.",
        "is_generic_optimization_final": false
    },
    {
        "hash": "7e0f51cb445be8d3aee80e433ed8da4a33ad0157",
        "author": "Andy Lutomirski",
        "date": "2015-10-07T11:34:06+02:00",
        "message": "x86/uaccess: Add unlikely() to __chk_range_not_ok() failure paths\n\nThis should improve code quality a bit. It also shrinks the kernel text:\n\n Before:\n       text     data      bss       dec    filename\n   21828379  5194760  1277952  28301091    vmlinux\n\n After:\n       text     data      bss       dec    filename\n   21827997  5194760  1277952  28300709    vmlinux\n\n... by 382 bytes.\n\nSigned-off-by: Andy Lutomirski <luto@kernel.org>\nCc: Andy Lutomirski <luto@amacapital.net>\nCc: Borislav Petkov <bp@alien8.de>\nCc: Brian Gerst <brgerst@gmail.com>\nCc: Denys Vlasenko <dvlasenk@redhat.com>\nCc: H. Peter Anvin <hpa@zytor.com>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: linux-kernel@vger.kernel.org\nLink: http://lkml.kernel.org/r/f427b8002d932e5deab9055e0074bb4e7e80ee39.1444091584.git.luto@kernel.org\nSigned-off-by: Ingo Molnar <mingo@kernel.org>",
        "modified_files_count": 1,
        "modified_files": [
            "arch/x86/include/asm/uaccess.h"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/7e0f51cb445be8d3aee80e433ed8da4a33ad0157",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "get_fs"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization strategy involved adding `unlikely()` macros to failure paths in the `__chk_range_not_ok()` function to improve branch prediction and reduce kernel text size.",
            "The optimization strategy involved adding `unlikely()` macros to failure paths in the `__chk_range_not_ok()` function to improve branch prediction and reduce kernel text size.",
            "The optimization strategy involved adding `unlikely()` macros to failure paths in the `__chk_range_not_ok()` function to improve branch prediction and reduce kernel text size.",
            "The optimization strategy involved adding `unlikely()` macros to failure paths in the `__chk_range_not_ok()` function to improve branch prediction and reduce kernel text size.",
            "The optimization strategy involved adding `unlikely()` macros to failure paths in the `__chk_range_not_ok()` function to improve branch prediction and reduce kernel text size."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved adding `unlikely()` macros to failure paths in the `__chk_range_not_ok()` function to improve branch prediction and reduce kernel text size.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "e6e25101fd4addb24f9ec69032175c5d77ea7927",
        "author": "caballa",
        "date": "2022-05-26T22:29:07-06:00",
        "message": "refactor(optimizer): mark function as InaccessibleMemOnly\n\nLLVM may remove all calls to verifier.assume if it is marked as\nReadNone or ReadOnly even if the function is marked as OptimizeNone.\nThe attribute InaccessibleMemOnly should be good enough because it\nensures that the call may only access to memory that is innaccesible\nfrom the IR. Thus, LLVM optimizations should be okay.",
        "modified_files_count": 1,
        "modified_files": [
            "lib/Clam/Optimizer/Optimizer.cc"
        ],
        "github_commit_url": "https://github.com/seahorn/clam/commit/e6e25101fd4addb24f9ec69032175c5d77ea7927",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Optimizer::runOnModule"
        ],
        "is_opt_ds": "false",
        "is_opt_ds_simple": "true",
        "repository_name": "clam",
        "optimization_summary": [
            "The optimization strategy involves marking a function with the `InaccessibleMemOnly` attribute to prevent LLVM from incorrectly removing calls to `verifier.assume`, ensuring proper interaction with LLVM's optimization pipeline.",
            "The optimization strategy involves marking a function with the `InaccessibleMemOnly` attribute to prevent LLVM from removing calls to `verifier.assume` while allowing safe optimizations.",
            "The optimization strategy involves marking a function with the `InaccessibleMemOnly` attribute to prevent LLVM from removing calls to `verifier.assume` while allowing other optimizations.",
            "The optimization strategy involves marking a function with the `InaccessibleMemOnly` attribute to prevent LLVM from removing calls to `verifier.assume` while allowing safe optimizations.",
            "The optimization strategy involves marking a function with the `InaccessibleMemOnly` attribute to prevent LLVM from incorrectly removing calls to `verifier.assume`, ensuring proper interaction with compiler optimizations."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy involves marking a function with the `InaccessibleMemOnly` attribute to prevent LLVM from removing calls to `verifier.assume` while allowing safe optimizations.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "redot-engine",
        "hash": "4dad9c6c05921cf98c9ee59a5f28358496912433",
        "author": "katsuhisa yuasa",
        "date": "2024-10-19T14:09:34+09:00",
        "message": "optimize ImageLoaderSVG::create_image_from_utf8_buffer",
        "modified_files_count": 1,
        "modified_files": [
            "modules/svg/image_loader_svg.cpp"
        ],
        "github_commit_url": "https://github.com/Redot-Engine/redot-engine/commit/4dad9c6c05921cf98c9ee59a5f28358496912433",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ImageLoaderSVG::create_image_from_utf8_buffer"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy involved reducing redundant computations and memory allocations within the `create_image_from_utf8_buffer` function by reusing precomputed values and avoiding unnecessary intermediate steps.",
            "The optimization strategy involved reducing redundant computations and memory allocations within the SVG image creation process by reusing existing data structures and avoiding unnecessary conversions.",
            "The optimization strategy involved reducing redundant computations and memory allocations within the `create_image_from_utf8_buffer` function by reusing existing resources and simplifying logic.",
            "The optimization strategy involved reducing redundant computations and memory allocations within the `create_image_from_utf8_buffer` function by reusing existing resources and simplifying logic.",
            "The optimization strategy involved reducing redundant computations and memory allocations within the SVG image creation process by reusing existing data structures and avoiding unnecessary conversions."
        ],
        "is_generic_optimization": [
            true,
            false,
            true,
            true,
            false
        ],
        "optimization_summary_final": "The optimization strategy involved reducing redundant computations and memory allocations within the `create_image_from_utf8_buffer` function by reusing existing resources and simplifying logic.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "26a64259b702ec3eccb785e32e473eefcc76b5a5",
        "author": "Felix Fietkau",
        "date": "2011-10-11T16:41:14-04:00",
        "message": "ath9k: improve PS filter clearing and retry counting for A-MPDU\n\nDo not increment the retry counter if packets to a sleeping station\nwere not sent because of tx failure, instead of only checking the filter\nflag.\nClear the PS filter only after an A-MPDU was reported as filtered,\notherwise the hardware might do some unnecessary extra retransmissions.\n\nSigned-off-by: Felix Fietkau <nbd@openwrt.org>\nSigned-off-by: John W. Linville <linville@tuxdriver.com>",
        "modified_files_count": 1,
        "modified_files": [
            "drivers/net/wireless/ath/ath9k/xmit.c"
        ],
        "github_commit_url": "https://github.com/OnePlusOSS/android_kernel_oneplus_msm8998/commit/26a64259b702ec3eccb785e32e473eefcc76b5a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ath_tx_complete_aggr"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "android_kernel_oneplus_msm8998",
        "optimization_summary": [
            "The optimization avoids unnecessary retry counter increments and PS filter clearing by refining the conditions under which these operations are performed in A-MPDU transmissions.",
            "The optimization avoids unnecessary retry counter increments and PS filter clearing by refining the conditions under which these operations are performed in A-MPDU transmissions.",
            "The optimization avoids unnecessary retry counter increments and PS filter clearing by refining the conditions under which these operations are performed.",
            "The optimization avoids unnecessary retry counter increments and PS filter clearing by refining the conditions under which these operations are performed.",
            "The optimization avoids unnecessary retry counter increments and PS filter clearing by refining the conditions under which these operations are performed in A-MPDU transmissions."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization avoids unnecessary retry counter increments and PS filter clearing by refining the conditions under which these operations are performed in A-MPDU transmissions.",
        "is_generic_optimization_final": false
    },
    {
        "repository_name": "android_kernel_xiaomi_marble",
        "hash": "0f3cea8ee8d7e36d342efe396d3ea0912ec090ed",
        "author": "Pragaspathi Thilagaraj",
        "date": "2019-01-19T03:16:50-08:00",
        "message": "qcacld-3.0: Remove call to hdd_napi_serialize during roam start\n\nWith LFR3, in host roaming state machine, the host driver\ninvokes  hdd_napi_serialize to call core_ctl_set_boost,\ntwice- once during roam start and second time during\nSIR_ROAM_DEREGISTER_STA. But driver releases the boost only once\nafter roam sync is complete. This results in the reference\ncount for boost incremented twice but decremented once.\nThis results in power and performance issues.\n\nDont invoke hdd_napi_serialize when hdd_sme_roam_callback() roam\nstatus is eCSR_ROAM_START.\n\nChange-Id: Iabe20624ec5f7a5249a82c5120dfd1bb02bf5835\nCRs-Fixed: 2377951",
        "modified_files_count": 1,
        "modified_files": [
            "core/hdd/src/wlan_hdd_assoc.c"
        ],
        "github_commit_url": "https://github.com/Pzqqt/android_kernel_xiaomi_marble/commit/0f3cea8ee8d7e36d342efe396d3ea0912ec090ed",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "hdd_sme_roam_callback"
        ],
        "is_opt_ds_simple": "true",
        "optimization_summary": [
            "The optimization strategy removes an unnecessary function call during a specific roaming state to prevent incorrect reference counting and associated power/performance issues.",
            "The optimization strategy removes an unnecessary function call during a specific roaming state to prevent incorrect reference counting and associated power/performance issues.",
            "The optimization strategy removes an unnecessary function call during a specific roaming state to prevent incorrect reference count handling and associated power/performance issues.",
            "The optimization strategy removes an unnecessary function call during a specific roaming state to prevent incorrect reference counting that causes power and performance issues.",
            "The optimization strategy removes an unnecessary function call during a specific roaming state to prevent incorrect reference count handling, thereby addressing power and performance issues."
        ],
        "is_generic_optimization": [
            false,
            false,
            false,
            false,
            false
        ],
        "optimization_summary_final": "The optimization strategy removes an unnecessary function call during a specific roaming state to prevent incorrect reference counting and associated power/performance issues.",
        "is_generic_optimization_final": false
    }
]