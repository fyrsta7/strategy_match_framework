[
    {
        "hash": "873f1356a1781e8d638973ea320b722d3240fc5a",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "db_ttl_impl.h: pass func parameter by reference\n\nFix for:\n\n[utilities/ttl/db_ttl_impl.h:209]: (performance) Function parameter\n 'merge_op' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/ttl/db_ttl_impl.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/873f1356a1781e8d638973ea320b722d3240fc5a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "TtlMergeOperator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "55652043c83c463ce57b7748e01c6d12bb5bf9fe",
        "author": "Danny Al-Gaaf",
        "date": "2014-10-01T10:49:08+02:00",
        "message": "table/cuckoo_table_reader.cc: pass func parameter by reference\n\nFix for:\n\n[table/cuckoo_table_reader.cc:196]: (performance) Function\n parameter 'target' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/cuckoo_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/55652043c83c463ce57b7748e01c6d12bb5bf9fe",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BucketComparator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involves passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "4704833357a8609e7c42df4f337f938a8e870c08",
        "author": "jsteemann",
        "date": "2015-09-18T20:20:32+02:00",
        "message": "pass input string to WriteBatch() by const reference\n\nthis may lead to copying less data (in case compilers don't\noptimize away copying the string by themselves)",
        "modified_files_count": 1,
        "modified_files": [
            "include/rocksdb/write_batch.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/4704833357a8609e7c42df4f337f938a8e870c08",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatch"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves passing the input string to WriteBatch() by const reference to reduce unnecessary data copying.",
            "The optimization strategy involves passing an input string to the WriteBatch function by const reference to reduce data copying.",
            "The optimization strategy involves passing the input string to WriteBatch() by const reference to reduce data copying.",
            "The optimization strategy involves passing the input string to WriteBatch() by const reference to reduce data copying overhead.",
            "The optimization strategy involves passing the input string to WriteBatch() by const reference to reduce unnecessary data copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves passing the input string to WriteBatch() by const reference to reduce data copying.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "92ad4a88f3199b013532b37d6598c442319355a5",
        "author": "Changyu Bi",
        "date": "2024-08-27T13:57:40-07:00",
        "message": "Small CPU optimization in InlineSkipList::Insert() (#12975)\n\nSummary:\nreuse decode key in more places to avoid decoding length prefixed key x->Key().\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/12975\n\nTest Plan:\nran benchmarks simultaneously for \"before\" and \"after\"\n* fillseq:\n```\n(for I in $(seq 1 50); do ./db_bench --benchmarks=fillseq --disable_auto_compactions=1 --min_write_buffer_number_to_merge=100 --max_write_buffer_number=1000  --write_buffer_size=268435456 --num=5000000 --seed=1723056275 --disable_wal=1 2>&1 | grep \"fillseq\"\ndone;) | awk '{ t += $5; c++; print } END { printf (\"%9.3f\\n\", 1.0 * t / c) }';\n\nbefore: 1483191\nafter: 1490555 (+0.5%)\n```\n\n* fillrandom:\n```\n(for I in $(seq 1 2); do ./db_bench_imain --benchmarks=fillrandom --disable_auto_compactions=1 --min_write_buffer_number_to_merge=100 --max_write_buffer_number=1000  --write_buffer_size=268435456 --num=2500000 --seed=1723056275 --disable_wal=1 2>&1 | grep \"fillrandom\"\n\nbefore: 255463\nafter: 256128 (+0.26%)\n```\n\nReviewed By: anand1976\n\nDifferential Revision: D61835340\n\nPulled By: cbi42\n\nfbshipit-source-id: 70345510720e348bacd51269acb5d2dd5a62bf0a",
        "modified_files_count": 1,
        "modified_files": [
            "memtable/inlineskiplist.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/92ad4a88f3199b013532b37d6598c442319355a5",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "compare_"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves reusing the decoded key in more places to avoid redundant decoding of length-prefixed keys, reducing CPU overhead.",
            "The optimization strategy involves reusing the decoded key in more places to avoid redundant decoding of length-prefixed keys.",
            "The optimization strategy reused a decoded key in multiple places to avoid redundant decoding of length-prefixed keys.",
            "The optimization strategy reused a decoded key in multiple places to avoid redundant decoding of length-prefixed keys.",
            "The optimization strategy reused a decoded key in multiple places to avoid redundant decoding of length-prefixed keys."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy reused a decoded key in multiple places to avoid redundant decoding of length-prefixed keys.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "9f246298e2f0af3973918a0dac0c5f46bc0993c0",
        "author": "Changli Gao",
        "date": "2017-01-11T10:54:37-08:00",
        "message": "Performance: Iterate vector by reference\n\nSummary: Closes https://github.com/facebook/rocksdb/pull/1763\n\nDifferential Revision: D4398796\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: b82636d",
        "modified_files_count": 1,
        "modified_files": [
            "db/event_helpers.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/9f246298e2f0af3973918a0dac0c5f46bc0993c0",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "EventHelpers::LogAndNotifyTableFileDeletion"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
            "The optimization strategy used was changing value-based loop iteration to reference-based iteration to reduce copy overhead.",
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
            "The optimization strategy used was iterating over a vector by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved iterating over a vector by reference instead of by value to reduce copy overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "53910ddb152fbcba95a3e04b058a997c40f654ae",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "db_test.cc: pass parameter by reference\n\nFix for:\n\n[db/db_test.cc:6141]: (performance) Function parameter\n 'key' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/53910ddb152fbcba95a3e04b058a997c40f654ae",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "convertKey"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "8558457143bfa76d61e0d2f715e40ec2ddb6ffc2",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "ldb_cmd_execute_result.h: perform init in initialization list\n\nFix for:\n\n[util/ldb_cmd_execute_result.h:18]: (performance) Variable 'message_'\n is assigned in constructor body. Consider performing initialization\n in initialization list.\n[util/ldb_cmd_execute_result.h:23]: (performance) Variable 'message_'\n is assigned in constructor body. Consider performing initialization\n in initialization list.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "util/ldb_cmd_execute_result.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/8558457143bfa76d61e0d2f715e40ec2ddb6ffc2",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "LDBCommandExecuteResult"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves initializing member variables in the constructor's initialization list instead of the constructor body to improve performance.",
            "The optimization strategy involves initializing class member variables in the constructor's initialization list instead of the constructor body to improve performance.",
            "The optimization strategy involves initializing member variables in the constructor's initialization list instead of the constructor body to improve performance.",
            "The optimization strategy involves initializing member variables in the constructor's initialization list instead of the constructor body to improve performance.",
            "The optimization strategy involves initializing class member variables in the constructor's initialization list instead of the constructor body to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves initializing member variables in the constructor's initialization list instead of the constructor body to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "93548ce8f451a701ad0967ba705f04fef80aa11a",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "table/cuckoo_table_reader.cc: pass func parameter by ref\n\nFix for:\n\n[table/cuckoo_table_reader.cc:198]: (performance) Function\n parameter 'file_data' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/cuckoo_table_reader.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/93548ce8f451a701ad0967ba705f04fef80aa11a",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BucketComparator"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to reduce copy overhead.",
            "The optimization strategy involves passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "f82e693a31d07ab8b391888ff60eb7ff5b95bd13",
        "author": "Siying Dong",
        "date": "2019-05-16T15:24:28-07:00",
        "message": "RangeDelAggregator::StripeRep::Invalidate() to be skipped if empty (#5312)\n\nSummary:\nRangeDelAggregator::StripeRep::Invalidate() clears up several vectors. If we know there isn't anything to there, we can safe these small CPUs. Profiling shows that it sometimes take non-negligible amount of CPU. Worth a small optimization.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/5312\n\nDifferential Revision: D15380511\n\nPulled By: siying\n\nfbshipit-source-id: 53c5f34c33b4cb1e743643c6086ac56d0b84ec2e",
        "modified_files_count": 1,
        "modified_files": [
            "db/range_del_aggregator.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/f82e693a31d07ab8b391888ff60eb7ff5b95bd13",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Invalidate"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves skipping the `Invalidate` function call if the vectors it clears are already empty, saving CPU cycles.",
            "The optimization strategy involves skipping the `Invalidate` function if the vectors it clears are already empty, saving CPU cycles.",
            "The optimization strategy involves skipping the `Invalidate` function call if the vectors are already empty to save CPU cycles.",
            "The optimization strategy involves skipping the `Invalidate` function call if the vectors it operates on are empty, saving CPU cycles.",
            "The optimization strategy involves skipping the `Invalidate` function if the vectors it clears are already empty, saving CPU cycles."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves skipping the `Invalidate` function call if the vectors it clears are already empty, saving CPU cycles.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "25403c2265cb700462d59fa3cb9dbec85d25d48f",
        "author": "Andrew Kryczka",
        "date": "2018-06-28T13:20:29-07:00",
        "message": "Prefetch cache lines for filter lookup (#4068)\n\nSummary:\nSince the filter data is unaligned, even though we ensure all probes are within a span of `cache_line_size` bytes, those bytes can span two cache lines. In that case I doubt hardware prefetching does a great job considering we don't necessarily access those two cache lines in order. This guess seems correct since adding explicit prefetch instructions reduced filter lookup overhead by 19.4%.\nCloses https://github.com/facebook/rocksdb/pull/4068\n\nDifferential Revision: D8674189\n\nPulled By: ajkr\n\nfbshipit-source-id: 747427d9a17900151c17820488e3f7efe06b1871",
        "modified_files_count": 1,
        "modified_files": [
            "util/bloom.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/25403c2265cb700462d59fa3cb9dbec85d25d48f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "FullFilterBitsReader::HashMayMatch"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved adding explicit prefetch instructions to reduce filter lookup overhead by ensuring cache lines are prefetched for unaligned filter data.",
            "The optimization strategy involved adding explicit prefetch instructions to reduce filter lookup overhead by ensuring cache lines are prefetched for unaligned filter data.",
            "The optimization strategy involves adding explicit prefetch instructions to reduce filter lookup overhead by ensuring cache lines are prefetched for unaligned filter data.",
            "The optimization strategy involves adding explicit prefetch instructions to reduce filter lookup overhead by ensuring cache lines are prefetched for unaligned filter data.",
            "The optimization strategy involved adding explicit prefetch instructions to reduce filter lookup overhead by ensuring cache lines are prefetched for unaligned filter data."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved adding explicit prefetch instructions to reduce filter lookup overhead by ensuring cache lines are prefetched for unaligned filter data.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "e94eea4527f2d7de82a6bf3303177977011e5dd9",
        "author": "Haobo Xu",
        "date": "2013-12-20T16:29:05-08:00",
        "message": "[RocksDB] [Performance Branch] Minor fix, Remove string resize from WriteBatch::Clear\n\nSummary: tmp_batch_ will get re-allocated for every merged write batch because of the existing resize in WriteBatch::Clear. Note that in DBImpl::BuildBatchGroup, we have a hard coded upper limit of batch size 1<<20 = 1MB already.\n\nTest Plan: make check\n\nReviewers: dhruba, sdong\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D14787",
        "modified_files_count": 1,
        "modified_files": [
            "db/write_batch.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/e94eea4527f2d7de82a6bf3303177977011e5dd9",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "WriteBatch::Clear"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved removing an unnecessary string resize operation in WriteBatch::Clear to avoid re-allocation overhead for merged write batches.",
            "The optimization strategy involved removing an unnecessary string resize operation in WriteBatch::Clear to avoid re-allocation overhead for merged write batches.",
            "The optimization strategy involved removing an unnecessary string resize operation in WriteBatch::Clear to avoid re-allocation overhead during merged write batches.",
            "The optimization strategy involved removing an unnecessary string resize operation in WriteBatch::Clear to avoid re-allocation overhead during merged write batches.",
            "The optimization strategy involved removing an unnecessary string resize operation in WriteBatch::Clear to avoid re-allocation overhead during merged write batches."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved removing an unnecessary string resize operation in WriteBatch::Clear to avoid re-allocation overhead during merged write batches.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "b8b7117e97e649fc65d0a4dd397caf9a39fb71b1",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "db/version_set.cc: use !empty() instead of 'size() > 0'\n\nUse empty() since it should be prefered as it has, following\nthe standard, a constant time complexity regardless of the\ncontainter type. The same is not guaranteed for size().\n\nFix for:\n[db/version_set.cc:2250]: (performance) Possible inefficient\n checking for 'column_families_not_found' emptiness.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_set.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b8b7117e97e649fc65d0a4dd397caf9a39fb71b1",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VersionSet::Recover"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves replacing `size() > 0` with `empty()` for checking container emptiness to ensure constant time complexity.",
            "The optimization strategy used was replacing `size() > 0` with `empty()` to check for container emptiness, leveraging the constant time complexity of `empty()`.",
            "The optimization strategy involves replacing `size() > 0` with `empty()` to ensure constant time complexity for checking container emptiness.",
            "The optimization strategy involved replacing `size() > 0` with `!empty()` to check for container emptiness, leveraging the constant time complexity of `empty()`.",
            "The optimization strategy replaces `size() > 0` with `empty()` to ensure constant time complexity for checking container emptiness."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves replacing `size() > 0` with `empty()` to ensure constant time complexity for checking container emptiness.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "90d835507581324d0449f1ded4f56a8b16f20bf7",
        "author": "xiusir",
        "date": "2017-02-28T10:39:11-08:00",
        "message": "Fix the wrong address for PREFETCH in DynamicBloom::Prefetch\n\nSummary:\n- Change data_[b] to data_[b / 8] in DynamicBloom::Prefetch, as b means the b-th bit in data_ and data_[b / 8] is the proper byte in data_.\nCloses https://github.com/facebook/rocksdb/pull/1935\n\nDifferential Revision: D4628696\n\nPulled By: siying\n\nfbshipit-source-id: bc5a0c6",
        "modified_files_count": 1,
        "modified_files": [
            "util/dynamic_bloom.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/90d835507581324d0449f1ded4f56a8b16f20bf7",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DynamicBloom::Prefetch"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved correcting the address calculation for prefetching to ensure the proper byte is accessed, reducing unnecessary memory operations.",
            "The optimization strategy corrected the address calculation in a prefetch operation to ensure the proper byte is accessed, improving memory access efficiency.",
            "The optimization strategy involved correcting the address calculation for prefetching to ensure the proper byte is accessed, reducing unnecessary memory operations.",
            "The optimization strategy involved correcting the address calculation for prefetching by using the proper byte index instead of the bit index to improve memory access efficiency.",
            "The optimization strategy involved correcting the address calculation for prefetching to ensure the proper byte is accessed, reducing unnecessary memory operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved correcting the address calculation for prefetching to ensure the proper byte is accessed, reducing unnecessary memory operations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "30a017fecae60aa7b87c4a1e283b6ac027724a92",
        "author": "Yi Wu",
        "date": "2018-01-05T16:41:58-08:00",
        "message": "Blob DB: avoid having a separate read of checksum\n\nSummary:\nPreviously on a blob db read, we are making a read of the blob value, and then make another read to get CRC checksum. I'm combining the two read into one.\n\nreadrandom db_bench with 1G database with base db size of 13M, value size 1k:\n`./db_bench --db=/home/yiwu/tmp/db_bench --use_blob_db --value_size=1024 --num=1000000 --benchmarks=readrandom --use_existing_db --cache_size=32000000`\nmaster: throughput 234MB/s, get micros p50 5.984 p95 9.998 p99 20.817 p100 787\nthis PR: throughput 261MB/s, get micros p50 5.157 p95 9.928 p99 20.724 p100 190\nCloses https://github.com/facebook/rocksdb/pull/3301\n\nDifferential Revision: D6615950\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: 052410c6d8539ec0cc305d53793bbc8f3616baa3",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/blob_db/blob_db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/30a017fecae60aa7b87c4a1e283b6ac027724a92",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "BlobDBImpl::GetBlobValue"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy combines two separate reads (one for the blob value and one for the CRC checksum) into a single read to reduce I/O overhead.",
            "The optimization strategy combines two separate reads (one for the blob value and one for the CRC checksum) into a single read to reduce I/O overhead.",
            "The optimization strategy combines two separate reads (one for the blob value and one for the CRC checksum) into a single read to reduce I/O overhead.",
            "The optimization strategy involved combining two separate reads (one for the blob value and one for the CRC checksum) into a single read operation to reduce I/O overhead.",
            "The optimization strategy combines two separate reads (blob value and CRC checksum) into a single read operation to reduce I/O overhead."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy combines two separate reads (one for the blob value and one for the CRC checksum) into a single read to reduce I/O overhead.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "43c789c8f246a2a35864e3fca9585b55c40c2095",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "spatialdb/spatial_db.cc: use !empty() instead of 'size() > 0'\n\nUse empty() since it should be prefered as it has, following\nthe standard, a constant time complexity regardless of the\ncontainter type. The same is not guaranteed for size().\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "utilities/spatialdb/spatial_db.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/43c789c8f246a2a35864e3fca9585b55c40c2095",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SpatialIndexCursor"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves replacing `size() > 0` with `!empty()` to leverage the constant time complexity of `empty()` across different container types.",
            "The optimization strategy replaces `size() > 0` with `!empty()` to leverage the constant time complexity of `empty()` across different container types.",
            "The optimization strategy replaces `size() > 0` with `empty()` to ensure constant time complexity for checking container emptiness.",
            "The optimization strategy involves replacing `size() > 0` with `!empty()` to leverage the constant time complexity of `empty()` across different container types.",
            "The optimization strategy replaces `size() > 0` with `empty()` to leverage constant time complexity for checking container emptiness."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy replaces `size() > 0` with `!empty()` to leverage the constant time complexity of `empty()` across different container types.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "82e8e9e26bb16d1af07a26741bcf63d8342e4336",
        "author": "JiYou",
        "date": "2018-09-14T19:43:04-07:00",
        "message": "VersionBuilder: optmize SaveTo() to linear time. (#4366)\n\nSummary:\nBecause `base_files` and `added_files` both are sorted, using a merge\noperation to these two sorted arrays is more effective. The complexity\nis reduced to linear time.\n\n    - optmize the merge complexity.\n    - move the `NDEBUG` of sorted `added_files` out of merge process.\n\nSigned-off-by: JiYou <jiyou09@gmail.com>\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4366\n\nDifferential Revision: D9833592\n\nPulled By: ajkr\n\nfbshipit-source-id: dd32b67ebdca4c20e5e9546ab8082cecefe99fd0",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_builder.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/82e8e9e26bb16d1af07a26741bcf63d8342e4336",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "SaveTo"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy used was merging two sorted arrays (`base_files` and `added_files`) to reduce the complexity of the `SaveTo()` function to linear time.",
            "The optimization strategy used was merging two sorted arrays (`base_files` and `added_files`) to reduce the complexity of the `SaveTo()` function to linear time.",
            "The optimization strategy used was replacing a less efficient operation with a linear-time merge operation on two sorted arrays.",
            "The optimization strategy used was merging two sorted arrays (`base_files` and `added_files`) to reduce the complexity of the `SaveTo()` function to linear time.",
            "The optimization strategy used was merging two sorted arrays (`base_files` and `added_files`) to reduce the complexity of the `SaveTo` function from higher than linear to linear time."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was merging two sorted arrays (`base_files` and `added_files`) to reduce the complexity of the `SaveTo` function from higher than linear to linear time.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "68ca534169a4f9e1930f6511109e973b43cf5998",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:31+02:00",
        "message": "corruption_test.cc: pass parameter by reference\n\nFix for:\n\n[db/corruption_test.cc:134]: (performance) Function parameter\n 'fname' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "db/corruption_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/68ca534169a4f9e1930f6511109e973b43cf5998",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "CorruptFile"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy used was passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy used was passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy used was passing a function parameter by reference instead of by value to avoid unnecessary copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was passing a function parameter by reference instead of by value to avoid unnecessary copying.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "063471bf7613544496a4d4b5a1e1ba4a7aa605cf",
        "author": "Danny Al-Gaaf",
        "date": "2014-09-30T23:30:32+02:00",
        "message": "table/table_test.cc: pass func parameter by reference\n\nFix for:\n\n[table/table_test.cc:1218]: (performance) Function parameter\n 'prefix' should be passed by reference.\n\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>",
        "modified_files_count": 1,
        "modified_files": [
            "table/table_test.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/063471bf7613544496a4d4b5a1e1ba4a7aa605cf",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "AddInternalKey"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy used was passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
            "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved passing a function parameter by reference instead of by value to avoid unnecessary copying.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "beeee9dccc338ae7129016f2f2e17d2a40ecc5df",
        "author": "Igor Canadi",
        "date": "2014-04-08T11:06:39-07:00",
        "message": "Small speedup of CompactionFilterV2\n\nSummary: ToString() is expensive. Profiling shows that most compaction threads are stuck in jemalloc, allocating a new string. This will help out a litte.\n\nTest Plan: make check\n\nReviewers: haobo, danguo\n\nReviewed By: danguo\n\nCC: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D17583",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/beeee9dccc338ae7129016f2f2e17d2a40ecc5df",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::DoCompactionWork"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved reducing the frequency of expensive `ToString()` calls to minimize memory allocation overhead during compaction.",
            "The optimization strategy involves reducing the overhead of expensive `ToString()` calls by avoiding unnecessary string allocations during compaction.",
            "The optimization strategy involves reducing the frequency of expensive `ToString()` calls to minimize memory allocation overhead during compaction.",
            "The optimization strategy involves reducing the overhead of expensive `ToString()` calls by minimizing string allocations during compaction.",
            "The optimization strategy involves reducing the frequency of expensive `ToString()` calls to minimize memory allocation overhead during compaction."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves reducing the frequency of expensive `ToString()` calls to minimize memory allocation overhead during compaction.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "b8cea7cc279fe609de85b7ce4f50d4ff4f90047f",
        "author": "Changli Gao",
        "date": "2017-10-17T10:12:37-07:00",
        "message": "VersionBuilder: Erase with iterators for better performance\n\nSummary: Closes https://github.com/facebook/rocksdb/pull/3007\n\nDifferential Revision: D6077701\n\nPulled By: yiwu-arbug\n\nfbshipit-source-id: a6fd5b8a23f4feb1660b9ce027f651a7e90352b3",
        "modified_files_count": 1,
        "modified_files": [
            "db/version_builder.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/b8cea7cc279fe609de85b7ce4f50d4ff4f90047f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "Apply"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy used was replacing erase operations with iterator-based deletions to improve performance.",
            "The optimization strategy used was replacing erase operations with iterators to improve performance.",
            "The optimization strategy used was replacing erase operations with iterator-based erasures to improve performance.",
            "The optimization strategy used was replacing erase operations with iterator-based deletions to improve performance.",
            "The optimization strategy used was replacing erase operations with iterator-based erasures to improve performance."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used was replacing erase operations with iterator-based erasures to improve performance.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "a2de8e52bb6c13baf5f2323eba0ca356f1294f88",
        "author": "Simon Liu",
        "date": "2018-11-13T14:39:03-08:00",
        "message": "optimized the performance of autovector::emplace_back. (#4606)\n\nSummary:\nIt called the autovector::push_back simply in autovector::emplace_back.\nThis was not efficient, and then optimazed this function through the\nperfect forwarding.\n\nThis was the src and result of the benchmark(using the google'benchmark library, the type of elem in\nautovector was std::string, and call emplace_back with the \"char *\" type):\n\nhttps://gist.github.com/monadbobo/93448b89a42737b08cbada81de75c5cd\n\nPS: The benchmark's result of  previous PR was not accurate, and so I update the test case and result.\nPull Request resolved: https://github.com/facebook/rocksdb/pull/4606\n\nDifferential Revision: D13046813\n\nPulled By: sagar0\n\nfbshipit-source-id: 19cde1bcadafe899aa454b703acb35737a1cc02d",
        "modified_files_count": 1,
        "modified_files": [
            "util/autovector.h"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/a2de8e52bb6c13baf5f2323eba0ca356f1294f88",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "emplace_back"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy used perfect forwarding in the `emplace_back` function to improve performance by avoiding unnecessary copies or moves.",
            "The optimization strategy used perfect forwarding in the `autovector::emplace_back` function to improve performance by avoiding unnecessary copies or moves.",
            "The optimization strategy used perfect forwarding in the `emplace_back` function to improve performance by avoiding unnecessary copies or moves.",
            "The optimization strategy used perfect forwarding in the `autovector::emplace_back` function to improve performance by avoiding unnecessary copies or moves.",
            "The optimization strategy used perfect forwarding in the `emplace_back` function to improve performance by avoiding unnecessary copies or moves."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy used perfect forwarding in the `emplace_back` function to improve performance by avoiding unnecessary copies or moves.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "d2b0652b32b8671c9ec4057e6da2fa564d1cc610",
        "author": "Xinye Tao",
        "date": "2023-08-07T12:29:31-07:00",
        "message": "compute compaction score once for a batch of range file deletes (#10744)\n\nSummary:\nOnly re-calculate compaction score once for a batch of deletions. Fix performance regression brought by https://github.com/facebook/rocksdb/pull/8434.\n\nPull Request resolved: https://github.com/facebook/rocksdb/pull/10744\n\nTest Plan:\nIn one of our production cluster that recently upgraded to RocksDB 6.29, it takes more than 10 minutes to delete files in 30,000 ranges. The RocksDB instance contains approximately 80,000 files. After this patch, the duration reduces to 100+ ms, which is on par with RocksDB 6.4.\n\nCherry-picking downstream PR: https://github.com/tikv/rocksdb/pull/316\n\nSigned-off-by: tabokie <xy.tao@outlook.com>\n\nReviewed By: cbi42\n\nDifferential Revision: D48002581\n\nPulled By: ajkr\n\nfbshipit-source-id: 7245607ee3ad79c53b648a6396c9159f166b9437",
        "modified_files_count": 1,
        "modified_files": [
            "db/db_impl/db_impl.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/d2b0652b32b8671c9ec4057e6da2fa564d1cc610",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "DBImpl::DeleteFilesInRanges"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves computing the compaction score once for a batch of range file deletions instead of recalculating it for each deletion, reducing redundant calculations.",
            "The optimization strategy involves computing the compaction score once for a batch of range file deletions instead of recalculating it for each deletion, reducing redundant calculations.",
            "The optimization strategy involves computing the compaction score once for a batch of range file deletions instead of recalculating it for each deletion, reducing redundant calculations.",
            "The optimization strategy involves computing the compaction score once for a batch of range file deletions instead of recalculating it for each deletion, reducing redundant calculations.",
            "The optimization strategy involves computing the compaction score once for a batch of range file deletions instead of recalculating it for each deletion, reducing redundant calculations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            false,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves computing the compaction score once for a batch of range file deletions instead of recalculating it for each deletion, reducing redundant calculations.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "08be1803eecb5ae464440812ea06e79b21289053",
        "author": "Igor Canadi",
        "date": "2015-04-13T15:58:45-07:00",
        "message": "Fix bad performance in debug mode\n\nSummary:\nSee github issue 574: https://github.com/facebook/rocksdb/issues/574\n\nBasically when we're running in DEBUG mode we're calling `usleep(0)` on\nevery mutex lock. I bisected the issue to\nhttps://reviews.facebook.net/D36963. Instead of calling sleep(0), this\ndiff just avoids calling SleepForMicroseconds() when delay is not set.\n\nTest Plan:\n    bpl=10485760;overlap=10;mcz=2;del=300000000;levels=2;ctrig=10000000; delay=10000000; stop=10000000; wbn=30; mbc=20; mb=1073741824;wbs=268435456; dds=1; sync=0; r=100000; t=1; vs=800; bs=65536; cs=1048576; of=500000; si=1000000; ./db_bench --benchmarks=fillrandom --disable_seek_compaction=1 --mmap_read=0 --statistics=1 --histogram=1 --num=$r --threads=$t --value_size=$vs --block_size=$bs --cache_size=$cs --bloom_bits=10 --cache_numshardbits=4 --open_files=$of --verify_checksum=1 --db=/tmp/rdb10test --sync=$sync --disable_wal=1 --compression_type=snappy --stats_interval=$si --compression_ratio=0.5 --disable_data_sync=$dds --write_buffer_size=$wbs --target_file_size_base=$mb --max_write_buffer_number=$wbn --max_background_compactions=$mbc --level0_file_num_compaction_trigger=$ctrig --level0_slowdown_writes_trigger=$delay --level0_stop_writes_trigger=$stop --num_levels=$levels --delete_obsolete_files_period_micros=$del --min_level_to_compress=$mcz --max_grandparent_overlap_factor=$overlap --stats_per_interval=1 --max_bytes_for_level_base=$bpl --memtablerep=vector --use_existing_db=0 --disable_auto_compactions=1 --source_compaction_factor=10000000 | grep ops\n\nBefore:\nfillrandom   :     117.525 micros/op 8508 ops/sec;    6.6 MB/s\nAfter:\nfillrandom   :       1.283 micros/op 779502 ops/sec;  606.6 MB/s\n\nReviewers: rven, yhchiang, sdong\n\nReviewed By: sdong\n\nSubscribers: meyering, dhruba, leveldb\n\nDifferential Revision: https://reviews.facebook.net/D36963",
        "modified_files_count": 1,
        "modified_files": [
            "util/thread_status_util_debug.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/08be1803eecb5ae464440812ea06e79b21289053",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "ThreadStatusUtil::TEST_StateDelay"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved avoiding unnecessary calls to `SleepForMicroseconds()` when no delay is set, specifically in debug mode.",
            "The optimization strategy involved removing unnecessary `usleep(0)` calls in debug mode to avoid performance degradation.",
            "The optimization strategy involved removing unnecessary `usleep(0)` calls in DEBUG mode to avoid performance degradation.",
            "The optimization strategy involved avoiding unnecessary calls to `SleepForMicroseconds()` when no delay is set, specifically in debug mode.",
            "The optimization strategy involved avoiding unnecessary calls to `SleepForMicroseconds()` when no delay is set, specifically in debug mode."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved avoiding unnecessary calls to `SleepForMicroseconds()` when no delay is set, specifically in debug mode.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "536e9973e30d70fd510e5ab6e423ef75248ed582",
        "author": "Igor Canadi",
        "date": "2014-08-27T11:05:41-07:00",
        "message": "Remove assert in vector rep\n\nSummary: This assert makes Insert O(n^2) instead of O(n) in debug mode. Memtable insert is in the critical path. No need to assert uniqunnes of the key here, since we're adding a sequence number to it anyway.\n\nTest Plan: none\n\nReviewers: sdong, ljin\n\nReviewed By: ljin\n\nSubscribers: leveldb\n\nDifferential Revision: https://reviews.facebook.net/D22443",
        "modified_files_count": 1,
        "modified_files": [
            "util/vectorrep.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/536e9973e30d70fd510e5ab6e423ef75248ed582",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "VectorRep::Insert"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involved removing an assert statement that caused O(n^2) complexity in debug mode, improving the performance of the Insert operation to O(n).",
            "The optimization strategy involved removing an assert statement that caused O(n^2) complexity in debug mode, reducing it to O(n) for memtable insert operations.",
            "The optimization strategy involved removing an assert statement that caused O(n^2) complexity in debug mode, reducing the complexity to O(n) for the insert operation.",
            "The optimization strategy involved removing an assert statement that caused O(n^2) complexity in debug mode, reducing the complexity to O(n) for the insert operation.",
            "The optimization strategy involved removing an assert statement that caused O(n^2) complexity in debug mode, reducing it to O(n) for memtable insert operations."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involved removing an assert statement that caused O(n^2) complexity in debug mode, reducing the complexity to O(n) for the insert operation.",
        "is_generic_optimization_final": true
    },
    {
        "hash": "20dc5e74f276bdcb26c44c13bced506a2d920d3f",
        "author": "Sagar Vemuri",
        "date": "2017-08-05T00:15:35-07:00",
        "message": "Optimize range-delete aggregator call in merge helper.\n\nSummary:\nIn the condition:\n```\nif (range_del_agg != nullptr &&\n    range_del_agg->ShouldDelete(\n        iter->key(),\n        RangeDelAggregator::RangePositioningMode::kForwardTraversal) &&\n    filter != CompactionFilter::Decision::kRemoveAndSkipUntil) {\n...\n}\n```\nit could be possible that all the work done in `range_del_agg->ShouldDelete` is wasted due to not having the right `filter` value later on.\nInstead, check `filter` value before even calling `range_del_agg->ShouldDelete`, which is a much more involved function.\nCloses https://github.com/facebook/rocksdb/pull/2690\n\nDifferential Revision: D5568931\n\nPulled By: sagar0\n\nfbshipit-source-id: 17512d52360425c7ae9de7675383f5d7bc3dad58",
        "modified_files_count": 1,
        "modified_files": [
            "db/merge_helper.cc"
        ],
        "github_commit_url": "https://github.com/facebook/rocksdb/commit/20dc5e74f276bdcb26c44c13bced506a2d920d3f",
        "contains_optimization_keyword": true,
        "modified_func_count": 1,
        "modified_other": false,
        "modified_func": [
            "MergeHelper::MergeUntil"
        ],
        "is_opt_ds_simple": "true",
        "repository_name": "rocksdb",
        "optimization_summary": [
            "The optimization strategy involves reordering conditions in an if-statement to check a simpler condition (`filter != CompactionFilter::Decision::kRemoveAndSkipUntil`) before a more computationally expensive function call (`range_del_agg->ShouldDelete`).",
            "The optimization strategy involves reordering conditions in an if-statement to check a simpler condition (`filter != CompactionFilter::Decision::kRemoveAndSkipUntil`) before calling a more computationally expensive function (`range_del_agg->ShouldDelete`).",
            "The optimization strategy involves reordering conditions in an if-statement to check a simpler condition (`filter`) before a more computationally expensive function call (`range_del_agg->ShouldDelete`).",
            "The optimization strategy involves reordering conditions in an if-statement to check a simpler condition (`filter != CompactionFilter::Decision::kRemoveAndSkipUntil`) before calling a more computationally expensive function (`range_del_agg->ShouldDelete`).",
            "The optimization strategy involves reordering conditions in an if-statement to check a simpler condition (`filter`) before a more computationally expensive function (`range_del_agg->ShouldDelete`) to avoid unnecessary work."
        ],
        "is_generic_optimization": [
            true,
            true,
            true,
            true,
            true
        ],
        "optimization_summary_final": "The optimization strategy involves reordering conditions in an if-statement to check a simpler condition (`filter != CompactionFilter::Decision::kRemoveAndSkipUntil`) before calling a more computationally expensive function (`range_del_agg->ShouldDelete`).",
        "is_generic_optimization_final": true
    }
]