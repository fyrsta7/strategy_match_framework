import os
import json
import sys
import re
import concurrent.futures
from tqdm import tqdm
from colorama import Fore, Style, init
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import config
from openai import OpenAI

# åˆå§‹åŒ–colorama
init()

# å…¨å±€å˜é‡ï¼šè®¾ç½®æ˜¯å¦åœ¨ä¼˜åŒ–ç»“æœå·²å­˜åœ¨æ—¶é‡æ–°ç”Ÿæˆä¼˜åŒ–ç»“æœ
# è®¾ç½®ä¸º True æ—¶ï¼Œå³ä½¿æ–‡ä»¶å­˜åœ¨ï¼Œä¹Ÿä¼šé‡æ–°è°ƒç”¨ LLM ç”Ÿæˆä¼˜åŒ–ç»“æœ
# è®¾ç½®ä¸º False æ—¶ï¼Œå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡è¯¥æäº¤çš„ä¼˜åŒ–è¿‡ç¨‹
REGENERATE_EXISTING = False

# æ–°å¢ï¼šæ¯ä¸ªå‡½æ•°è¦é‡å¤ä¼˜åŒ–çš„æ¬¡æ•°
OPTIMIZATION_ATTEMPTS = 3

# æ–°å¢ï¼šå½“LLMå›å¤ä¸ç¬¦åˆè¦æ±‚æ—¶ï¼Œæœ€å¤§é‡è¯•æ¬¡æ•°
MAX_RETRY_ATTEMPTS = 3

# prompt ä¸­çš„ä¾‹å­æ•°é‡
MAX_EXAMPLES = 4

# ä½¿ç”¨çš„çŸ¥è¯†åº“ç‰ˆæœ¬
KNOWLEDGE_BASE_SEZE = 19998

# å®šä¹‰éœ€è¦å¤„ç†çš„æ¨¡å‹
MODELS = ['gpt-4o', 'deepseek-v3']

# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
SUPPORTED_MODELS = ['deepseek-v3', 'deepseek-reasoner', 'gpt-4o', 'o1-mini', 'o3-mini']

# æ”¾ commit ç›¸å…³æ–‡ä»¶çš„è·¯å¾„
COMMIT_DIR = config.root_path + "benchmark/{repo}/modified_file/{commit}"

# å°†ä¼˜åŒ–ç»“æœæ”¾åœ¨ COMMIT_DIR/OUTPUT_DIR/<model name>/ è¿™ä¸ªå­æ–‡ä»¶å¤¹ä¸­
OUTPUT_DIR = "bm25"

# åŠ è½½å…¨å±€çš„ç›¸ä¼¼æ€§æ•°æ®
similarity_path = os.path.join(config.root_path, f"commit_similarity_bm25_{KNOWLEDGE_BASE_SEZE}_top20.json")

# æŒ‡å®šè¯»å–éœ€è¦è¢«ä¼˜åŒ–çš„ commit åˆ—è¡¨æ–‡ä»¶ï¼ˆæ–‡ä»¶å†…å®¹ä¸º commit å¯¹è±¡æ•°ç»„ï¼ŒåŒ…å« "hash" ç­‰ä¿¡æ¯ï¼‰
COMMIT_LIST_FILE = os.path.join(config.root_path, 'benchmark', 'rocksdb', 'filtered_test_result.json')

def extract_code_blocks(text):
    """
    ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰ä»£ç å—
    è¿”å›: åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰æ‰¾åˆ°çš„ä»£ç å—å†…å®¹ï¼ˆä¸å«å›´æ ï¼‰
    """
    # åŒ¹é…æ ¼å¼ä¸º ```language code ``` çš„ä»£ç å—ï¼Œå¿½ç•¥è¯­è¨€æ ‡è¯†
    pattern = r"```(?:[a-zA-Z0-9+]*\n)?(.*?)```"
    # re.DOTALL æ ‡å¿—ä½¿ . èƒ½åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„æ‰€æœ‰å­—ç¬¦
    matches = re.findall(pattern, text, re.DOTALL)
    return [match.strip() for match in matches]

def get_client_and_model_info(model):
    """
    æ ¹æ®ä¼ å…¥çš„æ¨¡å‹åç§°è¿”å› (client, model_name)ã€‚
    æ³¨æ„ï¼šä¸åŒæ¨¡å‹éœ€è¦ä¸åŒçš„è°ƒç”¨å‚æ•°å’Œå˜é‡ã€‚
    """
    if model not in SUPPORTED_MODELS:
        raise ValueError(f"Error: Unsupported model '{model}'. Supported: {SUPPORTED_MODELS}")
    
    if model == 'deepseek-v3':
        model_name = "volc/deepseek-v3-241226"
    elif model == 'deepseek-reasoner':
        model_name = "volc/deepseek-r1-250120"
    else:
        # å¯¹äº 'gpt-4o'ã€'o1-mini' æˆ– 'o3-mini'
        model_name = "closeai/" + model
    
    try:
        client = OpenAI(
            base_url=config.xmcp_base_url,
            api_key=config.xmcp_api_key,
        )
    except Exception as e:
        raise RuntimeError(f"Client initialization failed for model {model}: {e}")
    
    return client, model_name

def load_example_data(commit_info):
    """Load example data (before_func and diff)"""
    result_dir = os.path.join(
        config.root_path,
        'knowledge_base',
        commit_info["repository_name"],
        'modified_file',
        commit_info["commit_hash"]
    )
    
    data = {}
    try:
        with open(os.path.join(result_dir, 'before_func.txt'), 'r', encoding='utf-8') as f:
            data['before'] = f.read().strip()
        with open(os.path.join(result_dir, 'diff.txt'), 'r', encoding='utf-8') as f:
            data['diff'] = f.read().strip()
        return data
    except Exception as e:
        print(f"Failed to load example {commit_info['commit_hash']}: {str(e)}")
        return None

def build_examples_section(commit_hash, repo_name, similarity_data):
    """Build examples section (ascending similarity order)"""
    query_entry = next(
        (item for item in similarity_data 
         if item["query_commit"]["commit_hash"] == commit_hash
         and item["query_commit"]["repository_name"] == repo_name),
        None
    )
    
    if not query_entry:
        return ""
    
    # ä¸å†æ ¹æ®ç›¸ä¼¼åº¦è¿‡æ»¤ï¼Œç›´æ¥é‡‡ç”¨æ‰€æœ‰ç¤ºä¾‹
    valid_examples = query_entry["similar_commits"]
    
    sorted_examples = sorted(
        valid_examples,
        key=lambda x: x["similarity_score"],
        reverse=True
    )[:MAX_EXAMPLES][::-1]  # ä¿è¯æŒ‰ç›¸ä¼¼æ€§å‡åºæ’åˆ—
    
    examples = []
    for ex in sorted_examples:
        if (ex_data := load_example_data(ex)):
            examples.append({
                "similarity": ex["similarity_score"],
                "before": ex_data['before'],
                "diff": ex_data['diff']
            })
    
    example_text = ""
    for idx, ex in enumerate(examples):
        example_text += (
            f"==== Example {idx+1} (Similarity: {ex['similarity']:.1f}) ====\n"
            "Original Function:\n"
            f"{ex['before']}\n\n"
            "Optimization Changes:\n"
            f"```diff\n{ex['diff']}\n```\n"
            "------------------------\n\n"
        )
    
    return example_text.strip()

def generate_prompt(target_function, examples_section):
    """Generate optimized English prompt"""
    return f"""Optimize the following C/C++ function based on the reference examples. Requirements:
1. Maintain EXACT functionality
2. Place your complete optimized function in a single code block using triple backticks (```)
3. You may include explanations of your optimization approach, but ensure there is only ONE code block in your reply
Reference optimization examples (ordered by ascending similarity):
{examples_section if examples_section else "No relevant examples"}
Function to optimize:
```cpp
{target_function}
```
Return your optimized function with explanations if needed, but make sure to include exactly ONE code block with the complete optimized code."""

def optimize_function_single_attempt(client, repo_name, commit_hash, similarity_data, current_model, model_name, attempt_number):
    """
    å•æ¬¡è°ƒç”¨LLMè¿›è¡Œä»£ç ä¼˜åŒ–
    """
    # æ„å»ºå­˜å‚¨è·¯å¾„ - ä¿®æ”¹ä¸ºä½¿ç”¨æ¨¡å‹åä½œä¸ºå­ç›®å½•
    commit_dir = COMMIT_DIR.format(repo=repo_name, commit=commit_hash)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œä»¥æ¨¡å‹åç§°ä½œä¸ºå­æ–‡ä»¶å¤¹
    output_dir = os.path.join(commit_dir, OUTPUT_DIR, current_model)
    os.makedirs(output_dir, exist_ok=True)
    
    # æ„å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨æ•°å­—ä½œä¸ºæ–‡ä»¶å
    output_path = os.path.join(output_dir, f"{attempt_number}.txt")
    
    # å¦‚æœç»“æœæ–‡ä»¶å·²å­˜åœ¨ä¸”ä¸å…è®¸é‡æ–°ç”Ÿæˆï¼Œåˆ™è·³è¿‡è¯¥æäº¤
    if os.path.exists(output_path) and not REGENERATE_EXISTING:
        return {
            "status": "skipped",
            "message": f"Skipping existing commit: {commit_hash} (model: {current_model}, attempt: {attempt_number})",
            "output_path": output_path,
            "commit_hash": commit_hash
        }
    
    # è¯»å–å¾…ä¼˜åŒ–çš„åŸå§‹å‡½æ•°
    before_func_path = os.path.join(commit_dir, 'before_func.txt')
    if not os.path.exists(before_func_path):
        return {
            "status": "error",
            "message": f"Missing source file: {before_func_path}",
            "output_path": None,
            "commit_hash": commit_hash
        }
    
    try:
        with open(before_func_path, 'r', encoding='utf-8') as f:
            target_function = f.read().strip()
    except Exception as e:
        return {
            "status": "error",
            "message": f"Failed to read target function for commit {commit_hash}: {str(e)}",
            "output_path": None,
            "commit_hash": commit_hash
        }
    
    # æ„å»º promptï¼šåŒ…æ‹¬ç¤ºä¾‹éƒ¨åˆ†ä¸ç›®æ ‡å‡½æ•°
    examples_section = build_examples_section(commit_hash, repo_name, similarity_data)
    full_prompt = generate_prompt(target_function, examples_section)
    
    messages = [{"role": "user", "content": full_prompt}]
    
    # å°è¯•è°ƒç”¨LLMï¼Œå¹¶åœ¨å¿…è¦æ—¶é‡è¯•
    for retry_count in range(MAX_RETRY_ATTEMPTS):
        try:
            if current_model in ["o1-mini", "o3-mini"]:
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    # temperature=0,
                    # max_tokens=8192
                )
            else:
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    temperature=0,
                    max_tokens=8192
                )
            
            response_content = response.choices[0].message.content.strip()
            
            # æå–ä»£ç å—
            code_blocks = extract_code_blocks(response_content)
            
            # æ£€æŸ¥ä»£ç å—æ•°é‡
            if len(code_blocks) == 0:
                if retry_count < MAX_RETRY_ATTEMPTS - 1:
                    messages.append({"role": "assistant", "content": response_content})
                    messages.append({
                        "role": "user", 
                        "content": "You didn't include a code block with your optimized function. Please provide your complete optimized function in a single markdown code block using triple backticks (```)."
                    })
                    continue
                else:
                    return {
                        "status": "error",
                        "message": f"Error: Commit {commit_hash}, attempt {attempt_number} failed to generate code block after {MAX_RETRY_ATTEMPTS} retries.",
                        "output_path": None,
                        "commit_hash": commit_hash
                    }
            
            elif len(code_blocks) > 1:
                if retry_count < MAX_RETRY_ATTEMPTS - 1:
                    messages.append({"role": "assistant", "content": response_content})
                    messages.append({
                        "role": "user", 
                        "content": "You included multiple code blocks. Please provide only ONE code block with your complete optimized function."
                    })
                    continue
                else:
                    return {
                        "status": "error",
                        "message": f"Error: Commit {commit_hash}, attempt {attempt_number} generated multiple code blocks after {MAX_RETRY_ATTEMPTS} retries.",
                        "output_path": None,
                        "commit_hash": commit_hash
                    }
            
            # è·å–æå–çš„ä»£ç 
            optimized_code = code_blocks[0]
            
            # ä¿å­˜ä¼˜åŒ–ç»“æœè‡³æ–‡ä»¶
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(optimized_code)
                status_text = "Regenerated" if os.path.exists(output_path) else "Created"
                return {
                    "status": "success",
                    "message": f"{status_text} optimization for commit {commit_hash} (model: {current_model}, attempt: {attempt_number})",
                    "output_path": output_path,
                    "commit_hash": commit_hash
                }
            except Exception as e:
                return {
                    "status": "error",
                    "message": f"Failed to write output file for commit {commit_hash}: {str(e)}",
                    "output_path": None,
                    "commit_hash": commit_hash
                }
            
        except Exception as e:
            if retry_count < MAX_RETRY_ATTEMPTS - 1:
                continue
            return {
                "status": "error",
                "message": f"API request failed for commit {commit_hash} (model: {current_model}, attempt: {attempt_number}, retry: {retry_count+1}): {str(e)}",
                "output_path": None,
                "commit_hash": commit_hash
            }
    
    return {
        "status": "error",
        "message": f"Error: All optimization attempts failed for commit {commit_hash}, attempt {attempt_number}",
        "output_path": None,
        "commit_hash": commit_hash
    }

def optimize_function(client, repo_name, commit_hash, similarity_data, current_model, model_name):
    """
    å¯¹å‡½æ•°è¿›è¡Œå¤šæ¬¡ä¼˜åŒ–ï¼Œæ¯æ¬¡äº§ç”Ÿä¸€ä¸ªå•ç‹¬çš„ç»“æœæ–‡ä»¶
    """
    results = []
    
    for attempt in range(1, OPTIMIZATION_ATTEMPTS + 1):
        result = optimize_function_single_attempt(
            client, repo_name, commit_hash, similarity_data, current_model, model_name, attempt
        )
        results.append(result)
    
    return results

def process_commit(args):
    """ç”¨äºå¹¶è¡Œå¤„ç†çš„åŒ…è£…å‡½æ•°"""
    client, repo_name, commit_obj, similarity_data, current_model, model_name = args
    commit_hash = commit_obj.get("hash")
    if not commit_hash:
        return [{
            "status": "error", 
            "message": "Warning: commit object missing 'hash' field, skipping.",
            "output_path": None,
            "commit_hash": None
        }]
    
    # åœ¨ commit_similarity.json ä¸­æŸ¥æ‰¾å¯¹åº”çš„è®°å½•
    query_entry = next(
        (item for item in similarity_data
         if item["query_commit"]["commit_hash"] == commit_hash \
            and item["query_commit"]["repository_name"] == repo_name),
        None
    )
    if not query_entry:
        return [{
            "status": "error",
            "message": f"Commit {commit_hash} not found in similarity data, skipping.",
            "output_path": None,
            "commit_hash": commit_hash
        }]
    
    return optimize_function(client, repo_name, commit_hash, similarity_data, current_model, model_name)

def print_result_with_color(result):
    """æ ¼å¼åŒ–è¾“å‡ºç»“æœï¼Œå¸¦æœ‰é¢œè‰²æ ‡è®°"""
    status = result["status"]
    message = result["message"]
    output_path = result["output_path"]
    commit_hash = result["commit_hash"]
    
    if status == "success":
        status_color = Fore.GREEN
        path_info = f"\n  ğŸ“ Result saved to: {output_path}"
    elif status == "skipped":
        status_color = Fore.YELLOW
        path_info = f"\n  ğŸ“ Existing file path: {output_path}"
    else:  # error
        status_color = Fore.RED
        path_info = ""
    
    print(f"{status_color}[{status.upper()}]{Style.RESET_ALL} {message}{path_info}")

def summarize_results(results_by_commit, model):
    """ç”Ÿæˆå¹¶æ‰“å°ç»“æœæ‘˜è¦"""
    success_count = 0
    skipped_count = 0
    error_count = 0
    total_attempts = 0
    
    for commit_hash, attempts in results_by_commit.items():
        for result in attempts:
            total_attempts += 1
            if result["status"] == "success":
                success_count += 1
            elif result["status"] == "skipped":
                skipped_count += 1
            else:  # error
                error_count += 1
    
    success_rate = (success_count / total_attempts * 100) if total_attempts > 0 else 0
    
    print("\n" + "=" * 70)
    print(f"SUMMARY FOR MODEL: {model}")
    print("=" * 70)
    print(f"Total commits processed: {len(results_by_commit)}")
    print(f"Total optimization attempts: {total_attempts}")
    print(f"{Fore.GREEN}Successful optimizations: {success_count} ({success_rate:.1f}%){Style.RESET_ALL}")
    print(f"{Fore.YELLOW}Skipped optimizations: {skipped_count}{Style.RESET_ALL}")
    print(f"{Fore.RED}Failed optimizations: {error_count}{Style.RESET_ALL}")
    print("=" * 70 + "\n")

def main():
    repo_name = "rocksdb"
    
    try:
        with open(similarity_path, 'r', encoding='utf-8') as f:
            similarity_data = json.load(f)
    except Exception as e:
        print(f"{Fore.RED}Failed to load similarity data: {str(e)}{Style.RESET_ALL}")
        sys.exit(1)
    
    # åŠ è½½éœ€è¦ä¼˜åŒ–çš„ commit åˆ—è¡¨ï¼Œæ–‡ä»¶ä¸­æ¯ä¸ªå…ƒç´ ä¸ºä¸€ä¸ª commit å¯¹è±¡ï¼Œå…¶ä¸­å¿…é¡»åŒ…å« "hash" å­—æ®µ
    try:
        with open(COMMIT_LIST_FILE, 'r', encoding='utf-8') as f:
            commit_list = json.load(f)
    except Exception as e:
        print(f"{Fore.RED}Failed to load commit list from {COMMIT_LIST_FILE}: {str(e)}{Style.RESET_ALL}")
        sys.exit(1)
    
    print(f"Loaded {len(commit_list)} commits to process")
    print(f"Will optimize each function {OPTIMIZATION_ATTEMPTS} times with up to {MAX_RETRY_ATTEMPTS} retries per attempt")
    print(f"Results will be saved to <commit_hash>/{OUTPUT_DIR}/<model_name> directory for each commit")
    
    # é’ˆå¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œå¤„ç†
    for current_model in MODELS:
        print(f"\n{Fore.CYAN}=================== Processing with model {current_model} ==================={Style.RESET_ALL}")
        
        try:
            client, model_name = get_client_and_model_info(current_model)
        except Exception as e:
            print(f"{Fore.RED}Failed to initialize client for model {current_model}: {e}{Style.RESET_ALL}")
            continue
        
        # å‡†å¤‡å¹¶è¡Œå¤„ç†çš„å‚æ•°
        args_list = [(client, repo_name, commit_obj, similarity_data, current_model, model_name) 
                     for commit_obj in commit_list]
        
        # ä½¿ç”¨è¿›åº¦æ¡å’Œå¹¶è¡Œæ‰§è¡Œ
        results_all = []
        with concurrent.futures.ThreadPoolExecutor() as executor:
            results_all = list(tqdm(
                executor.map(process_commit, args_list),
                total=len(args_list),
                desc=f"Optimization Progress ({current_model})"
            ))
        
        # ç»„ç»‡ç»“æœæŒ‰æäº¤åˆ†ç»„
        results_by_commit = {}
        for commit_results in results_all:
            for result in commit_results:
                commit_hash = result["commit_hash"]
                if commit_hash:
                    if commit_hash not in results_by_commit:
                        results_by_commit[commit_hash] = []
                    results_by_commit[commit_hash].append(result)
        
        # è¾“å‡ºè¯¦ç»†ç»“æœ
        print(f"\n{Fore.CYAN}Detailed Results for {current_model}:{Style.RESET_ALL}")
        for commit_hash, results in results_by_commit.items():
            print(f"\n{Fore.BLUE}Commit: {commit_hash}:{Style.RESET_ALL}")
            for result in results:
                print_result_with_color(result)
        
        # æ‰“å°æ‘˜è¦
        summarize_results(results_by_commit, current_model)

if __name__ == "__main__":
    main()
